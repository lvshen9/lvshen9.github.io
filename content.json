{"meta":{"title":"Lvshen's Blog","subtitle":"This is My World","description":"学如逆水行舟，不进则退","author":"我的技术小房间","url":"http://lvshen9.gitee.io"},"pages":[{"title":"","date":"2018-01-09T01:42:44.853Z","updated":"2018-01-09T01:42:44.853Z","comments":true,"path":"baidu_verify_0imziD1hc9.html","permalink":"http://lvshen9.gitee.io/baidu_verify_0imziD1hc9.html","excerpt":"","text":"0imziD1hc9"},{"title":"","date":"2017-08-29T06:09:42.572Z","updated":"2017-08-29T03:16:13.724Z","comments":true,"path":"google5e5c17e06508829d.html","permalink":"http://lvshen9.gitee.io/google5e5c17e06508829d.html","excerpt":"","text":"google-site-verification: google5e5c17e06508829d.html"},{"title":"","date":"2017-08-22T04:11:36.501Z","updated":"2017-08-22T04:11:36.501Z","comments":true,"path":"404.html","permalink":"http://lvshen9.gitee.io/404.html","excerpt":"","text":"404 *{margin:0;padding:0;outline:none;font-family:\\5FAE\\8F6F\\96C5\\9ED1,宋体;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-khtml-user-select:none;user-select:none;cursor:default;font-weight:lighter;} .center{margin:0 auto;} .whole{width:100%;height:100%;line-height:100%;position:fixed;bottom:0;left:0;z-index:-1000;overflow:hidden;} .whole img{width:100%;height:100%;} .mask{width:100%;height:100%;position:absolute;top:0;left:0;background:#000;opacity:0.6;filter:alpha(opacity=60);} .b{width:100%;text-align:center;height:400px;position:absolute;top:50%;margin-top:-230px}.a{width:150px;height:50px;margin-top:30px}.a a{display:block;float:left;width:150px;height:50px;background:#fff;text-align:center;line-height:50px;font-size:18px;border-radius:25px;color:#333}.a a:hover{color:#000;box-shadow:#fff 0 0 20px} p{color:#fff;margin-top:40px;font-size:24px;} #num{margin:0 5px;font-weight:bold;} var num=4; function redirect(){ num--; document.getElementById(\"num\").innerHTML=num; if(num"},{"title":"categories","date":"2017-08-22T04:59:14.000Z","updated":"2017-08-22T05:01:00.239Z","comments":false,"path":"categories/index.html","permalink":"http://lvshen9.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2019-06-30T03:31:55.850Z","updated":"2019-06-30T03:31:55.850Z","comments":true,"path":"about/index.html","permalink":"http://lvshen9.gitee.io/about/index.html","excerpt":"","text":"关于我 愿上帝赐我平静，去忍受我必须忍受的事；愿上帝赐我勇气，去改变我可以改变的事。——请上帝赐我智慧，让我分辨两者之间的不同。 92年生，15年毕业，屌丝程序员一枚，常用网名：Lvshen9。 联系邮箱：wujialv98@126.com github: @lvshen9 微博：@野良神之歌 我的专长 自我评价我对工作的态度： 第一，要高效完成自己的本职工作。第二，要在完成的基础上寻找完美。第三,要在完美的基础上，与其他同事 互相交流学习,互相提升。工作是一种生活方式,不是一份养家糊口的差事。 我怎样克服困难：不用百度是第一原则,在遇到技术问题时我往往会去Google、Stack over flow上寻找答案。但通常很多问题 并不一定已经被人解决,所以熟练地阅读源码、在手册、规范甚至 REPL的环境自己做实验才是最终解决问题的办法。相信事实的结果，自己动手去做。 怎样保持自己的视野：我一直认为软件开发中视野极其重要，除了在 CSDN 上关注业界大牛，Github 也是每周必刷。 另外 Podcast、Hacker News、Reddit 以及TechRadar 也是重要的一手资料。保持开阔视野才能找到更酷的解决方案。 我的优势： 热爱技术、自学能力强,有良好的自我认知。全面的技能树与开阔的视野，良好的心态、情商与沟通能力。 我的劣势： 非科班出身没有科班同学对算法的熟练掌握，但我决定死磕技术，弥补不足。 关于本站开通于2017年8月12日，问题还很多，仍在不断完善中。本站所有文章除非特别说明均属原创，转载需保留署名和原文链接。 本站使用JavaScript开发，基于Hexo+Node.js+Gitee，部署于Gitee。 本站所有博客纯属个人笔记，错误、描述不到位、理解片面等等情况在所难免，如有不正确的地方欢迎评论中指正，我会及时更正。因为博客建立的太晚，很多以前写在各个角落的笔记、博客被我重新整理发表在这里，所以你会看到很多很基础很入门的文章。"},{"title":"","date":"2018-05-29T12:44:56.282Z","updated":"2018-05-29T12:44:56.282Z","comments":true,"path":"collection/index.html","permalink":"http://lvshen9.gitee.io/collection/index.html","excerpt":"","text":"人们对于“美”，都有着超乎自己想象的执念。 Website Hello，这是一个收藏一些漂亮网站的页面。还有这是我的博客： Lvshen’s Blog 写代码的猴子 冷淡简洁风格 jsdatav.is fatesinger themeakina html5up Akina theme 淡腾 louie iacool TA4.cn 波浪 EndSkin Wordpress主题 tagDiv &amp; （报纸）NEWSMAG 漂亮的蒙层 漂亮的电影网站 SPOTLIGHT 萨利机长 humaan Philip Walton(Engineer @ Google) Just Good Themes Mirana wordpress DREAMFY 老酒街 BeSteve code123.cc Statamic Hover效果 http://archive.li/A7Ro2 Funny Links ibireme Red Blob Games Joe’s Blog tarikfayad 设计筆記 朱腾鹏（像素癖） CaiCai PHILANTHROPY 2016 tagDiv IGK nerds.company &amp; 404 Oops 404 A Developer Diary 图集 from Dribbble img from Dribbble from Dribbble from Dribbble"},{"title":"tags","date":"2017-08-22T04:59:01.000Z","updated":"2017-08-22T05:00:11.494Z","comments":true,"path":"tags/index.html","permalink":"http://lvshen9.gitee.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis进阶","slug":"1","date":"2020-04-08T11:31:09.000Z","updated":"2020-04-08T14:34:43.500Z","comments":true,"path":"2020/04/08/1/","link":"","permalink":"http://lvshen9.gitee.io/2020/04/08/1/","excerpt":"Redis为什么快？项目中会用到redis，因为redis可做缓存，并发每秒能处理10w条数据。但你知道为什么redis存取那么快么，你可能会说redis基于内存，基于K-V存储，单线程….。等等，为什么单线程反而会快了呢？ 其实Redis是基于NIO的多路复用模型。Windows环境下是select的多路复用，Linux环境下是epoll的多路复用。可能有人会问，什么是多路复用。","text":"Redis为什么快？项目中会用到redis，因为redis可做缓存，并发每秒能处理10w条数据。但你知道为什么redis存取那么快么，你可能会说redis基于内存，基于K-V存储，单线程….。等等，为什么单线程反而会快了呢？ 其实Redis是基于NIO的多路复用模型。Windows环境下是select的多路复用，Linux环境下是epoll的多路复用。可能有人会问，什么是多路复用。 多路复用简单来说，Redis将数据的读取交给内核去做 多路复用 redis会将n个客户端连接放入一个集合中（这里就是一个进程），然后再调用epoll（Windows下没有这个函数）或者select函数将集合放入操作系统内核kernel中进行处理，通过事件驱动，内核会获取有数据的连接并循环读取，时间复杂度为O(1)。 如果你问什么是NIO？你需要额外的补充NIO的知识。 Redis value结构常见5种结构 value结构 使用场景String比如微信公众号统计阅读数量就可以使用value为String 12INCR article:readcount:&#123;文章id&#125;GET article:readcount:&#123;文章id&#125; 可以做分布式系统全局的序列号 1INCRBY orderId 1000 //一次性生成1000个id,可以存入队列中，按需获取 tips: 可以用setnx命令 + 超时时间做 分布式锁 ，github上有关于我的redis分布式锁的项目：dislock 除了redis可以做分布式锁外，zookeeper也可以做分布式锁(基于节点名唯一，watcher机制)，相比于redis，zookeeper在最终一致性上强于redis，但性能会弱于redis。github分布式锁项目：distributelock Bitmap可以统计用户 任意时间窗口登录了几次 bitmap是一个二进制的数组，长度不限（当长度为20亿时，占用内存200多MB）。数组内的值为0或1。如上图，用户sean第4天登录，则为 10001 第9天登录为 1000100001 以此类推。最后一行为统计第一个索引到最后一个索引之间值为1的次数。 我们还可以用bitmap统计活跃用户数 123456789101112131415#第一天7号用户登录一次127.0.0.1:6379&gt; setbit 20200101 7 1( integer ) 0#第一天3号用户登录一次127.0.0.1:6379&gt;set bit 20200101 3 1( integer ) 0#第二天3号用户登录一次127.0.0.1:6379&gt; setbit 20200102 3 1( integer ) 0#或运算127.0.0.1:6379&gt; BITOP or res 20200101 20200102#统计活跃用户127.0.0.1:6379&gt; BITCOUNT res( integer ) 22人 tips：大名鼎鼎的布隆过滤器就可以用bitmap是实现 Hashhash可以存购物车相关信息 如上图：以用户id为key，商品id为filed，商品数量为value存储。可以展示购物车信息。 123456789101112131415161718192021222324127.0.0.1:6379&gt; hset cart:1001 10088 1(integer) 1127.0.0.1:6379&gt; hincrby cart:1001 10088 1(integer)2127.0.0.1:6379&gt; hget cart:1001 10088\"2\"127.0.0.1:6379&gt; hset cart:1001 10088 1(integer)0127.0.0.1:6379&gt; hset cart:1001 20088 1(integer) 1127.0.0.1:6379&gt; hlen cart:1001(integer) 2127.0.0.1:6379&gt; hdel cart:1001 20088(integer) 1127.0.0.1:6379&gt; hlen cart:1001(integer)1127.0.0.1:6379&gt; hset cart:1001 30088 1(integer) 1127.0.0.1:6379&gt; hgetall cart:10011)\"10088\"2)\"1\"3)\"30088\"I4)\"1\"127.0.0.1:6379&gt; hash结构有以下优缺点： 优点 1)同类数据归类整合储存，方便数据管理2)相比string操作消耗内存与cpu更小3)相比string储存更节省空间 缺点 1)过期功能不能使用在field上，只能用在key上2)Redis集群架构下不适合大规模使用 总的来说hash可用于存储 详情页聚合，数据来自不同的库的聚合。 Listlist可用于作队列，栈等数据结构 微博消息和公众号消息场景 1234567lvshen关注了MacTalk,备胎说车等大V1)MacTalk发微博，消息ID为10018LPUSH msg:(lvshen-ID&#125; 100182)备胎说车发微博，消息ID为10086LPUSH msg:(lvshen-ID) 100863)查看最新微博消息LRANGE msg:(lvshen-ID&#125; 0 5 list常用操作 1234567LPUSH key value [value ...] //将一个或多个值value插入到key列表的表头（最左边）RPUSH key value [value ...] //将一个或多个值value插入到key列表的表尾（最右边）LPOP key //移除并返回key列表的头元素RPOP key //移除并返回key列表的尾元素LRANGE key start stop //返回列表key中指定区间内的元素，区间以偏移量start和stop指定BLPOP key [key ...] timeout //从key列表表头弹出一个元素，若列表中没有元素，阻塞等待timeout秒，如果timeout=0,一直阻塞等待BRPOP key [key ...] timeout //从key列表表尾弹出一元素，若列表中没有元素，阻塞等待timeout秒，如果timeout=0,一直阻塞等待 Setset可以用作微信抽奖小程序 1234561)点击【参与抽奖】加入集合SADD key &#123;userlD&#125;2)查看参与抽奖所有用户SMEMBERS key3)抽取count名中奖者SRANDMEMBER key [count] /SPOP key [count] 也可以用于微信微博点赞 123456789101)点赞SADD like:&#123;消息ID&#125; &#123;用户ID&#125;2)取消点赞SREM like:&#123;消息ID&#125; &#123;用户ID&#125;3)检查用户是否点过赞SISMEMBER like:&#123;消息ID&#125; &#123;用户ID&#125;4)获取点赞的用户列表SMEMBERS like:&#123;消息ID&#125;5)获取点赞用户数SCARD like:&#123;消息ID&#125; 可以通过集合操作实现微博微信关注模型 123456789101112131415161718192021221)Lvshen(我)关注的人：#lvshenSet-&gt; &#123;A, B, C&#125;192.168.42.128:6379&gt; sadd lvshenSet A B C(integer) 32)A关注的人：I#aSet--&gt; &#123;lvshen, B, C, guojia&#125;192.168.42.128:6379&gt; sadd aSet lvshen B C guojia(integer) 43)B关注的人：#bSet-&gt; &#123;lvshen, A, guojia, C, xunyu)192.168.42.128:6379&gt; sadd bSet lvshen A guojia C xunyu(integer) 54)我和A共同关注：SINTER lvshenSet aSet--&gt; &#123;B, C&#125;5)我关注的人也关注他（A）:SISMEMBER bSet ASISMEMBER cSet A6)我可能认识的人：SDIFF aSet lvshenSet--&gt; (lvshen, guojia) set常用操作 12345678910111213141516//Set常用操作SADD key member [member...] //往集合key中存入元素，元素存在则忽略，若key不存在则新建SREM key member [member...] //从集合key中删除元素SMEMBERS key //获取集合key中所有元素SCARD key //获取集合key的元素个数SISMEMBER key member //判断member元素是否存在于集合key中SRANDMEMBER key [count] //从集合key中选出count个元素，元素不从key中删除SPOP key [count] //从集合key中选出count个元素，元素从key中删除//Set运算操作SINTER key [key...] //交集运算SINTERSTORE destination key [key..] //将交集结果存入新集合destination中SUNION key [key..] //并集运算SUNIONSTORE destination key [key...] //将并集结果存入新集合destination中SDIFF key [key...] //差集运算SDIFFSTORE destination key [key...] //将差集结果存入新集合destination中 总的来说set可以用于去重，抽奖等操作 Zset zset为有序的去重集合，可用于实现排行榜 总结：zset可以用于排行榜，翻页等场景。zset可以用于作延迟队列，score为延迟的时间点，获取时顺序获取端口的值，如果当前时间戳等于score则可取出。 zset的底层数据结构为跳表，一种特殊的链表，同时查找和增删都很优秀，具体知识可以参考文章: Redis—跳跃表 GEO redis还可以支持地理位置查询，适用与LBS的开发 常用命令 Stream Stream 5.0版本开始的新结构“流”。使用场景：消费者生产者场景（类似MQ) 常用命令 示例 1234567891011121314151617181920212223242526272829303132333435363738127.0.0.1:6379&gt; xadd room:msg:1001 * userId tony content hello\"1568106742941-0\"127.0.0.1:6379&gt; xadd room:msg:1001 * userId tony content hello2\"1568106753764-0\"127.0.0.1:6379&gt; type room:msg:1001stream127.0.0.1:6379&gt; xlen room:msg:1001(integer)2127.0.0.1:6379&gt; xrange room:msg:1001 - +1) 1)\"1568106742941-0\" 2) 1)\"userId\" 2)\"tony\" 3)\"content\" 4)\"hello\"2) 1)\"1568106753764-0\" 2) 1)\"userId\" 2)\"tony\" 3)\"content\" 4)\"hello2\"127.0.0.1:6379&gt;127.0.0.1:6379&gt; xread count streams room:msg:1001 01) 1)\"room:msg:1001\" 2) 1) 1)\"1568106742941-0\" 2) 1)\"userId\" 2)\"tony\" 3)\"content\" 4)\"hello\" 2) 1)\"1568106753764-0\" 2) 1)\"userId\" 2)\"tony\" 3)\"content\" 4)\"hello2\"127.0.0.1:6379&gt; xread count 2 streams room:msg:1001 $(nil)127.0.0.1:6379&gt; xread count 2 streams room:msg:1001 $(nil)127.0.0.1:6379&gt; xread count 2 block 10000 streams room:msg:1001 $ 现在redis普遍用的都是3.x，list也可用于消息队列。所以很少有人用stream。 Redis集群有关集群的搭建可以参考：Redis3.0集群搭建 关于集群关心的问题1、增加了slot槽的计算，是不是比单机性能差？共16384个槽，slots槽计算方式公开的，HASH_SLOT=CRC16(key)mod16384。为了避免每次都需要服务器计算重定向，优秀的java客户端都实现了本地计算，并且缓存服务器slots分配，有变动时再更新本地内容，从而避免了多次重定向带来的性能损耗。 2、redis集群大小，到底可以装多少数据？理论是可以做到16384个槽，每个槽对应一个实例，但是redis官方建议是最大1000个实例。存储足够大了。 3、ask和moved重定向的区别重定向包括两种情况 a.若确定slot不属于当前节点，redis会返回moved。 b.若当前redis节点正在处理slot迁移，则代表此处请求对应的key暂时不在此节点，返回ask,告诉客户端本次请求重定向。 4、数据倾斜和访问倾斜的问题倾斜导致集群中部分节点数据多，压力大。解决方案分为前期和后期：前期是业务层面提前预测，哪些key是热点，在设计的过程中规避。后期是slot迁移，尽量将压力分摊（slot调整有自动rebalance、reshard和手动）。 5、读写分离redis cluster默认所有从节点上的读写，都会重定向到key对接槽的主节点上。可以通过readonly设置当前连接可读，通过readwrite取消当前连接的可读状态。注意：主从节点依然存在数据不一致的问题 Redis可用性通过主从集群实现高可用，slave节点向master节点发送syn请求同步命令。master节点会通过bgsave命令创建rdb文件将数据以二进制形式存储其中，然后将文件分发给slave节点。 tips: 1.bgsave是创建了子线程工作，不影响主线程; 2.主从结构以线性链表部署，不要图状结构部署 Redis缓存失效问题缓存一致性模型查询信息时，先从缓存中获取信息；缓存中没有则从数据库中获取；将值塞到缓存。 缓存击穿查询一个不存在的key，查询会直接落到数据库上。如果黑客用不存在的key查询，很可能搞垮数据库。 解决思路：查询之前先判断目标数据是否存在，不存在的直接忽略。将流量拦截于缓存和数据库之前。 这里使用布隆过滤器： 布隆过滤器 demo示例： 12345678910111213141516171819202122232425@Testpublic void testBit() &#123; String userId = \"1001\"; int hasValue = Math.abs(userId.hashCode()); //key 做hash运算 long index = (long) (hasValue % Math.pow(2, 32)); //hash值与数组长度取模 Boolean bloomFilter = redisTemplate.opsForValue().setBit(\"user_bloom_filter\", index, true); log.info(\"user_bloom_filter:&#123;&#125;\",bloomFilter);&#125;//缓存击穿解决方法@Testpublic void testUnEffactiveCache() &#123; String userId = \"1001\"; //1.系统初始化是init 布隆过滤器，将所有数据存于redis bitmap中 //2.查询是先做判断，该key是否存在与redis中 int hasValue = Math.abs(userId.hashCode()); //key 做hash运算 long index = (long) (hasValue % Math.pow(2, 32)); //hash值与数组长度取模 Boolean result = redisTemplate.opsForValue().getBit(\"user_bloom_filter\", index); if (!result) &#123; log.info(\"该userId在数据库中不存在：&#123;&#125;\",userId); //return null; &#125; //3.从缓存中获取 //4.缓存中没有，从数据库中获取，并存放于redis中&#125; 布隆过滤器优缺点优点： 内存空间占用少 缺点： 布隆过滤器需要不断维护，带来新的工作布隆过滤器并不能精准过滤。(布隆过滤器判定不存在，100%不存在，判断为存在，则可能不存在的。）理论上Hash计算值是有碰撞的（不同的内容hash计算出同样的值）,导致不存在的元素可能会被判断为存在 为了减少hash碰撞，可以将key用几个hash算法获取index值。然而布隆过滤器并非需要拦截所有的请求，只需要将缓存击穿控制在一定的量即可。 缓存雪崩当大量的key在统一时间过期，而这时又有大量的访问key，请求落到数据上，导致数据库崩溃。 解决办法： Semaphore信号量限流J.U.C包重要的并发编程工具类，又称“信号量”，控制多个线程争抢许可。核心方法acquire:获取一个许可，如果没有就等待，release:释放一个许可。典型场景1、代码并发处理限流； 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.lvshen.demo.semaphore;import java.util.Random;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.Semaphore;import java.util.concurrent.TimeUnit;/** * Description:信号量机制 * * @author Lvshen * @version 1.0 * @date: 2020/3/21 20:34 * @since JDK 1.8 */public class SemaphoreDemo &#123; public static void main(String[] args) &#123; SemaphoreDemo semaphoreDemo = new SemaphoreDemo(); int count = 9; //数量 //循环屏障 CyclicBarrier cyclicBarrier = new CyclicBarrier(count); Semaphore semaphore = new Semaphore(5);//限制请求数量 for (int i = 0; i &lt; count; i++) &#123; String vipNo = \"vip-00\" + i; new Thread(() -&gt; &#123; try &#123; cyclicBarrier.await(); //semaphore.acquire();//获取令牌 boolean tryAcquire = semaphore.tryAcquire(3000L, TimeUnit.MILLISECONDS); if (!tryAcquire) &#123; System.out.println(\"获取令牌失败：\" + vipNo); &#125; //执行操作逻辑 System.out.println(\"当前线程：\" + Thread.currentThread().getName()); semaphoreDemo.service(vipNo); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125;).start(); &#125; &#125; // 限流控制5个线程同时访问 public void service(String vipNo) throws InterruptedException &#123; System.out.println(\"楼上出来迎接贵宾一位，贵宾编号\" + vipNo + \",...\"); Thread.sleep(new Random().nextInt(3000)); System.out.println(\"欢送贵宾出门，贵宾编号\" + vipNo); &#125;&#125; 容错降级如果令牌被抢完（并发时还没来的及释放令牌），线程执行到这里时可以返回一个异常码。 redis集群方案还有一种可能，如果哦redis key来不及删除，由于内存淘汰策略。会删除一些key，导致缓存失效。集群方案可以解决内存不足问题。 高并发下缓存不一致问题根据缓存一致性模型： 查询信息时，a.1:先从缓存中获取信息；a.2:缓存中没有则从数据库中获取；a.3:将值塞到缓存。 更新数据时，b.1:更新数据库；b.2:删除缓存 如果查询和更新是两个线程，由于以上执行并非原子性，b.2可能会先于a.3执行。导致redis里面数据和数据库数据不一致。 解决方法可以先将数据预热到redis中，去掉查询时存入redis的操作。再部署一个mysql服务，收集mysql日志。数据库数据发生变化的时候，通知缓存维护程序，把变化后的数据更到到缓存里面。 关于数据库监听，阿里有一套开源框架 Canal ,可以监听mysql的数据变化。 Redis持久化1.RDB快照：将数据以二进制形式写到文件中 2.AOF:将写命令以追加的形式写入到aof文件中 关于aof有下面几种形式： a. redis没操作一次，写一次文件。优点时保证完整性，缺点是一致性会下降 b. 每秒钟将写命令写入到一个buffer中，当buffer中存满一定的数据，再写入到文件中（aof默认采用此种写入） c.每次操作将写命令存入buffer中，之后再写入文件中 使用默认是使用rdb恢复数据，如果开启aof，重启之后会加载aof文件恢复。当然生产环境上是混合使用。比如8点之前我使用rdb恢复，8点之后我是用aof恢复。 欢迎收藏我的Blog:Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://lvshen9.gitee.io/tags/Redis/"},{"name":"缓存","slug":"缓存","permalink":"http://lvshen9.gitee.io/tags/缓存/"}]},{"title":"我所用到的Java8-续","slug":"1","date":"2019-08-16T11:16:22.000Z","updated":"2020-04-08T03:42:22.916Z","comments":true,"path":"2019/08/16/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/08/16/1/","excerpt":"工作之余，总结了下Java8的相关运用，主要是关于Stream流的。还有一些工作总结笔记。 Java8","text":"工作之余，总结了下Java8的相关运用，主要是关于Stream流的。还有一些工作总结笔记。 Java8 Stream流操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//map集合获取value 获取新方式map.getOrDefault(goodsId, 0L)default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue;&#125;//flatMap使用List&lt;OrderSetDetail&gt; setDetails = order.getDetails().stream() .filter(x -&gt; CollectionUtils.isNotEmpty(x.getOrderSetDetails())) .flatMap(orderDetail -&gt; orderDetail.getOrderSetDetails().stream()) .collect(Collectors.toList());//distinctdistinct主要用来去重，以下代码片段使用 distinct 对元素进行去重：List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);numbers.stream().distinct().forEach(System.out::println);//3,2,7,5//groupingBy&amp;count分组统计Map&lt;String, Long&gt; collect = lists.stream().collect(Collectors .groupingBy(Student::getName, Collectors.counting()));//Java8 Map集合遍历 Map&lt;String, Integer&gt; updateStockMap = Optional.ofNullable(updateActivityStockList).orElseGet(ArrayList::new) .stream().collect(Collectors.groupingBy(UpdateActivityStock::getId, Collectors.reducing(Integer.valueOf(0), UpdateActivityStock::getStock, Integer::sum)));updateStockMap.forEach((id, stockNum) -&gt; &#123; ActivityStock oldStock = stockMap.get(id); if (oldStock != null) &#123; ActivityStock stock = new ActivityStock(); stock.setId(id); stock.setStock(stockNum); &#125;&#125;);//Java8 Map集合遍历2public class IterateHashMapExample &#123; public static void main(String[] args) &#123; Map &lt; Integer, String &gt; coursesMap = new HashMap &lt; Integer, String &gt; (); coursesMap.put(1, \"C\"); coursesMap.put(2, \"C++\"); coursesMap.put(3, \"Java\"); coursesMap.put(4, \"Spring Framework\"); coursesMap.put(5, \"Hibernate ORM framework\"); // 5. 使用 Stream API 遍历 HashMap coursesMap.entrySet().stream().forEach((entry) - &gt; &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue()); &#125;); &#125;&#125;// java8之后。上面的操作可以简化为一行，若key对应的value为空，会将第二个参数的返回值存入并返回Object key2 = map.computeIfAbsent(\"key\", k -&gt; new Object());//相当于： if(map.get(\"key\") == null) &#123; map.put(\"key\", new Object()); &#125; //List转Map(key去重)Map&lt;String, Student&gt; studentMap = list1.stream().collect(Collectors.toMap(Student::getName, value -&gt; value, (a1, a2) -&gt; a1)); Example条件查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public Activity getEffectiveActivity() &#123; Date now = new Date(); Example example = new Example(Activity.class); example.createCriteria().andEqualTo(\"isEnable\", SystemConstants.YES) .andEqualTo(\"activityType\", ActivityType.RUN) .andLessThanOrEqualTo(\"startDate\", now) .andGreaterThanOrEqualTo(\"endDate\", now); List&lt;Activity&gt; activities = listAllByExample(example); if(!activities.isEmpty()) &#123; return activities.get(0); &#125; else &#123; return null; &#125;&#125;//单一计算SpokesmanUser entity = new SpokesmanUser();entity.setParentId(userId);return this.dao.selectCount(entity);// 租户之间用户id保证唯一//多条件统计Example example = new Example(SpokesmanUser.class);Example.Criteria criteria = example.createCriteria();criteria.andEqualTo(\"parentId\", userId);criteria.andNotEqualTo(\"id\", excludChildId);return this.dao.selectCountByExample(example);// 租户之间用户id保证唯一//sql拼接if (query.getStartTime() != null &amp;&amp; query.getEndTime() != null &amp;&amp; query.getEndTime().after(query.getStartTime())) &#123; String startTime = DateTimeUtils.formatDateTime(query.getStartTime()); String endTime = DateTimeUtils.formatDateTime(query.getEndTime()); criteria.andCondition(String.format( \"((start_time &gt;= '%s' AND '%s' &gt;= start_time) OR ('%s' &gt;= start_time AND end_time &gt;= '%s') OR (end_time &gt;= '%s' AND '%s' &gt;= end_time))\", startTime, endTime, startTime, endTime, startTime, endTime));&#125;public List&lt;Entity&gt; listByCsId(String csId) &#123; Example example = new Example(Entity.class); example.createCriteria().andEqualTo(\"csId\", csId) .andEqualTo(\"isAssignCs\", SystemConstants.YES) .andEqualTo(\"isEndSession\", SystemConstants.NO); example.setOrderByClause(\"update_date DESC\"); return this.listAllByExample(example);&#125;//updateByExample使用ChatSession updateEntity = new ChatSession();updateEntity.setId(chatSession.getId());updateEntity.setServiceEndDate(new Date());updateEntity.setIsEndSession(SystemConstants.YES);updateEntity.setRemark(remark);updateEntity.setUpdateDate(new Date());updateEntity.setUpdateBy(operator);Example example = new Example(ChatSession.class);example.createCriteria().andEqualTo(\"id\", chatSession.getId()).andEqualTo(\"isEndSession\", SystemConstants.NO);int result = chatSessionRepository.updateByExample(updateEntity, example); 使用SecureRandom123456789101112131415由于java.util.Random类依赖于伪随机数生成器，因此该类和相关的java.lang.Math.random（）方法不应用于安全关键应用程序或保护敏感数据。 在这种情况下，应该使用依赖于加密强随机数生成器（RNG）的java.security.SecureRandom类。PRNG(伪随机数)：伪随机数， 计算机不能生成真正的随机数，而是通用一定的方法来模拟随机数。伪随机数有一部分遵守一定的规律，另一部分不遵守任何规律。RNG(随机数)：随机数是由“随机种子”产生的，“随机种子”是一个无符号整形数。反例：Random random = new Random(); // Questionable use of Randombyte bytes[] = new byte[20];random.nextBytes(bytes);正例：SecureRandom random = new SecureRandom(); byte bytes[] = new byte[20]; arthas命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253wget https://alibaba.github.io/arthas/arthas-boot.jar#启动示例java -jar arthas-boot.jar#获取trace调用链trace -j com.xxx.xxx.application.command.WechatLotteryRunService drawPrize '#cost &gt; 300'# 获取Servlet调用路径，并过滤掉JDK的函数trace -j javax.servlet.Servlet * &gt;&gt; test.log# 获取Filter调用路径，并过滤掉JDK的函数trace -j javax.servlet.Filter * &gt;&gt; test.logtrace -j org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient * &gt;&gt; test.logwatch org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient execute \"&#123;params,target,throwExp,returnObj&#125;\" -e -x 2 -b -s -n 2trace -j com.xxx.erp.action.autocalculate.WarehouseAction | com.xxx.erp.action.autocalculate.ExpressAction * '#cost &gt; 100'# 录制重放tt -t -n 2 org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient execute# 查看idtt -l# 详情tt -i 1000# 重放tt -i 1000 -p# 获取spring 容器tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethodtt -i 1000 -w 'target.getApplicationContext()'tt -i 1000 -w 'target.getApplicationContext().getBean(\"helloWorldService\").getHelloMessage()'ognl '#context=@com.yjh.mushroom.common.spring.SpringContextHolder@applicationContext, #context.getBean(\"idGenerator\").nextId()'# 快速排查Spring Boot应用404/401问题stack -E javax.servlet.http.HttpServletResponse sendError|setStatus params[0]==404# 800错误排查watch com.xxx.xxx.framework.spring.web.GlobalExceptionHandler handleUncatchedException params[2]#oms 异常排查watch com.xxx.xxx.main.order.web.OrderController * \"&#123;clazz.name, params[0],throwExp&#125;\" -e -x 2#oms调用eureka地址检查watch com.netflix.client.ClientRequest replaceUri \"params[0]\"#oms数据库连接排查watch com.mysql.jdbc.MysqlIO doHandshake \"&#123;params[0],params[1],params[2],target.host&#125;\" -b#oms订单任务判断watch com.xxx.oms.sync.domain.service.PlatformDomainEventService handlePendingEvent params[0] 自动化脚本模拟并发123cd wrk/wrk-master/wrk -t4 -c1000 -d60s -T10s --latency http://localhost:9016 --script=scripts/20190621/方法名.lua 时间差计算1long diffMinutes = ChronoUnit.MINUTES.between(Instant.now(), sendDate.toInstant()); Java8 Duration12Duration duration = Duration.ofDays(verifyDays * -1);Instant lastValidDate = Instant.now().plus(duration); 微信接口调用实例RestTemplate调用接口示列123456789101112131415161718JSONObject param = new JSONObject();param.put(\"type\", request.getData()); // 素材的类型，图片（image）、视频（video）、语音 （voice）、图文（news）param.put(\"offset\", (request.getPageNo() - 1) * request.getPageSize()); // 从全部素材的该偏移位置开始返回，0表示从第一个素材 返回param.put(\"count\", request.getPageSize()); // 返回素材的数量，取值在1到20之间RestTemplate restTemplate = new RestTemplate();restTemplate.getMessageConverters().set(1, new StringHttpMessageConverter(StandardCharsets.UTF_8)); // 处理中文乱码ResponseEntity&lt;String&gt; re = restTemplate.postForEntity(\"https://api.weixin.qq.com/cgi-bin/material/batchget_material?access_token=\" + token, param, String.class);if (HttpStatus.OK.equals(re.getStatusCode()) &amp;&amp; re.getBody() != null) &#123; JSONObject result = JSONObject.parseObject(re.getBody()); if (!result.containsKey(\"errcode\")) &#123; pageInfo.setTotal(result.getLong(\"total_count\")); List&lt;MpMaterialVO&gt; list = Lists.newArrayList(); JSONArray itemArr = result.getJSONArray(\"item\"); itemArr.forEach(item -&gt; list.add(new MpMaterialVO((JSONObject) item))); pageInfo.setList(list); return pageInfo; &#125;&#125; httpclient调用实例1234567891011121314151617181920212223242526272829public static String sendGet(String url, PayAccountBizCodeType bizCodeType) &#123; HttpGet httpGet = new HttpGet(url); httpGet.setHeader(\"Content-Type\", \"application/json;charset=UTF-8\"); httpGet.setHeader(\"Accept\", \"application/json\"); httpGet.setHeader(\"User-Agent\", getUserAgent()); httpGet.setHeader(\"Authorization\", getAuthorization(\"GET\", url, \"\", bizCodeType)); String result = executeRequest(httpGet); logger.info(\"调用微信GET接口，url:&#123;&#125; ,result:&#123;&#125;\", url, result); return result; &#125;private static String executeRequest(HttpUriRequest request) &#123; CloseableHttpClient client = HttpClients.createDefault(); String result = \"\"; try &#123; CloseableHttpResponse response = client.execute(request); HttpEntity entity = response.getEntity(); result = EntityUtils.toString(entity, \"UTF-8\"); &#125; catch (IOException e) &#123; logger.error(\"调用微信接口失败，失败原因：\" + e.getMessage(), e); &#125; finally &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; logger.error(\"关闭httpclient失败，失败原因:&#123;&#125;\", e); &#125; &#125; return result;&#125; 获取Json数据1234567public MpMaterialVO(JSONObject jsonObject) &#123; this.mediaId = jsonObject.getString(\"media_id\"); JSONObject news = (JSONObject) jsonObject.getJSONObject(\"content\").getJSONArray(\"news_item\").get(0); this.title = news.getString(\"title\"); this.digest = news.getString(\"digest\"); this.thumbUrl = news.getString(\"thumb_url\");&#125; Json与VO相互转换12345678910111213141516171819202122232425/** * 对应VO转为内容json */public void voToJson() &#123; if (type == MaterialTemplateTypeEnum.MINI_CARD) &#123; contentJson = JsonUtils.toJsonString(miniCardVO); &#125; else if (type == MaterialTemplateTypeEnum.ADVANCED_IMAGE_TEXT) &#123; contentJson = JsonUtils.toJsonString(advancedImageTextVO); &#125; else &#123; contentJson = JsonUtils.toJsonString(content); &#125;&#125;/** * 内容json转为对应VO */public void jsonToVO() &#123; if (type == MaterialTemplateTypeEnum.MINI_CARD) &#123; miniCardVO = JsonUtils.toBean(contentJson, MiniCardVO.class); &#125; else if (type == MaterialTemplateTypeEnum.ADVANCED_IMAGE_TEXT) &#123; advancedImageTextVO = JsonUtils.toBean(contentJson, AdvancedImageTextVO.class); &#125; else &#123; content = JsonUtils.toBean(contentJson, String.class); &#125;&#125; 微信发送图文消息举例123456789101112131415161718192021222324252627282930&#123; \"touser\":\"OPENID\", \"msgtype\":\"news\", \"news\":&#123; \"articles\": [ &#123; \"title\":\"Happy Day\", \"description\":\"Is Really A Happy Day\", \"url\":\"URL\", \"picurl\":\"PIC_URL\" &#125; ] &#125;&#125;public JSONObject initAdvancedImageText(AdvancedImageTextVO advancedImageTextVO) &#123; JSONObject param = new JSONObject(); param.put(MSG_TYPE, \"news\"); JSONObject news = new JSONObject(); JSONArray articles = new JSONArray(); JSONObject article = new JSONObject(); article.put(TITLE, advancedImageTextVO.getTitle()); article.put(\"description\", advancedImageTextVO.getDescription()); article.put(\"url\", advancedImageTextVO.getHref()); article.put(\"picurl\", advancedImageTextVO.getUrl()); articles.add(article); news.put(\"articles\", articles); param.put(\"news\", news); return param;&#125; mybatis的Sql使用xml配置123456789101112131415161718192021222324252627282930&lt;sql id=\"memberColumns\"&gt; a.id AS \"id\", a.card_no AS \"cardNo\", a.mobile AS \"mobile\", a.login_name AS \"loginName\", a.password AS \"password\", a.status AS \"status\", a.sex AS \"sex\", a.birthday AS \"birthday\", a.nick_name AS \"nickName\", a.icon AS \"icon\", a.is_created_order AS \"isCreatedOrder\", a.binding_status AS \"bindingStatus\", a.province AS \"province\", a.city AS \"city\", a.create_date AS \"createDate\", a.create_by AS \"createBy\", a.update_date AS \"updateDate\", a.update_by AS \"updateBy\", a.del_flag AS \"delFlag\", a.remarks AS \"remarks\", a.tenant_id AS \"tenantId\", a.ext_tenant_id AS \"extTenantId\"&lt;/sql&gt; &lt;select id=\"listMember\" resultMap=\"memberCO\"&gt; SELECT b.channel, &lt;include refid=\"memberColumns\"/&gt; .... &lt;/select&gt; java使用1List&lt;memberCO&gt; list = memberChannelExtRepository.listMember(\"参数\"); Java ES api相关使用12345678910111213141516171819202122232425262728293031323334//范围查询if (null != query.getCancelTimeStart()) &#123; RangeQueryBuilder cancelTimeStartQuery = QueryBuilders.rangeQuery(\"cancelTime\") .gte(DateTimeUtils.formatDateTime(query.getCancelTimeStart())); filter.must(cancelTimeStartQuery);&#125;if (null != query.getCancelTimeEnd()) &#123; RangeQueryBuilder cancelTimeEndQuery = QueryBuilders.rangeQuery(\"cancelTime\") .lte(DateTimeUtils.formatDateTime(query.getCancelTimeEnd())); filter.must(cancelTimeEndQuery);&#125;//集合查询if (ValidateUtils.isNotEmptyCollection(query.getPaymentStatuses())) &#123; List&lt;String&gt; paymentStatuses = query.getPaymentStatuses().stream() .map(paymentStatus -&gt; paymentStatus.toString()).collect(Collectors.toList()); TermsQueryBuilder paymentStatusesQuery = QueryBuilders.termsQuery(\"paymentStatus\", paymentStatuses); filter.must(paymentStatusesQuery);&#125;//精确查询 TermsQueryBuilder originalExpressIdQuery = QueryBuilders .termsQuery(\"originalExpressId\", query.getOriginalExpressId()); filter.must(originalExpressIdQuery);//QueryBuilder queryBuilder = QueryBuilders.wildcardQuery(\"user\", \"ki*hy\");//模糊查询RegexpQueryBuilder externalCodeQuery = QueryBuilders.regexpQuery(\"externalCode\", “*”+ query.getExternalCode() + “*”);WildcardQueryBuilder externalCodeQuery = QueryBuilders.wildcardQuery(\"externalCode\", \"*\"+query.getExternalCode()+\"*\"); parseInt与valueOf123Integer dailySignPointToInt = Integer.parseInt(resultData);//推荐2，有缓存Integer dailySignPointToInt = Integer.valueOf(resultData); Arrays.asList()与Collections.singletonList()12Arrays.asList(strArray)返回值是仍然是一个可变的集合，但是返回值是其内部类，不具有add方法，可以通过set方法进行增加值，默认长度是10Collections.singletonList()返回的同样是不可变的集合，但是这个长度的集合只有1，可以减少内存空间。但是返回的值依然是Collections的内部实现类，同样没有add的方法，调用add，set方法会报错 @Transient1@Transient表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性. 如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic 本地导出文件测试1curl -X POST --header 'Content-Type: application/json' --header 'Accept: application/octet-stream' --header 'X-Client-Id: swagger' --header 'X-Client-Token: 852311eac642cbf8059928c371784461' --header 'X-Tenant-Id: newretail' --header 'X-Ext-Tenant-Id: 1275854953286784' -d '&#123;&#125;' 'http://localhost:9017/api/earningRuleRetail/exportExcel' -o aa.xlsx Kafka操作12345//消费者bin/windows/kafka-console-consumer.bat --zookeeper localhost:2181 --topic lvshen_demo_test --from-beginning//生产者bin/windows/kafka-console-producer.bat --broker-list localhost:9092 --topic lvshen_demo_test 判断小程序或h51String clientType = ServletUtils.getRequest().getHeader(&quot;X-Client-Type&quot;); InitializingBean12345678910InitializingBean接口为bean提供了初始化方法的方式，它只包括afterPropertiesSet方法，凡是继承该接口的类，在初始化bean的时候都会执行该方法。//示例public class SensitiveWordFilterHelper implements InitializingBean &#123; @Override public void afterPropertiesSet() throws Exception &#123; refreshAllWord(); &#125; ...&#125; kafka重试123451. new KafkaProducer()后创建一个后台线程KafkaThread扫描RecordAccumulator中是否有消息； 2. 调用KafkaProducer.send()发送消息，实际上只是把消息保存到RecordAccumulator中； 3. 后台线程KafkaThread扫描到RecordAccumulator中有消息后，将消息发送到kafka集群； 4. 如果发送成功，那么返回成功； 5. 如果发送失败，那么判断是否允许重试。如果不允许重试，那么返回失败的结果；如果允许重试，把消息再保存到RecordAccumulator中，等待后台线程KafkaThread扫描再次发送； ArrayDeque方法（双队列）addFirst(E e)12345678//addFirst(E e)public void addFirst(E e) &#123; if (e == null)//不允许放入null throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界 if (head == tail)//1.空间是否够用 doubleCapacity();//扩容&#125; 时间单位转换12345678//3600分钟 转换成 小时 是多少System.out.println(TimeUnit.HOURS.convert(3600, TimeUnit.MINUTES));//3600分钟 转换成 天 是多少System.out.println(TimeUnit.DAYS.convert(3600, TimeUnit.MINUTES));//3600分钟 转换成 秒 是多少System.out.println(TimeUnit.SECONDS.convert(3600, TimeUnit.MINUTES)); 事务结束后代码处理逻辑1afterTransactionExecutor.execute(() -&gt; clearCacheCommodityByIds(ids)); 地址路径为方法参数12345678@PostMapping(\"/changeSort/&#123;id&#125;/&#123;type&#125;\")@ApiOperation(value = \"调整排序 TOTOP/UP\", tags = TagConstant.PC)@RequiresPermissions(\"xxx-commodity:commodityParam:edit\")public void changeSort(@PathVariable(\"id\") String id, @PathVariable(\"type\") String type) &#123; Assert.hasLength(id, \"属性id有误\"); commodityParamQueryService.get(id); commodityParamService.changeSort(id, type);&#125; 批量操作tipsjava12345678//批量操作时，先将索引字段排序，有利于避免死锁.按顺序加锁不会产生锁环stockAllocateList.sort(Comparator.comparing(StockAllocate::getSkuId));stockAllocateList.forEach(item -&gt; &#123; int size = this.dao.updateSubAllocateStock(item); if (size &lt;= 0) &#123; throw new BusinessException(\"stockSubAllocate_error\", stockAllocateVOS.toString()); &#125;&#125;); sql1234&lt;update id=\"updateSubAllocateStock\" &gt; update stock set allocate_stock = allocate_stock - #&#123;commodityNumber&#125; where sku_id=#&#123;skuId&#125; and allocate_stock &gt;= #&#123;commodityNumber&#125;&lt;/update&gt; 锁查询123456789101112131415161718192021222324252627282930select * from information_schema.innodb_locks;show engine innodb status;SELECT * FROM information_schema.innodb_lock_waits;SHOW VARIABLES LIKE 'optimizer_trace';SET optimizer_trace=\"enabled=on\";SELECT * FROM student WHERE name = 'fly';SELECT * FROM information_schema.OPTIMIZER_TRACE;--MySQL监控-- 开启标准监控CREATE TABLE innodb_monitor (a INT) ENGINE=INNODB;-- 关闭标准监控DROP TABLE innodb_monitor;-- 开启锁监控CREATE TABLE innodb_lock_monitor (a INT) ENGINE=INNODB; -- 关闭锁监控DROP TABLE innodb_lock_monitor;--在 MySQL 5.6.16 之后，可以通过设置系统参数来开启锁监控-- 开启标准监控set GLOBAL innodb_status_output=ON;-- 关闭标准监控set GLOBAL innodb_status_output=OFF;-- 开启锁监控set GLOBAL innodb_status_output_locks=ON;-- 关闭锁监控set GLOBAL innodb_status_output_locks=OFF;--MySQL 提供了一个系统参数 innodb_print_all_deadlocks 专门用于记录死锁日志，当发生死锁时，死锁日志会记录到 MySQL 的错误日志文件中set GLOBAL innodb_print_all_deadlocks=ON; MySQL死锁模拟12345678910111213141516171819202122232425262728--事务Amysql&gt; begin;Query OK, 0 rows affected--执行顺序 1mysql&gt; update student set age=31 where name = 'fly';Query OK, 1 row affectedRows matched: 1 Changed: 1 Warnings: 0--执行顺序 3mysql&gt; update student set age=32 where name = 'alan';Query OK, 1 row affectedRows matched: 1 Changed: 1 Warnings: 0--事务Bmysql&gt; begin;Query OK, 0 rows affected (0.00 sec)--执行顺序 2mysql&gt; update student set age=31 where name = 'alan';Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0--执行顺序 4mysql&gt; update student set age=21 where name = 'fly';ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 使用Mybatis操作注意不要先查询再操作 删除1234567891011121314//推荐@Testpublic void testDelete() &#123; Student student = new Student(); student.setName(\"Hare\"); int delete = studentRepository.delete(student); log.info(\"删除&#123;&#125;条数据\",delete);&#125;//不推荐public void testDelete() &#123; Student student = studentRepositoryg.getByName(\"Hare\"); int delete = studentRepository.delete(student); log.info(\"删除&#123;&#125;条数据\",delete);&#125; 更新12345678910111213141516171819202122232425262728293031//更新@Testpublic void testUpdate() &#123; Student student = new Student(); student.setId(\"2073678416402304\"); student.setAge(26); studentRepository.update(student); log.info(\"test is success!!!\");&#125;//按条件更新@Testpublic void testUpdateByExample() &#123; //修改内容 Student student = new Student(); student.setAge(27); //修改条件 Example example = new Example(Student.class); Example.Criteria criteria = example.createCriteria(); criteria.andIn(\"name\", ImmutableList.of(\"fly\",\"lvshen\")); int i = studentRepository.updateByExample(student, example); log.info(\"test is success!!!&#123;&#125;\",i);&#125;//不推荐@Testpublic void testUpdate() &#123; Student student = studentRepository.get(\"2073678416402304\"); studentRepository.update(student); log.info(\"test is success!!!\");&#125; linux命令12345#内存信息jmap -F -dump:format=b,file=test.bin 22829（pid）#堆信息jstat -gcutil 22829（pid）","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lvshen9.gitee.io/tags/Java8/"},{"name":"Stream","slug":"Stream","permalink":"http://lvshen9.gitee.io/tags/Stream/"}]},{"title":"我所用到的Java8","slug":"1","date":"2019-07-06T04:16:22.000Z","updated":"2019-07-06T07:57:33.170Z","comments":true,"path":"2019/07/06/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/07/06/1/","excerpt":"进入新公司几个月，陆陆续续使用到了Java8的新技术，其中流使用的最多，在处理集合方面非常方便，下面是是我工作中常用到的Java8的功能。","text":"进入新公司几个月，陆陆续续使用到了Java8的新技术，其中流使用的最多，在处理集合方面非常方便，下面是是我工作中常用到的Java8的功能。 Lambda表达式和forEach循环1234567if (CollectionUtils.isNotEmpty(prizes)) &#123; prizes.forEach(x -&gt; &#123; if (PrizeType.BOOK.equals(x.getPrizeType())) &#123; books.add(getByActivityId(x.getPrizeId())); &#125; &#125;);&#125; 当循环遍历的数据很多时（1000条以上），Java8中的for循环新能要强于普通的for循环。 集合创建123if (CollectionUtils.isEmpty(memberList)) &#123; return ImmutableList.of();&#125; 使用Guava的ImmutableList.of()创建的是不可变集合，这样有利于节省空间。 Java8常用的集合操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110//filter过滤List&lt;RedeemActivity&gt; redeemActivitiesOfPrize = activities.stream() .filter(x -&gt; activityIdsOfPrize.contains(x.getId())).collect(Collectors.toList());//使用流降序排序userCOS.stream() .sorted(Comparator.comparing(userCO::getCreateDate).reversed()).collect(Collectors.toList());//通过昵称获取userId列表 List&lt;String&gt; userIds = users.stream().collect(() -&gt; new ArrayList&lt;String&gt;(), (list, user) -&gt; list.add(user.getId()), (list1, list2) -&gt; list1.addAll(list2)); List&lt;String&gt; orderNos = orderStatus.stream().map(OrderDetail::getOrderNo).collect(toList());//Optional.ofNullable使用List&lt;CommodityActivityRule&gt; excludedCommodityActivityRules = Optional.ofNullable(commodityActivityRules) .orElseGet(ArrayList::new).stream() // 排除当前活动 .filter(commodityActivityRule -&gt; !commodityActivityRule.getActivity().getId().equals(activityId)) .collect(Collectors.toList());//对象不为null时使用of,对象可能为null也可能不为null时用ofNullable//orElseGet:对象不为null不会重新创建；orElse：对象为不为null也会重新创建 Optional.of(marketingConfigRepository.listAll(new MarketingConfig())).orElseGet(ArrayList::new).stream() .filter(marketingConfig -&gt; excludedMarketingConfigTypes.contains(marketingConfig.getType())) .map(MarketingConfig::getId).collect(Collectors.toList());//返回对象的时候可以用Optional.ofNullable(usageRules).orElseGet(ArrayList::new)//BigDecimal累加BigDecimal commodityAmount = orderDetails.stream().map(OrderDetail::getCommodityAmount).reduce(BigDecimal.ZERO, BigDecimal::add);//判断Optional里面是否有值Optional&lt;GradeThresholdInfoCO&gt; nextOptional = gradeThresholdList.stream().filter(x -&gt; x.getLevel() != null &amp;&amp; x.getLevel() == level + 1).findFirst(); if (nextOptional.isPresent()) &#123; return nextOptional.get(); &#125;//findFirst()List&lt;Cookie&gt; targetCookies = Optional.ofNullable(cookies).orElseGet(ArrayList::new).stream() .filter(e -&gt; \"jsessionid\".equalsIgnoreCase(e.getName())).collect(Collectors.toList()); log.info(\"Cookie名称为：&#123;&#125;的值为:&#123;&#125;\", \"jsessionid\", Optional.ofNullable(targetCookies).orElseGet(ArrayList::new).get(0).getValue()); Optional&lt;Cookie&gt; first = Optional.ofNullable(cookies).orElseGet(ArrayList::new).stream() .filter(e -&gt; \"jsessionid\".equalsIgnoreCase(e.getName())).findFirst(); if (first.isPresent()) &#123; log.info(\"Cookie名称为：&#123;&#125;的值为:&#123;&#125;\", \"jsessionid\", first.get().getValue()); &#125;//流大小比较Optional&lt;Optional&lt;Integer&gt;&gt; maxLevelOptional = ruleList.stream().map(x -&gt; x.getEarningRuleMap().keySet().stream().max((o1, o2) -&gt; o1.compareTo(o2))).max((o1, o2) -&gt; &#123; Integer value1 = o1.isPresent() ? o1.get() : 0; Integer value2 = o2.isPresent() ? o2.get() : 0; return value1.compareTo(value2); &#125;);//日期获取最值（最大，最小）Optional&lt;ActivityVO&gt; max = activityVOS.stream().max(Comparator.comparing(ActivityVO::getEndDate));Optional&lt;ActivityVO&gt; min = activityVOS.stream().min(Comparator.comparing(ActivityVO::getStartDate));Date maxEndDate = max.get().getEndDate();Date minStartDate = min.get().getStartDate();//groupingBy分组1 Map&lt;PrizeType, List&lt;RedeemActivityPrize&gt;&gt; prizeTypeAndPrizesMap = redeemActivityPrize.stream().collect(Collectors.groupingBy(RedeemActivityPrize::getPrizeType)); List&lt;RedeemActivityPrize&gt; couponPrizes = prizeTypeAndPrizesMap.get(PrizeType.COUPON); List&lt;RedeemActivityPrize&gt; presentPrizes = prizeTypeAndPrizesMap.get(PrizeType.PRESENT);//groupingBy分组2prizes.stream().collect(Collectors.groupingBy(RedeemActivityPrize::getPrizeId)) .forEach((prizeId, activityPrizes) -&gt; &#123; List&lt;String&gt; activityIdsOfPrize = activityPrizes.stream() .map(RedeemActivityPrize::getRedeemActivityId).collect(Collectors.toList()); List&lt;RedeemActivity&gt; redeemActivitiesOfPrize = activities.stream() .filter(x -&gt; activityIdsOfPrize.contains(x.getId())).collect(Collectors.toList()); List&lt;RedeemActivityBriefCO&gt; briefCOS = ModelConvertorHelper.convertList(redeemActivitiesOfPrize, RedeemActivityBriefCO.class); RedeemUsedPresentCO co = new RedeemUsedPresentCO(); co.setPresentId(prizeId); co.setActivities(briefCOS); result.add(co); &#125;);//Java8 Function函数的使用//T-入参类型，R-出参类型 private static &lt;T, R&gt; List&lt;R&gt; transform(List&lt;T&gt; list, Function&lt;T, R&gt; fx) &#123; List&lt;R&gt; result = new ArrayList&lt;&gt;(); for (T element : list) &#123; result.add(fx.apply(element)); &#125; return result; &#125;List&lt;Integer&gt; namesLength = transform(names, String::length);//集合添加..Stream.of(task1, task2, task3, task4, task5).collect(toList())//显示前几位的集合数据tasks.stream().filter(task -&gt; task.getType() == TaskType.READING).sorted(comparing(Task::getCreatedOn)).map(Task::getTitle).limit(n).collect(toList());//Java8循环遍历couponIds.forEach(x -&gt; &#123; RedeemActivityPrize presentRedeem = new RedeemActivityPrize(); presentRedeem.setRedeemActivityId(redeemActivityId); presentRedeem.setPrizeType(PrizeType.COUPON); presentRedeem.setPrizeId(x); redeemActivityPrizeList.add(presentRedeem);&#125;); Spring创建对象12private final static ActivityRepository redeemActivityRepository = SpringContextHolder .getBean(ActivityRepository.class); 除了@Autowired生成对象，Spring其他生成对象的方式。 BigDecimal使用注意123你可能认为java中用new BigDecimal(0.1)创建的BigDecimal应该等于0.1（一个是1的无精度的值，一个是有精度的值），但实际上精确的是等于0.1000000000000000055511151231257827021181583404541015625。这是因为0.1不能被double精确的表示（下面大概描述一下原理）。因此，传入构造函数的值不是精确的等于0.1。当遇到需要涉及到精确计算的时候，如上面代码所示，要注意该构造函数是一个精确的转换，它无法得到与先调用Double.toString(double)方法将double转换成String，再使用BigDecimal(String)构造函数一样的结果。如果要达到这种结果，应该使用new BigDecimal(String value) 或 BigDecimal.valueof(double value) 使用SecureRandom123456789101112131415由于java.util.Random类依赖于伪随机数生成器，因此该类和相关的java.lang.Math.random（）方法不应用于安全关键应用程序或保护敏感数据。 在这种情况下，应该使用依赖于加密强随机数生成器（RNG）的java.security.SecureRandom类。PRNG(伪随机数)：伪随机数， 计算机不能生成真正的随机数，而是通用一定的方法来模拟随机数。伪随机数有一部分遵守一定的规律，另一部分不遵守任何规律。RNG(随机数)：随机数是由“随机种子”产生的，“随机种子”是一个无符号整形数。反例：Random random = new Random(); // Questionable use of Randombyte bytes[] = new byte[20];random.nextBytes(bytes);正例：SecureRandom random = new SecureRandom(); byte bytes[] = new byte[20]; Java8 List转Map123456789101112131415161718192021222324//1.这里有个实体对象(员工对象)public class Employee &#123; // member variables private int empId; private String empName; private int empAge; private String empDesignation;//2.比如式样员工对象的empId作为key，值是员工姓名 Map&lt;Integer, String&gt; mapOfEmployees = employees.stream().collect( Collectors.toMap(e -&gt; e.getEmpId(),e -&gt; e.getEmpName()));//3.Map的Key是empId，整个对象为Map的值,但如果List中有重复的empId，映射到Map时，Key时不能重复的 Map&lt;Integer, String&gt; mapOfEmployees = employees.stream().collect( Collectors.toMap( e -&gt; e.getEmpId(), e -&gt; e.getEmpName(), (e1, e2) -&gt; e1 )); // Merge Function//4.将List转换为Map - 使用TreeMap对键进行自然排序 Map&lt;Integer, String&gt; mapOfEmployees = employees.stream().collect( Collectors.toMap( e -&gt; e.getEmpId(), e -&gt; e.getEmpName(), (e1, e2) -&gt; e1 , // Merge Function TreeMap&lt;Integer, String&gt;::new)); // Map Supplier//如果你的TreeMap实现需要加入比较器，将上面代码中TreeMap&lt;Integer, String&gt;::new替换成：() -&gt; new TreeMap&lt;Integer, String&gt;(new MyComparator())","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lvshen9.gitee.io/tags/Java8/"},{"name":"Stream","slug":"Stream","permalink":"http://lvshen9.gitee.io/tags/Stream/"}]},{"title":"MySQL为什么选择B+Tree做索引","slug":"1","date":"2019-05-26T02:31:24.000Z","updated":"2019-05-26T03:13:16.050Z","comments":true,"path":"2019/05/26/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/05/26/1/","excerpt":"MySQL为什么选择B+Tree? 理解MySQL索引的几个原则 索引是什么？是为了加速对表中数据行的检索而创建的一种分散存储的数据结构。 工作机制 如上图：以id创建索引，索引数据结构里存储了索引键（关键字）以及对应的值（地址值），当搜寻id=101的数据时，直接找到对应的地址0x123456。时间复杂度为O(1)。","text":"MySQL为什么选择B+Tree? 理解MySQL索引的几个原则 索引是什么？是为了加速对表中数据行的检索而创建的一种分散存储的数据结构。 工作机制 如上图：以id创建索引，索引数据结构里存储了索引键（关键字）以及对应的值（地址值），当搜寻id=101的数据时，直接找到对应的地址0x123456。时间复杂度为O(1)。 二叉查找树时间复杂度O($log_2n$) 二叉查找树 二叉树测试地址： https://www.cs.usfca.edu/~galles/visualization/BST.html 二叉树缺点： 二叉树缺点 平衡二叉查找树 平衡二叉查找树 每一个节点与子节点的高度差不能大于1。 平衡二叉树测试地址： https://www.cs.usfca.edu/~galles/visualization/AVLtree.html 二叉树缺陷： 搜索时IO次数过多，节点数据内太多。 多路平衡二叉树（B树） 多路平衡二叉树 多路平衡二叉树测试地址： https://www.cs.usfca.edu/~galles/visualization/BTree.html 经常变化的字段不要建索引，对B树的维护不好。B树的合并和分裂对性能有损耗。 B+Tree B+Tree 左闭合区间，id从小到大的递增。数据变动可能是最右边的变动 。 MySQL使用B+Tree的原因： B+Tree扫库、扫表能力更强。 B+Tree的磁盘读写能力更强。 B+Tree的排序能力更强。 B+Tree的传效率更稳定。 MySQL文件存储两种类型的表： 两种类型的表 两种表的存储文件类型： 存储的文件 索引用Hash算法的缺点： 1.无法范围查询 2.无法排序 InnoDB引擎存储节点的规则InnoDB采取的⽅式是：将数据划分为若⼲个⻚，以⻚作为磁盘和内存之间交互的基本单位，InnoDB 中⻚的⼤⼩⼀般为 16 KB。也就是在⼀般情况下，⼀次最少从磁盘中读取16KB的内容到内存中，⼀次最少把内存中的16KB内容刷新到磁盘中 我们的实际⽤户记录其实都存放在B+树的最底层的节点上，这些节点也被称为叶⼦节点或叶节点，其余⽤来存放⽬录项的节点称为⾮叶⼦节点或者内节点，其中B+树最上边的那个节点也称为根节点。 假设所有存放⽤户记录的叶⼦节点代表的数据⻚可以存放100条⽤户记录，所有存放⽬录项记录的内节点代表的数据⻚可以存放1000条⽬录项记录，那么： 如果B+树只有1层，也就是只有1个⽤于存放⽤户记录的节点， 最多能存放100条记录。 如果B+树有2层，最多能存放1000×100=100000条记录。 如果B+树有3层，最多能存放1000×1000×100=100000000条记录。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://lvshen9.gitee.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"http://lvshen9.gitee.io/tags/索引/"},{"name":"B+Tree","slug":"B-Tree","permalink":"http://lvshen9.gitee.io/tags/B-Tree/"}]},{"title":"我的一次微服务实战-SpringCloud学习","slug":"1","date":"2019-04-14T11:10:44.000Z","updated":"2019-06-29T14:55:50.826Z","comments":true,"path":"2019/04/14/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/04/14/1/","excerpt":"The article has been encrypted, please enter your password to view.","text":"Please enter the password to read the blog. Incorrect Password! No content to display! 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","categories":[{"name":"工作","slug":"工作","permalink":"http://lvshen9.gitee.io/categories/工作/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://lvshen9.gitee.io/tags/Java/"},{"name":"微服务","slug":"微服务","permalink":"http://lvshen9.gitee.io/tags/微服务/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lvshen9.gitee.io/tags/SpringCloud/"}]},{"title":"HashMap源码学习","slug":"1","date":"2019-03-11T05:48:09.000Z","updated":"2019-03-11T06:43:03.675Z","comments":true,"path":"2019/03/11/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/03/11/1/","excerpt":"HashMap概述 在JDK1.8之前，HashMap采用数组+链表实现，即使用链表处理冲突，同一hash值的节点都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。而JDK1.8中，HashMap采用数组+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。 下图中代表jdk1.8之前的hashmap结构，左边部分即代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。 jdk1.8之前的hashmap结构图","text":"HashMap概述 在JDK1.8之前，HashMap采用数组+链表实现，即使用链表处理冲突，同一hash值的节点都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。而JDK1.8中，HashMap采用数组+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。 下图中代表jdk1.8之前的hashmap结构，左边部分即代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。 jdk1.8之前的hashmap结构图 jdk1.8之前的hashmap都采用上图的结构，都是基于一个数组和多个单链表，hash值冲突的时候，就将对应节点以链表的形式存储。如果在一个链表中查找其中一个节点时，将会花费$O(n)$的查找时间，会有很大的性能损失。到了jdk1.8，当同一个hash值的节点数不小于8时，不再采用单链表形式存储，而是采用红黑树，如下图所示。 jdk1.8 hashmap结构图 说明：上图很形象的展示了HashMap的数据结构（数组+链表+红黑树），桶中的结构可能是链表，也可能是红黑树，红黑树的引入是为了提高效率。 涉及到的数据结构：处理hash冲突的链表和红黑树以及位桶链表的实现 Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。来看具体代码： 12345678910111213141516171819202122232425262728293031323334353637383940//Node是单向链表，它实现了Map.Entry接口static class Node&lt;k,v&gt; implements Map.Entry&lt;k,v&gt; &#123; final int hash; final K key; V value; Node&lt;k,v&gt; next; //构造函数Hash值 键 值 下一个节点 Node(int hash, K key, V value, Node&lt;k,v&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + = + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; //判断两个node是否相等,若key和value都相等，返回true。可以与自身比较为true public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;!--?,?--&gt; e = (Map.Entry&lt;!--?,?--&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 可以看到，node中包含一个next变量，这个就是链表的关键点，hash结果相同的元素就是通过这个next进行关联的。 红黑树1234567891011121314151617181920//红黑树static final class TreeNode&lt;k,v&gt; extends LinkedHashMap.Entry&lt;k,v&gt; &#123; TreeNode&lt;k,v&gt; parent; // 父节点 TreeNode&lt;k,v&gt; left; //左子树 TreeNode&lt;k,v&gt; right;//右子树 TreeNode&lt;k,v&gt; prev; // needed to unlink next upon deletion boolean red; //颜色属性 TreeNode(int hash, K key, V val, Node&lt;k,v&gt; next) &#123; super(hash, key, val, next); &#125; //返回当前节点的根节点 final TreeNode&lt;k,v&gt; root() &#123; for (TreeNode&lt;k,v&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125;&#125; 红黑树比链表多了四个变量，parent父节点、left左节点、right右节点、prev上一个同级节点，红黑树内容较多，不在赘述。 位桶1transient Node&lt;k,v&gt;[] table;//存储（位桶）的数组 HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。 ​ 有了以上3个数据结构，只要有一点数据结构基础的人，都可以大致联想到HashMap的实现了。首先有一个每个元素都是链表（可能表述不准确）的数组，当添加一个元素（key-value）时，就首先计算元素key的hash值，以此确定插入数组中的位置，但是可能存在同一hash值的元素已经被放在数组同一位置了，这时就添加到同一hash值的元素的后面，他们在数组的同一位置，但是形成了链表，所以说数组存放的是链表。而当链表长度太长时，链表就转换为红黑树，这样大大提高了查找的效率。 HashMap源码分析类的继承关系1public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable ​ 可以看到HashMap继承自父类（AbstractMap），实现了Map、Cloneable、Serializable接口。其中，Map接口定义了一组通用的操作；Cloneable接口则表示可以进行拷贝，在HashMap中，实现的是浅层次拷贝，即对拷贝对象的改变会影响被拷贝的对象；Serializable接口表示HashMap实现了序列化，即可以将HashMap对象保存至本地，之后可以恢复状态。 类的属性12345678910111213141516171819202122232425262728public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; // 序列号 private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的填充因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树 static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表 static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍 transient Node&lt;k,v&gt;[] table; // 存放具体元素的集 transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet; // 存放元素的个数，注意这个不等于数组的长度。 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容 int threshold; // 填充因子 final float loadFactor;&#125; 说明：类的数据成员很重要，以上也解释得很详细了。 类的构造函数（1）HashMap(int, float)型构造函数 1234567891011121314151617public HashMap(int initialCapacity, float loadFactor) &#123; // 初始容量不能小于0，否则报错 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); // 初始容量不能大于最大值，否则为最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 填充因子不能小于或等于0，不能为非数字 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // 初始化填充因子 this.loadFactor = loadFactor; // 初始化threshold大小 this.threshold = tableSizeFor(initialCapacity); &#125; 说明：tableSizeFor(initialCapacity)返回大于initialCapacity的最小的二次幂数值。 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 说明：&gt;&gt;&gt; 操作符表示无符号右移，高位取0。 （2）HashMap(int)型构造函数。 1234public HashMap(int initialCapacity) &#123; // 调用HashMap(int, float)型构造函数 this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; （3）HashMap()型构造函数。 1234public HashMap() &#123; // 初始化填充因子 this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; （4）HashMap(Map&lt;? extends K&gt;)型构造函数。 123456public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 初始化填充因子 this.loadFactor = DEFAULT_LOAD_FACTOR; // 将m中的所有元素添加至HashMap中 putMapEntries(m, false);&#125; 说明：putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict)函数将m的所有元素存入本HashMap实例中。 123456789101112131415161718192021222324final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; // 判断table是否已经初始化 if (table == null) &#123; // pre-size // 未初始化，s为m的实际元素个数 float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 计算得到的t大于阈值，则初始化阈值 if (t &gt; threshold) threshold = tableSizeFor(t); &#125; // 已初始化，并且m元素个数大于阈值，进行扩容处理 else if (s &gt; threshold) resize(); // 将m中的所有元素添加至HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; hash算法在JDK 1.8中，hash方法如下： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; （1）首先获取对象的hashCode()值，然后将hashCode值右移16位，然后将右移后的值与原来的hashCode做异或运算，返回结果。（其中h&gt;&gt;&gt;16，在JDK1.8中，优化了高位运算的算法，使用了零扩展，无论正数还是负数，都在高位插入0）。 （2）在putVal源码中，我们通过(n-1)&amp;hash获取该对象的键在hashmap中的位置。（其中hash的值就是（1）中获得的值）其中n表示的是hash桶数组的长度，并且该长度为2的n次方，这样(n-1)&amp;hash就等价于hash%n。因为&amp;运算的效率高于%运算。 12345678final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; ... if ((p = tab[i = (n - 1) &amp; hash]) == null)//获取位置 tab[i] = newNode(hash, key, value, null); ...&#125; ​ tab即是table，n是map集合的容量大小，hash是上面方法的返回值。因为通常声明map集合时不会指定大小，或者初始化的时候就创建一个容量很大的map对象，所以这个通过容量大小与key值进行hash的算法在开始的时候只会对低位进行计算，虽然容量的2进制高位一开始都是0，但是key的2进制高位通常是有值的，因此先在hash方法中将key的hashCode右移16位在与自身异或，使得高位也可以参与hash，更大程度上减少了碰撞率。 下面举例说明下，n为table的长度。 重要方法分析（1）putVal方法 首先说明，HashMap并没有直接提供putVal接口给用户调用，而是提供的put方法，而put方法就是通过putVal来插入元素的。 1234public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); &#125; putVal方法执行过程可以通过下图来理解： ①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 具体源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else &#123; Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // 步骤④：判断该链为红黑树 // hash值不相等，即key不相等；为红黑树结点 else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 // 为链表结点 else &#123; // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 if ((e = p.next) == null) &#123; // 在尾部插入新结点 p.next = newNode(hash, key, value, null); // 结点数量达到阈值，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 跳出循环 break; &#125; // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; // 表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改 ++modCount; // 步骤⑥：超过最大容量 就扩容 // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;&#125; HashMap的数据存储实现原理 流程： 根据key计算得到key.hash = (h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)； 根据key.hash计算得到桶数组的索引index = key.hash &amp; (table.length - 1)，这样就找到该key的存放位置了： ① 如果该位置没有数据，用该数据新生成一个节点保存新数据，返回null； ② 如果该位置有数据是一个红黑树，那么执行相应的插入 / 更新操作； ③ 如果该位置有数据是一个链表，分两种情况一是该链表没有这个节点，另一个是该链表上有这个节点，注意这里判断的依据是key.hash是否一样： 如果该链表没有这个节点，那么采用尾插法新增节点保存新数据，返回null；如果该链表已经有这个节点了，那么找到该节点并更新新数据，返回老数据。 注意： HashMap的put会返回key的上一次保存的数据，比如： 1234HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();System.out.println(map.put(\"a\", \"A\")); // 打印nullSystem.out.println(map.put(\"a\", \"AA\")); // 打印ASystem.out.println(map.put(\"a\", \"AB\")); // 打印AA （2）getNode方法 说明：HashMap同样并没有直接提供getNode接口给用户调用，而是提供的get方法，而get方法就是通过getNode来取得元素的。 1234public V get(Object key) &#123; Node&lt;k,v&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; （3）resize方法 ①.在jdk1.8中，resize方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize方法进行扩容； ②.每次扩展的时候，都是扩展2倍； ③.扩展后Node对象的位置要么在原位置，要么移动到原偏移量两倍的位置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table;//oldTab指向hash桶数组 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123;//如果oldCap不为空的话，就是hash桶数组不为空 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;//如果大于最大容量了，就赋值为整数最大的阀值 threshold = Integer.MAX_VALUE; return oldTab;//返回 &#125;//如果当前hash桶数组的长度在扩容后仍然小于最大容量 并且oldCap大于默认值16 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold 双倍扩容阀值threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];//新建hash桶数组 table = newTab;//将新数组的值复制给旧的hash桶数组 if (oldTab != null) &#123;//进行扩容操作，复制Node对象值到新的hash桶数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123;//如果旧的hash桶数组在j结点处不为空，复制给e oldTab[j] = null;//将旧的hash桶数组在j结点处设置为空，方便gc if (e.next == null)//如果e后面没有Node结点 newTab[e.hash &amp; (newCap - 1)] = e;//直接对e的hash值对新的数组长度求模获得存储位置 else if (e instanceof TreeNode)//如果e是红黑树的类型，那么添加到红黑树中 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next;//将Node结点的next赋值给next if ((e.hash &amp; oldCap) == 0) &#123;//如果结点e的hash值与原hash桶数组的长度作与运算为0 if (loTail == null)//如果loTail为null loHead = e;//将e结点赋值给loHead else loTail.next = e;//否则将e赋值给loTail.next loTail = e;//然后将e复制给loTail &#125; else &#123;//如果结点e的hash值与原hash桶数组的长度作与运算不为0 if (hiTail == null)//如果hiTail为null hiHead = e;//将e赋值给hiHead else hiTail.next = e;//如果hiTail不为空，将e复制给hiTail.next hiTail = e;//将e复制个hiTail &#125; &#125; while ((e = next) != null);//直到e为空 if (loTail != null) &#123;//如果loTail不为空 loTail.next = null;//将loTail.next设置为空 newTab[j] = loHead;//将loHead赋值给新的hash桶数组[j]处 &#125; if (hiTail != null) &#123;//如果hiTail不为空 hiTail.next = null;//将hiTail.next赋值为空 newTab[j + oldCap] = hiHead;//将hiHead赋值给新的hash桶数组[j+旧hash桶数组长度] &#125; &#125; &#125; &#125; &#125; return newTab;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://lvshen9.gitee.io/tags/HashMap/"},{"name":"源码","slug":"源码","permalink":"http://lvshen9.gitee.io/tags/源码/"},{"name":"Java","slug":"Java","permalink":"http://lvshen9.gitee.io/tags/Java/"}]},{"title":"ELK之grok解析日志实战","slug":"1","date":"2019-01-21T08:34:54.000Z","updated":"2019-04-15T13:14:54.960Z","comments":true,"path":"2019/01/21/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/01/21/1/","excerpt":"准备说明根据业务情况，会出现ELK解析多种格式的日志需求，这时需要在logstash的配置文件中配置grok规则解析日志文件，grok解析建议使用在线工具测试。 在线Grok解析工具地址：Grok Debugger 在线测试样例： Grok Debugger","text":"准备说明根据业务情况，会出现ELK解析多种格式的日志需求，这时需要在logstash的配置文件中配置grok规则解析日志文件，grok解析建议使用在线工具测试。 在线Grok解析工具地址：Grok Debugger 在线测试样例： Grok Debugger Grok的语句需要写在ELK的logstash中的配置文件中，如下图： Logstash文件配置 异常日志123452018-11-09 23:01:18.766 [ERROR] com.ailk.rpc.server.handler.ServerHandler - 调用com.ailk.search.server.SearchServer.search时发生错误！java.lang.reflect.InvocationTargetException at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) grok解析 %{TIMESTAMP_ISO8601:log_time} [%{DATA:log_level}] %{GREEDYDATA:message} 12345678910filebeat配置filebeat: prospectors: - paths: - /home/elk/logs/*.log type: log multiline.pattern: &apos;^\\[&apos; multiline.negate: true multiline.match: after 解析结果1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123;\"log_time\": [ [ \"2018-11-09 23:01:18.766\" ]],\"YEAR\": [ [ \"2018\" ]],\"MONTHNUM\": [ [ \"11\" ]],\"MONTHDAY\": [ [ \"09\" ]],\"HOUR\": [ [ \"23\", null ]],\"MINUTE\": [ [ \"01\", null ]],\"SECOND\": [ [ \"18.766\" ]],\"ISO8601_TIMEZONE\": [ [ null ]],\"log_level\": [ [ \"ERROR\" ]],\"message\": [ [ \" com.ailk.rpc.server.handler.ServerHandler - 调用com.ailk.search.server.SearchServer.search时发生错误！\" ]] 业务报文日志123456789&lt;operation_in&gt;请求报文：service_name接口名，sysfunc_id功能号，operator_id 操作员id，organ_id 机构号，request_seq 请求流水2018-11-12 15:03:41.388 639211542011357848 [DEBUG] com.base.core.aop.http.HttpClient.send(HttpClient.java:128) - reqid:b7fb8f90ddeb11e83d622c02b34132f7;AOP 发送信息: &lt;?xml version=\"1.0\" encoding=\"GBK\"?&gt;&lt;operation_in&lt;service_name&gt;BSM_SaleSystemLogin&lt;/service_name&gt; &lt;sysfunc_id&gt;91008027&lt;/sysfunc_id&gt;&lt;request_type&gt;1002&lt;/request_type&gt;&lt;verify_code&gt;304147201506190000000040&lt;/verify_code&gt;&lt;operator_id&gt;9991445&lt;/operator_id&gt; &lt;organ_id&gt;9999997&lt;/organ_id&gt;&lt;request_time&gt;20181112150341&lt;/request_time&gt;&lt;request_seq&gt;154200622111&lt;/request_seq&gt;&lt;request_source&gt;304147&lt;/request_source&gt;&lt;request_target&gt;&lt;/request_target&gt;&lt;msg_version&gt;0100&lt;/msg_version&gt;&lt;cont_version&gt;0100&lt;/cont_version&gt;&lt;access_token&gt;&lt;/access_token&gt;&lt;content&gt;&lt;request&gt;&lt;msisdn&gt;13666945211&lt;/msisdn&gt;&lt;password&gt;871221&lt;/password&gt;&lt;portal_id&gt;101704&lt;/portal_id&gt;&lt;login_type&gt;34&lt;/login_type&gt;&lt;machine_mac&gt;0000&lt;/machine_mac&gt;&lt;machine_ip&gt;120.33.230.198, 10.46.161.182, &lt;/machine_ip&gt;&lt;machine_cpu&gt;&lt;/machine_cpu&gt;&lt;machine_system_ver&gt;12.0.1&lt;/machine_system_ver&gt;&lt;machine_totalmemory&gt;&lt;/machine_totalmemory&gt;&lt;machine_usablememory&gt;&lt;/machine_usablememory&gt;&lt;machine_ie_ver&gt;&lt;/machine_ie_ver&gt;&lt;/request&gt;&lt;/content&gt;&lt;/operation_in&gt;&lt;operation_out&gt;&lt;operation_out&gt;&lt;service_name&gt;BSM_SaleSystemLogin&lt;/service_name&gt;&lt;request_type&gt;1002&lt;/request_type&gt;&lt;sysfunc_id&gt;91008027&lt;/sysfunc_id&gt;&lt;request_seq&gt;154200622111&lt;/request_seq&gt;&lt;response_time&gt;20181112150342&lt;/response_time&gt;&lt;response_seq&gt;471860579309&lt;/response_seq&gt;&lt;request_source&gt;304147&lt;/request_source&gt;&lt;response&gt;&lt;resp_type&gt;0&lt;/resp_type&gt;&lt;resp_code&gt;0000&lt;/resp_code&gt;&lt;resp_desc/&gt;&lt;/response&gt;&lt;content&gt;&lt;response&gt;&lt;base_info&gt;&lt;verifycode&gt;173616671275425657328820&lt;/verifycode&gt;&lt;operator_id&gt;132394&lt;/operator_id&gt;&lt;row&gt;&lt;msisdn&gt;13666945211&lt;/msisdn&gt;&lt;role_id&gt;6100004&lt;/role_id&gt;&lt;owning_mode&gt;1&lt;/owning_mode&gt;&lt;status&gt;1&lt;/status&gt;&lt;inure_time&gt;20170623145448&lt;/inure_time&gt;&lt;expire_time&gt;30000101000000&lt;/expire_time&gt;&lt;request_source&gt;0&lt;/request_source&gt;&lt;modify_time&gt;20170623145448&lt;/modify_time&gt;&lt;modify_operator_id&gt;4020205&lt;/modify_operator_id&gt;&lt;modify_content&gt;创建手机号码与角色对应关系 grok解析 %{TIMESTAMP_ISO8601:log_time} %{DATA:serial_number} [%{DATA:log_level}] %{GREEDYDATA:message}%{DATA:service_name} %{DATA:sysfunc_id}%{DATA:other}%{DATA:organ_id}%{DATA:request_time}%{DATA:request_seq}%{DATA:other} 解析结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&#123; \"log_time\": [ [ \"2018-11-12 15:03:41.388\" ] ], \"YEAR\": [ [ \"2018\" ] ], \"MONTHNUM\": [ [ \"11\" ] ], \"MONTHDAY\": [ [ \"12\" ] ], \"HOUR\": [ [ \"15\", null ] ], \"MINUTE\": [ [ \"03\", null ] ], \"SECOND\": [ [ \"41.388\" ] ], \"ISO8601_TIMEZONE\": [ [ null ] ], \"serial_number\": [ [ \"639211542011357848 \" ] ], \"log_level\": [ [ \"DEBUG\" ] ], \"message\": [ [ \" com.base.core.aop.http.HttpClient.send(HttpClient.java:128) - reqid:b7fb8f90ddeb11e83d622c02b34132f7;AOP 发送信息: &lt;?xml version=\"1.0\" encoding=\"GBK\"?&gt; &lt;operation_in\" ] ], \"service_name\": [ [ \"BSM_SaleSystemLogin\" ] ], \"sysfunc_id\": [ [ \"91008027\" ] ], \"other\": [ [ \"1002&lt;/request_type&gt;&lt;verify_code&gt;304147201506190000000040&lt;/verify_code&gt;&lt;operator_id&gt;9991445\", \"304147&lt;/request_source&gt;&lt;request_target&gt;&lt;/request_target&gt;&lt;msg_version&gt;0100&lt;/msg_version&gt;&lt;cont_version&gt;0100&lt;/cont_version&gt;&lt;access_token&gt;&lt;/access_token&gt;&lt;content&gt;&lt;request&gt;&lt;msisdn&gt;13666945211&lt;/msisdn&gt;&lt;password&gt;871221&lt;/password&gt;&lt;portal_id&gt;101704&lt;/portal_id&gt;&lt;login_type&gt;34&lt;/login_type&gt;&lt;machine_mac&gt;0000&lt;/machine_mac&gt;&lt;machine_ip&gt;120.33.230.198, 10.46.161.182, &lt;/machine_ip&gt;&lt;machine_cpu&gt;&lt;/machine_cpu&gt;&lt;machine_system_ver&gt;12.0.1&lt;/machine_system_ver&gt;&lt;machine_totalmemory&gt;&lt;/machine_totalmemory&gt;&lt;machine_usablememory&gt;&lt;/machine_usablememory&gt;&lt;machine_ie_ver&gt;&lt;/machine_ie_ver&gt;&lt;/request&gt;&lt;/content&gt;&lt;/operation_in&gt;\" ] ], \"organ_id\": [ [ \"9999997\" ] ], \"request_time\": [ [ \"20181112150341\" ] ], \"request_seq\": [ [ \"154200622111\" ] ]&#125; nginx的access.log一条请求就是一条交易量110.48.224.3 - - [12/Nov/2018:14:26:50 +0800] \"POST /o2o_usercenter_svc/remote/bsspInvokeService?req_sid=9c5d5600e64311e808a886c802c592cb&amp;syslogid=null HTTP/1.1\" 200 234 \"-\" \"Java/1.7.0_21\" grok解析 %{IPORHOST:ip} - %{DATA:data} [%{HTTPDATE:timestamp}] \\”%{WORD:method} %{DATA:nginx_access_url} HTTP/%{NUMBER:ngnix_access_http_version}\\” %{NUMBER:nginx_access_response_code} %{NUMBER:nginx_access_body_sent_bytes} \\”%{DATA:nginx_access_referrer]}\\” \\”%{DATA:nginx_access_agent}\\” 解析结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&#123; &#123; &quot;ip&quot;: [ [ &quot;10.48.224.3&quot; ] ], &quot;HOSTNAME&quot;: [ [ &quot;10.48.224.3&quot; ] ], &quot;IP&quot;: [ [ null ] ], &quot;IPV6&quot;: [ [ null ] ], &quot;IPV4&quot;: [ [ null ] ], &quot;data&quot;: [ [ &quot;-&quot; ] ], &quot;timestamp&quot;: [ [ &quot;12/Nov/2018:14:26:50 +0800&quot; ] ], &quot;MONTHDAY&quot;: [ [ &quot;12&quot; ] ], &quot;MONTH&quot;: [ [ &quot;Nov&quot; ] ], &quot;YEAR&quot;: [ [ &quot;2018&quot; ] ], &quot;TIME&quot;: [ [ &quot;14:26:50&quot; ] ], &quot;HOUR&quot;: [ [ &quot;14&quot; ] ], &quot;MINUTE&quot;: [ [ &quot;26&quot; ] ], &quot;SECOND&quot;: [ [ &quot;50&quot; ] ], &quot;INT&quot;: [ [ &quot;+0800&quot; ] ], &quot;method&quot;: [ [ &quot;POST&quot; ] ], &quot;nginx_access_url&quot;: [ [ &quot;/o2o_usercenter_svc/remote/bsspInvokeService?req_sid=9c5d5600e64311e808a886c802c592cb&amp;syslogid=null&quot; ] ], &quot;ngnix_access_http_version&quot;: [ [ &quot;1.1&quot; ] ], &quot;BASE10NUM&quot;: [ [ &quot;1.1&quot;, &quot;200&quot;, &quot;234&quot; ] ], &quot;nginx_access_response_code&quot;: [ [ &quot;200&quot; ] ], &quot;nginx_access_body_sent_bytes&quot;: [ [ &quot;234&quot; ] ], &quot;nginx_access_referrer]&quot;: [ [ &quot;-&quot; ] ], &quot;nginx_access_agent&quot;: [ [ &quot;Java/1.7.0_21&quot; ] ]&#125; nginx error日志解析12018/11/01 23:30:39 [error] 15105#0: *397937824 connect() failed (111: Connection refused) while connecting to upstream, client: 10.48.224.3, server: 127.0.0.1, request: \"POST /o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null HTTP/1.1\", upstream: \"http://127.0.0.1:8082/o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null\", host: \"10.46.148.155:9090\" grok解析 (?%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) [%{LOGLEVEL:severity}] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?%{IP}|%{HOSTNAME}))(?:, server: %{IPORHOST:server}?)(?:, request: %{QS:request})?(?:, upstream: (?\\”%{URI}\\”|%{QS}))?(?:, host: %{QS:request_host})?(?:, referrer: \\”%{URI:referrer}\\”)? 解析结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200&#123; &quot;timestamp&quot;: [ [ &quot;2018/11/01 23:30:39&quot; ] ], &quot;YEAR&quot;: [ [ &quot;2018&quot; ] ], &quot;MONTHNUM&quot;: [ [ &quot;11&quot; ] ], &quot;MONTHDAY&quot;: [ [ &quot;01&quot; ] ], &quot;TIME&quot;: [ [ &quot;23:30:39&quot; ] ], &quot;HOUR&quot;: [ [ &quot;23&quot; ] ], &quot;MINUTE&quot;: [ [ &quot;30&quot; ] ], &quot;SECOND&quot;: [ [ &quot;39&quot; ] ], &quot;severity&quot;: [ [ &quot;error&quot; ] ], &quot;pid&quot;: [ [ &quot;15105&quot; ] ], &quot;NUMBER&quot;: [ [ &quot;0&quot; ] ], &quot;BASE10NUM&quot;: [ [ &quot;0&quot; ] ], &quot;errormessage&quot;: [ [ &quot;*397937824 connect() failed (111: Connection refused) while connecting to upstream&quot; ] ], &quot;remote_addr&quot;: [ [ &quot;10.48.224.3&quot; ] ], &quot;IP&quot;: [ [ &quot;10.48.224.3&quot;, null, null, null ] ], &quot;IPV6&quot;: [ [ null, null, null, null ] ], &quot;IPV4&quot;: [ [ &quot;10.48.224.3&quot;, null, null, null ] ], &quot;HOSTNAME&quot;: [ [ null, &quot;127.0.0.1&quot;, &quot;127.0.0.1&quot;, null ] ], &quot;server&quot;: [ [ &quot;127.0.0.1&quot; ] ], &quot;request&quot;: [ [ &quot;&quot;POST /o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null HTTP/1.1&quot;&quot; ] ], &quot;QUOTEDSTRING&quot;: [ [ &quot;&quot;POST /o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null HTTP/1.1&quot;&quot;, null, &quot;&quot;10.46.148.155:9090&quot;&quot; ] ], &quot;upstream&quot;: [ [ &quot;&quot;http://127.0.0.1:8082/o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null&quot;&quot; ] ], &quot;URI&quot;: [ [ &quot;http://127.0.0.1:8082/o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null&quot; ] ], &quot;URIPROTO&quot;: [ [ &quot;http&quot;, null ] ], &quot;USER&quot;: [ [ null, null ] ], &quot;USERNAME&quot;: [ [ null, null ] ], &quot;URIHOST&quot;: [ [ &quot;127.0.0.1:8082&quot;, null ] ], &quot;IPORHOST&quot;: [ [ &quot;127.0.0.1&quot;, null ] ], &quot;port&quot;: [ [ &quot;8082&quot;, null ] ], &quot;URIPATHPARAM&quot;: [ [ &quot;/o2o_usercenter_svc/remote/sysUserInfoService?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null&quot;, null ] ], &quot;URIPATH&quot;: [ [ &quot;/o2o_usercenter_svc/remote/sysUserInfoService&quot;, null ] ], &quot;URIPARAM&quot;: [ [ &quot;?req_sid=1612e430ddeb11e83d622c02b34132f7&amp;syslogid=null&quot;, null ] ], &quot;QS&quot;: [ [ null ] ], &quot;fire_wall_ip&quot;: [ [ &quot;&quot;10.46.148.155:9090&quot;&quot; ] ], &quot;referrer&quot;: [ [ null ] ]&#125;","categories":[{"name":"工作","slug":"工作","permalink":"http://lvshen9.gitee.io/categories/工作/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://lvshen9.gitee.io/tags/ELK/"},{"name":"grok","slug":"grok","permalink":"http://lvshen9.gitee.io/tags/grok/"},{"name":"logstash","slug":"logstash","permalink":"http://lvshen9.gitee.io/tags/logstash/"}]},{"title":"我在github上面的一个项目————用Python爬取12306火车票","slug":"1","date":"2019-01-11T08:19:56.000Z","updated":"2019-02-19T08:03:31.305Z","comments":true,"path":"2019/01/11/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/01/11/1/","excerpt":"github地址：Scrapy-Tickets-Python 运行示例这是一个爬取火车票的python代码，先上效果图：","text":"github地址：Scrapy-Tickets-Python 运行示例这是一个爬取火车票的python代码，先上效果图： 工程目录 如上图：color_set.py是用来设置字体颜色的。 里面设置了红色和黄色的字体。 Creat_set.py是用来创建字典的。 在浏览器里面可以输入上面那串url。 经过Creat_station.py处理，结果数据在station.py文件中 下面是信息初始化的代码。 代码中的url可能会变化，需要作相应的调整。 然后是我们主体的程序。 显示票价及相关信息 最后就是最前面的结果啦 年底了，不知各位有没有抢到票呢，反正我是抢到了😀 欢迎关注我的博客：Lvshen’s Blog 备用博客：Lvshen’s Blog 备用","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"github","slug":"github","permalink":"http://lvshen9.gitee.io/tags/github/"},{"name":"Python","slug":"Python","permalink":"http://lvshen9.gitee.io/tags/Python/"},{"name":"爬取","slug":"爬取","permalink":"http://lvshen9.gitee.io/tags/爬取/"}]},{"title":"浅谈分布式消息技术 Kafka","slug":"1","date":"2019-01-10T11:33:45.000Z","updated":"2019-01-17T07:16:51.169Z","comments":true,"path":"2019/01/10/1/","link":"","permalink":"http://lvshen9.gitee.io/2019/01/10/1/","excerpt":"This is kafka 本文转载自 浅谈分布式消息技术 Kafka Kafka的基本介绍Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。主要应用场景是：日志收集系统和消息系统。 Kafka主要设计目标如下：以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。同时支持离线数据处理和实时数据处理。","text":"This is kafka 本文转载自 浅谈分布式消息技术 Kafka Kafka的基本介绍Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。主要应用场景是：日志收集系统和消息系统。 Kafka主要设计目标如下：以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。同时支持离线数据处理和实时数据处理。 Kafka的设计原理分析 kafka总体结构 一个典型的kafka集群中包含若干producer，若干broker，若干consumer，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。 Kafka专用术语：- Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。- Topic：一类消息，Kafka集群能够同时负责多个topic的分发。- Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。- Segment：partition物理上由多个segment组成。- offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息。- Producer：负责发布消息到Kafka broker。- Consumer：消息消费者，向Kafka broker读取消息的客户端。- Consumer Group：每个Consumer属于一个特定的Consumer Group。#### Kafka数据传输的事务特点- at most once：最多一次，这个和JMS中”非持久化”消息类似，发送一次，无论成败，将不会重发。消费者fetch消息，然后保存offset，然后处理消息；当client保存offset之后，但是在消息处理过程中出现了异常，导致部分消息未能继续处理。那么此后”未处理”的消息将不能被fetch到，这就是”at most once”。- at least once：消息至少发送一次，如果消息未能接受成功，可能会重发，直到接收成功。消费者fetch消息，然后处理消息，然后保存offset。如果消息处理成功之后，但是在保存offset阶段zookeeper异常导致保存操作未能执行成功，这就导致接下来再次fetch时可能获得上次已经处理过的消息，这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态。- exactly once：消息只会发送一次。kafka中并没有严格的去实现（基于2阶段提交），我们认为这种策略在kafka中是没有必要的。 通常情况下”at-least-once”是我们首选。#### Kafka消息存储格式##### Topic &amp; Partition一个topic可以认为一个一类消息，每个topic将被分成多个partition，每个partition在存储层面是append log文件。 kafka的topic与partition 在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。 每个partion（目录）相当于一个巨型文件被平均分配到多个大小相等segment（段）数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。 每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。 这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。 segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件. segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。 存储文件 segment中index与data file对应关系物理结构如下： 上图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message（在全局partiton表示第368772个message），以及该消息的物理偏移地址为497。 了解到segment data file由许多message组成，下面详细说明message物理结构如下： 参数说明： 关键字 解释说明 8 byte offset 在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message 4 byte message size message大小 4 byte CRC32 用crc32校验message 1 byte “magic” 表示本次发布Kafka服务程序协议版本号 1 byte “attributes” 表示为独立版本、或标识压缩类型、或编码类型。 4 byte key length 表示key的长度,当key为-1时，K byte key字段不填 K byte key 可选 value bytes payload 表示实际消息数据。 副本（replication）策略Kafka的高可靠性的保障来源于其健壮的副本（replication）策略。 1) 数据同步 kafka在0.8版本前没有提供Partition的Replication机制，一旦Broker宕机，其上的所有Partition就都无法提供服务，而Partition又没有备份数据，数据的可用性就大大降低了。所以0.8后提供了Replication机制来保证Broker的failover。引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。 2) 副本放置策略 为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。Kafka分配Replica的算法如下： 将所有存活的N个Brokers和待分配的Partition排序 将第i个Partition分配到第(i mod n)个Broker上，这个Partition的第一个Replica存在于这个分配的Broker上，并且会作为partition的优先副本 将第i个Partition的第j个Replica分配到第((i + j) mod n)个Broker上假设集群一共有4个brokers，一个topic有4个partition，每个Partition有3个副本。下图是每个Broker上的副本分配情况。 3) 同步策略 Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少，Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。 一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。为了提高性能，每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中。因此，对于已经commit的消息，Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费。 Consumer读消息也是从Leader读取，只有被commit过的消息才会暴露给Consumer。Kafka Replication的数据流如下图所示： 对于Kafka而言，定义一个Broker是否“活着”包含两个条件： 一是它必须维护与ZooKeeper的session（这个通过ZooKeeper的Heartbeat机制来实现）。 二是Follower必须能够及时将Leader的消息复制过来，不能“落后太多”。 Leader会跟踪与其保持同步的Replica列表，该列表称为ISR（即in-sync Replica）。如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除。这里所描述的“落后太多”指Follower复制的消息落后于Leader后的条数超过预定值或者Follower超过一定时间未向Leader发送fetch请求。 Kafka只解决fail/recover，一条消息只有被ISR里的所有Follower都从Leader复制过去才会被认为已提交。这样就避免了部分数据被写进了Leader，还没来得及被任何Follower复制就宕机了，而造成数据丢失（Consumer无法消费这些数据）。而对于Producer而言，它可以选择是否等待消息commit。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。 4) leader选举 Leader选举本质上是一个分布式锁，有两种方式实现基于ZooKeeper的分布式锁： 节点名称唯一性：多个客户端创建一个节点，只有成功创建节点的客户端才能获得锁 临时顺序节点：所有客户端在某个目录下创建自己的临时顺序节点，只有序号最小的才获得锁 Majority Vote的选举策略和ZooKeeper中的Zab选举是类似的，实际上ZooKeeper内部本身就实现了少数服从多数的选举策略。kafka中对于Partition的leader副本的选举采用了第一种方法：为Partition分配副本，指定一个ZNode临时节点，第一个成功创建节点的副本就是Leader节点，其他副本会在这个ZNode节点上注册Watcher监听器，一旦Leader宕机，对应的临时节点就会被自动删除，这时注册在该节点上的所有Follower都会收到监听器事件，它们都会尝试创建该节点，只有创建成功的那个follower才会成为Leader（ZooKeeper保证对于一个节点只有一个客户端能创建成功），其他follower继续重新注册监听事件。 Kafka消息分组，消息消费原理同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。 这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。 Push vs. Pull作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。 push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。 对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 Kafak顺序写入与数据读取生产者（producer）是负责向Kafka提交数据的，Kafka会把收到的消息都写入到硬盘中，它绝对不会丢失数据。为了优化写入速度Kafak采用了两个技术，顺序写入和MMFile。 顺序写入因为硬盘是机械结构，每次读写都会寻址，写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最“讨厌”随机I/O，最喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。 每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高。 对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka是不会删除数据的，它会把所有的数据都保留下来，每个消费者（Consumer）对每个Topic都有一个offset用来表示读取到了第几条数据。 即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高I/O效率。 在Linux Kernal 2.2之后出现了一种叫做“零拷贝(zero-copy)”系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存空间的直接映射，数据不再复制到“用户态缓冲区”系统上下文切换减少2次，可以提升一倍性能。 通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存）。使用这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。） 消费者（读取数据）试想一下，一个Web Server传送一个静态文件，如何优化？答案是zero copy。传统模式下我们从硬盘读取一个文件是这样的。 先复制到内核空间（read是系统调用，放到了DMA，所以用内核空间），然后复制到用户空间（1、2）；从用户空间重新复制到内核空间（你用的socket是系统调用，所以它也有自己的内核空间），最后发送给网卡（3、4）。 Zero Copy中直接从内核空间（DMA的）到内核空间（Socket的），然后发送网卡。这个技术非常普遍，Nginx也是用的这种技术。 实际上，Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把“文件”发送给消费者。当不需要把整个文件发出去的时候，Kafka通过调用Zero Copy的sendfile这个函数，这个函数包括： out_fd作为输出（一般及时socket的句柄） in_fd作为输入文件句柄 off_t表示in_fd的偏移（从哪里开始读取） size_t表示读取多少个 「 浅谈大规模分布式系统中那些技术点」系列文章： 浅谈分布式事务 浅谈分布式服务协调技术 Zookeeper Reference http://www.cnblogs.com/liuming1992/p/6423007.html http://blog.csdn.net/lifuxiangcaohui/article/details/51374862 http://www.jasongj.com/2015/01/02/Kafka深度解析 http://www.infoq.com/cn/articles/kafka-analysis-part-2 http://zqhxuyuan.github.io/2016/02/23/2016-02-23-Kafka-Controller https://tech.meituan.com/kafka-fs-design-theory.html https://my.oschina.net/silence88/blog/856195 https://toutiao.io/posts/508935/app_preview","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://lvshen9.gitee.io/tags/分布式/"},{"name":"kafka","slug":"kafka","permalink":"http://lvshen9.gitee.io/tags/kafka/"}]},{"title":"Log4X统一日志平台部署记录","slug":"Log4X统一日志平台部署记录","date":"2018-11-28T03:40:59.000Z","updated":"2018-12-03T02:56:42.819Z","comments":true,"path":"2018/11/28/Log4X统一日志平台部署记录/","link":"","permalink":"http://lvshen9.gitee.io/2018/11/28/Log4X统一日志平台部署记录/","excerpt":"author: made by lvshen Log4X平台介绍Log4X是负责实现日志采集、分析、展示的产品。针对分布式系统环境下的分散日志，进行记中存储、分析以及运用的日志管理平台。","text":"author: made by lvshen Log4X平台介绍Log4X是负责实现日志采集、分析、展示的产品。针对分布式系统环境下的分散日志，进行记中存储、分析以及运用的日志管理平台。 web页面展示 web页面缩略图 架构图 log4x架构图 如上图是数据的流向架构图。 Log4x的客户端，通过Agent和Client将采集部分代码通过字节码增强或者植入代码到应用服务（APP&amp;WEB）系统中，完成数据的采集，并发送到kafka，属于日志采集模块；以Strom集群作为实时流处理的核心系统，完成Trace日志的处理、统计和预警功能，并将数据存储于Hbase和RDBMS中，属于日志分析模块子系统；日志应用服务器完成日志统计结果的查询和搜索，通过CSF框架提供数据供web端展现，属于日志可视化子系统。 APP应用端部署添加jar包为了获取APP的日志以及调用链等数据，这里CRM应用需要做一些配置。在deploy用户下，路径：deploy@10.242.219.49:/home/deploy/subversion/library/wadelib/common/lib/需要添加Log4X相关的jar包 1234567slf4j-log4j12-1.7.6.jar slf4j-api-1.7.6.jar scala-library-2.11.7.jarlog4x-appender-1.0.1.jar log4x-client-3.0.0.jar log4x-common-1.0.0.jarlog4x-logging-1.0.0.jar snakeyaml-1.17.jar snappy-java-1.1.1.7.jarjackson-databind-2.7.5.jar jackson-core-2.7.5.jar jackson-annotations-2.7.5.jardisruptor-3.3.6.jar metrics-core-2.2.0.jar log4j-1.2.17.jarkafka-clients-0.8.2.2.jar kafka_2.11-0.8.2.2.jar commons-dbcp-1.4.jarcommons-pool-1.5.4.jar 修改配置文件log4j.properties路径：deploy@10.242.219.49:/home/deploy/subversion/runtime-config/app/config/ 需要添加log4x的日志采集： log4x日志开关 log4x其他配置： log4x其他配置 新增log4x.yaml新增文件有几个地方需要注意： 123456789101112131415161718192021222324252627282930313233343536#log4x相关功能开启traceEnabled: truelogEnabled: truemetricEnabled: true...#kafka相关topic创建producerType: kafkamessage: default: topic: LOG4X-MSG-TOPIC # file|discard bufferFullPolicy: discard trace: topic: LOG4X-TRACE-TOPIC sampleRatio: 1 # file|discard bufferFullPolicy: discard log: topic: LOG4X-LOG-TOPIC metric: topic: LOG4X-METRIC-TOPIC #添加WADE框架的线程 thread: enabled: true category: - name: Wade pattern: 'wade-container'#kafka地址配置kafka: default: bootstrap.servers: 10.242.219.49:9092#文件存储地址 $&#123;user.home&#125;=/home/app/supportfile: dataDir: \"$&#123;user.home&#125;/log4x/data\" 至此deploy用户配置结束 app用户配置登陆app用户，在/home/app/sbin/setEnv.sh文件中添加： 1JAVA_OPTS=\"$JAVA_OPTS -javaagent:$&#123;HOME&#125;/support/agent/log4x-agent.jar\" 在/home/app/support路径下添加：agent客户端（由log4x方提供），agent目录如下： agent目录 这里有一个aif-log4x-adapter-srd-5.5.0.jar是我们为了获取调用链而写的埋点类。下面介绍下埋点方法 app应用埋点首先需要到http://git.wadecn.com:18082/wade-root.git上下载埋点的示例代码，比如给WADE框架里的`Hessian2Server.java`的`doService()`方法埋点获取调用服务名的链。 埋点规则1231. 适配器的包路径必须以: com.ai.aif.log4x.agent.trans.adapter.impl 开头。2. com.ai.aif.log4x.agent.trans.adapter.impl 后续路径作为tag标识，配置于log4x-agent.json。3. 适配器类名的命名规则: 被埋点的类 + &quot;Adapter&quot; 埋点示例12345678910111213141516171819202122232425262728293031323334353637public class Hessian2ServerAdapter extends AbsJavassistSwitchAdapter &#123; @Override public String[] getInjectedMethodHeaders() &#123; return new String[]&#123; \"private com.ailk.common.data.IDataOutput doService(com.ailk.common.data.IDataInput input)\" &#125;; &#125; @Override public String addBeforeInvoke(CtMethod ctMethod) &#123; WrappedStringBuilder buf = new WrappedStringBuilder(); buf.appendln(\"com.ai.aif.log4x.message.format.Trace trace = com.ai.aif.log4x.Log4xManager.client().getTrace();\"); /*buf.appendln(\"trace.setCallType(\\\"CSF\\\");\");*/ buf.appendln(\"trace.setCallType(\\\"APP\\\");\"); buf.appendln(\"trace.setServiceName($1.getHead().getString(com.ailk.common.Constants.X_TRANS_CODE));\"); buf.appendln(\"com.ai.aif.log4x.Log4xManager.client().startTrace(trace);\"); return buf.toString(); &#125; @Override public String addAfterInvoke(CtMethod ctMethod, String retType, String retName) &#123; WrappedStringBuilder buf = new WrappedStringBuilder(); buf.appendln(\"com.ai.aif.log4x.Log4xManager.client().finishTrace(true);\"); return buf.toString(); &#125; @Override public String addInExceptionCatch(CtMethod ctMethod, String exName, String exValue) &#123; WrappedStringBuilder buf = new WrappedStringBuilder(); buf.appendln(\"trace.setRetCode(\\\"-1\\\");\"); buf.appendln(\"trace.setRetMsg(\\\"failed\\\");\"); buf.appendln(\"trace.setThrowable(\" + exValue + \");\"); buf.appendln(\"com.ai.aif.log4x.Log4xManager.client().finishTrace(false);\"); return buf.toString(); &#125;&#125; 埋点要点 埋点要点 这里解释下获取怎么服务名：我们翻开Hessian2Server.doService(): 1234567private IDataOutput doService(IDataInput input) &#123; ... IData head = input.getHead(); ... String serviceName = head.getString(Constants.X_TRANS_CODE); ...&#125; 这里获取服务名需要用到方法的第一个参数input，所以使用$1。编译打包。 埋点打包 log4x-agent.json文件配置app用户下，路径：/home/app/support/agent/log4x-agent.json,添加埋点的路径。 log4x-agent.json文件配置 然后就可以发布APP了 中间件部署版本要求123hadoop:2.8.4 jstorm:2.2.1 zookeeper:3.4.8hbase :1.2.6.1 es :5.6.9 kafka :0.9.0.1tomcat:7.0.91 这里版本一定要一致，不然会出现很多问题，如：es版本导致log4x界面图表不能显示，SQL无法统计；zk版本问题导致JStorm无法连接上zk，JStorm版本问题导致数据进不了es等等。 软件安装目录 log4x安装目录 如上图：bin目录下面的脚本为中间件的启停脚本，data目录下存放个中间件数据，logs目录下存放日志，support目录存放安装的中间件。 support目录 中间件目录 es2.4.1这里弃用。下面讲讲各软件的部署。我们根据数据传输顺序讲解 JDK部署jdk解压目录如下： jdk目录 .bash_profile文件修改 环境变量文件 Kafka部署文件目录kafka目录如下： kafka目录 配置server.properties这里也只需要修改配置文件 vi ~/support/kafka/server.properties 123456789101112131415161718############################# Socket Server Settings ############################## The port the socket server listens onbroker.id=1port=9092# Hostname the broker will bind to. If not set, the server will bind to all interfaceshost.name=10.242.219.49#advertised.host.name=10.173.245.214#advertised.port=9092...############################# Log Basics ############################## A comma seperated list of directories under which to store log fileslog.dirs=/home/log4x/logs/kafkanum.partitions=1...############################# Zookeeper #############################zookeeper.connect=10.242.219.49/kafka# Timeout in ms for connecting to zookeeper... 启动进程与数据展示执行/home/log4x/bin/start-kafka.sh即可启动kafka。这里就会自动创建好我们之前在log4x.yaml里面配置的topic。比如我们想查询APP的callType。查询语句如下： 1./kafka-console-consumer.sh --zookeeper 10.242.219.49:2181/kafka --from-beginning --topic LOG4X-TRACE-TOPIC | grep '\"callType\":\"APP\"' 就会返还数据： kafka消费者数据查询 也可以打开Kafka Consumer Offset Monitor的web监控界面： kafka的web监控 如上图，显示随时间数据的消费曲线。 JStorm部署文件目录Jstorm目录如下： JStorm目录 这里这个log4x目录需要自己创建，把log4x开发好的log4x-jstorm-3.0.0.jar放入~/support/jstorm/log4x/lib/下，用于jstorm拓扑启动worker时加载。 配置.bash_profile添加环境变量 12vi ~/.bash_profileexport JSTORM_HOME=/home/log4x/support/jstorm 配置storm.yaml这里需要修改配置文件~/support/jstorm/conf，storm.yaml文件： 123456789101112########### These MUST be filled in for a storm configuration storm.zookeeper.servers: - \"10.242.219.49\" storm.zookeeper.port: 2281 storm.zookeeper.root: \"/jstorm\" nimbus.host: 10.242.219.49 cluster.name: \"log4x-storm-cluster\" # %JSTORM_HOME% is the jstorm home directory storm.local.dir: \"/home/log4x/data/jstorm/data\" # please set absolute path, default path is JSTORM_HOME/logs jstorm.log.dir: \"/home/log4x/logs/jstorm\" ... 配置log4x.jstorm.yaml此外还需要修改log4x.jstorm.yaml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115...#数据库连接配置四件套jdbc.driver: \"com.mysql.jdbc.Driver\"jdbc.url: \"jdbc:mysql://10.242.219.49:3306/log4x?allowMultiQueries=true&amp;amp;useSSL=false\"jdbc.username: \"root\"jdbc.password: \"root\"...#使用jstorm使用的zookeeper配置zookeeper: server.list: \"10.242.219.49:2181\" #在zookeeper中使用的根目录 log4x base.path: \"/log4x\"...#Hbase数据库配置hbase: #Hbase本地缓存入库的间隔时间，即每过间隔时间，会执行一次入库 flush.period.ms: 10000 #Hbase默认配置 default: #Hbase表的命名空间 namespace: \"cx_log4x\" #配置数据存活时间，用于HBase表创建 ttl: 86400 #Hbase使用Zookeeper配置 zookeeper: server.list: \"10.242.219.49:2181\" ...#Kafka配置，各类型数据可分开使用kafka，不定义及使用default默认kafka: #Kafka根目录 broker.zk.path: \"/kafka/brokers\" #jstorm消费的offset记录位置 consumer.zk.root: \"/log4x/consumer\" #默认使用的Zookeeper配置 default: zookeeper: server.list: \"10.242.219.49:2181\" ... topic: \"LOG4X-MSG-TOPIC\" #链路日志Kafka相关配置 trace: topic: \"LOG4X-TRACE-TOPIC\" #业务日志Kafka相关配置 log: topic: \"LOG4X-LOG-TOPIC\" #性能监控日志Kafka相关配置 metric: topic: \"LOG4X-METRIC-TOPIC\"#数据过滤配置，使用列表表示，每一个元素即为一个过滤器配置filters: #object为使用该过滤器配置的对象类 - object: \"AggregateBolt\" #配置过滤规则 rules: #该规则即要求callType字段匹配CSF值,如果有其他类型的callType，需要添加。如添加APP，SERVICE - callType: \"CSF,CSFClient,EJBCall,EJBProcess\" ps: \"true\" - object: \"TraceESBolt\" rules: #该规则即要求callType字段匹配CSF值或者JDBC值 - callType: \"CSF,JDBC\" ps: \"true\"#链路日志的处理映射trace.mapping: CEN: callType: \"CSF,CSFClient,EJBCall\" ps: \"true\" CHL: callType: \"CSF,CSFClient,EJBCall\" ps: \"true\" appName: callType: \"CSF\"...#预警相关配置alarm.window.step: 60...#ElasticSearch配置elasticsearch: #默认配置 default: #es集群名称 cluster.name: \"test185\" cluster.hosts: \"10.242.219.49:9200\"... #es分片数 shards: 2 replicas: 0......#Jstorm初始化相关配置storm: #配置worker数量 worker.num: 1 #配置初始包路径，用于查找配置的component类 package: \"com.ai.aif.log4x.jstorm.storm\" topology: component: #括号里的数值为Spout或Bolt的并发处理数，根据机器数或集群数适当调整。 - \"TraceJsonSpout-1[2]\" - \"AggregateBolt-1[3]\" - \"TraceJsonSpout-2[2]\" - \"TraceESBolt-1[3]\" - \"MonitorBolt-1[1]\"...... 这个文件里需要连接的有：MySQL、kafka、HBase、Zookeeper、ElsaticSearch。三个点为为省略的内容。 启动进程进入~/bin下就可以启动start-jstorm-nimbus.sh，start-jstorm-supervisor.sh，start-jstorm-topology.sh。 我们jps命令监控进程： jstorm进程 安装JStormUI先执行命令： 12mkdir ~/.jstormcp ~/support/jstorm/conf/storm.yaml ~/.jstorm 然后将JStormUI的war包放入tomcat，即可在界面访问。 JStormUI HBase部署文件目录HBase目录如下： HBase目录 配置hbase-site.xmlvi ~/support/hbase/conf/hbase-site.xml 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;file:///home/log4x/data/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distrubuted&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;10.174.26.145&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.tmp.dir&lt;/name&gt; &lt;value&gt;/home/log4x/logs/hbase/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hbase-env.shvi ~/support/hbase/conf/hbase-env.sh 1export HBASE_MANAGES_ZK=false 进程启动与数据展示执行~/support/hbase/bin/start-hbase.sh。 jps查看 HBase进程 执行~/support/hbase/bin/hbase shell进入数据库，我们可以看到程序已建好的表： Hbase表.png web页面也能看到： hbase的web界面 这里需要提前创立表空间：cx_log4x hbase常用命令（需要进入hbase shell）: 1234567891011121314151617#hbase创建表空间create_namespace 'cx_log4x'#列出表明&gt;list#统计表的记录条数&gt; count 'cx_log4x:WEB'#查看表的数据，使用指定的时间范围和返回10条。&gt; scan 'cx_log4x:SRV', &#123;LIMIT=&gt;10,TIMERANGE=&gt;[1495953605000,1496385605000]&#125;#创建表，base指列名，TTL是数据存活时间，单位秒。&gt; create 'cx_log4x:ESB', &#123;NAME =&gt; 'base',VERSIONS =&gt; 1, TTL =&gt; 7200, COMPRESSION =&gt; 'NONE'&#125;#清空表，清空表数据。&gt; truncate 'cx_log4x:WEB Hadoop部署如果hbase需要用到分布式文件系统HDFS作为存储，这里就需要部署hadoop。 文件目录hadoop目录如下： hadoop目录 配置core-site.xml修改配置文件：vi ~/support/hadoop/etc/hadoop/core-site.xml 123456789101112131415&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://10.242.219.49:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;10.242.219.49:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/log4x/logs/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xmlvi ~/support/hadoop/etc/hadoop/hdfs-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/log4x/data/hadoop/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/home/log4x/data/hadoop/datanode&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动进程启动之前，需要格式化文件系统 123456789cd ~/support/hadoop/bin./hadoop namenode -format./hadoop fs -mkdir /hbase./hadoop fs -chmod 777 /hbase./hadoop fs -ls /#下面为显示的结果Found 1 itemsdrwxrwxrwx - log4x supergroup 0 2018-10-24 12:02 /hbase 启动HDFS:~/support/hadoop/sbin/start-dfs.sh。 jps命令查看进程： HDFS进程 Elasticsearch部署文件目录es解压后的目录如下： es目录 配置elasticsearch.yml这里只需要修改配置文件elasticsearch.yml vi /home/log4x/support/elasticsearch/config/elasticsearch.yml 123456789node.name: log4x-escluster#node.attr.rack: r1path.data: /home/log4x/data/espath.logs: /home/log4x/logs/es...network.host: 10.242.219.49http.port: 9200...discovery.zen.ping.unicast.hosts: [\"10.242.219.49\"] 启动进程与数据展示执行/home/log4x/bin/start.es启动es 在Chrome浏览器上安装elasticsearch-head插件，就能图形化显示es的内容： es索引显示 如图，显示了几个索引，索引里面的数据需要通过kafka输送过来 es数据展示 之前我们埋点设置了APP类型的callType，只要kafka启动，jstorm启动，es里面就有APP类型的数据，查询步骤见上图。 Zookeeper部署创建myid首先在~/support/data/zk/下创建文件myid，里面写入1。 文件目录目录如下： zk目录 配置zoo.cfg修改配置文件：vi ~/support/zk/etc/zoo.cfg 123456789...# the directory where the snapshot is stored.dataDir=/home/log4x/data/zk...clientPort=2181minSessionTimeout=5000maxSessionTimeout=10000server.1=10.242.219.49:28880:38880 进程启动执行脚本 ~/bin/start-zk.sh web界面查看（自己部署的zkweb监控） zkweb界面 之前注册到zk的中间都有显示：jstorm，log4x，hbase，kafka LOG4X-WEB部署文件目录主目录如下： log4x-web主目录 其中bin目录放的启停脚本，deploy下方的log4x-web文件，support目录下面放的csfproxy，csfserver，tomcat 配置tomcat由于文件放在tomcat外面，需要配置vi ~/support/log4xweb/support/tomcat/conf/server.xml tomcat配置 还要修改log4x-web的服务地址。vi ~/support/log4xweb/deploy/log4x-web/WEB-INF/classes/config.properties 12service_http_ip=10.242.219.49service_http_port=12222 配置csfproxyvi ~/support/log4xweb/support/csfproxy/configext/log4x.properties 1234567891011121314...## file|kafka|msgFramemsg.sender=kafkamsg.sender.trace.topic=CRM-TRACE-TOPICmsg.sender.log.topic=CRM-LOG-TOPICmsg.sender.batch.size=1## Kafka settingskafka.metadata.broker.list=10.242.219.49:9092...## logfile settings, if msg.sender=filemsg.logfile.dir=/home/log4x/support/log4xweb/logs/csfproxymsg.logfile.maxFileSize=100... 配置csfserver修改log4x-service.yaml vi ~/support/log4xweb/support/csfserver/configext/log4x-service.yaml 1234567891011121314151617181920212223242526272829303132333435db:... jdbc.driver: com.mysql.jdbc.Driver jdbc.url: jdbc:mysql://10.242.219.49:3306/log4x?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true jdbc.username: root jdbc.password: root...hbase: hbase.row.max: 500 hbase.namespace: cx_log4x hbase.zookeeper: 10.242.219.49:2181 hbase.zookeeper.client: hbasees: cluster: - es.cluster.name: log4x es.url: http://10.242.219.49:9200 ... index.group: - topic: log4x_log cluster: log4x - topic: log4x_perf cluster: log4x - topic: log4x_trace cluster: log4x - topic: log4x_dict_spec_sql cluster: log4x...task: #服务同步任务 - task.name: serviceSync #是否开启 task.open: true #周期,每分钟同步一次 task.cron: \"0/30 * * * * ?\" ... 修改csf.xml vi ~/support/log4xweb/support/csfserver/configext/csf/csf.xml 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Csf&gt; &lt;Category name=\"client\" description=\"客户端运行引擎需要的配置\"&gt; ... &lt;Item name=\"zk.server.list\"&gt; &lt;value&gt;10.242.219.49:2181&lt;/value&gt; &lt;description&gt;多个地址用逗号(,)隔开 &lt;/description&gt; &lt;/Item&gt; ... &lt;/Category&gt; ...&lt;/Csf&gt; 修改defaults.xml vi ~/support/log4xweb/support/csfserver/configext/system/service/defaults.xml 1234567891011121314151617181920&lt;!-- 全局默认配置信息 --&gt;&lt;defaults&gt; ... &lt;!--默认数据源信息 --&gt; &lt;datasource&gt; &lt;!--映射每个DAO模块对应的操作数据源 --&gt; &lt;clazz name=\"com.ai.appframe2.complex.datasource.impl.LocalMutilDataSourceImpl\"&gt; &lt;property name=\"tableName\" value=\"cfg_db_acct\" /&gt; &lt;/clazz&gt; &lt;pool name=\"base\" primary=\"true\" type=\"SELF\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql://10.242.219.49:3306/log4x\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"root\" /&gt; ... ... &lt;/datasource&gt;&lt;/defaults&gt; 启动脚本cd ~/support/log4xweb/bin，依次启动： 1234./start-csfproxy.sh./start-csfserver.sh./start-task.sh./star-tomcat.sh MySQL部署初始化配置上面的应用需要用到MySQL数据库，这里讲讲怎么离线部署MySQL数据库。将下载好的mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz解压。目录如下： mysql目录 这里需要创建my.cnf文件。里面需要修改的内容： 123456789101112131415161718192021222324252627[client]default-character-set=utf8 [mysqld]datadir=/home/log4x/support/mysqlsocket=/home/log4x/data/mysqluser=mysqlport=3306bind-address=0.0.0.0#忽略表名大小写lower_case_table_names=1# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0#default-character-set=utf8character-set-server=utf8init_connect='SET NAMES utf8' [mysql]no-auto-rehashdefault-character-set=utf8 [mysqld_safe]log-error=/home/log4x/logs/mysql/mysqld.logpid-file=/home/log4x/support/mysql/mysqld.pidsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESlog_timestamps=SYSTEM 接下来需要安装，命令如下： 123456789101112131415161718192021222324252627282930313233343536373839#添加环境变量vi ~/.bash_profileexport MYSQL_HOME=/home/log4x/support/mysqlPATH=$MYSQL_HOME/bin:$PATH:$HOME/.local/bin:$HOME/binexport PATH#执行安装./mysqld --initialize --user=mysql --basedir=/home/log4x/support/mysql/ --datadir=/home/log4x/data/mysql --explicit_defaults_for_timestamp#服务启动(启动成功，会出现mysqld的服务，端口3306)cd ~/support/mysql/bin/./mysqld_safe --defaults-file=/home/log4x/support/mysql/my.cnf &amp;#mysql启停cd ~/support/mysql/binmysqld_safe&amp; --defaults-file=/app/mysql/mysql/my.cnf &amp; 启动mysqladmin shutdown -uroot -proot 停#开始不需要密码登陆[log4x@deploy bin]$ mysql -uroot -p 【注释，在下面的要求你输入密码的时候，你不用管，直接回车键一敲就过去了】Enter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 48Server version: 5.1.41-log Source distributionType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; use mysql;Database changed#设置密码mysql&gt;update mysql.user set authentication_string=password('root') where user='root' ;#创建用户CREATE USER 'log4x'@'%' IDENTIFIED BY 'password';#创建databaseCREATE DATABASE 'log4x'#导入数据（举例）source /home/log4x/support/mysql/sql/log4x_sql/mysql/*.sql 创建&amp;插入表数据需要插入如下图的表： mysql脚本 脚本执行顺序： 12341. appframe/appframe_create_table.sql2. table-mysql.sql3. uspa/uspa[1-8]4. initialdata.sql 进入mysql客户端： 123mysql -uroot -prootuse log4x;show table; mysql表整合 上图画红框的为jstorm创建的表，会以天为单位创建。 实例信息和服务信息的表的配置应用有多少个中心，首先就应该在l4x_stats_config表里面就要配多少个中心。这里配置多少个中心，对应log4x-web的界面上的首页-服务监控、服务排行榜、服务视图上就展示多少个中心。例如： 1INSERT INTO `l4x_stats_config` (`STATS_CONFIG_ID`, `STATS_TYPE_ID`, `STATS_CODE`, `STATS_NAME`, `STATE`, `SYS_CODE`, `STATS_DESC`, `STATS_TYPE_CODE`, `STATS_TYPE_NAME`) VALUES ('2', '1', 'OrderCentre', '订单中心', 'U', 'CRM', '', 'CEN', '中心'); log4x提供了一个同步服务信息的功能，会定时将表l4x_svc_cen_XXXX（日期格式为yyyyMMdd）有的，但是l4x_service_info没有记录的服务信息查询出来，然后根据`log4x-service.xml里面serviceSync标签配置的匹配规则，根据serviceCode找到对应的centerCode，然后将这条服务信息插入到l4x_service_info表格中。例如： 1INSERT INTO `l4x_service_info` (`SERVICE_INFO_ID`, `SERVICE_NAME`, `SERVICE_CODE`, `CENTER_CODE`, `SERVICE_INFO_DESC`, `STATE`, `SYS_CODE`, `SERVICE_TYPE`) VALUES ('42', 'OrderCentre.person.ISubscriberQuerySV.queryCentreInfo', 'OrderCentre.person.ISubscriberQuerySV.queryCentreInfo', 'OrderCentre', 'OrderCentre.person.ISubscriberQuerySV.queryCentreInfo', 'U', 'CRM', 'DEFAULT'); 需要对哪些应用实例进行监控，就应该在l4x_app_info表中配置这些实例的信息。在这里配置的实例信息，对应log4x-web的界面上的性能数据监控、实例统计都是可以看的到的，其中APP_NAME对应l4x_app_call_XX的TYPE_CODE字段。一般可以拿建设方案里面的主机配置excel表格导出来，导入到app info表里面去。例如： 1INSERT INTO `l4x_app_info` (`APP_ID`, `APP_NAME`, `HOST_NAME`, `HOST_IP`, `CENTER_CODE`, `CENTER_NAME`, `GROUP_NAME`, `SYS_CODE`, `SYS_NAME`) VALUES ('1', 'app-node01-srv01', 'app-node', '10.242.219.45', 'ord', '订单中心', 'app-node01', 'CRM', 'CRM'); 界面展示123#log4x 页面访问地址http://10.242.219.49:8080/log4x-web/homeadmin/log4x123!@# 业务办理轨迹查询如图显示调用链情况： 调用链显示情况 服务视图 服务运行详情 服务排行榜 服务排行榜 性能数据监控 性能数据监控 日志查询 日志监控 SQL统计 sql统计","categories":[{"name":"工作","slug":"工作","permalink":"http://lvshen9.gitee.io/categories/工作/"}],"tags":[{"name":"日志","slug":"日志","permalink":"http://lvshen9.gitee.io/tags/日志/"},{"name":"Log4X","slug":"Log4X","permalink":"http://lvshen9.gitee.io/tags/Log4X/"}]},{"title":"Redis3.0集群搭建","slug":"1","date":"2018-09-05T02:57:07.000Z","updated":"2019-01-17T07:08:26.489Z","comments":true,"path":"2018/09/05/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/09/05/1/","excerpt":"Redis3.0 及其之后的版本提供了redis-cluster 集群支持，用于在多个redis节点间共享数据，以提高服务的可用性。 构建 redis-cluster 集群可以通过 redis-trib.rb 工具来完成。redis-trib.rb 是redis官方提供的一个集群管理工具，集成在redis安装包的 src 目录下。redis-trib.rb 封装了redis提供的集群命令，使用简单、便捷。 因为 redis-trib.rb 是由ruby语言编写的，所以使用该工具需要ruby语言环境的支持。 12$ ruby -vruby 2.3.1p112 (2016-04-26) [x86_64-linux-gnu]","text":"Redis3.0 及其之后的版本提供了redis-cluster 集群支持，用于在多个redis节点间共享数据，以提高服务的可用性。 构建 redis-cluster 集群可以通过 redis-trib.rb 工具来完成。redis-trib.rb 是redis官方提供的一个集群管理工具，集成在redis安装包的 src 目录下。redis-trib.rb 封装了redis提供的集群命令，使用简单、便捷。 因为 redis-trib.rb 是由ruby语言编写的，所以使用该工具需要ruby语言环境的支持。 12$ ruby -vruby 2.3.1p112 (2016-04-26) [x86_64-linux-gnu] redis-cluster集群1、配置要启用redis-cluster集群，需要先修改redis配置文件集群配置部分的内容 redis.conf 1234567891011################################ REDIS CLUSTER ################################ 启用redis-cluster集群cluster-enabled yes# 集群节点配置文件# 该文件无需手工修改，由redis自动维护（创建和更新）# 需要注意，单机运行多实例时，确保该文件没有被其他实例覆盖（不允许重名）cluster-config-file nodes-6377.conf# 节点超时时长（毫秒）cluster-node-timeout 150001234567891011 为了方便进行演示，这里分别以端口 6377、6378、6379 各启用一个实例来代表不同的redis服务器 ps aux | grep redis 2、创建集群创建集群使用 redis-trib 的 create 命令完成，create 命令的格式为： 1create host1:port1 ... hostN:portN1 默认情况下，ruby 是无法识别redis的，直接执行 redis-trib.rb create IP:PORT 将会报错 1234$ ./redis-trib.rb create 192.168.206.128:6377 192.168.206.128:6378 192.168.206.128:6379/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:55:in `require': cannot load such file -- redis (LoadError) from /usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:55:in `require' from ./redis-trib.rb:25:in `&lt;main&gt;'1234 所以需要先为ruby安装redis第三方接口，执行命令 gem install redis 即可 12345678$ sudo gem install redis[sudo] password for zhangcs: Fetching: redis-4.0.1.gem (100%)Successfully installed redis-4.0.1Parsing documentation for redis-4.0.1Installing ri documentation for redis-4.0.1Done installing documentation for redis after 1 seconds1 gem installed12345678 此时再使用 create 就可以将6377、6378、6379 这3台服务器构建成一个集群了 创建集群 有一点需要注意的是，redis-cluster集群至少需要3个可用节点。 3、查看集群使用 info 命令指定集群上任一节点的地址便可以查看集群状态 集群状态 主从复制模型刚才说到，redis-cluster至少需要保证3个节点可用。那么为了避免节点宕机导致服务不可用，我们就需要添加主从配置，为集群中的节点增加从节点；使其在主节点宕机时，能够将从节点提升为主节点代替原来的主节点进行工作。 在非集群的单节点环境中，配置主从关系的方法大致有 2 种： 1、修改从服务器配置文件 redis.conf 的 slaveof &lt;masterip&gt; &lt;masterport&gt; 选项； 2、在从服务器上使用slaveof 命令直接指定主服务器。 然而在redis-cluster集群环境中，启用了cluster配置的情况下slaveof 是不可用的。 假定有 6381 服务器配置 slaveof 指定主服务器 6377 ，同时该服务器启用了redis-cluster配置 1234567################################# REPLICATION #################################slaveof 192.168.206.128 6377################################ REDIS CLUSTER ###############################cluster-enabled yescluster-config-file nodes-6381.confcluster-node-timeout 150001234567 那么此时 6381 端口的服务器将无法成功启动 12345$ ./redis-server /usr/local/redis/6381/redis.conf *** FATAL CONFIG FILE ERROR ***Reading the configuration file, at line 283&gt;&gt;&gt; 'slaveof 192.168.206.128 6377'slaveof directive not allowed in cluster mode12345 显然我们无法使用原有的主从配置方法对集群进行配置。此时我们需要借助于 redis-trib.rb 工具来进行从节点的添加操作，先将节点加入集群中，然后再声明节点为原有节点的从节点。 1、启用服务后先将该节点加入集群，直接使用redis-trib.rb的 add-node 命令即可实现： 1redis-trib add-node new_host:new_port existing_host:existing_port1 添加节点 此时通过 redis-trib info 能够查看到该节点已经成功加入了集群中，并且该节点并没有分配哈希槽 集群状态2 2、声明该节点为集群中某一节点的从节点，需要使用客户端进入该节点（此处即为新增的从节点 6381）进行设置，使用 cluster replicate 命令指定所属主节点ID。 主节点ID可以使用客户端连接到集群后通过命令 cluster nodes 查看 ： 节点信息 使用客户端连接新增的从节点 6381 ，指定主节点 6377 在集群中的ID ，声明为 6377 节点的从节点 123$ ./redis-cli -h 192.168.206.128 -c -p 6381192.168.206.128:6381&gt; cluster replicate e10dde558fb46fe8ae6fe66e54ef56032fbcce0fOK 至此就完成了集群中一个节点的主从配置，查看 6377 节点能够看到其包含一个从节点： 集群状态3 查询出 6377 端口服务对应的PID，然后通过 kill 将服务关闭，使该节点在集群上不可用；此时查看集群信息，能够发现从节点 6381 自动提升为主节点，顶替了不可用的 6377 节点。 关闭服务 集群状态4 重新启动已宕机的服务后，该节点将会被当做从节点添加到管理原先的哈希槽分配范围的节点上。这里也就是添加到了 6381 节点上，6381 节点管理的哈希槽就是原先由 6377 节点所管理的 重启宕机的服务器 客户端连接 redis-cluster客户端在连接 redis 服务器时带上参数 -c 即为连接到cluster集群 12345$ redis-cli -h 192.168.206.128 -c -p 6377192.168.206.128:6377&gt; set name zhangcs-&gt; Redirected to slot [5798] located at 192.168.206.128:6378OK192.168.206.128:6378&gt;12345 可以看到，在 6377 端口的服务器上存储一个string类型的键值对 name = zhangsan 的时，操作被重定向到了 6378 端口的服务器上，而 name = zhangsan 这个键值对最终也被存储在了 6378 端口的服务器里。 同理，在获取数据时，也会重定向到对应数据实际存储的服务器上，然后在该服务器上进行操作。 1234$ ./redis-cli -h 192.168.206.128 -c -p 6377192.168.206.128:6378&gt; get name\"zhangcs\"192.168.206.128:6378&gt;1234 单独连接集群上的节点需要注意的是，节点在加入集群后，如果不声明参数 -c 连接集群而是单独连接集群上的节点，那么在操作时如果需要重定向到其他的服务器，是无法成功重定向然后完成操作的。 例如键值对 name = zhangsan 存储在 6378 端口的服务器上，此时如果我们单独连接到 6377 端口的服务器上进行操作，那么该操作是无法成功的。 123456$ redis-cli -h 127.0.0.1 -p 6377127.0.0.1:6377&gt; get name(error) MOVED 5798 127.0.0.1:6378127.0.0.1:6377&gt; set name lisi(error) MOVED 5798 127.0.0.1:6378127.0.0.1:6377&gt;123456 而如果无需重定向，则能成功完成操作。 1234$ redis-cli -h 127.0.0.1 -p 6378127.0.0.1:6378&gt; get name\"zhangsan\"127.0.0.1:6378&gt;1234 Spring集成 redis-cluster1、连接池配置 12345678@Beanpublic JedisPoolConfig jedisPoolConfig() &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(100); jedisPoolConfig.setMaxIdle(10); jedisPoolConfig.setMaxWaitMillis(1500); return jedisPoolConfig;&#125; 2、JedisCluster对象配置 12345678910@Beanpublic JedisCluster jedisCluster() &#123; Set&lt;HostAndPort&gt; nodes = new HashSet&lt;HostAndPort&gt;(); nodes.add(new HostAndPort(\"192.168.206.128\", 6377)); nodes.add(new HostAndPort(\"192.168.206.128\", 6378)); nodes.add(new HostAndPort(\"192.168.206.128\", 6379)); nodes.add(new HostAndPort(\"192.168.206.128\", 6381)); JedisCluster jedisCluster = new JedisCluster(nodes, jedisPoolConfig()); return jedisCluster;&#125; 3、JedisCluster对象的使用 123456789101112131415@Autowiredprivate JedisCluster jedisCluster;@Testpublic void testCluster() &#123; Assert.assertNotNull(jedisCluster); String result = jedisCluster.set(\"name\", \"zhangsan\"); Assert.assertNotNull(result); Assert.assertEquals(\"OK\", result); String name = jedisCluster.get(\"name\"); Assert.assertNotNull(name); Assert.assertEquals(\"zhangsan\", name);&#125; spring-cache集成1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Configuration@ComponentScan(basePackages = &#123;\"org.pro.service\"&#125;)// 启用缓存@EnableCachingpublic class RootConfig &#123; /** * jedis连接池配置 * */ @Bean public JedisPoolConfig jedisPoolConfig() &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(1000); jedisPoolConfig.setMaxIdle(10); jedisPoolConfig.setMaxWaitMillis(1500); return jedisPoolConfig; &#125; /** * redis-cluster配置 * */ @Bean public RedisClusterConfiguration redisClusterConfiguration() &#123; RedisClusterConfiguration redisClusterConfiguration = new RedisClusterConfiguration(); Set&lt;RedisNode&gt; nodes = new HashSet&lt;&gt;(); nodes.add( new RedisNode(\"127.0.0.1\", 6377)); nodes.add( new RedisNode(\"127.0.0.1\", 6378)); nodes.add( new RedisNode(\"127.0.0.1\", 6379)); redisClusterConfiguration.setClusterNodes(nodes); redisClusterConfiguration.setMaxRedirects(4); return redisClusterConfiguration; &#125; /** * jedis连接工厂 * */ @Bean public JedisConnectionFactory jedisConnectionFactory() &#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(redisClusterConfiguration(), jedisPoolConfig()); jedisConnectionFactory.setTimeout(15000); return jedisConnectionFactory; &#125; /** * redis模板 * */ @Bean public RedisTemplate redisTemplate() &#123; RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(jedisConnectionFactory()); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); redisTemplate.setKeySerializer(stringRedisSerializer); redisTemplate.setValueSerializer(stringRedisSerializer); redisTemplate.setHashKeySerializer(stringRedisSerializer); redisTemplate.setHashValueSerializer(stringRedisSerializer); return redisTemplate; &#125; /** * redis缓存管理器 * */ @Bean public RedisCacheManager redisCacheManager() &#123; RedisCacheManager redisCacheManager = new RedisCacheManager(redisTemplate()); return redisCacheManager; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://lvshen9.gitee.io/tags/Redis/"},{"name":"集群","slug":"集群","permalink":"http://lvshen9.gitee.io/tags/集群/"}]},{"title":"工作总结","slug":"工作总结","date":"2018-09-01T01:45:51.000Z","updated":"2019-01-17T07:12:33.612Z","comments":true,"path":"2018/09/01/工作总结/","link":"","permalink":"http://lvshen9.gitee.io/2018/09/01/工作总结/","excerpt":"一、我的收获部署CRM这次有个比较大的收获就是自己部署CRM系统，CRM系统很复杂，光部署的用户就有10多个。这次的系统部署中，部署的用户有deploy, web, app, cache, search, sec（权限缓存redis）, sna（Session缓存redis）,kafka, zk, proxy, nginx。 要启动系统，这些都要启动。比如：不启动nginx。就获取不到静态资源，登陆的js就会报错，点击登录按钮没反应；没有启动proxy，CRM的页面就不能访问，这个代理程序可以配置端口；还有redis也需要启动，不然登陆出现错误； 其次学会了很多linux 命令操作，尤其是vi的操作。比如vi文件后，假如要删除里面某些内容，我以前通过退格键一个一个数据的删除，后来才知道 ：dd --删除当前行，ndd --删除n行数据，dG --删除当前后之后的全部行。ESC+u --撤销操作。","text":"一、我的收获部署CRM这次有个比较大的收获就是自己部署CRM系统，CRM系统很复杂，光部署的用户就有10多个。这次的系统部署中，部署的用户有deploy, web, app, cache, search, sec（权限缓存redis）, sna（Session缓存redis）,kafka, zk, proxy, nginx。 要启动系统，这些都要启动。比如：不启动nginx。就获取不到静态资源，登陆的js就会报错，点击登录按钮没反应；没有启动proxy，CRM的页面就不能访问，这个代理程序可以配置端口；还有redis也需要启动，不然登陆出现错误； 其次学会了很多linux 命令操作，尤其是vi的操作。比如vi文件后，假如要删除里面某些内容，我以前通过退格键一个一个数据的删除，后来才知道 ：dd --删除当前行，ndd --删除n行数据，dG --删除当前后之后的全部行。ESC+u --撤销操作。 学会了简单的python脚本，shell脚本的编写 shell脚本举例：linux 软件安装脚本 python脚本举例: 远程发布文件 —— 远程发布文件脚本 python比较文件异同: 文件异同比较 Log4x部署学习12log4x@test186 ~/support $ lselasticsearch hadoop hbase jdk jstorm kafka redis-4.0.9 zk log4x需要安装 以上的软件，部署本身没啥难度，只要把配置文件的地址，路径配对。系统就可以启起来。 工作流程：app，web的日志发送到kafka里，jstorm会从这里面取数据（实时计算），把处理后的数据存储到hbase，oracle，elasticsearch中。zk相当于一个公告板，告诉这些软件有哪些信息。 Amber部署学习进行中….. 二、我对技术的一些了解关于redisRedis是一种key/value型数据库，我们存值时采用如下命令： 1redis&gt;SET message \"hello redis\" 那么key为message，value为“hello redis”。这里的value为string类型的。redis的值还有其他类型。 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 直接启动进入redis根目录，执行命令: 1./redis-server &amp; 在工作中遇到过一个问题，就是当机器非正常断电关机时，无法直接启动redis。直接启动会报错，说进程已经存在。但是进程明明没有了。 指定配置文件启动这时候可以同过配置文件启动，假如我们redis的配置为：etc/redis-7001.conf进入redis根目录，输入命令： 1./redis-server etc/redis-7001.conf 这样就能启动redis。 如果给redis配置了自定义的端口，使用redis-cli客户端连接时，也需要指定端口，例如： 1./redis-cli -p 7001 关于redis消息订阅redis的发布订阅系统有点类似于我们生活中的电台，电台可以在某一个频率上发送广播，而我们可以接收任何一个频率的广播，这种消息订阅没有kafka高效。 订阅消息的方式如下: 1234567891011127.0.0.1:12001&gt; SUBSCRIBE c1 c2 c3Reading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"c1\"3) (integer) 11) \"subscribe\"2) \"c2\"3) (integer) 21) \"subscribe\"2) \"c3\"3) (integer) 3 这个表示接收c1，c2，c3三个频道传来的消息，发送消息的方式如下： 12127.0.0.1:12001&gt; PUBLISH c1 \"I am lvshen\"(integer) 1 当c1这个频道上有消息发出时，此时在消息订阅控制台可以看到如下输出： 1231) \"message\"2) \"c1\"3) \"I am lvshen\" 在redis中，我们也可以使用模式匹配订阅，如下： 12345127.0.0.1:12001&gt; PSUBSCRIBE c* Reading messages... (press Ctrl-C to quit)1) \"psubscribe\"2) \"c*\"3) (integer) 1 此时可以接收到所有以c开头的频道发来的消息。 创建c1频道 另一边在这个频道上发布一个消息 这里接收到我发布的消息 Redis3.0集群搭建12amber@test185 ~/support/redis/etc $ lsredis-7001.conf redis-7002.conf redis-7003.conf redis-7004.conf redis-7005.conf redis-7006.conf redis-7007.conf 假设我们要把redis-7007.conf,添加到之前的集群中，并作为7001的从属节点。 先启动redis-7007，sbin目录下：./redis-server ../etc/redis-7007.conf 将7007添加到7001上： 123456789101112131415161718192021222324252627amber@test185 ~/support/redis/sbin $ ./redis-trib.rb add-node 10.174.26.185:7007 10.174.26.185:7001&gt;&gt;&gt; Adding node 10.174.26.185:7007 to cluster 10.174.26.185:7001&gt;&gt;&gt; Performing Cluster Check (using node 10.174.26.185:7001)M: b43c58a7052cbe85e4b1118780874556ba70894c 10.174.26.185:7001 slots:0-5460 (5461 slots) master 1 additional replica(s)M: d30c4cde028c4480a4ab69c8b30d103377d36777 10.174.26.185:7002 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: ed81aa0569744c8bb78d92480e69500d77536c6d 10.174.26.185:7004 slots: (0 slots) slave replicates 0c42214d66597845cc58da5fed9e17018adba246M: 0c42214d66597845cc58da5fed9e17018adba246 10.174.26.185:7003 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 79b4f97b36e62849028915752d2c5c117095a0d0 10.174.26.185:7006 slots: (0 slots) slave replicates d30c4cde028c4480a4ab69c8b30d103377d36777S: 6e5eb750cae44b638cdc3372bc2a9146aff56df5 10.174.26.185:7005 slots: (0 slots) slave replicates b43c58a7052cbe85e4b1118780874556ba70894c[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.&gt;&gt;&gt; Send CLUSTER MEET to node 10.174.26.185:7007 to make it join the cluster.[OK] New node added correctly. 查看集群信息： 1234567amber@test185 ~/support/redis/sbin $ ./redis-trib.rb info 10.174.26.185:700710.174.26.185:7007 (ad0f484f...) -&gt; 0 keys | 0 slots | 0 slaves.10.174.26.185:7001 (b43c58a7...) -&gt; 0 keys | 5461 slots | 1 slaves.10.174.26.185:7003 (0c42214d...) -&gt; 0 keys | 5461 slots | 1 slaves.10.174.26.185:7002 (d30c4cde...) -&gt; 0 keys | 5462 slots | 1 slaves.[OK] 0 keys in 4 masters.0.00 keys per slot on average. 7007并没有挂在7001上。 挂载从属节点： 123456789101112./redis-cli -h 10.174.26.185 -c -p 700710.174.26.185:7007&gt; cluster nodesb43c58a7052cbe85e4b1118780874556ba70894c 10.174.26.185:7001@17001 master - 0 1536119538737 1 connected 0-5460ed81aa0569744c8bb78d92480e69500d77536c6d 10.174.26.185:7004@17004 slave 0c42214d66597845cc58da5fed9e17018adba246 0 1536119541000 3 connected6e5eb750cae44b638cdc3372bc2a9146aff56df5 10.174.26.185:7005@17005 slave b43c58a7052cbe85e4b1118780874556ba70894c 0 1536119540800 1 connected0c42214d66597845cc58da5fed9e17018adba246 10.174.26.185:7003@17003 master - 0 1536119541833 3 connected 10923-1638379b4f97b36e62849028915752d2c5c117095a0d0 10.174.26.185:7006@17006 slave d30c4cde028c4480a4ab69c8b30d103377d36777 0 1536119539789 2 connectedad0f484fc7b6399e0aa9e3b6d67d5771554a91aa 10.174.26.185:7007@17007 myself,master - 0 1536119539000 0 connectedd30c4cde028c4480a4ab69c8b30d103377d36777 10.174.26.185:7002@17002 master - 0 1536119539000 2 connected 5461-1092210.174.26.185:7007&gt; cluster replicate b43c58a7052cbe85e4b1118780874556ba70894cOK10.174.26.185:7007&gt; quit 查看结果： 123456amber@test185 ~/support/redis/sbin $ ./redis-trib.rb info 10.174.26.185:700710.174.26.185:7001 (b43c58a7...) -&gt; 0 keys | 5461 slots | 2 slaves.10.174.26.185:7003 (0c42214d...) -&gt; 0 keys | 5461 slots | 1 slaves.10.174.26.185:7002 (d30c4cde...) -&gt; 0 keys | 5462 slots | 1 slaves.[OK] 0 keys in 3 masters.0.00 keys per slot on average. 查看nodes-7001.conf文件 12345678amber@test185 ~/data/redis-data $ more nodes-7001.confd30c4cde028c4480a4ab69c8b30d103377d36777 10.174.26.185:7002@17002 master - 0 1536130505000 2 connected 5461-10922ed81aa0569744c8bb78d92480e69500d77536c6d 10.174.26.185:7004@17004 slave 0c42214d66597845cc58da5fed9e17018adba246 0 1536130507000 4 connected0c42214d66597845cc58da5fed9e17018adba246 10.174.26.185:7003@17003 master - 0 1536130507099 3 connected 10923-1638379b4f97b36e62849028915752d2c5c117095a0d0 10.174.26.185:7006@17006 slave d30c4cde028c4480a4ab69c8b30d103377d36777 0 1536130507000 6 connectedb43c58a7052cbe85e4b1118780874556ba70894c 10.174.26.185:7001@17001 myself,master - 0 1536130504000 1 connected 0-54606e5eb750cae44b638cdc3372bc2a9146aff56df5 10.174.26.185:7005@17005 slave b43c58a7052cbe85e4b1118780874556ba70894c 0 1536130507000 5 connectedad0f484fc7b6399e0aa9e3b6d67d5771554a91aa 10.174.26.185:7007@17007 slave b43c58a7052cbe85e4b1118780874556ba70894c 0 1536130507912 1 connected 关于JstormJstorm是阿里巴巴在storm上改造的软件，特点：24小时时时计算。用于数据分析，如分析日志。 Jstorm用于海量数据计算，除此之外还有Hadoop的MapReduce编程模型。这个理论模型是由Google发表的。 MapReduce可以分成Map和Reduce两部分理解。 1.Map：映射过程，把一组数据按照某种Map函数映射成新的数据。 2.Reduce：归约过程，把若干组映射结果进行汇总并输出。 MapReduce 但是hadoop的这中MapReduce job是执行完就结束，进程退出。而jstorm是执行一遍，又执行一边，24小时永久执行。JStorm之所以能源源不断的运行，是由于当Worker失效或机器出现故障时， 自动分配新的Worker替换失效Worker。使得JStorm具有良好的健壮性。 JStorm组件spoutspout代表输入的数据源（kafka，DB，HBase，HDFS） boltbolt代表处理逻辑，bolt收到消息之后，对消息做处理（即执行用户的业务逻辑），处理完以后，既可以将处理后的消息继续发送到下游的bolt，这样会形成一个处理流水线（pipeline，不过更精确的应该是个有向图）；也可以直接结束。 通常一个流水线的最后一个bolt，会做一些数据的存储工作，比如将实时计算出来的数据写入DB、HBase等，以供前台业务进行查询和展现。 tuple在JStorm中有对于流stream的抽象，流是一个不间断的无界的连续tuple，注意JStorm在建模事件流时，把流中的事件抽象为tuple即元组。 一个tuple就是一个值列表value list，list中的每个value都有一个name，并且该value可以是基本类型，字符类型，字节数组等，当然也可以是其他可序列化的类型。拓扑的每个节点都要说明它所发射出的元组的字段的name，其他节点只需要订阅该name就可以接收处理。 可以抽象为：spout是一个水龙头，tuple就是水龙头流出的水，bolt就是一个水处理器。spout源头接收其他中间件吐出的数据，数据装配为tuple，流向bolt进行数据处理。处理后的数据存入数据库了。 基于消息的流水线系统 流水线系统 JVM中的jstorm进程 JVM中的JStorm进程 Jstorm相关角色12345–Nimbus：资源调度角色–Supervisor：接受nimubs 任务安排，启动任务–Worker：进程 –Executor：执行线程–Task：执行逻辑单元 Storm原理 Storm原理 组件接口JStorm框架对spout组件定义了一个接口：nextTuple，顾名思义，就是获取下一条消息。执行时，可以理解成JStorm框架会不停地调这个接口，以从数据源拉取数据并往bolt发送数据。 同时，bolt组件定义了一个接口：execute，这个接口就是用户用来处理业务逻辑的地方。 每一个topology，既可以有多个spout，代表同时从多个数据源接收消息，也可以多个bolt，来执行不同的业务逻辑。 调度执行接下来就是topology的调度和执行原理，对一个topology，JStorm最终会调度成一个或多个worker，每个worker即为一个真正的操作系统执行进程，分布到一个集群的一台或者多台机器上并行执行。 而每个worker中，又可以有多个task，分别代表一个执行线程。每个task就是上面提到的组件(component)的实现，要么是spout要么是bolt。 一个topology对应多个worker；每个worker，对应多个task；每个task，需要靠spout或bolt实现 消息之间的通信 spout与bolt，bolt与bolt之间是怎么通信的？ 首先，从spout发送消息的时候，JStorm会计算出消息要发送的目标task id列表，然后看目标task id是在本进程中，还是其他进程中，如果是本进程中，那么就可以直接走进程内部通信（如直接将这个消息放入本进程中目标task的执行队列中）；如果是跨进程，那么JStorm会使用netty来将消息发送到目标task中。 ack机制用于判断spout发出的消息是否被成功处理，或失败处理。 123在规定的时间内，spout收到Acker的ack响应，即认为该tuple 被后续bolt成功处理在规定的时间内，没有收到Acker的ack响应tuple，就触发fail动作，即认为该tuple处理失败，或者收到Acker发送的fail响应tuple，也认为失败，触发fail动作 源码分析源码围绕Spout和Bolt构建 Spout123456789public interface ISpout extends Serializable &#123; void open(Map conf, TopologyContext context, SpoutOutputCollector collector); void close(); void activate(); void deactivate(); void nextTuple(); void ack(Object msgId); void fail(Object msgId);&#125; 其中注意： spout对象必须是继承Serializable， 因此要求spout内所有数据结构必须是可序列化的 spout可以有构造函数，但构造函数只执行一次，是在提交任务时，创建spout对象，因此在task分配到具体worker之前的初始化工作可以在此处完成，一旦完成，初始化的内容将携带到每一个task内（因为提交任务时将spout序列化到文件中去，在worker起来时再将spout从文件中反序列化出来）。 open是当task起来后执行的初始化动作 close是当task被shutdown后执行的动作 activate 是当task被激活时，触发的动作 deactivate 是task被deactive时，触发的动作 nextTuple 是spout实现核心， nextuple完成自己的逻辑，即每一次取消息后，用collector 将消息emit出去。 ack， 当spout收到一条ack消息时，触发的动作 fail， 当spout收到一条fail消息时，触发的动作 Bolt12345public interface IBolt extends Serializable &#123; void prepare(Map stormConf, TopologyContext context, OutputCollector collector); void execute(Tuple input); void cleanup();&#125; 注意： prepare是当task起来后执行的初始化动作 cleanup是当task被shutdown后执行的动作 execute是bolt实现核心， 完成自己的逻辑，即接受每一次取消息后，处理完，有可能用collector 将产生的新消息emit出去。在executor中，当程序处理一条消息时，需要执行collector.ack， 在executor中，当程序无法处理一条消息时或出错时，需要执行collector.fail。 额外学习：《Java8实战》读书笔记Java8的两个新特性：Lambda表达式和stream()的使用，简化了我们的开发。举个例子： Lambda-对苹果按重量排序1234567891011//Java8之前Collections.sort(inventory, new Comparator&lt;Apple&gt;() &#123; public int compare(Apple a1, Apple a2)&#123; return a1.getWeight().compareTo(a2.getWeight()); &#125; &#125;);//Java8特性(方法引用)inventory.sort(comparing(Apple::getWeight));//Lambda表达式Comparator&lt;Apple&gt; byWeight =(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); Stream-筛选金额较高的交易1234567891011121314151617//未使用流Map&lt;Currency, List&lt;Transaction&gt;&gt; transactionsByCurrencies = new HashMap&lt;&gt;();for (Transaction transaction : transactions) &#123; if(transaction.getPrice() &gt; 1000)&#123; Currency currency = transaction.getCurrency(); List&lt;Transaction&gt; transactionsForCurrency = transactionsByCurrencies.get(currency); if (transactionsForCurrency == null) &#123; transactionsForCurrency = new ArrayList&lt;&gt;(); transactionsByCurrencies.put(currency,transactionsForCurrency); &#125; transactionsForCurrency.add(transaction); &#125;&#125;//使用流import static java.util.stream.Collectors.toList;Map&lt;Currency, List&lt;Transaction&gt;&gt; transactionsByCurrencies = transactions.stream().filter((Transaction t) -&gt; t.getPrice() &gt; 1000).collect(groupingBy(Transaction::getCurrency)); Java8中的default关键字用于在接口中扩充方法，而不影响子接口，或子类。 1234567891011121314//接口中的方法用default修饰后，可以有结构体public interface DefaultTest &#123; default void foo()&#123; System.out.println(\"Calling A.foo()\"); &#125;&#125;//该类实现了DefaultTest接口，并不用实现foo(),因为foo()被default关键字修饰public class DefaultTestImpl implements DefaultTest &#123; public static void main(String[] args)&#123; DefaultTestImpl defaultTest = new DefaultTestImpl(); defaultTest.foo(); &#125;&#125; 三、下一步学习方向linux系统方面的，python编程，大数据（Hbase，kafka，zk等）尽量了解源码，了解他们的代码风格。学习学习。 具体步骤：一看技术文章/书籍，二请教大佬，三动手实践操作。 Python Study方案： Python Study 大数据学习： 扒源码，最近在看Jstorm的源码。 Linux系统学习： 命令，shell脚本等等 红帽RHCE认证 四、现有工作建议 自己工作主动性缺乏，需要改正 工作内容不明确，有时候不知道我们的工作内容，哪些是需要我们做的。","categories":[{"name":"工作","slug":"工作","permalink":"http://lvshen9.gitee.io/categories/工作/"}],"tags":[{"name":"CRM","slug":"CRM","permalink":"http://lvshen9.gitee.io/tags/CRM/"},{"name":"Jstorm","slug":"Jstorm","permalink":"http://lvshen9.gitee.io/tags/Jstorm/"}]},{"title":"我在GitHub上的一个关于Python版打飞机的项目","slug":"1","date":"2018-07-20T07:56:42.000Z","updated":"2019-01-17T07:00:01.098Z","comments":true,"path":"2018/07/20/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/07/20/1/","excerpt":"PlaneWar简介a game-PlaneWar，Written by Python 这是一个用Python写的打飞机游戏，类似当年的微信打飞机。下面有相关的截图。其实代码也很简单，就是一些加载图片，游戏的逻辑处理，加载游戏音效。怎么个Python游戏用的核心库：pygame。以后打算用Java再写一个。里面的代码就不详细介绍了。有兴趣的可以访问我的GitHub项目。不过需要安装Python环境，最好是Python3环境。 GitHub地址： Python版打飞机(飞机大战)","text":"PlaneWar简介a game-PlaneWar，Written by Python 这是一个用Python写的打飞机游戏，类似当年的微信打飞机。下面有相关的截图。其实代码也很简单，就是一些加载图片，游戏的逻辑处理，加载游戏音效。怎么个Python游戏用的核心库：pygame。以后打算用Java再写一个。里面的代码就不详细介绍了。有兴趣的可以访问我的GitHub项目。不过需要安装Python环境，最好是Python3环境。 GitHub地址： Python版打飞机(飞机大战) 初始界面： 初始界面 如上图：程序运行之后的界面。 子弹射击： 子弹射击 如上图：按下空格键，可实现子弹射击 GameOver gameover 敌机碰撞飞机后，游戏GameOver。 实机演示 PlanWars_Action 实机演示图就是这样啦。 GitHub地址： Python版打飞机(飞机大战) 欢迎下载！","categories":[{"name":"游戏","slug":"游戏","permalink":"http://lvshen9.gitee.io/categories/游戏/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://lvshen9.gitee.io/tags/Python/"},{"name":"Github","slug":"Github","permalink":"http://lvshen9.gitee.io/tags/Github/"},{"name":"打飞机","slug":"打飞机","permalink":"http://lvshen9.gitee.io/tags/打飞机/"}]},{"title":"Git命令学习","slug":"1","date":"2018-07-06T06:45:41.000Z","updated":"2019-01-17T06:58:14.112Z","comments":true,"path":"2018/07/06/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/07/06/1/","excerpt":"Git重要概念master head每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。在Git里，有个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点：","text":"Git重要概念master head每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。在Git里，有个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长：当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： 从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 工作区，暂存区 工作区Workspace：就是你在电脑里能看到的目录，即你代码放的那个文件夹。即时性强，对文件的所有更改都会立刻提现在这里。 版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 暂存区 Index / Stage：git add以后，当前对文件的更改会保存到这个区 本地仓库Repository：git commit以后，当前暂存区里对文件的更改会提交到本地仓库 远程仓库Remote：远程仓库名一般叫origin。git push以后，本地仓库里优先于远程仓库的commit会被push到远程仓库 下载安装git官网下载 初始化初始化参数12$ git config --global user.name \"你的名字\"$ git config --global user.email \"你的邮箱地址\" 因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。 注意git config命令的–global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 初始化本地仓库1$ git init SSH key生成1$ ssh-keygen -t rsa -C \"你的邮箱地址\" clone代码1234# 克隆master分支$ git clone &lt;版本库的网址&gt;# 指定克隆的分支名$ git clone -b &lt;分支名&gt; &lt;版本库的网址&gt; .gitignore生效办法12345# 先把本地缓存删除（改变成未track状态）$ git rm -r --cached .# 然后再提交$ git add .$ git commit -m 'update .gitignore' 查看各种状态12345678# 查看当前状态（分支名，有哪些改动，有哪些冲突，工作区暂存区中的内容，几个commit等等）$ git status# 查看本地仓库的提交历史$ git log# 查看本地仓库的提交历史，简洁版$ git log --pretty=oneline# 查看命令历史$ git reflog 分支123456789101112131415161718# 查看分支：$ git branch -a# 创建本地分支：$ git branch &lt;分支名&gt;# 切换本地分支：$ git checkout &lt;分支名&gt;# 创建+切换本地分支：$ git checkout -b &lt;name&gt;# 合并某分支到当前分支：$ git merge &lt;要合并的分支&gt;# 将本地分支推送到远程$ git push origin &lt;要推送的本地分支名&gt;# 以远程分支为基础，建一个本地分支$ git checkout -b &lt;本地分支名&gt; origin/&lt;远程分支名&gt;# 删除本地分支：$ git branch -d &lt;本地分支名&gt;# 删除远程分支。将本地空分支推送到远程分支,相当于删除远程分支$ git push origin :&lt;要删除的远程分支名 更新和提交代码一个新的文件,或改动.刚开始只存在你的工作区。当你使用git add的时候，Git就会缓存这个改动并且跟踪。当你使用git commit的时候就会把你的改动提交到仓库里。 12345678910# 缓存所有改动$ git add --all# 缓存单个文件的改动$ git add &lt;该文件的文件名，包含路径&gt;# 提交至本地仓库$ git commit -m &lt;提交备注&gt;# 更新本地代码$ git pull origin &lt;分支名&gt;# 将本地commit推送至远端$ git push orign &lt;分支名&gt; 撤销12345678910111213141516171819# 撤销工作区某个文件的更改$ git checkout [file]# 撤销工作区所有文件的更改$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致。但更改并没有消失，而是更改打回工作区$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致。$ git reset --hard &lt;当前分支名&gt;# 重置当前分支的指针为指定commit，同时重置暂存区。但更改并没有消失，而是更改打回工作区$ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致。$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 暂时将未提交的变化存入stash，稍后再弹出$ git stash$ git stash popgit review 代码评审使用gerrit系统，git中使用git review &lt;分支名&gt;(默认是master) 命令执行review操作。 规则 提交reivew之前pull远程代码，保证提交以前是最新代码，有冲突需要本地合并处理。 一个单一的功能的变更放入一个commit中，提交一次reivew。 特殊情况1234567891011121314151617181920212223242526272829#review没有通过怎么办？先回到要修改的那个commit$ git reset --soft &lt;要修改的那个commit的id&gt;#继续修改你要改的文件。修改后add缓存文件，并执行$ git commit --amend#将刚生产的变更归并到上一次变更里，继续执行git review#已经做了多个提交commits怎么办？#如果多个提交是相关联的，请合并这个提交为一个提交# 查询最先提交的commit, 记住id.$ git log # 进行变基操作$ git rebase -i &lt;上一步查到的id&gt;# 弹出的界面上罗列了最先提交的commit到现在的所有提交记录#将每列开头的 'pick' 改成 's', 只保留第一列的 'pick'。#保存修改后系统会自动把这些commits合并成一个commit.# 如果遇到冲突需要手动解决。合并冲突后，继续变基， 直到所有commits都合并为止.$ git rebase --continue#如果review中提交了多个commits，其中一个commit没review过怎么办(包括以前某个commit中没有生成change #id)？一次commit对应生成一个review, 前一个review没通过的话，后面的review 通过了也提交不了。 必须把前面#一个review 弄通过，后面的review才能提交。# 查询未通过的review对应的commit id(gerrit里有记录)# 回到这个commit的前一个节点，注意有个^$ 执行 git rebase -i &lt;未通过的review对应的commit id&gt;^ # 修改并缓存要提交的文件后$ git commit --amend# 返回head处$ git rebase --continue # 提交对老review的更新$ git review 特别提示1234567#如果git review &lt;分支名&gt;后提示缺失commit_id，可能是前面rebase操作造成的。# 现将rebase好的commit推回工作区$ git reset head^# 再重新add和commit，产生新的commit_id$ git add .$ git commit -m &lt;备注信息&gt;$ git review &lt;分支名&gt;","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://lvshen9.gitee.io/tags/Git/"},{"name":"命令","slug":"命令","permalink":"http://lvshen9.gitee.io/tags/命令/"}]},{"title":"redis相关命令操作","slug":"1","date":"2018-07-05T12:06:10.000Z","updated":"2018-07-05T12:09:16.974Z","comments":true,"path":"2018/07/05/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/07/05/1/","excerpt":"redis的启动方式直接启动 进入redis根目录，执行命令: 1./redis-server &amp; 加上‘&amp;’号使redis以后台程序方式运行","text":"redis的启动方式直接启动 进入redis根目录，执行命令: 1./redis-server &amp; 加上‘&amp;’号使redis以后台程序方式运行 通过指定配置文件启动 可以为redis服务启动指定配置文件，例如配置为/etc/redis/6379.conf 进入redis根目录，输入命令： 1./redis-server /etc/redis/6379.conf 如果更改了端口，使用redis-cli客户端连接时，也需要指定端口，例如： 1./redis-cli -p 6380 使用redis启动脚本设置开机自启动 启动脚本 redis_init_script 位于位于Redis的 /utils/目录下，redis_init_script脚本代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/sh## Simple Redis init.d script conceived to work on Linux systems# as it does use of the /proc filesystem. #redis服务器监听的端口REDISPORT=6379 #服务端所处位置EXEC=/usr/local/bin/redis-server #客户端位置CLIEXEC=/usr/local/bin/redis-cli #redis的PID文件位置，需要修改PIDFILE=/var/run/redis_$&#123;REDISPORT&#125;.pid #redis的配置文件位置，需将$&#123;REDISPORT&#125;修改为文件名CONF=\"/etc/redis/$&#123;REDISPORT&#125;.conf\" case \"$1\" in start) if [ -f $PIDFILE ] then echo \"$PIDFILE exists, process is already running or crashed\" else echo \"Starting Redis server...\" $EXEC $CONF fi ;; stop) if [ ! -f $PIDFILE ] then echo \"$PIDFILE does not exist, process is not running\" else PID=$(cat $PIDFILE) echo \"Stopping ...\" $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/$&#123;PID&#125; ] do echo \"Waiting for Redis to shutdown ...\" sleep 1 done echo \"Redis stopped\" fi ;; *) echo \"Please use start or stop as first argument\" ;;esac 根据启动脚本，将修改好的配置文件复制到指定目录下，用root用户进行操作： 12mkdir /etc/rediscp redis.conf /etc/redis/6379.conf 将启动脚本复制到/etc/init.d目录下，本例将启动脚本命名为redisd（通常都以d结尾表示是后台自启动服务）。 1cp redis_init_script /etc/init.d/redisd 设置为开机自启动，直接配置开启自启动 chkconfig redisd on 发现错误： service redisd does not support chkconfig 解决办法，在启动脚本开头添加如下注释来修改运行级别： 12#!/bin/sh# chkconfig: 2345 90 10 再设置即可 123456#设置为开机自启动服务器chkconfig redisd on#打开服务service redisd start#关闭服务service redisd stop 消息订阅redis的发布订阅系统有点类似于我们生活中的电台，电台可以在某一个频率上发送广播，而我们可以接收任何一个频率的广播，Android中的broadcast也和这类似。 订阅消息的方式如下: 1234567891011127.0.0.1:12001&gt; SUBSCRIBE c1 c2 c3Reading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"c1\"3) (integer) 11) \"subscribe\"2) \"c2\"3) (integer) 21) \"subscribe\"2) \"c3\"3) (integer) 3 这个表示接收c1，c2，c3三个频道传来的消息，发送消息的方式如下： 12127.0.0.1:12001&gt; PUBLISH c1 \"I am lvshen\"(integer) 1 当c1这个频道上有消息发出时，此时在消息订阅控制台可以看到如下输出： 1231) \"message\"2) \"c1\"3) \"I am lvshen\" 在redis中，我们也可以使用模式匹配订阅，如下： 12345127.0.0.1:12001&gt; PSUBSCRIBE c* Reading messages... (press Ctrl-C to quit)1) \"psubscribe\"2) \"c*\"3) (integer) 1 此时可以接收到所有以c开头的频道发来的消息。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"命令","slug":"命令","permalink":"http://lvshen9.gitee.io/tags/命令/"},{"name":"redis","slug":"redis","permalink":"http://lvshen9.gitee.io/tags/redis/"}]},{"title":"Windows端免密ssh登陆Linux服务器","slug":"1","date":"2018-05-30T09:37:25.000Z","updated":"2018-05-30T10:03:55.981Z","comments":true,"path":"2018/05/30/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/05/30/1/","excerpt":"创建ssh信任关系copy公钥123456#在本地生成公钥和密钥：ssh-keygen -t rsa#将本机生成的公钥发送到服务器上（建立信任关系）：ssh-copy-id -i C:/Users/UserName/.ssh/id_rsa.pub root@server_ip #UserName是电脑的用户名#测试ssh远程登录是否成功：ssh root@server_ip","text":"创建ssh信任关系copy公钥123456#在本地生成公钥和密钥：ssh-keygen -t rsa#将本机生成的公钥发送到服务器上（建立信任关系）：ssh-copy-id -i C:/Users/UserName/.ssh/id_rsa.pub root@server_ip #UserName是电脑的用户名#测试ssh远程登录是否成功：ssh root@server_ip 远程服务端会有.ssh目录12345[lvshen@wade ~]$ ls -altotal 56...drwxr-xr-x 2 lvshen lvshen 4096 Jan 5 10:45 .ssh... 修改.ssh权限12[lvshen@wade ~]$ chmod 700 .ssh[lvshen@wade ~]$ chmod 600 .ssh/authorized_keys root用户下操作cat /var/log/secure 查看系统的安全日志，然后再安全日志中看到SSH登录过程中提示了如下错误： 123...May 30 16:53:36 wade sshd[30159]: Authentication refused: bad ownership or modes for directory /git... 解决SSH Authentication Refused12[root@wade ~]# chmod g-w /home/lvshen[root@wade ~]# service sshd restart 赋予root权限修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示： 123#Allow root to run any commands anywhereroot ALL=(ALL) ALLgit ALL=(ALL) ALL","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://lvshen9.gitee.io/tags/Linux/"},{"name":"git","slug":"git","permalink":"http://lvshen9.gitee.io/tags/git/"}]},{"title":"JStorm学习","slug":"1","date":"2018-05-25T01:57:20.000Z","updated":"2019-01-17T06:54:42.988Z","comments":true,"path":"2018/05/25/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/05/25/1/","excerpt":"JStorm运用场景JStorm处理数据的方式是基于消息的流水线处理， 因此特别适合无状态计算，也就是计算单元的依赖的数据全部在接受的消息中可以找到， 并且最好一个数据流不依赖另外一个数据流。 因此，常常用于","text":"JStorm运用场景JStorm处理数据的方式是基于消息的流水线处理， 因此特别适合无状态计算，也就是计算单元的依赖的数据全部在接受的消息中可以找到， 并且最好一个数据流不依赖另外一个数据流。 因此，常常用于 日志分析，从日志中分析出特定的数据，并将分析的结果存入外部存储器如数据库。目前，主流日志分析技术就使用JStorm或Storm 管道系统， 将一个数据从一个系统传输到另外一个系统， 比如将数据库同步到Hadoop 消息转化器， 将接受到的消息按照某种格式进行转化，存储到另外一个系统如消息中间件 统计分析器， 从日志或消息中，提炼出某个字段，然后做count或sum计算，最后将统计值存入外部存储器。中间处理过程可能更复杂。 Hadoop与JStorm的区别hadoop的MR，提交到hadoop的MR job，执行完就结束了，进程就退出了，而一个JStorm任务（JStorm中称为topology），是7*24小时永远在运行的，除非用户主动kill。JStorm之所以能源源不断的运行，是由于当Worker失效或机器出现故障时， 自动分配新的Worker替换失效Worker。使得JStorm具有良好的健壮性。 JStorm组件spoutspout代表输入的数据源（kafka，DB，HBase，HDFS） boltbolt代表处理逻辑，bolt收到消息之后，对消息做处理（即执行用户的业务逻辑），处理完以后，既可以将处理后的消息继续发送到下游的bolt，这样会形成一个处理流水线（pipeline，不过更精确的应该是个有向图）；也可以直接结束。 通常一个流水线的最后一个bolt，会做一些数据的存储工作，比如将实时计算出来的数据写入DB、HBase等，以供前台业务进行查询和展现。 tuple在JStorm中有对于流stream的抽象，流是一个不间断的无界的连续tuple，注意JStorm在建模事件流时，把流中的事件抽象为tuple即元组。 一个tuple就是一个值列表value list，list中的每个value都有一个name，并且该value可以是基本类型，字符类型，字节数组等，当然也可以是其他可序列化的类型。拓扑的每个节点都要说明它所发射出的元组的字段的name，其他节点只需要订阅该name就可以接收处理。 可以抽象为：spout是一个水龙头，tuple就是水龙头流出的水，bolt就是一个水处理器。spout源头接收其他中间件吐出的数据，数据装配为tuple，流向bolt进行数据处理。处理后的数据存入数据库了。 基于消息的流水线系统 流水线系统 JVM中的jstorm进程 JVM中的JStorm进程 Jstorm相关角色12345–Nimbus：资源调度角色–Supervisor：接受nimubs 任务安排，启动任务–Worker：进程 –Executor：执行线程–Task：执行逻辑单元 Storm原理 Storm原理 组件接口JStorm框架对spout组件定义了一个接口：nextTuple，顾名思义，就是获取下一条消息。执行时，可以理解成JStorm框架会不停地调这个接口，以从数据源拉取数据并往bolt发送数据。 同时，bolt组件定义了一个接口：execute，这个接口就是用户用来处理业务逻辑的地方。 每一个topology，既可以有多个spout，代表同时从多个数据源接收消息，也可以多个bolt，来执行不同的业务逻辑。 调度执行接下来就是topology的调度和执行原理，对一个topology，JStorm最终会调度成一个或多个worker，每个worker即为一个真正的操作系统执行进程，分布到一个集群的一台或者多台机器上并行执行。 而每个worker中，又可以有多个task，分别代表一个执行线程。每个task就是上面提到的组件(component)的实现，要么是spout要么是bolt。 一个topology对应多个worker；每个worker，对应多个task；每个task，需要靠spout或bolt实现 消息之间的通信 spout与bolt，bolt与bolt之间是怎么通信的？ 首先，从spout发送消息的时候，JStorm会计算出消息要发送的目标task id列表，然后看目标task id是在本进程中，还是其他进程中，如果是本进程中，那么就可以直接走进程内部通信（如直接将这个消息放入本进程中目标task的执行队列中）；如果是跨进程，那么JStorm会使用netty来将消息发送到目标task中。 ack机制用于判断spout发出的消息是否被成功处理，或失败处理。 123在规定的时间内，spout收到Acker的ack响应，即认为该tuple 被后续bolt成功处理在规定的时间内，没有收到Acker的ack响应tuple，就触发fail动作，即认为该tuple处理失败，或者收到Acker发送的fail响应tuple，也认为失败，触发fail动作 源码分析源码围绕Spout和Bolt构建 Spout123456789public interface ISpout extends Serializable &#123; void open(Map conf, TopologyContext context, SpoutOutputCollector collector); void close(); void activate(); void deactivate(); void nextTuple(); void ack(Object msgId); void fail(Object msgId);&#125; 其中注意： spout对象必须是继承Serializable， 因此要求spout内所有数据结构必须是可序列化的 spout可以有构造函数，但构造函数只执行一次，是在提交任务时，创建spout对象，因此在task分配到具体worker之前的初始化工作可以在此处完成，一旦完成，初始化的内容将携带到每一个task内（因为提交任务时将spout序列化到文件中去，在worker起来时再将spout从文件中反序列化出来）。 open是当task起来后执行的初始化动作 close是当task被shutdown后执行的动作 activate 是当task被激活时，触发的动作 deactivate 是task被deactive时，触发的动作 nextTuple 是spout实现核心， nextuple完成自己的逻辑，即每一次取消息后，用collector 将消息emit出去。 ack， 当spout收到一条ack消息时，触发的动作 fail， 当spout收到一条fail消息时，触发的动作 Bolt12345public interface IBolt extends Serializable &#123; void prepare(Map stormConf, TopologyContext context, OutputCollector collector); void execute(Tuple input); void cleanup();&#125; 注意： prepare是当task起来后执行的初始化动作 cleanup是当task被shutdown后执行的动作 execute是bolt实现核心， 完成自己的逻辑，即接受每一次取消息后，处理完，有可能用collector 将产生的新消息emit出去。 ** 在executor中，当程序处理一条消息时，需要执行collector.ack， 在executor中，当程序无法处理一条消息时或出错时，需要执行collector.fail。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"JStorm","slug":"JStorm","permalink":"http://lvshen9.gitee.io/tags/JStorm/"},{"name":"大数据","slug":"大数据","permalink":"http://lvshen9.gitee.io/tags/大数据/"}]},{"title":"《Java8实战》学习笔记(一)","slug":"1","date":"2018-05-23T02:16:42.000Z","updated":"2019-01-17T07:49:52.464Z","comments":true,"path":"2018/05/23/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/05/23/1/","excerpt":"最近抽空看了《Java8实战这本书》，收获很多，这本书着重介绍了Java8的两个新特性：Lambda表达式和stream()的使用，简化了我们的开发。下面是我在读这本书是所做的笔记，也是我的一些收获。","text":"最近抽空看了《Java8实战这本书》，收获很多，这本书着重介绍了Java8的两个新特性：Lambda表达式和stream()的使用，简化了我们的开发。下面是我在读这本书是所做的笔记，也是我的一些收获。 第一段代码对苹果按重量排序1234567891011//Java8之前Collections.sort(inventory, new Comparator&lt;Apple&gt;() &#123; public int compare(Apple a1, Apple a2)&#123; return a1.getWeight().compareTo(a2.getWeight()); &#125; &#125;);//Java8特性(方法引用)inventory.sort(comparing(Apple::getWeight));//Lambda表达式Comparator&lt;Apple&gt; byWeight =(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); 筛选金额较高的交易1234567891011121314151617//未使用流Map&lt;Currency, List&lt;Transaction&gt;&gt; transactionsByCurrencies = new HashMap&lt;&gt;();for (Transaction transaction : transactions) &#123; if(transaction.getPrice() &gt; 1000)&#123; Currency currency = transaction.getCurrency(); List&lt;Transaction&gt; transactionsForCurrency = transactionsByCurrencies.get(currency); if (transactionsForCurrency == null) &#123; transactionsForCurrency = new ArrayList&lt;&gt;(); transactionsByCurrencies.put(currency,transactionsForCurrency); &#125; transactionsForCurrency.add(transaction); &#125;&#125;//使用流import static java.util.stream.Collectors.toList;Map&lt;Currency, List&lt;Transaction&gt;&gt; transactionsByCurrencies = transactions.stream().filter((Transaction t) -&gt; t.getPrice() &gt; 1000).collect(groupingBy(Transaction::getCurrency)); 函数式接口只定义了一个方法的接口，例如： 123456789public interface Predicate&lt;T&gt;&#123; boolean test (T t);&#125;public interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2);&#125;//注：此接口不能继承其他接口，不然会继承其方法 函数时接口的使用123456789101112131415161718192021//注意：此接口的方法返回boolean@FunctionalInterfacepublic interface Predicate&lt;T&gt;&#123; boolean test(T t);&#125;//定义一个实现功能的方法public static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p) &#123; List&lt;T&gt; results = new ArrayList&lt;&gt;(); for(T s: list)&#123; if(p.test(s))&#123; results.add(s); &#125; &#125; return results;&#125;//使用Lambda表达式Predicate&lt;String&gt; nonEmptyStringPredicate = (String s) -&gt; !s.isEmpty();List&lt;String&gt; nonEmpty = filter(listOfStrings, nonEmptyStringPredicate);//上面两段代码相当于List&lt;String&gt; nonEmpty = filter(listOfStrings, (String s) -&gt; !s.isEmpty()); Java8中forEach方法的使用假如有一个list集合，循环获取里面的值，Java8之前是这样做的。 12345678910//使用foreach循环获取for (int i:list) &#123; System.out.println(\"Iterator Value::\"+i);&#125;//或者使用迭代Iterator&lt;Integer&gt; it = list.iterator();while (it.hasNext())&#123; System.out.println(\"Iterator Value::\"+it.next());&#125; Java8后有一个forEach的方法，配合Lambda表达式。简直不要更简单。 123list.forEach(a -&gt; &#123; System.out.println(\"Iterator Value::\"+ a);&#125;); Java8中的default关键字用于在接口中扩充方法，而不影响子接口，或子类。 1234567891011121314//接口中的方法用default修饰后，可以有结构体public interface DefaultTest &#123; default void foo()&#123; System.out.println(\"Calling A.foo()\"); &#125;&#125;//该类实现了DefaultTest接口，并不用实现foo(),因为foo()被default关键字修饰public class DefaultTestImpl implements DefaultTest &#123; public static void main(String[] args)&#123; DefaultTestImpl defaultTest = new DefaultTestImpl(); defaultTest.foo(); &#125;&#125; Lambda表达式及函数时接口的例子 Lambda表达式使用的例子 T -&gt; R Function,将类型T的对象转换为类型R的对象 R apply(T t) (int, int)-&gt;int IntBinaryOperator具有唯一一个抽象方法，叫作applyAsInt int applyAsInt(int left, int right T-&gt;void Consumer具有唯一一个抽象方法叫作accept void accept(T t) ()-&gt;T Supplier具有唯一一个抽象方法叫作get T get() (T, U)-&gt;R BiFunction具有唯一一个抽象方法叫作apply R apply(T t,) Lambda表达式类型检查过程示例 Lambda表达式类型检查 注意特殊的兼容规则如果一个Lambda的主体是一个语句表达式， 它就和一个返回void的函数描述符兼容（当然需要参数列表也兼容）。例如，以下两行都是合法的，尽管List的add方法返回了一个boolean，而不是Consumer上下文（T -&gt; void）所要求的void： 1234// Predicate返回了一个booleanPredicate&lt;String&gt; p = s -&gt; list.add(s);// Consumer返回了一个voidConsumer&lt;String&gt; b = s -&gt; list.add(s); 方法引用类似Lambda表达式，但比Lambda表达式更直观，简洁 12345//先前：inventory.sort((Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()));//之后（使用方法引用和java.util.Comparator.comparing）：inventory.sort(comparing(Apple::getWeight));//Apple::getWeight相当于(Apple a) -&gt; a.getWeight() Lambda表达式及其等效方法引用 Lambda 等效的方法引用 (Apple a) -&gt; a.getWeight() Apple::getWeight () -&gt; Thread.currentThread().dumpStack() Thread.currentThread()::dumpStack (str, i) -&gt; str.substring(i) String::substring (String s) -&gt; System.out.println(s) System.out::println 快速创建list集合1List&lt;Integer&gt; weights = Arrays.asList(7,3,4,10); Java8 stream学习代码举例假设我现在要获取卡路里小于400的食物，并将这些食物排序 123456789public static void main(String[] args)&#123; getLowCaloricDishesNamesInJava8(Dish.menu).forEach(System.out::println);&#125;public static List&lt;String&gt; getLowCaloricDishesNamesInJava8(List&lt;Dish&gt; dishes)&#123; return dishes.stream().filter(d -&gt; d.getCalories() &lt; 400).sorted(Comparator.comparing(Dish::getCalories)) .map(Dish::getName).collect(Collectors.toList());&#125;//Dish类是一个实体类，用于存储数据的 stream流的中间操作和终端操作 stream流的中间操作和终端操作 如上图，流是有数据连（如集合），中间操作链（形成流的一条流水线），终端操作（生成结果）。其中，中间操作的返回结果类型为：Stream&lt;T&gt;。 流的总结 流是“从支持数据处理操作的源生成的一系列元素”。 流利用内部迭代：迭代通过filter、map、sorted等操作被抽象掉了。 流操作有两类：中间操作和终端操作。 filter和map等中间操作会返回一个流，并可以链接在一起。可以用它们来设置一条流水线，但并不会生成任何结果。 forEach和count等终端操作会返回一个非流的值，并处理流水线以返回结果。 流中的元素是按需计算的。 将字符串列表转成字母列表代码如下： 123456List&lt;String&gt; title = Arrays.asList(\"Java8\", \"In\", \"Action\");List&lt;Integer&gt; wordLengths = title.stream().map(String::length).collect(toList());List&lt;String&gt; collect = title.stream().map(word -&gt; word.split(\"\")).flatMap(Arrays::stream).distinct().collect(toList());System.out.println(collect);//打印结果:[J, a, v, 8, I, n, A, c, t, i, o] 执行过程如图： flatMap拆分数组 Lambda表达式打印数组类型的集合12345List&lt;Integer&gt; numbers1 = Arrays.asList(1, 2, 3);List&lt;Integer&gt; numbers2 = Arrays.asList(3, 4);List&lt;int[]&gt; pairs = numbers1.stream().flatMap(i -&gt; numbers2.stream().map(j -&gt; new int[]&#123;i, j&#125;)).collect(toList());//如上面，有一个pairs的数组集合。java8的打印方式如下。pairs.forEach(pair -&gt; System.out.println(\"(\"+pair[0]+\",\"+pair[1]+\")\")); 由于本书才看了一半，后续的笔记还在记录当中。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lvshen9.gitee.io/tags/Java8/"},{"name":"Lambda表达式","slug":"Lambda表达式","permalink":"http://lvshen9.gitee.io/tags/Lambda表达式/"}]},{"title":"字典序算法","slug":"1","date":"2018-04-10T02:01:56.000Z","updated":"2019-01-17T07:45:16.138Z","comments":true,"path":"2018/04/10/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/04/10/1/","excerpt":"算法题目给定一个正整数，实现一个方法来求出离该整数最近的大于自身的“换位数”。 什么是换位数呢？就是把一个整数各个数位的数字进行全排列，从而得到新的整数。例如53241和23541。 小灰也不知道这种经过换位的整数应该如何称呼，所以姑且称其为“换位数”。","text":"算法题目给定一个正整数，实现一个方法来求出离该整数最近的大于自身的“换位数”。 什么是换位数呢？就是把一个整数各个数位的数字进行全排列，从而得到新的整数。例如53241和23541。 小灰也不知道这种经过换位的整数应该如何称呼，所以姑且称其为“换位数”。 题目要求写一个方法来寻找最近的且大于自身的换位数。比如下面这样： 输入12345，返回12354 输入12354，返回12435 输入12435，返回12453 解题思路比如给定整数12354，如何找到离它最近且大于它的换位数呢？ 为了和原数接近，我们需要尽量保持高位不变，低位在最小的范围内变换顺序。 那么，究竟需要变换多少位呢？这取决于当前整数的逆序区域。 换位数1 如果所示，12354的逆序区域是最后两位，仅看这两位已经是当前的最大组合。若想最接近原数，又比原数更大，必须从倒数第3位开始改变。 怎样改变呢？12345的倒数第3位是3，我们需要从后面的逆序区域中寻找到刚刚大于3的数字，和3的位置进行互换： 换位数2 互换后的临时结果是12453，倒数第3位已经确定，这时候最后两位仍然是逆序状态。我们需要把最后两位转变回顺序，以此保证在倒数第3位数值为4的情况下，后两位尽可能小： 换位数3 这样一来，我们就得到了想要的结果12435。 算法步骤1.从后向前查看逆序区域，找到逆序区域的前一位，也就是数字置换的边界 2.把逆序区域的前一位和逆序区域中刚刚大于它的数字交换位置 3.把原来的逆序区域转为顺序 Java代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//主流程，返回最近一个大于自身的相同数字组成的整数。public static int[] findNearestNumber(int[] numbers)&#123; //拷贝入参，避免直接修改入参 int[] numbersCopy = Arrays.copyOf(numbers, numbers.length); //1.从后向前查看逆序区域，找到逆序区域的前一位，也就是数字置换的边界 int index = findTransferPoint(numbersCopy); //如果数字置换边界是0，说明整个数组已经逆序，无法得到更大的相同数字组成的整数，返回自身 if(index == 0)&#123; return null; &#125; //2.把逆序区域的前一位和逆序区域中刚刚大于它的数字交换位置 exchangeHead(numbersCopy, index); //3.把原来的逆序区域转为顺序 reverse(numbersCopy, index); return numbersCopy;&#125;private static int findTransferPoint(int[] numbers)&#123; for(int i=numbers.length-1; i&gt;0; i--)&#123; if(numbers[i] &gt; numbers[i-1])&#123; return i; &#125; &#125; return 0;&#125;private static int[] exchangeHead(int[] numbers, int index)&#123; int head = numbers[index-1]; for(int i=numbers.length-1; i&gt;0; i--)&#123; if(head &lt; numbers[i])&#123; numbers[index-1] = numbers[i]; numbers[i] = head; break; &#125; &#125; return numbers;&#125;private static int[] reverse(int[] num, int index)&#123; for(int i=index,j=num.length-1; i&lt;j; i++,j--)&#123; int temp = num[i]; num[i] = num[j]; num[j] = temp; &#125; return num;&#125;public static void main(String[] args) &#123; int[] numbers = &#123;1,2,3,4,5&#125;; for(int i=0; i&lt;10;i++)&#123; numbers = findNearestNumber(numbers); outputNumbers(numbers); &#125;&#125;//输出数组private static void outputNumbers(int[] numbers)&#123; for(int i : numbers)&#123; System.out.print(i); &#125; System.out.println();&#125; 时间复杂度字典序算法的时间复杂度是$O(n)$","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"字典序","slug":"字典序","permalink":"http://lvshen9.gitee.io/tags/字典序/"}]},{"title":"《算法图解》读书笔记","slug":"1","date":"2018-03-19T09:45:02.000Z","updated":"2019-01-17T07:43:56.663Z","comments":true,"path":"2018/03/19/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/03/19/1/","excerpt":"最近看了这本《算法图解》，学到了很多有意思的东西。特来分享一下。 散列表长度调整填装因子越低，发生冲突的可能性越小，散列表的性能越高。一个不错的经验规则是：一旦填装因子大于0.7，就调整散列表的长度。","text":"最近看了这本《算法图解》，学到了很多有意思的东西。特来分享一下。 散列表长度调整填装因子越低，发生冲突的可能性越小，散列表的性能越高。一个不错的经验规则是：一旦填装因子大于0.7，就调整散列表的长度。 广度优先搜索广度优先搜索（breadth-first search，BFS）是一种位图算法。可以找出两样东西之间的最短距离。 使用这个算法可以做到： 编写国际跳棋AI，计算最少走多少步就可获胜； 编写拼写检查器，计算最少编辑多少个地方就可将错拼的单词改成正确的单词，如将 READED改为READER需要编辑一个地方； 根据你的人际关系网络找到关系最近的医生。 广度优先搜索有两个步骤： 使用图来建立问题模型。 使用广度优先搜索解决问题。 图 图由节点和边组成，一个节点可能与众多节点直接相连，这些节点被称为邻居。在前面的欠钱图中，Rama是Alex的邻居。Adit不是Alex的邻居，因为他们不直接相连。但Adit既是Rama的邻居，又是Tom的邻居。图用于模拟不同的东西是如何相连的。 广度优先搜索广度优先搜索是一种用于图的查找算法，可帮助回答两类问题。 第一类问题：从节点A出发，有前往节点B的路径吗？ 第二类问题：从节点A出发，前往节点B的哪条路径最短？ 广度优先搜索的运行时间为$O(人数 + 边数)$，这通常写作$O(V + E)$，其中V为顶点（vertice）数，E为边数。 MapReduce有一种特殊的并行算法正越来越流行，它就是分布式算法。在并行算法只需两到四个内核时，完全可以在笔记本电脑上运行它，但如果需要数百个内核呢？在这种情况下，可让算法在多台计算机上运行。MapReduce是一种流行的分布式算法，我们一般在Hadoop上面会使用它。 分布式算法非常适合用于在短时间内完成海量工作，其中的MapReduce基于两个简单的理念：映射（map）函数和归并（reduce）函数。 本书的最后还介绍了很多算法，像狄克斯特拉算法，贪婪算法，K最近邻算法等。不过好多没有领悟出来。这里就不做介绍。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"MapReduce","slug":"MapReduce","permalink":"http://lvshen9.gitee.io/tags/MapReduce/"}]},{"title":"MapReduce介绍","slug":"1","date":"2018-03-17T03:00:07.000Z","updated":"2019-01-17T07:42:18.812Z","comments":true,"path":"2018/03/17/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/03/17/1/","excerpt":"转载至：漫画：什么是MapReduce？ 什么是MapReduce？MapReduce是一种编程模型，其理论来自Google公司发表的三篇论文（MapReduce，BigTable，GFS）之一，主要应用于海量数据的并行计算。","text":"转载至：漫画：什么是MapReduce？ 什么是MapReduce？MapReduce是一种编程模型，其理论来自Google公司发表的三篇论文（MapReduce，BigTable，GFS）之一，主要应用于海量数据的并行计算。 MapReduce可以分成Map和Reduce两部分理解。 1.Map：映射过程，把一组数据按照某种Map函数映射成新的数据。 2.Reduce：归约过程，把若干组映射结果进行汇总并输出。 让我们来看一个实际应用的栗子，如何高效地统计出全国所有姓氏的人数？ 我们可以利用MapReduce的思想，针对每个省的人口做并行映射，统计出若干个局部结果，再把这些局部结果进行整理和汇总： 这张图是什么意思呢？我们来分别解释一下步骤： 1.Map： 以各个省为单位，多个线程并行读取不同省的人口数据，每一条记录生成一个Key-Value键值对。图中仅仅是简化了的数据。 2.Shuffle Shuffle这个概念在前文并未提及，它的中文意思是“洗牌”。Shuffle的过程是对数据映射的排序、分组、拷贝。 3.Reduce 执行之前分组的结果，并进行汇总和输出。 需要注意的是，这里描述的Shuffle只是抽象的概念，在实际执行过程中Shuffle被分成了两部分，一部分在Map任务中完成，一部分在Reduce任务中完成。 Hadoop如何实现MapReduce？ Hadoop是Apache基金会开发的一套分布式系统框架，包含多个组件，其核心就是HDFS和MapReduce。 由于篇幅原因，文本不会对Hadoop做完整的介绍，只是简单介绍一下Haddoop框架当中如何实现MapReduce。 下面这张图是Hadoop框架执行一个MapReduce Job的全过程： 这里需要对几种实体进行解释： HDFS: Hadoop的分布式文件系统，为MapReduce提供数据源和Job信息存储。 Client Node: 执行MapReduce程序的进程，用来提交MapReduce Job。 JobTracker Node: 把完整的Job拆分成若干Task，负责调度协调所有Task，相当于Master的角色。 TaskTracker Node: 负责执行由JobTracker指派的Task，相当于Worker的角色。这其中的Task分为MapTask和ReduceTask。 当然MapReduce只是大数据领域的冰山一角，除了上面介绍的技术，还要学习Hive、Spark、Storm等技术。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://lvshen9.gitee.io/tags/大数据/"},{"name":"Reduce","slug":"Reduce","permalink":"http://lvshen9.gitee.io/tags/Reduce/"}]},{"title":"《图解http》读书笔记","slug":"1","date":"2018-03-16T09:34:10.000Z","updated":"2019-01-17T07:38:12.684Z","comments":true,"path":"2018/03/16/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/03/16/1/","excerpt":"最近花了点时间看了上野 宣的《图解http》,收获良多。本书浅显易懂，小白也能看懂。 我把看书过程中感兴趣的做了一些笔记。","text":"最近花了点时间看了上野 宣的《图解http》,收获良多。本书浅显易懂，小白也能看懂。 我把看书过程中感兴趣的做了一些笔记。 TCP/IP 的分层管理4层：应用层/传输层/网络层/数据链路层 好处：如果互联网只由一个协议统筹，某个地方需要改变设计时，就必须把所有部分整体替换掉。 但如果分层了，只需要把变动的层替换即可。 层次化之后，设计也变得相对简单了。处于应用层上的应用可以只考虑分派给自己的任务，而不需要弄清对方在地球上哪个地方、对方的传输路线是怎样的、是否能确保传输送达等问题 四层协议 发送端与接收端的数据传输 数据传输 说明：发送端层与层之间传输数据时，每经过一层会被打上该层所属的首部的信息。而再接收端层与层传输数据时，每经过一层，会把对应的首部去掉。 TCP三次握手握手的过程中使用了TCP的标志：SYN（synchronize） 和ACK（acknowledgement）。 三次握手 各个协议与http协议下图详细介绍了IP协议，TCP协议和DNS服务在使用HTTP协议的通信过程中发挥的作用。 ip与http与tcp URI和URL的区别URI：统一资源标识符 URL：统一资源定位符，就是访问web页面在浏览器上输入的网址。 至于区别，知乎上有人形象比喻： 统一资源标志符URI就是在某一规则下能把一个资源独一无二地标识出来。拿人做例子，假设这个世界上所有人的名字都不能重复，那么名字就是URI的一个实例，通过名字这个字符串就可以标识出唯一的一个人。现实当中名字当然是会重复的，所以身份证号才是URI，通过身份证号能让我们能且仅能确定一个人 上面是URI，看看下面的URL: 那统一资源定位符URL是什么呢。也拿人做例子然后跟HTTP的URL做类比，就可以有：动物住址协议://地球/中国/浙江省/杭州市/西湖区/某大学/14号宿舍楼/525号寝/张三.人可以看到，这个字符串同样标识出了唯一的一个人，起到了URI的作用，所以URL是URI的子集。URL是以描述人的位置来唯一确定一个人的。 URI用字符串标识某一互联网资源，而URL表示资源的地点。可以说，URL是URI的子集。 URI格式 GET与POSTGET：获取资源 get POST：传输实体主体 POST的主要目的并不是获取响应的主体内容。 post HTTP支持的方法 get等 如上图，我们一般只用前5个方法。 状态码类别 状态码类别 HTTPS为了保证服务器与客户端信息传递的安全性，需要在HTTP上再加入加密处理和认证等机制。添加了这种机制的HTTP称为HTTPS(HTTP Secure)。 HTTPS 除了上面的知识，书中还介绍了一些注入攻击的内容，不过有些技术可能现在已经派不上用场。也就不记录下来了","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"http","slug":"http","permalink":"http://lvshen9.gitee.io/tags/http/"},{"name":"tcp","slug":"tcp","permalink":"http://lvshen9.gitee.io/tags/tcp/"}]},{"title":"使用BOOTICE修复双系统引导","slug":"1","date":"2018-03-09T09:01:21.000Z","updated":"2019-01-17T07:33:53.024Z","comments":true,"path":"2018/03/09/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/03/09/1/","excerpt":"之前不小心删除掉了系统的一个启动文件，电脑一开机就报系统引导文件错误。开机U盘启动进入PE系统，执行修复引导项，还是解决不了。重装系统是可以解决问题的，但不想重装系统。于是我在其他盘里装了一个临时系统，用于主系统的修复。 本文使用的软件是：BOOTICE，本软件分32位和64位，请根据系统选择正确的版本。","text":"之前不小心删除掉了系统的一个启动文件，电脑一开机就报系统引导文件错误。开机U盘启动进入PE系统，执行修复引导项，还是解决不了。重装系统是可以解决问题的，但不想重装系统。于是我在其他盘里装了一个临时系统，用于主系统的修复。 本文使用的软件是：BOOTICE，本软件分32位和64位，请根据系统选择正确的版本。 操作步骤： 启动进入系统，运行BOOTICE，切换到“BCD编辑”页，点“智能编辑模式”； 进入BCD编辑，点击“添加”—“新建Windows 7/8/8.1启动项”； 在右边“启动设备”中选择“启动磁盘”，选择Win7安装所在的硬盘； 在“启动分区”中选择Win7安装所在的分区； 在“菜单标题”中可以修改启动项显示的名字，然后点击右下方的“保存当前系统设置”即可。左下角的“全局设置”中可以修改“超时时间”即启动菜单等待时间，修改后需要点击“保存全局设置”才能生效。 保存后，重启，过了Win10 LOGO界面后就会出现启动菜单“选择操作系统”。 终于大功告成，又可以愉快的写代码了。以后再也不手贱乱删文件了😭。","categories":[{"name":"生活","slug":"生活","permalink":"http://lvshen9.gitee.io/categories/生活/"}],"tags":[{"name":"双系统","slug":"双系统","permalink":"http://lvshen9.gitee.io/tags/双系统/"},{"name":"BOOTICE","slug":"BOOTICE","permalink":"http://lvshen9.gitee.io/tags/BOOTICE/"}]},{"title":"CSF云化框架服务治理平台搭建笔记","slug":"1","date":"2018-03-08T06:23:41.000Z","updated":"2019-01-17T07:31:29.013Z","comments":true,"path":"2018/03/08/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/03/08/1/","excerpt":"CSF是一个远程服务管理平台，其平台搭建过程如下。 用户创建需要创建两个用户：zk，chaapp 1234567#如果已经创建了组，可以省略groupadd ngboss useradd -d /home/zk -g ngboss zkuseradd -d /home/chaapp -g ngboss chaapp#创建密码echo '1q1w1e1r' | passwd --stdin chaapp zk的安装前面已经学习过，这里略过。","text":"CSF是一个远程服务管理平台，其平台搭建过程如下。 用户创建需要创建两个用户：zk，chaapp 1234567#如果已经创建了组，可以省略groupadd ngboss useradd -d /home/zk -g ngboss zkuseradd -d /home/chaapp -g ngboss chaapp#创建密码echo '1q1w1e1r' | passwd --stdin chaapp zk的安装前面已经学习过，这里略过。 CSF相关的东西放到chaapp目录下。 如图上传这两个文件，解压。 解压后的目录如下图： 服务器配置修改AIConfig.xml123vi /home/chaapp/config/AIConfig.xml106 &lt;ConfigItem name=\"DATABASE_DIALECT\" remarks=\"数据的方言(如果没有,采用OracleDialectImpl)\" &gt;com.ai.appframe2.bo.dialect.OracleDialectImpl&lt;/ConfigItem&gt; csf.xml123456vi /home/chaapp/config/csf/csf.xml #163行&lt;Item name=\"zk.server.list\"&gt; &lt;value&gt;127.0.0.1:2181&lt;/value&gt; &lt;description&gt;多个地址用逗号(,)隔开 &lt;/description&gt;&lt;/Item&gt; defaults.xml12345678vi /home/chaapp/config/system/service/defaults.xml&lt;pool name=\"base\" primary=\"true\"&gt; &lt;property name=\"driverClassName\" value=\"oracle.jdbc.OracleDriver\" /&gt; &lt;property name=\"url\" value=\"jdbc:oracle:thin:@10.13.3.13:1521:shxicrm\" /&gt; &lt;property name=\"username\" value=\"UCR_PSWD\" /&gt; &lt;property name=\"password\" value=\"UCR_PSWD\" /&gt;... 启动服务端123456[chaapp@centos7-node01 ~]$ lsbin config configext lib libext logs sbin soa_web sql support[chaapp@centos7-node01 ~]$ cd sbin/[chaapp@centos7-node01 sbin]$ lsstart_app_21.sh start_app_22.sh start_app_23.sh start_app_24.sh start_app.sh statistic.sh stop_app.sh taillog.sh[chaapp@centos7-node01 sbin]$ ./start_app_21.sh tomcat配置进入此目录中 12345[chaapp@centos7-node01 webapps]$ pwd/home/chaapp/soa_web/apache-tomcat-7.0.68/webapps[chaapp@centos7-node01 webapps]$ lscsf_web csf_web.war docs examples host-manager manager ROOT zkweb zkweb.war[chaapp@centos7-node01 webapps]$ 这里有两个目录需要配置：csf_web和zkweb。 csf_web目录下12345678910111213141516171819202122232425[chaapp@centos7-node01 classes]$ pwd/home/chaapp/soa_web/apache-tomcat-7.0.68/webapps/csf_web/WEB-INF/classes[chaapp@centos7-node01 classes]$ lsAIConfig.xml AIRootConfig.xml config.properties log4j.properties SrvFrameConfig.xml TaskConfig.xmlAiLog.properties com csf.properties menu.xml system[chaapp@centos7-node01 classes]$ vi AIConfig.xml #104行修改成Oracle方言[chaapp@centos7-node01 classes]$ vi csf.properties #修改zk地址 config.properties也一样修改zk.server.list=192.168.71.137:2181#进入此目录中[chaapp@centos7-node01 service]$ pwd/home/chaapp/soa_web/apache-tomcat-7.0.68/webapps/csf_web/WEB-INF/classes/system/service[chaapp@centos7-node01 service]$ vi defaults.xml ... 51 &lt;pool name=\"base\" primary=\"true\"&gt; 52 &lt;property name=\"driverClassName\" value=\"oracle.jdbc.OracleDriver\" /&gt; 53 &lt;property name=\"url\" value=\"jdbc:oracle:thin:@10.13.3.13:1521:shxicrm\" /&gt; 54 &lt;property name=\"username\" value=\"UCR_PSWD\" /&gt; 55 &lt;property name=\"password\" value=\"UCR_PSWD\" /&gt; ... zk_web目录下12345[chaapp@centos7-node01 classes]$ pwd/home/chaapp/soa_web/apache-tomcat-7.0.68/webapps/zkweb/WEB-INF/classes[chaapp@centos7-node01 classes]$ lsc3p0.properties com log4j.xml spring zk.properties#修改zk.properties的zk地址。貌似不用改也阔以 启动tomcat在tomcat的bin目录下 1[chaapp@centos7-node01 bin]$ ./startup.sh 浏览器上输入：http://192.168.71.137:8080/csf_web/common/index.jsp 如图： 本地Java工程Java工程的目录如下： 例如：我在AddMoneyCSVImpl.java中写了一个方法 12345678910111213public class AddMoneyCSVImpl implements IAddMoneyCSV &#123; public String getMoney(Userman userman) &#123; return userman.getMoney(); &#125; public String getId(String name) &#123; return name+\"调用成功\"; &#125; //这个方法 public String getLvshen(String name)&#123; return \"Hello I'm\" + name; &#125;&#125; TestService.java中的内容如下： 123456789public class TestService &#123; public static void main(String[] args) throws Exception &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(\"name\", \"Lvshen\"); //这里括号中的命名规则为：中心明_类名_方法名 IClientSV sv = CsfServiceFactory.getService(\"order_IAddMoneyCSV_getLvshen\"); System.out.println(\"********************\"+sv.service(map)); &#125;&#125; 然后打开注册工具，把服务注册进入数据库和zk，操作如下图： 点击View→Setting，在config界面中进行相关的设置（上图有数据库的配置），项目配置和ClassPath的配置如下图： 配置好之后，软件界面上就会有java工程的相关目录了如下： 输入中心名，选择方法，右键注册即可。 这样前端界面就可以看到新添加的服务。 之后就可以对服务进行相关的操作了。 把Java工程打包成jar包放入服务器的/home/chaapp/lib目录下。运行Java工程，项目就可以远程调用服务跑起来了。","categories":[{"name":"Work","slug":"Work","permalink":"http://lvshen9.gitee.io/categories/Work/"}],"tags":[{"name":"服务治理","slug":"服务治理","permalink":"http://lvshen9.gitee.io/tags/服务治理/"},{"name":"CSF","slug":"CSF","permalink":"http://lvshen9.gitee.io/tags/CSF/"}]},{"title":"Zookeeper、HDFS、HBase安装笔记","slug":"1","date":"2018-03-02T09:21:16.000Z","updated":"2018-03-02T10:08:04.133Z","comments":true,"path":"2018/03/02/1/","link":"","permalink":"http://lvshen9.gitee.io/2018/03/02/1/","excerpt":"zk安装经过这几天的学习，对大数据有了一定的了解。这次在我自己的本机上安装了zookeeper、HDFS、HBase集群。并把安装时的过程记录了下来。","text":"zk安装经过这几天的学习，对大数据有了一定的了解。这次在我自己的本机上安装了zookeeper、HDFS、HBase集群。并把安装时的过程记录了下来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#1.创建用户groupadd ngbossuseradd -d /home/zk -g ngboss zkuseradd -d /home/hdfs -g ngboss hdfsuseradd -d /home/hbase -g ngboss hbase#2.root下添加hosts信息vi /etc/hosts192.168.71.132 centos7-node01192.168.71.131 centos7-node02 192.168.71.133 centos7-node03#3.拓展IPv4的IP是32bit的，/xx 表示从右往左多少位是掩码（不变的），余下的是可变的192.168.0.0/16 表示 192.168.0.0 -&gt; 192.168.255.255192.168.0.0/16 表示 192.168.0.0 -&gt; 192.168.255.255192.168.0.0/24 表示 192.168.0.0 -&gt; 192.168.0.255#4.jdk配置vi ~/.bash_profile# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then. ~/.bashrcfi# +-------------------------------------+# | J2EE'S PROFILE, DON'T MODIFY! |# +-------------------------------------+alias grep='grep --colour=auto'alias vi='vim'alias ll='ls -l'alias ls='ls --color=auto'alias mv='mv -i'alias rm='rm -i'export PS1=\"\\[\\033[01;32m\\]\\u@\\h\\[\\033[01;34m\\] \\w \\$\\[\\033[00m\\] \"export TERM=linuxexport EDITOR=vimexport PATH=$&#123;HOME&#125;/bin:$&#123;HOME&#125;/support/jdk/bin:$&#123;HOME&#125;/support/ant/bin:$&#123;HOME&#125;/support/python/bin:$PATHexport LANG=zh_CN.utf8export PYTHONUNBUFFERED=1export TIMOUT=3000export HISTSIZE=1000#5.验证jdk安装是否成功. ~/.bash_profilewhich java#6.zoo.cfg文件配置vi ~/etc/zoo.cfg server.1=192.168.71.131:28880:38880server.2=192.168.71.132:28880:38880server.3=192.168.71.133:28880:38880#7.acl.conf文件配置vi ~/etc/acl.conf192.18.0.0/16#8.myid文件配置vi ~/data/myid#9.zk启动zk@hadoop-node02 ~/bin $ ./zkServer.sh start#10.端口验证netstat -tnlp | grep 2181#11.结构zk@centos7-node01 ~ $ lsbin data etc lib logs sbin support hdfs安装12345678910111213141516171819202122232425262728293031323334353637383940414243444546#1.解压hdfs和jdk...#2.生成密匙ssh-keygen -t rsa#3.拷贝公匙到其他主机ssh-copy-id -i hdfs@192.168.71.131#4.给用户创建密码echo '1q1w1e1r' | passwd --stdin hdfs #5.修改slaves文件修改：vi /home/hdfs/etc/hadoop/slavescentos7-node02centos7-node03#6.修改core-site.xml修改：/home/hdfs/etc/hadoop/core-site.xmlhdfs:// 这一行改成第一台主机的IP，端口啥的都不变#7.修改hdfs-site.xmlvi /home/hdfs/etc/hadoop/hdfs-site.xml &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/home/hdfs/data/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/home/hdfs/data/data&lt;/value&gt;....#8.初始化hdfs：cd /home/hdfs/bin./hadoop namenode -format#9.启动hdfscd ~/sbin./start-dfs.sh#10.hdfs目录hdfs@centos7-node03 ~ $ lsbin data etc include lib libexec logs sbin share support temp hbase安装123456789101112131415161718192021222324252627282930#1.解压hbase和jdk#2.创建公匙 拷贝公匙到其他主机#3.创建logs目录只要logs目录，没有data目录，hbase的数据存到hdfs上去了#4.在hdfs第一台服务器上执行以下命令hdfs@centos7-node01 ~ $ cd /home/hdfs/binhdfs@centos7-node01 ~/bin $ ./hadoop fs -mkdir /hbasehdfs@centos7-node01 ~/bin $ ./hadoop fs -chmod 777 /hbasehdfs@centos7-node01 ~/bin $ ./hadoop fs -ls /Found 1 itemsdrwxrwxrwx - hdfs supergroup 0 2018-02-01 00:14 /hbase#5.配置 hbase，vi /home/hbase/conf/hbase-site.xml&lt;value&gt;centos7-node01,centos7-node02,centos7-node03&lt;/value&gt;#6.配置regionservers文件hbase@centos7-node01 ~/bin $ vi ~/conf/regionservers centos7-node02centos7-node03find . -type f | xargs grep 'bst'#7.启动hbasecd bin./start-hbase.sh","categories":[{"name":"Work","slug":"Work","permalink":"http://lvshen9.gitee.io/categories/Work/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://lvshen9.gitee.io/tags/大数据/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://lvshen9.gitee.io/tags/Zookeeper/"}]},{"title":"从分布式协调到Zookeeper","slug":"从分布式协调到Zookeeper","date":"2018-01-25T08:52:11.000Z","updated":"2018-01-25T09:06:02.964Z","comments":true,"path":"2018/01/25/从分布式协调到Zookeeper/","link":"","permalink":"http://lvshen9.gitee.io/2018/01/25/从分布式协调到Zookeeper/","excerpt":"转载至：ZooKeeper学习第一期—Zookeeper简单介绍 - 邬兴亮 - 博客园 一、分布式协调技术在给大家介绍ZooKeeper之前先来给大家介绍一种技术——分布式协调技术。那么什么是分布式协调技术？那么我来告诉大家，其实分布式协调技术 主要用来解决分布式环境当中多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成”脏数据”的后果。这时，有人可能会说这个简单，写一个调 度算法就轻松解决了。说这句话的人，可能对分布式系统不是很了解，所以才会出现这种误解。如果这些进程全部是跑在一台机上的话，相对来说确实就好办了，问 题就在于他是在一个分布式的环境下，这时问题又来了，那什么是分布式呢？这个一两句话我也说不清楚，但我给大家画了一张图希望能帮助大家理解这方面的内 容，如果觉得不对尽可拍砖，来咱们看一下这张图，如图1.1所示。 图 1.1 分布式系统图","text":"转载至：ZooKeeper学习第一期—Zookeeper简单介绍 - 邬兴亮 - 博客园 一、分布式协调技术在给大家介绍ZooKeeper之前先来给大家介绍一种技术——分布式协调技术。那么什么是分布式协调技术？那么我来告诉大家，其实分布式协调技术 主要用来解决分布式环境当中多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成”脏数据”的后果。这时，有人可能会说这个简单，写一个调 度算法就轻松解决了。说这句话的人，可能对分布式系统不是很了解，所以才会出现这种误解。如果这些进程全部是跑在一台机上的话，相对来说确实就好办了，问 题就在于他是在一个分布式的环境下，这时问题又来了，那什么是分布式呢？这个一两句话我也说不清楚，但我给大家画了一张图希望能帮助大家理解这方面的内 容，如果觉得不对尽可拍砖，来咱们看一下这张图，如图1.1所示。 图 1.1 分布式系统图 给大家分析一下这张图，在这图中有三台机器，每台机器各跑一个应用程序。然后我们将这三台机器通过网络将其连接起来，构成一个系统来为用户提供服务，对用户来说这个系统的架构是透明的，他感觉不到我这个系统是一个什么样的架构。那么我们就可以把这种系统称作一个分布式系统。 那我们接下来再分析一下，在这个分布式系统中如何对进程进行调度，我假设在第一台机器上挂载了一个资源，然后这三个物理分布的进程都要竞争这个资源，但我们又不希望他们同时进行访问，这时候我们就需要一个协调器，来让他们有序的来访问这个资源。这个协调器就是我们经常提到的那个锁，比如说”进程-1”在使用该资源的时候，会先去获得锁，”进程1”获得锁以后会对该资源保持独占，这样其他进程就无法访问该资源，”进程1”用完该资源以后就将锁释放掉，让其他进程来获得锁，那么通过这个锁机制，我们就能保证了分布式系统中多个进程能够有序的访问该临界资源。那么我们把这个分布式环境下的这个锁叫作分布式锁。这个分布式锁也就是我们分布式协调技术实现的核心内容，那么如何实现这个分布式呢，那就是我们后面要讲的内容。 二、分布式锁的实现好我们知道，为了防止分布式系统中的多个进程之间相互干扰，我们需要一种分布式协调技术来对这些进程进行调度。而这个分布式协调技术的核心就是来实现这个分布式锁。那么这个锁怎么实现呢？这实现起来确实相对来说比较困难的。 1.1 面临的问题在看了图1.1所示的分布式环境之后，有人可能会感觉这不是很难。无非是将原来在同一台机器上对进程调度的原语，通过网络实现在分布式环境中。是的，表面上是可以这么说。但是问题就在网络这，在分布式系统中，所有在同一台机器上的假设都不存在：因为网络是不可靠的。 比如，在同一台机器上，你对一个服务的调用如果成功，那就是成功，如果调用失败，比如抛出异常那就是调用失败。但是在分布式环境中，由于网络的不可 靠，你对一个服务的调用失败了并不表示一定是失败的，可能是执行成功了，但是响应返回的时候失败了。还有，A和B都去调用C服务，在时间上 A还先调用一些，B后调用，那么最后的结果是不是一定A的请求就先于B到达呢？ 这些在同一台机器上的种种假设，我们都要重新思考，我们还要思考这些问题给我们的设计和编码带来了哪些影响。还有，在分布式环境中为了提升可靠性，我们往 往会部署多套服务，但是如何在多套服务中达到一致性，这在同一台机器上多个进程之间的同步相对来说比较容易办到，但在分布式环境中确实一个大难题。 所以分布式协调远比在同一台机器上对多个进程的调度要难得多，而且如果为每一个分布式应用都开发一个独立的协调程序。一方面，协调程序的反复编写浪 费，且难以形成通用、伸缩性好的协调器。另一方面，协调程序开销比较大，会影响系统原有的性能。所以，急需一种高可靠、高可用的通用协调机制来用以协调分 布式应用。 1.2 分布式锁的实现者目前，在分布式协调技术方面做得比较好的就是Google的Chubby还有Apache的ZooKeeper他们都是分布式锁的实现者。有人会问 既然有了Chubby为什么还要弄一个ZooKeeper，难道Chubby做得不够好吗？不是这样的，主要是Chbby是非开源的，Google自家 用。后来雅虎模仿Chubby开发出了ZooKeeper，也实现了类似的分布式锁的功能，并且将ZooKeeper作为一种开源的程序捐献给了 Apache，那么这样就可以使用ZooKeeper所提供锁服务。而且在分布式领域久经考验，它的可靠性，可用性都是经过理论和实践的验证的。所以我们 在构建一些分布式系统的时候，就可以以这类系统为起点来构建我们的系统，这将节省不少成本，而且bug也 将更少。 三、ZooKeeper概述ZooKeeper是一种为分布式应用所设计的高可用、高性能且一致的开源协调服务，它提供了一项基本服务：分布式锁服务。由于ZooKeeper的开源特性，后来我们的开发者在分布式锁的基础上，摸索了出了其他的使用方法：配置维护、组服务、分布式消息队列、分布式通知/协调等。 注意：ZooKeeper性能上的特点决定了它能够用在大型的、分布式的系统当中。从可靠性方面来说，它并不会因为一个节点的错误而崩溃。除此之外，它严格的序列访问控制意味着复杂的控制原语可以应用在客户端上。ZooKeeper在一致性、可用性、容错性的保证，也是ZooKeeper的成功之处，它获得的一切成功都与它采用的协议——Zab协议是密不可分的，这些内容将会在后面介绍。 前面提到了那么多的服务，比如分布式锁、配置维护、组服务等，那它们是如何实现的呢，我相信这才是大家关心的东西。ZooKeeper在实现这些服务时，首先它设计一种新的数据结构——Znode，然后在该数据结构的基础上定义了一些原语，也就是一些关于该数据结构的一些操作。有了这些数据结构和原语还不够，因为我们的ZooKeeper是工作在一个分布式的环境下，我们的服务是通过消息以网络的形式发送给我们的分布式应用程序，所以还需要一个通知机制——Watcher机制。那么总结一下，ZooKeeper所提供的服务主要是通过：数据结构+原语+watcher机制，三个部分来实现的。那么我就从这三个方面，给大家介绍一下ZooKeeper。 四、ZooKeeper数据模型4.1 ZooKeeper数据模型ZnodeZooKeeper拥有一个层次的命名空间，这个和标准的文件系统非常相似，如下图3.1 所示。 图4.1 ZooKeeper数据模型与文件系统目录树 ](https://images0.cnblogs.com/blog/671563/201411/301534562152768.png) ![img 从图中我们可以看出ZooKeeper的数据模型，在结构上和标准文件系统的非常相似，都是采用这种树形层次结构，ZooKeeper树中的每个节点被称为—Znode。和文件系统的目录树一样，ZooKeeper树中的每个节点可以拥有子节点。但也有不同之处： (1) 引用方式 Zonde通过路径引用，如同Unix中的文件路径。路径必须是绝对的，因此他们必须由斜杠字符来开头。除此以外，他们必须是唯一的，也就是说每一个路径只有一个表示，因此这些路径不能改变。在ZooKeeper中，路径由Unicode字符串组成，并且有一些限制。字符串”/zookeeper”用以保存管理信息，比如关键配额信息。 (2) Znode结构 ZooKeeper命名空间中的Znode，兼具文件和目录两种特点。既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分。图中的每个节点称为一个Znode。 每个Znode由3部分组成: ① stat：此为状态信息, 描述该Znode的版本, 权限等信息 ② data：与该Znode关联的数据 ③ children：该Znode下的子节点 ZooKeeper虽然可以关联一些数据，但并没有被设计为常规的数据库或者大数据存储，相反的是，它用来管理调度数据，比如分布式应用中的配置文件信息、状态信息、汇集位置等等。这些数据的共同特性就是它们都是很小的数据，通常以KB为大小单位。ZooKeeper的服务器和客户端都被设计为严格检查并限制每个Znode的数据大小至多1M，但常规使用中应该远小于此值。 (3) 数据访问 ZooKeeper中的每个节点存储的数据要被原子性的操作。也就是说读操作将获取与节点相关的所有数据，写操作也将替换掉节点的所有数据。另外，每一个节点都拥有自己的ACL(访问控制列表)，这个列表规定了用户的权限，即限定了特定用户对目标节点可以执行的操作。 (4) 节点类型 ZooKeeper中的节点有两种，分别为临时节点和永久节点。节点的类型在创建时即被确定，并且不能改变。 ① 临时节点：该节点的生命周期依赖于创建它们的会话。一旦会话(Session)结束，临时节点将被自动删除，当然可以也可以手动删除。虽然每个临时的Znode都会绑定到一个客户端会话，但他们对所有的客户端还是可见的。另外，ZooKeeper的临时节点不允许拥有子节点。 ② 永久节点：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。 (5) 顺序节点 当创建Znode的时候，用户可以请求在ZooKeeper的路径结尾添加一个递增的计数。这个计数对于此节点的父节点来说是唯一的，它的格式为”%10d”(10位数字，没有数值的数位用0补充，例如”0000000001”)。当计数值大于232-1时，计数器将溢出。 (6) 观察 客户端可以在节点上设置watch，我们称之为监视器。当节点状态发生改变时(Znode的增、删、改)将会触发watch所对应的操作。当watch被触发时，ZooKeeper将会向客户端发送且仅发送一条通知，因为watch只能被触发一次，这样可以减少网络流量。 4.2 ZooKeeper中的时间ZooKeeper有多种记录时间的形式，其中包含以下几个主要属性： (1) Zxid 致使ZooKeeper节点状态改变的每一个操作都将使节点接收到一个Zxid格式的时间戳，并且这个时间戳全局有序。也就是说，也就是说，每个对 节点的改变都将产生一个唯一的Zxid。如果Zxid1的值小于Zxid2的值，那么Zxid1所对应的事件发生在Zxid2所对应的事件之前。实际 上，ZooKeeper的每个节点维护者三个Zxid值，为别为：cZxid、mZxid、pZxid。 ① cZxid： 是节点的创建时间所对应的Zxid格式时间戳。② mZxid：是节点的修改时间所对应的Zxid格式时间戳。 实现中Zxid是一个64为的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个 新的epoch。低32位是个递增计数。 (2) 版本号 对节点的每一个操作都将致使这个节点的版本号增加。每个节点维护着三个版本号，他们分别为： ① version：节点数据版本号② cversion：子节点版本号③ aversion：节点所拥有的ACL版本号 4.3 ZooKeeper节点属性通过前面的介绍，我们可以了解到，一个节点自身拥有表示其状态的许多重要属性，如下图所示。 图 4.2 Znode节点属性结构 五、ZooKeeper服务中操作在ZooKeeper中有9个基本操作，如下图所示： 图 5.1 ZooKeeper类方法描述 更新ZooKeeper操作是有限制的。delete或setData必须明确要更新的Znode的版本号，我们可以调用exists找到。如果版本号不匹配，更新将会失败。 更新ZooKeeper操作是非阻塞式的。因此客户端如果失去了一个更新(由于另一个进程在同时更新这个Znode)，他可以在不阻塞其他进程执行的情况下，选择重新尝试或进行其他操作。 尽管ZooKeeper可以被看做是一个文件系统，但是处于便利，摒弃了一些文件系统地操作原语。因为文件非常的小并且使整体读写的，所以不需要打开、关闭或是寻地的操作。 六、Watch触发器(1) watch概述 ZooKeeper可以为所有的读操作设置watch，这些读操作包括：exists()、getChildren()及getData()。watch事件是一次性的触发器，当watch的对象状态发生改变时，将会触发此对象上watch所对应的事件。watch事件将被异步地发送给客户端，并且ZooKeeper为watch机制提供了有序的一致性保证。理论上，客户端接收watch事件的时间要快于其看到watch对象状态变化的时间。 (2) watch类型 ZooKeeper所管理的watch可以分为两类： ① 数据watch(data watches)：getData和exists负责设置数据watch② 孩子watch(child watches)：getChildren负责设置孩子watch 我们可以通过操作返回的数据来设置不同的watch： ① getData和exists：返回关于节点的数据信息② getChildren：返回孩子列表 因此 ① 一个成功的setData操作将触发Znode的数据watch ② 一个成功的create操作将触发Znode的数据watch以及孩子watch ③ 一个成功的delete操作将触发Znode的数据watch以及孩子watch (3) watch注册与处触发 图 6.1 watch设置操作及相应的触发器如图下图所示： ① exists操作上的watch，在被监视的Znode创建、删除或数据更新时被触发。② getData操作上的watch，在被监视的Znode删除或数据更新时被触发。在被创建时不能被触发，因为只有Znode一定存在，getData操作才会成功。③ getChildren操作上的watch，在被监视的Znode的子节点创建或删除，或是这个Znode自身被删除时被触发。可以通过查看watch事件类型来区分是Znode，还是他的子节点被删除：NodeDelete表示Znode被删除，NodeDeletedChanged表示子节点被删除。 Watch由客户端所连接的ZooKeeper服务器在本地维护，因此watch可以非常容易地设置、管理和分派。当客户端连接到一个新的服务器 时，任何的会话事件都将可能触发watch。另外，当从服务器断开连接的时候，watch将不会被接收。但是，当一个客户端重新建立连接的时候，任何先前 注册过的watch都会被重新注册。 (4) 需要注意的几点 Zookeeper的watch实际上要处理两类事件： ① 连接状态事件(type=None, path=null) 这类事件不需要注册，也不需要我们连续触发，我们只要处理就行了。 ② 节点事件 节点的建立，删除，数据的修改。它是one time trigger，我们需要不停的注册触发，还可能发生事件丢失的情况。 上面2类事件都在Watch中处理，也就是重载的process(Event event) 节点事件的触发，通过函数exists，getData或getChildren来处理这类函数，有双重作用： ① 注册触发事件 ② 函数本身的功能 函数的本身的功能又可以用异步的回调函数来实现,重载processResult()过程中处理函数本身的的功能。 七、ZooKeeper应用举例 为了方便大家理解ZooKeeper，在此就给大家举个例子，看看ZooKeeper是如何实现的他的服务的，我以ZooKeeper提供的基本服务分布式锁为例。 7.1 分布式锁应用场景在分布式锁服务中，有一种最典型应用场景，就是通过对集群进行Master选举，来解决分布式系统中的单点故障。什么是分布式系统中的单点故障：通常分布式系统采用主从模式，就是一个主控机连接多个处理节点。主节点负责分发任务，从节点负责处理任务，当我们的主节点发生故障时，那么整个系统就都瘫痪了，那么我们把这种故障叫作单点故障。如下图7.1和7.2所示： 图 7.1 主从模式分布式系统 图7.2 单点故障 7.2 传统解决方案传统方式是采用一个备用节点，这个备用节点定期给当前主节点发送ping包，主节点收到ping包以后向备用节点发送回复Ack，当备用节点收到回复的时候就会认为当前主节点还活着，让他继续提供服务。如图7.3所示： 图 7.3 传统解决方案 当主节点挂了，这时候备用节点收不到回复了，然后他就认为主节点挂了接替他成为主节点如下图7.4所示： 图 7.4传统解决方案 但是这种方式就是有一个隐患，就是网络问题，来看一网络问题会造成什么后果，如下图7.5所示： 图 7.5 网络故障 也就是说我们的主节点的并没有挂，只是在回复的时候网络发生故障，这样我们的备用节点同样收不到回复，就会认为主节点挂了，然后备用节点将他的Master实例启动起来，这样我们的分布式系统当中就有了两个主节点也就是—双Master， 出现Master以后我们的从节点就会将它所做的事一部分汇报给了主节点，一部分汇报给了从节点，这样服务就全乱了。为了防止出现这种情况，我们引入了 ZooKeeper，它虽然不能避免网络故障，但它能够保证每时每刻只有一个Master。我么来看一下ZooKeeper是如何实现的。 7.3 ZooKeeper解决方案(1) Master启动 在引入了Zookeeper以后我们启动了两个主节点，”主节点-A”和”主节点-B”他们启动以后，都向ZooKeeper去注册一个节点。我们 假设”主节点-A”锁注册地节点是”master-00001”，”主节点-B”注册的节点是”master-00002”，注册完以后进行选举，编号最 小的节点将在选举中获胜获得锁成为主节点，也就是我们的”主节点-A”将会获得锁成为主节点，然后”主节点-B”将被阻塞成为一个备用节点。那么，通过这 种方式就完成了对两个Master进程的调度。 图7.6 ZooKeeper Master选举 (2) Master故障 如果”主节点-A”挂了，这时候他所注册的节点将被自动删除，ZooKeeper会自动感知节点的变化，然后再次发出选举，这时候”主节点-B”将在选举中获胜，替代”主节点-A”成为主节点。 图7.7 ZooKeeper Master选举 (3) Master 恢复 图7.8 ZooKeeper Master选举 如果主节点恢复了，他会再次向ZooKeeper注册一个节点，这时候他注册的节点将会是”master-00003”，ZooKeeper会感知节点的变化再次发动选举，这时候”主节点-B”在选举中会再次获胜继续担任”主节点”，”主节点-A”会担任备用节点。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://lvshen9.gitee.io/tags/Zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"http://lvshen9.gitee.io/tags/分布式/"}]},{"title":"Hexo博客部署到Linux服务器上","slug":"Hexo博客部署到Linux服务器上","date":"2018-01-08T05:53:55.000Z","updated":"2018-01-08T08:37:57.456Z","comments":true,"path":"2018/01/08/Hexo博客部署到Linux服务器上/","link":"","permalink":"http://lvshen9.gitee.io/2018/01/08/Hexo博客部署到Linux服务器上/","excerpt":"服务器部署博客：AsiaInfo 以前Hexo博客是托管到github上，因为国内访问github速度有些慢，这次试着把博客部署到阿里云的服务器上。本地系统Windows10上需要安装node.js+hexo。下面做一个详细的介绍。 本地端安装git bash（git安装原文来自百度经验）由于使用的是git命令。所以需要安装git bash，安装过程如下。 由于安装过程千篇一律，安装的详细过程请百度一下： 图文详解Windows下安装最新版Git_百度经验","text":"服务器部署博客：AsiaInfo 以前Hexo博客是托管到github上，因为国内访问github速度有些慢，这次试着把博客部署到阿里云的服务器上。本地系统Windows10上需要安装node.js+hexo。下面做一个详细的介绍。 本地端安装git bash（git安装原文来自百度经验）由于使用的是git命令。所以需要安装git bash，安装过程如下。 由于安装过程千篇一律，安装的详细过程请百度一下： 图文详解Windows下安装最新版Git_百度经验 安装node.js1、Windows 安装包(.msi)32 位安装包下载地址 : https://nodejs.org/dist/v4.4.3/node-v4.4.3-x86.msi 64 位安装包下载地址 : https://nodejs.org/dist/v4.4.3/node-v4.4.3-x64.msi 本文实例以 v0.10.26 版本为例，其他版本类似， 安装步骤： 步骤 1 : 双击下载后的安装包 v0.10.26，如下所示： 步骤 2 : 点击以上的Run(运行)，将出现如下界面： 步骤 3 : 勾选接受协议选项，点击 next（下一步） 按钮 : 步骤 4 : Node.js默认安装目录为 “C:\\Program Files\\nodejs\\” , 你可以修改目录，并点击 next（下一步）： 步骤 5 : 点击树形图标来选择你需要的安装模式 , 然后点击下一步 next（下一步） 步骤 6 :点击 Install（安装） 开始安装Node.js。你也可以点击 Back（返回）来修改先前的配置。 然后并点击 next（下一步）： 安装过程： 点击 Finish（完成）按钮退出安装向导。 检测PATH环境变量是否配置了Node.js，点击开始$=》运行=》输入”cmd” =&gt; 输入命令”path”$，输出如下结果： 12345PATH=C:\\oraclexe\\app\\oracle\\product\\10.2.0\\server\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;c:\\python32\\python;C:\\MinGW\\bin;C:\\Program Files\\GTK2-Runtime\\lib;C:\\Program Files\\MySQL\\MySQL Server 5.5\\bin;C:\\Program Files\\nodejs\\;C:\\Users\\rg\\AppData\\Roaming\\npm 我们可以看到环境变量中已经包含了C:\\Program Files\\nodejs\\ 检查Node.js版本 2、Windows 二进制文件 (.exe)安装32 位安装包下载地址 : http://nodejs.org/dist/v0.10.26/node.exe 64 位安装包下载地址 : http://nodejs.org/dist/v0.10.26/x64/node.exe 安装步骤 步骤 1 : 双击下载的安装包 Node.exe ，将出现如下界面 : 点击 Run（运行）按钮将出现命令行窗口： 版本测试进入 node.exe 所在的目录，如下所示： node-version 如果你获得以上输出结果，说明你已经成功安装了Node.js。 Hexo安装利用命令行安装hexoNode.js安装完成后,在电脑任意位置,右键,选择 GitBash ,执行npm命令 1npm install -g hexo 创建本地hexo文件夹(地址名字可自定义)安装完成后,在本地选择一个目标文件夹(如:F:\\Hexo),注意:在F:\\Hexo文件夹内右键,选择GitBush,执行以下指令,Hexo就会自动在目标文件夹下创建建立网站所需要的文件,一分钟左右会执行完成 1hexo init 效果如下: 安装依赖包,该命令执行后没有什么提示,完成后的本地文件夹列表为图示,可能会有所不同 1hexo install 初始化完成后目录图: 注意:因Hexo 3.0以后把服务器独立成了单独的模块,所以还需要安装hexo-server才可以使用,执行命令 1npm install hexo-server –save 本地校验查看到目前为止,我们已经搭建起本地的hexo博客了,执行以下命令(在F:\\Hexo)中,然后根据提示到浏览器中进行访问,地址为 localhost:4000 12hexo g 或者 hexo generatehexo server 或者 hexo s 图示为: 如果访问成功,即代表了本地博客配置成功,但有以下几点需要注意： 每次想访问本地博客,至少需要执行hexo s命令,这样才相当于服务启动,然后才可访问 有的电脑4000端口可能被占用,导致每次访问localhost:4000提示一直找不到网页,这时就需要修改端口号,执行命令 hexo s -p 5000 即代表使用-p将端口号改为了5000,访问网址为localhost:5000 成功图示 : 按下Ctrl+C即可停止服务 Hexo主题设置你可以在官网 或者 https://github.com/hexojs/hexo/wiki/Themes 选择你需要的主题下载主题 1$ git clone &lt;repository&gt; themes/&lt;theme-name&gt; 启用主题修改your_blog_name目录下的_config.yml配置文件中的theme属性，将其设置为上面的 theme-name修改设置后如果在浏览器中没有看到想要的效果，使用$ hexo clean来清除缓存，然后重新生成静态文件$ hexo g修改主题修改主题是在 theme\\your_theme 目录下进行相关操作的，本节内容主要讲的是修改 raytaylorism 主题。使用 raytaylorism 主题的注意事项在该主题的官方 github 地址中已经说明得很清楚了，只需要严格按着开发者要求做，就不会出现什么大问题。 如果你想使用英文语言，建议将 languages 下的 default.yml 文件名修改为 en.yml，因为我在电脑上使用 default.yml 的时候，网页的语言会偶尔变成中文或者繁体，不知道什么原因。 如果你觉得正文在大屏幕下显得太窄（默认为700px定宽），可以修改 source\\css\\_base\\lib_customize.styl 中的 .container 类的宽度设置，修改之后往往会出现右侧的目录栏与正文重叠的情况，继续修改 source\\css\\_partial\\tablecontents.styl 里面的 left calc(50% + 350px) ，建议修为 350px 为你的正文宽度的一半，或者你自行调整直至满意。 在 layout\\_partial\\plugin\\reward.ejs 文件中可以替换转账二维码和显示的“打赏文本”。 站点分析工具我使用的是百度分析平台，在 _config.yml 配置文件中添加 1baidu_analytics: 然后将你的百度分析ID添加在后面。接着在 1layout\\_partial\\plugin\\analytics.ejs 文件后面添加如下代码： 1234567891011&lt;% if (theme.baidu_analytics)&#123; %&gt;&lt;script&gt;var _hmt = _hmt || [];(function() &#123;var hm = document.createElement(&quot;script&quot;);hm.src = &quot;https://hm.baidu.com/hm.js?&lt;%= theme.baidu_analytics %&gt;&quot;;var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);&#125;)();&lt;/script&gt;&lt;% &#125; %&gt; 为 raytaylorism 主题添加统计站点访问量的功能：在 1layout\\_partial\\after_footer.ejs 文件中添加如下代码： 1&lt;script async src=&quot;//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 然后将 1layout\\_partial\\footer.ejs 文件中最后一个 1&lt;p&gt; 元素替换成下面的代码： 1234&lt;p class=&quot;right&quot; style=&quot;margin-top: 0;&quot;&gt;&lt;span id=&quot;busuanzi_container_site_uv&quot; style=&quot;display: none;&quot;&gt;您好，您是本站点的第 &lt;span id=&quot;busuanzi_value_site_uv&quot; style=&quot;color: yellow;&quot;&gt;&lt;/span&gt; 位访客，祝您生活工作愉快&lt;/span&gt;&lt;/p&gt; 如果想给每篇文章添加统计阅读量，我的做法是在 1layout\\_partial\\aticle.ejs 文件中的 1&lt;%- partial(&apos;post/time&apos;) %&gt; 行后面添加如下代码： 1234&lt;div style=&quot;float: right;color: #E91E63&quot;&gt;&lt;span id=&quot;busuanzi_container_page_pv&quot; style=&quot;display: none;&quot;&gt;阅读次数 &lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 提醒，不要把上面的代码添加到 1layout\\_partial\\post\\time.ejs 服务器端在服务器端，我们需要完成以下几件事情。 为本地的 hexo_blog 配置一个部署静态文件的远程仓库。 配置 Nginx 托管博客文件目录。 配置远程仓库自动更新到博客文件目录的钩子。 创建私有 Git 仓库在/git/lvshen/下，创建一个名为 hexo_static的裸仓库（bare repo）。 然后修改目录的所有权和用户权限，之后 linux 用户都具备/git/lvshen/ 目录下所有新生成的目录和文件的权限。 123sudo mkdir /git/lvshen/sudo chown -R $USER:$USER /git/lvshen/sudo chmod -R 755 /git/lvshen/ 然后，执行如下命令： 12cd /git/lvshen/git init --bare hexo_static.git 创建 Git 钩子接下来，在服务器上的裸仓库 hexo_static 创建一个钩子，在满足特定条件时将静态 HTML 文件传送到 Web 服务器的目录下，即 /home/lvshen/hexo。 在自动生成的 hooks 目录下创建一个新的钩子文件： 1vim /home/git/wade/konwledge.git/hooks/post-receive 在该文件中添加两行代码，指定 Git 的工作树（源代码）和 Git 目录（配置文件等）。 123#!/bin/bashgit --work-tree=/home/nginx/html/doc/bl/lvshen --git-dir=/git/lvshen/konwledge.git checkout -f 保存并退出文件，并让该文件变为可执行文件。 1chmod +x /home/git/wade/konwledge.git/hooks/post-receive 配置 Nginx 托管文件目录接下来，创建 /home/nginx/html/doc/bl/lvshen 目录，用于 Nginx 托管。 1sudo mkdir -p /home/nginx/html/doc/bl/lvshen 和上一步类似，这里也需要修改目录的所有权和权限。 12sudo chown -R $USER:$USER /home/nginx/html/doc/bl/lvshensudo chmod -R 755 /home/nginx/html/doc/bl/lvshen 然后，修改 Nginx 的 conf 设置： 1sudo vim /home/nginx/conf/vhost/bl.wadecn.com.conf 将其中的 root 指令指向/home/nginx/html/doc/bl/lvshen 目录。 1234567891011sserver &#123; listen 9000; server_name bl.wadecn.com; index index.html index.htm index.php; root /home/nginx/html/doc/bl/lvshen; #/home/nginx/html/doc #log_format bl.wadecn.com '$remote_addr - $remote_user [$time_local] $request' #'$status $body_bytes_sent $http_referer ' #'$http_user_agent $http_x_forwarded_for'; #access_log log/bl.wadecn.com.log doc.wadecn.com;&#125; 保存并退出文件。如果以后购买并备案域名之后，可以再将配置中的 default_server 修改为你的域名。 最后，重启 Nginx 服务，使得改动生效。 1[root@bogon conf]# /home/nginx/sbin/nginx -s reload #重启nginx 建立SSH信任关系为了在本地能不需要密码的上传代码到服务器，需要在本地生成一个密匙并与服务器关联。 123456#在本地生成公钥和密钥：ssh-keygen -t rsa#将本机生成的公钥发送到服务器上（建立信任关系）：ssh-copy-id -i C:/Users/UserName/.ssh/id_rsa.pub root@server_ip #UserName是电脑的用户名#测试ssh远程登录是否成功：ssh root@server_ip 这样前后端的配置都完成了。我下载了一个主题： 1$ git clone https://github.com/iTimeTraveler/hexo-theme-hiker.git themes/hiker 部署博客地址：AsiaInfo","categories":[{"name":"Work","slug":"Work","permalink":"http://lvshen9.gitee.io/categories/Work/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://lvshen9.gitee.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"http://lvshen9.gitee.io/tags/博客/"}]},{"title":"监控平台配置文件说明","slug":"监控平台配置文件说明","date":"2017-11-19T01:36:02.000Z","updated":"2019-01-17T07:23:22.060Z","comments":true,"path":"2017/11/19/监控平台配置文件说明/","link":"","permalink":"http://lvshen9.gitee.io/2017/11/19/监控平台配置文件说明/","excerpt":"配置文件位于项目的config文件夹下，本文对监控平台console的配置文件做一些讲解说明。 配置文件相关目录配置文件在项目中的位置分布如下：","text":"配置文件位于项目的config文件夹下，本文对监控平台console的配置文件做一些讲解说明。 配置文件相关目录配置文件在项目中的位置分布如下： 配置文件目录结构 本文主要对database.xml 、 dbroute.properties 、 serviceconfig.xml 、 centerservice.xml 、 relax.xml这几个文件进行说明。 database.xml用于连接数据库的配置文件，例1： 12345678910111213&lt;database limit=\"100000\" connector=\"com.ailk.database.dbconn.impl.RefineConnectionManager\" trace=\"true\"&gt; &lt;base type=\"dbcp\" driver=\"oracle.jdbc.driver.OracleDriver\" url=\"jdbc:oracle:thin:@10.200.130.86:1521:centest\" user=\"UOP_PSWD\" passwd=\"UOP_PSWDtest\" initialSize=\"1\" maxActive=\"10\" maxIdle=\"5\" maxWait=\"1000\" /&gt;&lt;/database&gt; 配置文件说明：connector连接的RefineConnectionManager用于数据库精细化的配置，很多时候我们连接的数据库有很多，这时候我们就需要把这么多的数据库信息放到一些数据库表中，而不是在此配置文件里配置数据库。把数据库的相关连接信息放在数据库表中有利于集中管理。需要注意的是：如果connector连接了RefineConnectionManager,那么需要规定数据库名为base，RefineConnectionManager类规定的。数据库名base还有一个作用，DAO类如果定义了数据库名base，那么该类的sql语句就会在base数据库中起作用。 当然，我们也可以不用配置connector，例2： 123456789101112131415161718192021222324&lt;database limit=\"100001\"&gt; &lt;framework &lt;!--数据库名framework--&gt; type=\"dbcp\" driver=\"oracle.jdbc.driver.OracleDriver\" url=\"jdbc:oracle:thin:@10.13.3.10:1521:hnancrm\" user=\"UCR_CEN1\" passwd=\"123\" initialSize=\"1\" maxActive=\"10\" maxIdle=\"5\" maxWait=\"1000\" /&gt; &lt;cen1 &lt;!--数据库名cen1--&gt; type=\"dbcp\" driver=\"oracle.jdbc.driver.OracleDriver\" url=\"jdbc:oracle:thin:@10.13.3.10:1521:hnancrm\" user=\"UCR_CEN1\" passwd=\"123\" initialSize=\"1\" maxActive=\"10\" maxIdle=\"5\" maxWait=\"1000\" /&gt; &lt;/database&gt; 是用于配置较少数据库的情况。 dbroute.properties此文件用于group连接到指定的数据库，例如： 12345route.group.common=crm #common组路由到crmroute.group.console=crm #console组路由到crm...#route crmroute.crm.common=cen1 #指向crm路由的common再连接数据库cen1 serviceconfig.xml该文件位于config/service下，需要加载进serviceconfig.xml，该文件用于配置相关服务的信息，举例代码： 12345 ...&lt;serviceconfig&gt; &amp;common; &amp;console;&lt;/serviceconfig&gt; 再来看看console.xml 123456&lt;service subsys=\"console\"&gt; &lt;!--子系统名--&gt; &lt;entity name=\"DB_Query_getNotifysByIns\" path=\"com.ailk.hubble.service.db.AlarmRuleService@getNotifysByIns\" /&gt; &lt;!--服务名&amp;服务路径--&gt; &lt;entity name=\"DB_Query_getNotifysByKpi\" path=\"com.ailk.hubble.service.db.AlarmRuleService@getNotifysByKpi\" /&gt; ...&lt;/service&gt; 代码说明：subsys=&quot;console&quot;表示子系统名称为console，相当于group组名。里面每个entity包含一个服务名和相应的路径，@后面代表一个方法，该方法需要在该路径的类下定义。前端web和后端app通过服务名相连接。 centerservice.xml该文件位于config/service下，文件定义了中心center里面有哪些组group，例如： 123456&lt;centerservice&gt; &lt;center name=\"base\" desc=\"基础中心\"&gt; &lt;!--中心名--&gt; &lt;group name=\"common\" /&gt; &lt;!--组名--&gt; &lt;group name=\"console\" /&gt; &lt;!--组名--&gt; &lt;/center&gt;&lt;/centerservice&gt; 上面代码说明：中心center名为：base，中心base下的组名为common，console。 relax.xml该文件指明一个center下所包含的实例instance，例如： 12345&lt;relax&gt; &lt;center name=\"base\"&gt; &lt;instance name=\"console-node01-srv01\" listen=\"127.0.0.1:18080\" /&gt; &lt;/center&gt;&lt;/relax&gt; 上面代码说明：中心center下包含一个实例console-node01-srv01，该实例里面会绑定一个IP地址和一个端口127.0.0.1:18080。 这几个配置文件之间的关系上面的配置文件主要涉及到中心center、实例instance、组group、服务名servicename，那么它们之间有什么关系呢？ 来一张它们之间的关系图： 中心与组 我们为什么要定义这些？我们最终的目的是要调用服务，现在的架构是前端web和后端app分离。那么前端就要调用后端的服务。 前后端服务调用 一般来说，我们的后端服务器会部署很多instance实例，而每个实例又有自己的归属center，如果我们们要调用服务，那么该调用哪个instance上的服务？我们来梳理下这几个配置文件的调用流程： 调用目标服务，加载配置文件servicesonfig.xml，获取该文件的服务name和subsys=&quot;console&quot;，即group为console。 加载配置文件centerservice.xml，通过group获取center=&quot;base&quot;。 加载配置文件relax.xml，通过center获取instance，这样就知道调用哪些instance啦。 配图以作说明： 配置文件关系 除了上面3个配置文件，还有database.xml，dbroute.properties。他们存在如下关系。 数据库配置文件 如果我们的数据足够多，会涉及到分库分表。比如存在cen1、cen2....，我们有一个common组，那么dbroute.properties会将common组指向一个库（如：cen1）。","categories":[{"name":"Work","slug":"Work","permalink":"http://lvshen9.gitee.io/categories/Work/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://lvshen9.gitee.io/tags/监控/"},{"name":"配置","slug":"配置","permalink":"http://lvshen9.gitee.io/tags/配置/"}]},{"title":"红黑树的变色与旋转","slug":"红黑树的变色与旋转","date":"2017-11-07T06:06:49.000Z","updated":"2017-11-07T06:43:42.638Z","comments":true,"path":"2017/11/07/红黑树的变色与旋转/","link":"","permalink":"http://lvshen9.gitee.io/2017/11/07/红黑树的变色与旋转/","excerpt":"为什么需要红黑树？二叉查找树红黑树需要根据二叉查找树的规则生成，那么二叉查找树具备什么特性呢？其特性如下： 左子树上所有结点的值均小于或等于它的根结点的值。 右子树上所有结点的值均大于或等于它的根结点的值。 左、右子树也分别为二叉排序树。","text":"为什么需要红黑树？二叉查找树红黑树需要根据二叉查找树的规则生成，那么二叉查找树具备什么特性呢？其特性如下： 左子树上所有结点的值均小于或等于它的根结点的值。 右子树上所有结点的值均大于或等于它的根结点的值。 左、右子树也分别为二叉排序树。 二叉查找树的缺点如果我们在二叉查找树中插入某个值，可能会出现如下一种情况： 这样线性的结构大大影响了查找性能，这是就需要红黑树。 红黑树的特性红黑树是一种自平衡的二叉查找树，它在二叉查找树的基础上又具备如下特征： 节点是红色或黑色。 根节点是黑色。 每个叶子节点都是黑色的空节点（NIL节点）。 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 如下图，就是一颗典型的红黑树： 为了满足如上的规则，实现结构的平衡，我们在插入或删除节点的时候，就需要做一些相应的调整。 例如： 1.向原红黑树插入值为14的新节点： 2.向原红黑树插入值为21的新节点： 由于父节点22是红色节点，因此这种情况打破了红黑树的规则4（每个红色节点的两个子节点都是黑色），必须进行调整，使之重新符合红黑树的规则。 调整方法变色为了重新符合红黑树的规则，尝试把红色节点变为黑色，或者把黑色节点变为红色。 下图所表示的是红黑树的一部分，需要注意节点25并非根节点。因为节点21和节点22连续出现了红色，不符合规则4，所以把节点22从红色变成黑色： 但这样并不算完，因为凭空多出的黑色节点打破了规则5，所以发生连锁反应，需要继续把节点25从黑色变成红色： 此时仍然没有结束，因为节点25和节点27又形成了两个连续的红色节点，需要继续把节点27从红色变成黑色： 旋转左旋转逆时针旋转红黑树的两个节点，使得父节点被自己的右孩子取代，而自己成为自己的左孩子。说起来很怪异，大家看下图： 图中，身为右孩子的Y取代了X的位置，而X变成了自己的左孩子。此为左旋转。 右旋转顺时针旋转红黑树的两个节点，使得父节点被自己的左孩子取代，而自己成为自己的右孩子。大家看下图： 图中，身为左孩子的Y取代了X的位置，而X变成了自己的右孩子。此为右旋转。 实战举栗子我们以刚才插入节点21的情况为例： 首先，我们需要做的是变色，把节点25及其下方的节点变色： 此时节点17和节点25是连续的两个红色节点，那么把节点17变成黑色节点？恐怕不合适。这样一来不但打破了规则4，而且根据规则2（根节点是黑色），也不可能把节点13变成红色节点。 变色已无法解决问题，我们把节点13看做X，把节点17看做Y，像刚才的示意图那样进行左旋转： 旋转示意图 开始旋转啦 旋转一 由于根节点必须是黑色节点，所以需要变色，变色结果如下： 旋转后变色 这样就结束了吗？并没有。因为其中两条路径(17 -&gt; 8 -&gt; 6 -&gt; NIL)的黑色节点个数是4，其他路径的黑色节点个数是3，不符合规则5。 这时候我们需要把节点13看做X，节点8看做Y，像刚才的示意图那样进行右旋转： 旋转结果 最后根据规则来进行变色： 最终结果 如此一来，我们的红黑树变得重新符合规则。这一个例子的调整过程比较复杂，经历了如下步骤： $变色 -&gt; 左旋转 -&gt; 变色 -&gt; 右旋转 -&gt; 变色$ 红黑树使用场景其应用有很多，比如有JDK的集合类TreeMap和TreeSet底层就是红黑树，在Java8中，HashMap也是用到了红黑树。 😊欢迎关注我的博客😊： Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"红黑树","slug":"红黑树","permalink":"http://lvshen9.gitee.io/tags/红黑树/"}]},{"title":"前端常见跨域解决方案（全）","slug":"前端常见跨域解决方案（全）","date":"2017-11-06T06:14:51.000Z","updated":"2017-11-06T06:46:09.716Z","comments":true,"path":"2017/11/06/前端常见跨域解决方案（全）/","link":"","permalink":"http://lvshen9.gitee.io/2017/11/06/前端常见跨域解决方案（全）/","excerpt":"什么是跨域？跨域是指一个域下的文档或脚本试图去请求另一个域下的资源，这里跨域是广义的。 广义的跨域： 1231.) 资源跳转： A链接、重定向、表单提交2.) 资源嵌入： &lt;link&gt;、&lt;script&gt;、&lt;img&gt;、&lt;frame&gt;等dom标签，还有样式中background:url()、@font-face()等文件外链3.) 脚本请求： js发起的ajax请求、dom和js对象的跨域操作等 其实我们通常所说的跨域是狭义的，是由浏览器同源策略限制的一类请求场景。","text":"什么是跨域？跨域是指一个域下的文档或脚本试图去请求另一个域下的资源，这里跨域是广义的。 广义的跨域： 1231.) 资源跳转： A链接、重定向、表单提交2.) 资源嵌入： &lt;link&gt;、&lt;script&gt;、&lt;img&gt;、&lt;frame&gt;等dom标签，还有样式中background:url()、@font-face()等文件外链3.) 脚本请求： js发起的ajax请求、dom和js对象的跨域操作等 其实我们通常所说的跨域是狭义的，是由浏览器同源策略限制的一类请求场景。 什么是同源策略？同源策略/SOP（Same origin policy）是一种约定，由Netscape公司1995年引入浏览器，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，浏览器很容易受到XSS、CSFR等攻击。所谓同源是指”协议+域名+端口”三者相同，即便两个不同的域名指向同一个ip地址，也非同源。 同源策略限制以下几种行为： 1231.) Cookie、LocalStorage 和 IndexDB 无法读取2.) DOM 和 Js对象无法获得3.) AJAX 请求不能发送 常见跨域场景1234567891011121314151617181920URL 说明 是否允许通信http://www.domain.com/a.jshttp://www.domain.com/b.js 同一域名，不同文件或路径 允许http://www.domain.com/lab/c.jshttp://www.domain.com:8000/a.jshttp://www.domain.com/b.js 同一域名，不同端口 不允许 http://www.domain.com/a.jshttps://www.domain.com/b.js 同一域名，不同协议 不允许 http://www.domain.com/a.jshttp://192.168.4.12/b.js 域名和域名对应相同ip 不允许 http://www.domain.com/a.jshttp://x.domain.com/b.js 主域相同，子域不同 不允许http://domain.com/c.js http://www.domain1.com/a.jshttp://www.domain2.com/b.js 不同域名 不允许 跨域解决方案1、 通过jsonp跨域2、 document.domain + iframe跨域3、 location.hash + iframe4、 window.name + iframe跨域5、 postMessage跨域6、 跨域资源共享（CORS）7、 nginx代理跨域8、 nodejs中间件代理跨域9、 WebSocket协议跨域 一、 通过jsonp跨域通常为了减轻web服务器的负载，我们把js、css，img等静态资源分离到另一台独立域名的服务器上，在html页面中再通过相应的标签从不同域名下加载静态资源，而被浏览器允许，基于此原理，我们可以通过动态创建script，再请求一个带参网址实现跨域通信。 1.）原生实现： 12345678910111213&lt;script&gt; var script = document.createElement('script'); script.type = 'text/javascript'; // 传参并指定回调执行函数为onBack script.src = 'http://www.domain2.com:8080/login?user=admin&amp;callback=onBack'; document.head.appendChild(script); // 回调执行函数 function onBack(res) &#123; alert(JSON.stringify(res)); &#125;&lt;/script&gt; 服务端返回如下（返回时即执行全局函数）： 1onBack(&#123;\"status\": true, \"user\": \"admin\"&#125;) 2.）jquery ajax： 1234567$.ajax(&#123; url: 'http://www.domain2.com:8080/login', type: 'get', dataType: 'jsonp', // 请求方式为jsonp jsonpCallback: \"onBack\", // 自定义回调函数名 data: &#123;&#125;&#125;); 3.）vue.js： 123456this.$http.jsonp('http://www.domain2.com:8080/login', &#123; params: &#123;&#125;, jsonp: 'onBack'&#125;).then((res) =&gt; &#123; console.log(res); &#125;) 后端node.js代码示例： 1234567891011121314151617var querystring = require('querystring');var http = require('http');var server = http.createServer();server.on('request', function(req, res) &#123; var params = qs.parse(req.url.split('?')[1]); var fn = params.callback; // jsonp返回设置 res.writeHead(200, &#123; 'Content-Type': 'text/javascript' &#125;); res.write(fn + '(' + JSON.stringify(params) + ')'); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...'); jsonp缺点：只能实现get一种请求。 二、 document.domain + iframe跨域此方案仅限主域相同，子域不同的跨域应用场景。 实现原理：两个页面都通过js强制设置document.domain为基础主域，就实现了同域。 1.）父窗口：(http://www.domain.com/a.html) 12345&lt;iframe id=\"iframe\" src=\"http://child.domain.com/b.html\"&gt;&lt;/iframe&gt;&lt;script&gt; document.domain = 'domain.com'; var user = 'admin';&lt;/script&gt; 2.）子窗口：(http://child.domain.com/b.html) 12345&lt;script&gt; document.domain = 'domain.com'; // 获取父窗口中变量 alert('get js data from parent ---&gt; ' + window.parent.user);&lt;/script&gt; 三、 location.hash + iframe跨域实现原理： a欲与b跨域相互通信，通过中间页c来实现。 三个页面，不同域之间利用iframe的location.hash传值，相同域之间直接js访问来通信。 具体实现：A域：a.html -&gt; B域：b.html -&gt; A域：c.html，a与b不同域只能通过hash值单向通信，b与c也不同域也只能单向通信，但c与a同域，所以c可通过parent.parent访问a页面所有对象。 1.）a.html：(http://www.domain1.com/a.html) 1234567891011121314&lt;iframe id=\"iframe\" src=\"http://www.domain2.com/b.html\" style=\"display:none;\"&gt;&lt;/iframe&gt;&lt;script&gt; var iframe = document.getElementById('iframe'); // 向b.html传hash值 setTimeout(function() &#123; iframe.src = iframe.src + '#user=admin'; &#125;, 1000); // 开放给同域c.html的回调方法 function onCallback(res) &#123; alert('data from c.html ---&gt; ' + res); &#125;&lt;/script&gt; 2.）b.html：(http://www.domain2.com/b.html) 123456789&lt;iframe id=\"iframe\" src=\"http://www.domain1.com/c.html\" style=\"display:none;\"&gt;&lt;/iframe&gt;&lt;script&gt; var iframe = document.getElementById('iframe'); // 监听a.html传来的hash值，再传给c.html window.onhashchange = function () &#123; iframe.src = iframe.src + location.hash; &#125;;&lt;/script&gt; 3.）c.html：(http://www.domain1.com/c.html) 1234567&lt;script&gt; // 监听b.html传来的hash值 window.onhashchange = function () &#123; // 再通过操作同域a.html的js回调，将结果传回 window.parent.parent.onCallback('hello: ' + location.hash.replace('#user=', '')); &#125;;&lt;/script&gt; 四、 window.name + iframe跨域window.name属性的独特之处：name值在不同的页面（甚至不同域名）加载后依旧存在，并且可以支持非常长的 name 值（2MB）。 1.）a.html：(http://www.domain1.com/a.html) 1234567891011121314151617181920212223242526272829303132333435var proxy = function(url, callback) &#123; var state = 0; var iframe = document.createElement('iframe'); // 加载跨域页面 iframe.src = url; // onload事件会触发2次，第1次加载跨域页，并留存数据于window.name iframe.onload = function() &#123; if (state === 1) &#123; // 第2次onload(同域proxy页)成功后，读取同域window.name中数据 callback(iframe.contentWindow.name); destoryFrame(); &#125; else if (state === 0) &#123; // 第1次onload(跨域页)成功后，切换到同域代理页面 iframe.contentWindow.location = 'http://www.domain1.com/proxy.html'; state = 1; &#125; &#125;; document.body.appendChild(iframe); // 获取数据以后销毁这个iframe，释放内存；这也保证了安全（不被其他域frame js访问） function destoryFrame() &#123; iframe.contentWindow.document.write(''); iframe.contentWindow.close(); document.body.removeChild(iframe); &#125;&#125;;// 请求跨域b页面数据proxy('http://www.domain2.com/b.html', function(data)&#123; alert(data);&#125;); 2.）proxy.html：(http://www.domain1.com/proxy….)中间代理页，与a.html同域，内容为空即可。 3.）b.html：(http://www.domain2.com/b.html) 123&lt;script&gt; window.name = 'This is domain2 data!';&lt;/script&gt; 总结：通过iframe的src属性由外域转向本地域，跨域数据即由iframe的window.name从外域传递到本地域。这个就巧妙地绕过了浏览器的跨域访问限制，但同时它又是安全操作。 五、 postMessage跨域postMessage是HTML5 XMLHttpRequest Level 2中的API，且是为数不多可以跨域操作的window属性之一，它可用于解决以下方面的问题：a.） 页面和其打开的新窗口的数据传递b.） 多窗口之间消息传递c.） 页面与嵌套的iframe消息传递d.） 上面三个场景的跨域数据传递 用法：postMessage(data,origin)方法接受两个参数data： html5规范支持任意基本类型或可复制的对象，但部分浏览器只支持字符串，所以传参时最好用JSON.stringify()序列化。origin： 协议+主机+端口号，也可以设置为”*”，表示可以传递给任意窗口，如果要指定和当前窗口同源的话设置为”/“。 1.）a.html：(http://www.domain1.com/a.html) 12345678910111213141516&lt;iframe id=\"iframe\" src=\"http://www.domain2.com/b.html\" style=\"display:none;\"&gt;&lt;/iframe&gt;&lt;script&gt; var iframe = document.getElementById('iframe'); iframe.onload = function() &#123; var data = &#123; name: 'aym' &#125;; // 向domain2传送跨域数据 iframe.contentWindow.postMessage(JSON.stringify(data), 'http://www.domain2.com'); &#125;; // 接受domain2返回数据 window.addEventListener('message', function(e) &#123; alert('data from domain2 ---&gt; ' + e.data); &#125;, false);&lt;/script&gt; 2.）b.html：(http://www.domain2.com/b.html) 1234567891011121314&lt;script&gt; // 接收domain1的数据 window.addEventListener('message', function(e) &#123; alert('data from domain1 ---&gt; ' + e.data); var data = JSON.parse(e.data); if (data) &#123; data.number = 16; // 处理后再发回domain1 window.parent.postMessage(JSON.stringify(data), 'http://www.domain1.com'); &#125; &#125;, false);&lt;/script&gt; 六、 跨域资源共享（CORS）普通跨域请求：只服务端设置Access-Control-Allow-Origin即可，前端无须设置，若要带cookie请求：前后端都需要设置。 需注意的是：由于同源策略的限制，所读取的cookie为跨域请求接口所在域的cookie，而非当前页。如果想实现当前页cookie的写入，可参考下文：七、nginx反向代理中设置proxy_cookie_domain 和 八、NodeJs中间件代理中cookieDomainRewrite参数的设置。 目前，所有浏览器都支持该功能(IE8+：IE8/9需要使用XDomainRequest对象来支持CORS）)，CORS也已经成为主流的跨域解决方案。 1、 前端设置：1.）原生ajax 12// 前端设置是否带cookiexhr.withCredentials = true; 示例代码： 1234567891011121314var xhr = new XMLHttpRequest(); // IE8/9需用window.XDomainRequest兼容// 前端设置是否带cookiexhr.withCredentials = true;xhr.open('post', 'http://www.domain2.com:8080/login', true);xhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');xhr.send('user=admin');xhr.onreadystatechange = function() &#123; if (xhr.readyState == 4 &amp;&amp; xhr.status == 200) &#123; alert(xhr.responseText); &#125;&#125;; 2.）jQuery ajax 12345678$.ajax(&#123; ... xhrFields: &#123; withCredentials: true // 前端设置是否带cookie &#125;, crossDomain: true, // 会让请求头中包含跨域的额外信息，但不会含cookie ...&#125;); 3.）vue框架在vue-resource封装的ajax组件中加入以下代码： 1Vue.http.options.credentials = true 2、 服务端设置：若后端设置成功，前端浏览器控制台则不会出现跨域报错信息，反之，说明没设成功。 1.）Java后台： 123456/* * 导入包：import javax.servlet.http.HttpServletResponse; * 接口参数中定义：HttpServletResponse response */response.setHeader(\"Access-Control-Allow-Origin\", \"http://www.domain1.com\"); // 若有端口需写全（协议+域名+端口）response.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); 2.）Nodejs后台示例： 123456789101112131415161718192021222324252627282930var http = require('http');var server = http.createServer();var qs = require('querystring');server.on('request', function(req, res) &#123; var postData = ''; // 数据块接收中 req.addListener('data', function(chunk) &#123; postData += chunk; &#125;); // 数据接收完毕 req.addListener('end', function() &#123; postData = qs.parse(postData); // 跨域后台设置 res.writeHead(200, &#123; 'Access-Control-Allow-Credentials': 'true', // 后端允许发送Cookie 'Access-Control-Allow-Origin': 'http://www.domain1.com', // 允许访问的域（协议+域名+端口） 'Set-Cookie': 'l=a123456;Path=/;Domain=www.domain2.com;HttpOnly' // HttpOnly:脚本无法读取cookie &#125;); res.write(JSON.stringify(postData)); res.end(); &#125;);&#125;);server.listen('8080');console.log('Server is running at port 8080...'); 七、 nginx代理跨域1、 nginx配置解决iconfont跨域浏览器跨域访问js、css、img等常规静态资源被同源策略许可，但iconfont字体文件(eot|otf|ttf|woff|svg)例外，此时可在nginx的静态资源服务器中加入以下配置。 123location / &#123; add_header Access-Control-Allow-Origin *;&#125; 2、 nginx反向代理接口跨域跨域原理： 同源策略是浏览器的安全策略，不是HTTP协议的一部分。服务器端调用HTTP接口只是使用HTTP协议，不会执行JS脚本，不需要同源策略，也就不存在跨越问题。 实现思路：通过nginx配置一个代理服务器（域名与domain1相同，端口不同）做跳板机，反向代理访问domain2接口，并且可以顺便修改cookie中domain信息，方便当前域cookie写入，实现跨域登录。 nginx具体配置： 123456789101112131415#proxy服务器server &#123; listen 81; server_name www.domain1.com; location / &#123; proxy_pass http://www.domain2.com:8080; #反向代理 proxy_cookie_domain www.domain2.com www.domain1.com; #修改cookie里域名 index index.html index.htm; # 当用webpack-dev-server等中间件代理接口访问nignx时，此时无浏览器参与，故没有同源限制，下面的跨域配置可不启用 add_header Access-Control-Allow-Origin http://www.domain1.com; #当前端只跨域不带cookie时，可为* add_header Access-Control-Allow-Credentials true; &#125;&#125; 1.) 前端代码示例： 12345678var xhr = new XMLHttpRequest();// 前端开关：浏览器是否读写cookiexhr.withCredentials = true;// 访问nginx中的代理服务器xhr.open('get', 'http://www.domain1.com:81/?user=admin', true);xhr.send(); 2.) Nodejs后台示例： 123456789101112131415161718var http = require('http');var server = http.createServer();var qs = require('querystring');server.on('request', function(req, res) &#123; var params = qs.parse(req.url.substring(2)); // 向前台写cookie res.writeHead(200, &#123; 'Set-Cookie': 'l=a123456;Path=/;Domain=www.domain2.com;HttpOnly' // HttpOnly:脚本无法读取 &#125;); res.write(JSON.stringify(params)); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...'); 八、 Nodejs中间件代理跨域node中间件实现跨域代理，原理大致与nginx相同，都是通过启一个代理服务器，实现数据的转发，也可以通过设置cookieDomainRewrite参数修改响应头中cookie中域名，实现当前域的cookie写入，方便接口登录认证。 1、 非vue框架的跨域（2次跨域）利用node + express + http-proxy-middleware搭建一个proxy服务器。 1.）前端代码示例： 12345678var xhr = new XMLHttpRequest();// 前端开关：浏览器是否读写cookiexhr.withCredentials = true;// 访问http-proxy-middleware代理服务器xhr.open('get', 'http://www.domain1.com:3000/login?user=admin', true);xhr.send(); 2.）中间件服务器： 123456789101112131415161718192021var express = require('express');var proxy = require('http-proxy-middleware');var app = express();app.use('/', proxy(&#123; // 代理跨域目标接口 target: 'http://www.domain2.com:8080', changeOrigin: true, // 修改响应头信息，实现跨域并允许带cookie onProxyRes: function(proxyRes, req, res) &#123; res.header('Access-Control-Allow-Origin', 'http://www.domain1.com'); res.header('Access-Control-Allow-Credentials', 'true'); &#125;, // 修改响应信息中的cookie域名 cookieDomainRewrite: 'www.domain1.com' // 可以为false，表示不修改&#125;));app.listen(3000);console.log('Proxy server is listen at port 3000...'); 3.）Nodejs后台同（六：nginx） 2、 vue框架的跨域（1次跨域）利用node + webpack + webpack-dev-server代理接口跨域。在开发环境下，由于vue渲染服务和接口代理服务都是webpack-dev-server同一个，所以页面与代理接口之间不再跨域，无须设置headers跨域信息了。 webpack.config.js部分配置： 123456789101112131415module.exports = &#123; entry: &#123;&#125;, module: &#123;&#125;, ... devServer: &#123; historyApiFallback: true, proxy: [&#123; context: '/login', target: 'http://www.domain2.com:8080', // 代理跨域目标接口 changeOrigin: true, cookieDomainRewrite: 'www.domain1.com' // 可以为false，表示不修改 &#125;], noInfo: true &#125;&#125; 九、 WebSocket协议跨域WebSocket protocol是HTML5一种新的协议。它实现了浏览器与服务器全双工通信，同时允许跨域通讯，是server push技术的一种很好的实现。原生WebSocket API使用起来不太方便，我们使用Socket.io，它很好地封装了webSocket接口，提供了更简单、灵活的接口，也对不支持webSocket的浏览器提供了向下兼容。 1.）前端代码： 12345678910111213141516171819202122&lt;div&gt;user input：&lt;input type=\"text\"&gt;&lt;/div&gt;&lt;script src=\"./socket.io.js\"&gt;&lt;/script&gt;&lt;script&gt;var socket = io('http://www.domain2.com:8080');// 连接成功处理socket.on('connect', function() &#123; // 监听服务端消息 socket.on('message', function(msg) &#123; console.log('data from server: ---&gt; ' + msg); &#125;); // 监听服务端关闭 socket.on('disconnect', function() &#123; console.log('Server socket has closed.'); &#125;);&#125;);document.getElementsByTagName('input')[0].onblur = function() &#123; socket.send(this.value);&#125;;&lt;/script&gt; 2.）Nodejs socket后台： 123456789101112131415161718192021222324252627var http = require('http');var socket = require('socket.io');// 启http服务var server = http.createServer(function(req, res) &#123; res.writeHead(200, &#123; 'Content-type': 'text/html' &#125;); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...');// 监听socket连接socket.listen(server).on('connection', function(client) &#123; // 接收信息 client.on('message', function(msg) &#123; client.send('hello：' + msg); console.log('data from client: ---&gt; ' + msg); &#125;); // 断开处理 client.on('disconnect', function() &#123; console.log('Client socket has closed.'); &#125;);&#125;);","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"跨域","slug":"跨域","permalink":"http://lvshen9.gitee.io/tags/跨域/"},{"name":"Javascript","slug":"Javascript","permalink":"http://lvshen9.gitee.io/tags/Javascript/"}]},{"title":"Paxos算法学习","slug":"Paxos算法学习","date":"2017-11-02T08:04:09.000Z","updated":"2017-11-02T08:39:18.625Z","comments":true,"path":"2017/11/02/Paxos算法学习/","link":"","permalink":"http://lvshen9.gitee.io/2017/11/02/Paxos算法学习/","excerpt":"转载：图解分布式一致性协议Paxos - loop in codes Paxos协议/算法是分布式系统中比较重要的协议，它有多重要呢？ &lt;分布式系统的事务处理&gt;： Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。 &lt;大规模分布式存储系统&gt;： 理解了这两个分布式协议之后(Paxos/2PC)，学习其他分布式协议会变得相当容易。 学习Paxos算法有两部分：a) 算法的原理/证明；b) 算法的理解/运作。 理解这个算法的运作过程其实基本就可以用于工程实践。而且理解这个过程相对来说也容易得多。 网上我觉得讲Paxos讲的好的属于这篇：paxos图解及Paxos算法详解，我这里就结合wiki上的实例进一步阐述。一些paxos基础通过这里提到的两篇文章，以及wiki上的内容基本可以理解。","text":"转载：图解分布式一致性协议Paxos - loop in codes Paxos协议/算法是分布式系统中比较重要的协议，它有多重要呢？ &lt;分布式系统的事务处理&gt;： Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。 &lt;大规模分布式存储系统&gt;： 理解了这两个分布式协议之后(Paxos/2PC)，学习其他分布式协议会变得相当容易。 学习Paxos算法有两部分：a) 算法的原理/证明；b) 算法的理解/运作。 理解这个算法的运作过程其实基本就可以用于工程实践。而且理解这个过程相对来说也容易得多。 网上我觉得讲Paxos讲的好的属于这篇：paxos图解及Paxos算法详解，我这里就结合wiki上的实例进一步阐述。一些paxos基础通过这里提到的两篇文章，以及wiki上的内容基本可以理解。 算法内容Paxos在原作者的《Paxos Made Simple》中内容是比较精简的： (a) A proposer selects a proposal number n and sends a prepare request with number n to a majority of acceptors. (b) If an acceptor receives a prepare request with number n greater than that of any prepare request to which it has already responded, then it responds to the request with a promise not to accept any more proposals numbered less than n and with the highest-numbered pro-posal (if any) that it has accepted. Phase 2 (a) If the proposer receives a response to its prepare requests (numbered n) from a majority of acceptors, then it sends an accept request to each of those acceptors for a proposal numbered n with a value v , where v is the value of the highest-numbered proposal among the responses, or is any value if the responses reported no proposals. (b) If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater than n. 借用paxos图解文中的流程图可概括为： 实例及详解Paxos中有三类角色Proposer、Acceptor及Learner，主要交互过程在Proposer和Acceptor之间。 Proposer与Acceptor之间的交互主要有4类消息通信，如下图： 这4类消息对应于paxos算法的两个阶段4个过程： phase 1 a) proposer向网络内超过半数的acceptor发送prepare消息 b) acceptor正常情况下回复promise消息 phase 2 a) 在有足够多acceptor回复promise消息时，proposer发送accept消息 b) 正常情况下acceptor回复accepted消息 因为在整个过程中可能有其他proposer针对同一件事情发出以上请求，所以在每个过程中都会有些特殊情况处理，这也是为了达成一致性所做的事情。如果在整个过程中没有其他proposer来竞争，那么这个操作的结果就是确定无异议的。但是如果有其他proposer的话，情况就不一样了。 以paxos中文wiki上的例子为例。简单来说该例子以若干个议员提议税收，确定最终通过的法案税收比例。 以下图中基本只画出proposer与一个acceptor的交互。时间标志T2总是在T1后面。propose number简称N。 情况之一如下图： A3在T1发出accepted给A1，然后在T2收到A5的prepare，在T3的时候A1才通知A5最终结果(税率10%)。这里会有两种情况： A5发来的N5小于A1发出去的N1，那么A3直接拒绝(reject)A5 A5发来的N5大于A1发出去的N1，那么A3回复promise，但带上A1的(N1, 10%) 这里可以与paxos流程图对应起来，更好理解。acceptor会记录(MaxN, AcceptN, AcceptV)。 A5在收到promise后，后续的流程可以顺利进行。但是发出accept时，因为收到了(AcceptN, AcceptV)，所以会取最大的AcceptN对应的AcceptV，例子中也就是A1的10%作为AcceptV。如果在收到promise时没有发现有其他已记录的AcceptV，则其值可以由自己决定。 针对以上A1和A5冲突的情况，最终A1和A5都会广播接受的值为10%。 其实4个过程中对于acceptor而言，在回复promise和accepted时由于都可能因为其他proposer的介入而导致特殊处理。所以基本上看在这两个时间点收到其他proposer的请求时就可以了解整个算法了。例如在回复promise时则可能因为proposer发来的N不够大而reject： 如果在发accepted消息时，对其他更大N的proposer发出过promise，那么也会reject该proposer发出的accept，如图： 这个对应于Phase 2 b)： it accepts the proposal unless it has already responded to a prepare request having a number greater than n. 总结Leslie Lamport没有用数学描述Paxos，但是他用英文阐述得很清晰。将Paxos的两个Phase的内容理解清楚，整个算法过程还是不复杂的。 至于Paxos中一直提到的一个全局唯一且递增的proposer number，其如何实现，引用如下： 如何产生唯一的编号呢？在《Paxos made simple》中提到的是让所有的Proposer都从不相交的数据集合中进行选择，例如系统有5个Proposer，则可为每一个Proposer分配一个标识j(0~4)，则每一个proposer每次提出决议的编号可以为5*i + j(i可以用来表示提出议案的次数) 参考文档 paxos图解, http://coderxy.com/archives/121 Paxos算法详解, http://coderxy.com/archives/136 Paxos算法 wiki, http://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95#.E5.AE.9E.E4.BE.8B","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"Paxos","slug":"Paxos","permalink":"http://lvshen9.gitee.io/tags/Paxos/"}]},{"title":"Kafka学习","slug":"Kafka学习","date":"2017-11-01T01:36:03.000Z","updated":"2019-01-17T07:19:11.524Z","comments":true,"path":"2017/11/01/Kafka学习/","link":"","permalink":"http://lvshen9.gitee.io/2017/11/01/Kafka学习/","excerpt":"转：大数据时代：Kafka 如何做到 1 秒发布百万条消息 说起 Kafka 的第一个突出特定就是“快”，而且是那种变态的“快”。据最新的数据：每天利用 Kafka 处理的消息超过1万亿条，在峰值时每秒钟会发布超过百万条消息，就算是在内存和 CPU 都不高的情况下，Kafka 的速度最高可以达到每秒十万条数据，并且还能持久化存储。那么，Kafka 是如何做到的呢？ 分布式消息系统 Kafka 授权协议：Apache 开发语言：Scala 操作系统：跨平台 开发厂商：Apache Github：https://github.com/apache/kafka ★6120","text":"转：大数据时代：Kafka 如何做到 1 秒发布百万条消息 说起 Kafka 的第一个突出特定就是“快”，而且是那种变态的“快”。据最新的数据：每天利用 Kafka 处理的消息超过1万亿条，在峰值时每秒钟会发布超过百万条消息，就算是在内存和 CPU 都不高的情况下，Kafka 的速度最高可以达到每秒十万条数据，并且还能持久化存储。那么，Kafka 是如何做到的呢？ 分布式消息系统 Kafka 授权协议：Apache 开发语言：Scala 操作系统：跨平台 开发厂商：Apache Github：https://github.com/apache/kafka ★6120 Kafka 简介Kafka 是一种分布式的，基于发布/订阅的消息系统。原本开发自 LinkedIn，用作 LinkedIn 的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。之后成为 Apache 项目的一部分，主要用于处理活跃的流式数据。 kafka 有如下特性：● 通过$O(1)$的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 ● 高吞吐量：即使是非常普通的硬件kafka也可以支持每秒数十万的消息。 ● 支持通过kafka服务器和消费机集群来分区消息。 ● 支持Hadoop并行数据加载。 Kafka 架构 Kafka 的整体架构非常简单，是显式分布式架构，producer、broker（kafka）和consumer都可以有多个。Producer，consumer 实现 Kafka 注册的接口，数据从 producer 发送到broker，broker 承担一个中间缓存和分发的作用。broker 分发注册到系统中的consumer。broker 的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。 kafka 相关名词解释如下：1、producer：消息生产者，发布消息到 kafka 集群的终端或服务。 2、broker：kafka 集群中包含的服务器。 3、topic：每条发布到 kafka 集群的消息属于的类别，即 kafka 是面向 topic 的。 4、partition：partition 是物理上的概念，每个 topic 包含一个或多个 partition。kafka 分配的单位是 partition。 5、consumer：从 kafka 集群中消费消息的终端或服务。 6、Consumer group：high-level consumer API 中，每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 的一个 Consumer 消费，但可以被多个 consumer group 消费。 7、replica：partition 的副本，保障 partition 的高可用。 8、leader：replica 中的一个角色， producer 和 consumer 只跟 leader 交互。 9、follower：replica 中的一个角色，从 leader 中复制数据。 10、controller：kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。 11、zookeeper：kafka 通过 zookeeper 来存储集群的 meta 信息。 Kafka 有四个核心的 API。客户端和服务器端的通信，是基于简单，高性能，且与编程语言无关的 TCP 协议。 因为每条消息都被 append 到该 Partition 中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是 Kafka 高吞吐率的一个很重要的保证）。 Kafka 集群分区日志如下所示： 每个分区是一个有序的，不可变的记录序列，不断附加到结构化的提交日志中。每个分区中的记录都被分配一个顺序的 id 号，称为唯一标识分区中每个记录的偏移量。 Kafka 应用场景消息队列比起大多数的消息系统来说，Kafka 有更好的吞吐量，内置的分区，冗余及容错性，这让 Kafka 成为了一个很好的大规模消息处理应用的解决方案。消息系统一般吞吐量相对较低，但是需要更小的端到端延时，并尝尝依赖于 Kafka 提供的强大的持久性保障。在这个领域，Kafka足以媲美传统消息系统，如 ActiveMR 或 RabbitMQ。 行为跟踪Kafka 的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的 Topic 里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到 hadoop 离线数据仓库里处理。 元信息监控作为操作记录的监控模块来使用，即汇集记录一些操作信息，可以理解为运维性质的数据监控吧。 日志收集日志收集方面，其实开源产品有很多，包括 Scribe、Apache Flume。很多人使用 Kafka 代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或 HDFS）进行处理。然而 Kafka 忽略掉文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让 Kafka 处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的系统比如 Scribe 或者 Flume 来说，Kafka 提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。 流处理这个场景可能比较多，也很好理解。保存收集流数据，以提供之后对接的Storm或其他流式计算框架进行处理。很多用户会将那些从原始 Topic 来的数据进行阶段性处理，汇总，扩充或者以其他的方式转换到新的 Topic 下再继续后面的处理。例如一个文章推荐的处理流程，可能是先从 RSS 数据源中抓取文章的内容，然后将其丢入一个叫做“文章”的topic中；后续操作可能是需要对这个内容进行清理，比如回复正常数据或者删除重复数据，最后再将内容匹配的结果返还给用户。这就在一个独立的 Topic 之外，产生了一系列的实时数据处理的流程。Strom 和 Samza 是非常著名的实现这种类型数据转换的框架。 事件源事件源是一种应用程序设计的方式，该方式的状态转移被记录为按时间顺序排序的记录序列。Kafka可以存储大量的日志数据，这使得它成为一个对这种方式的应用来说绝佳的后台。比如动态汇总（News feed）。 持久性日志（commit log）Kafka 可以为一种外部的持久性日志的分布式系统提供服务。这种日志可以在节点间备份数据，并为故障节点数据回复提供一种重新同步的机制。Kafka中日志压缩功能为这种用法提供了条件。在这种用法中，Kafka 类似于 Apache BookKeeper 项目。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://lvshen9.gitee.io/tags/Kafka/"},{"name":"消息","slug":"消息","permalink":"http://lvshen9.gitee.io/tags/消息/"}]},{"title":"Wade+Taperstry快速开发","slug":"quickstart","date":"2017-10-30T07:00:53.000Z","updated":"2019-01-17T06:46:56.843Z","comments":true,"path":"2017/10/30/quickstart/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/30/quickstart/","excerpt":"本次做了一个关于Wade5+Tapertry3的快速开发，开发环境为Eclipse+Windows10，功能为一个部门管理的增删改查。下面是一个关于本项目的数据传输结构图。 目录结构下图为本项目的目录结构。","text":"本次做了一个关于Wade5+Tapertry3的快速开发，开发环境为Eclipse+Windows10，功能为一个部门管理的增删改查。下面是一个关于本项目的数据传输结构图。 目录结构下图为本项目的目录结构。 config为配置相关的文件，这里面有两个重要的文件：serviceconfig.xml（服务配置）和database.xml（数据库配置）。src-common为公用包，供其它层里的文件使用。src-service里有一个bean包和一个service包，里面文件如下： serviceconfig.xml该文件在config的service包下，用于配置相关服务。部分内容如下： 1234567891011121314151617181920&lt;!DOCTYPE serviceconfig PUBLIC \"-//AILK WADE//WADE 4.0//CN\" \"http://www.wade.com/service/dtd/serviceconfig.dtd\" [ &lt;!ENTITY common SYSTEM \"classpath:common.xml\"&gt; &lt;!ENTITY resserv SYSTEM \"classpath:resserv.xml\"&gt;]&gt;&lt;serviceconfig&gt;&lt;config&gt; &lt;package name=\"quickstart\" dir=\"/quickstart\"/&gt; &lt;package name=\"saleserv\" dir=\"/saleserv\"/&gt; &lt;package name=\"acctmanm\" dir=\"/acctmanm\"/&gt;&lt;/config&gt;&lt;service subsys=\"quickstart\"&gt; ... &lt;entity name=\"RM.DepartManagerSvc.updateDepartInfo\" path=\"com.ailk.quickstart.service.depart.DepartManagerSvc@updateDepartInfo\" /&gt; &lt;entity name=\"RM.DepartManagerSvc.queryDepartInfo\" path=\"com.ailk.quickstart.service.depart.DepartManagerSvc@queryDepartInfo\" /&gt; &lt;entity name=\"RM.DepartManagerSvc.removeDepartInfo\" path=\"com.ailk.quickstart.service.depart.DepartManagerSvc@removeDepartInfo\" /&gt;&lt;/service&gt;&amp;common;&amp;resserv;&lt;/serviceconfig&gt; 该注册的服务需要在service包的Java文件中定义。 database.xml数据库文件配置： 1234567891011&lt;crm_lvshen type=\"dbcp\" driver=\"oracle.jdbc.driver.OracleDriver\" url=\"jdbc:oracle:thin:@localhost:1521:ORCL\" user=\"crm\" passwd=\"crm\" initialSize=\"1\" maxActive=\"10\" maxIdle=\"5\" maxWait=\"1000\"/&gt; 在这里我介绍一下添加功能的操作。并讲解每个文件的功能 DepartManager.html该文件和DepartManager.page在此目录下： 添加按钮123456&lt;div class=\"submitPlace\"&gt;&lt;/div&gt; &lt;div class=\"submit\"&gt; &lt;button class=\"e_button-form\" onclick=\"displayShowPopup();\"&gt; &lt;i class=\"e_ico-add\"&gt;&lt;/i&gt;&lt;span&gt;添加&lt;/span&gt; &lt;/button&gt;&lt;/div&gt; 表格显示1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;div id=\"DepartInfo\" jwcid=\"DepartInfo@Part\"&gt; &lt;!-- 表格 开始 --&gt; &lt;div class=\"c_scroll c_scroll-x c_scroll-table-5\"&gt; &lt;div class=\"c_table\"&gt; &lt;table id=\"departTable\" jwcid=\"@Table\" name=\"simCardtable\" rowClick=\"\" rowDBClick=\"\" contextMenu=\"\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th col=\"DEPART_ID\" name=\"DEPART_ID\"&gt;部门ID&lt;/th&gt; &lt;th col=\"DEPART_CODE\"&gt;部门编号&lt;/th&gt; &lt;th col=\"DEPART_NAME\"&gt;部门名称&lt;/th&gt; &lt;th col=\"DEPART_KIND_CODE\"&gt;部门类型&lt;/th&gt; &lt;th col=\"DEPART_FRAME\"&gt;部门结构&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;!-- 循环显示表格列，并设置行间隔颜色 --&gt; &lt;tr jwcid=\"@Foreach\" source=\"ognl:infos\" value=\"ognl:info\" element=\"tr\" index=\"ognl:rowIndex\" class=\"ognl:rowIndex % 2 == 0 ? '' : 'odd'\"&gt; &lt;td&gt;&lt;span jwcid=\"@Insert\" value=\"ognl:info.DEPART_ID\" raw=\"false\" /&gt;&lt;/td&gt; &lt;td&gt;&lt;span jwcid=\"@Insert\" value=\"ognl:info.DEPART_CODE\" raw=\"false\" /&gt;&lt;/td&gt; &lt;td&gt;&lt;span jwcid=\"@Insert\" value=\"ognl:info.DEPART_NAME\" raw=\"false\" /&gt;&lt;/td&gt; &lt;td&gt;&lt;span jwcid=\"@Insert\" value=\"ognl:info.DEPART_KIND_CODE\" raw=\"false\" /&gt;&lt;/td&gt; &lt;td&gt;&lt;span jwcid=\"@Insert\" value=\"ognl:info.DEPART_FRAME\" raw=\"false\" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- 表格 结束 --&gt; &lt;!-- 翻页（替换为页面组件） 开始 --&gt; &lt;div jwcid=\"@NavBar\" name=\"simnav\" cond=\"QueryCond\" part=\"DepartInfo\" listener=\"queryDepartInfo\" count=\"ognl:count\" pageSize=\"5\"&gt;&lt;/div&gt; &lt;!-- 翻页 结束 --&gt; &lt;/div&gt; 模态框显示12345678910111213141516171819202122&lt;div class=\"c_popup c_popup-drag\" id=\"my_popup\" style=\"display: none;\"&gt; &lt;div class=\"c_popupWrapper\"&gt; &lt;div class=\"c_popupHeight\"&gt;&lt;/div&gt; &lt;div class=\"c_popupBox\" style=\"width: 400px;\"&gt; &lt;div class=\"c_popupTitle\"&gt; &lt;div class=\"text\"&gt;添加&lt;/div&gt; &lt;div class=\"fn\"&gt; &lt;!--窗口的关闭按钮 --&gt; &lt;a class=\"close\" href=\"javascript:displayShowPopup()\"&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"c_popupContent\"&gt; &lt;div class=\"c_popupContentWrapper\"&gt; &lt;!-- 输入区 --&gt; &lt;!--插入的内容 --&gt; &lt;div class=\"c_form c_form-col-1 c_form-label-5\" id=\"QueryCond\"&gt; &lt;ul class=\"ul\" id=\"conditioinPart1\"&gt; &lt;li class=\"li\"&gt;&lt;span class=\"label\"&gt;&lt;span&gt;部门ID：&lt;/span&gt;&lt;/span&gt; &lt;span class=\"e_input\"&gt;&lt;span&gt;&lt;input type=\"text\" jwcid=\"@TextField\" value=\"ognl:condition.DEPART_ID\" name=\"condition_DEPART_ID\" desc=\"部门ID\" /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 1234&lt;li class=\"li\"&gt;&lt;span class=\"label\"&gt;&lt;span&gt;部门编号：&lt;/span&gt;&lt;/span&gt; &lt;span class=\"e_input\"&gt;&lt;span&gt;&lt;input type=\"text\" jwcid=\"@TextField\" value=\"ognl:condition.DEPART_CODE\" name=\"condition_DEPART_CODE\" desc=\"部门编号\" /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 1234&lt;li class=\"li\"&gt;&lt;span class=\"label\"&gt;&lt;span&gt;部门名称：&lt;/span&gt;&lt;/span&gt; &lt;span class=\"e_input\"&gt;&lt;span&gt;&lt;input type=\"text\" jwcid=\"@TextField\" value=\"ognl:condition.DEPART_NAME\" name=\"condition_DEPART_NAME\" desc=\"部门名称\" /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 12345678910111213141516171819202122232425262728293031 &lt;li class=\"li\"&gt;&lt;span class=\"label\"&gt;&lt;span&gt;部门类型：&lt;/span&gt;&lt;/span&gt; &lt;span class=\"e_input\"&gt;&lt;span&gt;&lt;input type=\"text\" jwcid=\"@TextField\" value=\"ognl:condition.DEPART_KIND_CODE\" name=\"condition_DEPART_KIND_CODE\" desc=\"部门类型\" /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; &lt;li class=\"li\"&gt;&lt;span class=\"label\"&gt;&lt;span&gt;部门结构：&lt;/span&gt;&lt;/span&gt; &lt;span class=\"e_input\"&gt;&lt;span&gt;&lt;input type=\"text\" jwcid=\"@TextField\" name=\"condition_DEPART_FRAME\" value=\"ognl:condition.DEPART_FRAME\" desc=\"部门结构\" /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;!--提交区域 --&gt; &lt;div class=\"submitPlace\"&gt;&lt;/div&gt; &lt;div class=\"submit\"&gt; &lt;button class=\"e_button-form\" onclick=\"updateDepartInfo();\"&gt; &lt;i class=\"e_ico-ok\"&gt;&lt;/i&gt;&lt;span&gt;提交&lt;/span&gt; &lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"c_popupBottom\"&gt; &lt;div&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=\"c_popupShadow\"&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;iframe class=\"c_popupFrame\"&gt;&lt;/iframe&gt; &lt;div class=\"c_popupCover\"&gt;&lt;/div&gt;&lt;/div&gt; Js函数12345678910111213141516171819202122232425&lt;script language=\"javascript\"&gt; function displayShowPopup() &#123; document.getElementById('my_popup').style.display = document .getElementById('my_popup').style.display == \"none\" ? \"block\" : \"none\"; &#125; //添加 function updateDepartInfo() &#123; if (verifyAll(\"QueryCond\")) &#123; rm.ajaxSubmitMsg(\"QueryCond\", \"updateDepartInfo\", null, null); &#125; &#125; //页面每刷新一次执行一次查询 queryDepartInfo(); //查询 function queryDepartInfo() &#123; rm.ajaxSubmitQry('QueryCond2', 'queryDepartInfo', null, \"DepartInfo\"); &#125; //伪删除，并没有删除数据库里的内容，相当于隐藏行 function removeDepartInfo() &#123; $.table.get(\"simCardtable\").deleteRow(); &#125;&lt;/script&gt; 还有一下数据提交的js这里就不在阐述了，可以自行百度ajax提交。 效果图 点击添加按钮，会弹出相应的添加模态框。 DepartManager.page是连接*.html和 *.java文件的桥梁，里面是相关参数的属性配置。 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE page-specification PUBLIC \"-//Apache Software Foundation//Tapestry Specification 3.0//EN\" \"http://jakarta.apache.org/tapestry/dtd/Tapestry_3_0.dtd\"&gt;&lt;page-specification class=\"com.ailk.quickstart.view.examples.depart.DepartMangager\"&gt; &lt;property-specification name=\"info\" type=\"com.ailk.common.data.IData\" /&gt; &lt;property-specification name=\"infos\" type=\"com.ailk.common.data.IDataset\" /&gt; &lt;property-specification name=\"condition\" type=\"com.ailk.common.data.IData\" /&gt; &lt;property-specification name=\"condit\" type=\"com.ailk.common.data.IData\" /&gt; &lt;property-specification name=\"cond\" type=\"com.ailk.common.data.IData\" /&gt; &lt;property-specification name=\"parent\" type=\"com.ailk.common.data.IData\" /&gt; &lt;property-specification name=\"tabinfos\" type=\"com.ailk.common.data.IDataset\" /&gt; &lt;property-specification name=\"tabinfo\" type=\"com.ailk.common.data.IData\" /&gt; &lt;property-specification name=\"count\" type=\"long\" /&gt; &lt;property-specification name=\"rowIndex\" type=\"int\" /&gt; &lt;property-specification name=\"right\" type=\"com.ailk.common.data.IData\" /&gt; &lt;/page-specification&gt; DepartMangager.javaDepartMangager.java位于此目录下 此类需要继承ResBizPage.java，其添加功能如下： 12345678910111213141516public void updateDepartInfo(IRequestCycle cycle) throws Exception &#123; IData inparam = this.getData(\"condition\", true); IData map = CSViewCall.call(this, \"RM.DepartManagerSvc.updateDepartInfo\", inparam).first(); //这里map等于null,搞不清原因，但不影响功能，索性略过了 if (map == null) &#123; return; &#125; int succNum = map.getInt(\"SUCCNUM\"); if (succNum &gt; 0) &#123; setAjaxMsg(\"入库成功\"); &#125; else &#123; setAjaxMsg(msgError, \"入库失败&lt;br&gt;失败\"); &#125;&#125; *.html、*.page、*.java共同组成一个页面，其命名要相同，前两个文件需放在同一个文件夹下。 DepartManagerSvc.java此类需继承ResBizService.java，用于服务开发。 123456public int updateDepartInfo(IData inparam) throws Exception &#123; DepartManagerBean bean = (DepartManagerBean) BeanManager .createBean(DepartManagerBean.class); int dataInt = bean.updateDepartInfo(inparam); return dataInt;&#125; DepartManagerBean.java该类需要继承BizBean.java，用于逻辑方面的开发。 123public int updateDepartInfo(IData inparam) throws Exception &#123; return DepartManagerDao.updateDepartInfo(inparam);&#125; DepartManagerDao.java该类需要继承BizDAO.java，其sql语句在数据库表Code_Code中获取。 sql语句： 1234INSERT INTO TD_M_DEPART (DEPART_ID,DEPART_CODE,DEPART_NAME,DEPART_KIND_CODE,DEPART_FRAME)VALUES(:DEPART_ID,:DEPART_CODE,:DEPART_NAME,:DEPART_KIND_CODE,:DEPART_FRAME) java代码执行sql语句： 1234public static int updateDepartInfo(IData inparam) throws Exception &#123; return ResDao.executeUpdateByCodeCode(\"TD_M_DEPART\", \"INSERT_INTO_TEST\", inparam, ResDao.lvshenConnName);&#125;//ResDao.lvshenConnName为连接的数据库，详情需查阅这个类ResDao 其他配置build用于项目的编译 build.properties123456789101112131415PROJECT_NAME = quickstartPROJECT_HOME = ..WADELIB_HOME = D:/Study/work/shiyongqiTest/devHN/devHN/ngboss/library/wadelibCRMLIB_HOME = D:/Study/work/shiyongqiTest/devHN/devHN/ngboss/library/crmlib# publib = $&#123;CRMLIB_HOME&#125;build=$&#123;PROJECT_HOME&#125;/buildconfig=$&#123;PROJECT_HOME&#125;/configsource=$&#123;PROJECT_HOME&#125;/srcclasses=$&#123;PROJECT_HOME&#125;/html/WEB-INF/classeshtml=$&#123;PROJECT_HOME&#125;/htmlJDK_VERSION=1.6 build.xml该文件用于执行编译操作，右键该文件→Run As→Ant Build，即可执行。 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE project [&lt;!ENTITY buildfile SYSTEM \"file:D:\\Study\\work\\shiyongqiTest\\devHN\\devHN\\ngboss\\library\\wadelib\\build\\build_wade4_plus.xml\"&gt;]&gt;&lt;project name=\"quickstart\" default=\"all\" basedir=\".\"&gt; &amp;buildfile; &lt;target name=\"all\" depends=\"clean,compile_app,jar_app,compile_web,copy_config,copy_lib,copy_web_resource\"/&gt; &lt;target name=\"all_jar\" depends=\"clean,compile_app,jar_app,clean_classes,compile_web,jar_web,copy_config,copy_lib,copy_web_resource\"/&gt; &lt;target name=\"all_war\" depends=\"clean,compile_app,jar_app,clean_classes,compile_web,jar_web,war_app\"/&gt; &lt;target name=\"app_war\" depends=\"clean,compile_app,jar_app,war_app\"/&gt;&lt;/project&gt; application该文件用于相关路径的配置 web.xml是用于项目启动时servlet，filter等相关配置。这里就不再讨论，只要是quickstart.application，命名要与项目名一致。 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE application PUBLIC \"-//Apache Software Foundation//Tapestry Specification 3.0//EN\" \"http://jakarta.apache.org/tapestry/dtd/Tapestry_3_0.dtd\"[ &lt;!ENTITY public SYSTEM \"public.application\"&gt; &lt;!ENTITY biz SYSTEM \"biz.application\"&gt; &lt;!ENTITY frame SYSTEM \"frame.application\"&gt;]&gt;&lt;application name=\"quickstart\" engine-class=\"com.ailk.web.BaseEngine\"&gt;&lt;description&gt;quickstart&lt;/description&gt; &amp;public; &amp;biz; &amp;frame; ... &lt;!--部门管理(new)--&gt; &lt;page name=\"examples.depart.departManager\" specification- path=\"/examples/depart/DepartManager.page\" version=\"1212\"/&gt;&lt;/application&gt; 测试这样项目就基本配置完毕啦，启动项目。输入http://localhost:8080/quickstart，登陆进去即可。我们来做一个测试： 如图，点击添加按钮，在弹出的框中输入相关信息 。点击提交，在表格中就会有显示： 就此该项目大功告成。 该项目的github地址： lvshen9-quickstart","categories":[{"name":"Work","slug":"Work","permalink":"http://lvshen9.gitee.io/categories/Work/"}],"tags":[{"name":"Wade","slug":"Wade","permalink":"http://lvshen9.gitee.io/tags/Wade/"},{"name":"Taperstry","slug":"Taperstry","permalink":"http://lvshen9.gitee.io/tags/Taperstry/"}]},{"title":"面向Java开发者的NoSQL选项","slug":"面向-Java-开发者的-NoSQL-选项","date":"2017-10-27T06:42:30.000Z","updated":"2017-10-27T07:07:18.348Z","comments":true,"path":"2017/10/27/面向-Java-开发者的-NoSQL-选项/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/27/面向-Java-开发者的-NoSQL-选项/","excerpt":"英文原文：NoSQL Options for Java Developers 因为了解和喜欢 Java 社区，所以尽管很少有人将 NoSQL 与某种语言绑在一起，我也要为全世界的 Java 开发者写下这篇文章。文中，我将为你展示几种 NoSQL 数据库。之后，我将根据实际在 Github stars 和 Stack Overflow tags 的项目中的使用情况，选出最常用的五个。并且我会让你知道它们是否支持 Spring Data 和 SpringBoot。 为什么使用 NoSQL?NoSQL 数据库帮助许多互联网公司通过最终一致性实现高可拓展性。因为 NoSQL 数据库通常分布在多台机器上，而且有一些延迟，所以它只保证所有的实例最终都是一致的。最终一致性服务通常被称为 BASE（基本可用，软状态，最终一致性）服务，这点与传统的 ACID 正好相反。 选择 NoSQL 的候选项定义前五名可能很困难。最近许多人都在尝试这个。请参考本文结尾处的研究和注释部分。 八月中旬，我在推特上告诉我的粉丝，我正在写这篇文章。我询问了关于 NoSQL 数据库的正面或负面的评述，收到了人们的反馈，其中有希望我涵盖的一些选项。 我收到许多建议，以下按字母顺序列出：","text":"英文原文：NoSQL Options for Java Developers 因为了解和喜欢 Java 社区，所以尽管很少有人将 NoSQL 与某种语言绑在一起，我也要为全世界的 Java 开发者写下这篇文章。文中，我将为你展示几种 NoSQL 数据库。之后，我将根据实际在 Github stars 和 Stack Overflow tags 的项目中的使用情况，选出最常用的五个。并且我会让你知道它们是否支持 Spring Data 和 SpringBoot。 为什么使用 NoSQL?NoSQL 数据库帮助许多互联网公司通过最终一致性实现高可拓展性。因为 NoSQL 数据库通常分布在多台机器上，而且有一些延迟，所以它只保证所有的实例最终都是一致的。最终一致性服务通常被称为 BASE（基本可用，软状态，最终一致性）服务，这点与传统的 ACID 正好相反。 选择 NoSQL 的候选项定义前五名可能很困难。最近许多人都在尝试这个。请参考本文结尾处的研究和注释部分。 八月中旬，我在推特上告诉我的粉丝，我正在写这篇文章。我询问了关于 NoSQL 数据库的正面或负面的评述，收到了人们的反馈，其中有希望我涵盖的一些选项。 我收到许多建议，以下按字母顺序列出： ArangoDB Cassandra Couchbase DynamoDB FaunaDB Hazelcast MongoDB Neo4j PostgreSQL JSON Redis (JetBrains) Xodus 人们还提到 Hibernate OGM（NoSQL 的 JPA）和 NoSQLUnit 来作为帮助访问和测试 NoSQL 数据库的工具。 请注意，我没有收到需要将 CouchDB，HBase，Elasticsearch 或 Solr 包括在内的任何请求。 由于 CouchDB 和 Couchbase 的名称相似，它们经常被混淆，但是它们是完全不一样的。 由于 CouchDB 是一个文件存储数据库，我将其包括在我的排名中。 我还添加了 HBase，因为它在 ITBusinessEdge，KDnuggets 和 DB-Engines 被提到过（在研究和注释部分）。 我没有将 Elasticsearch 或 Solr 包括在内，因为我相信这些并不常用作主数据存储。 aible 的排序技术我用 Indeed 上职位数量、GitHub 上 star 数量、Stack Overflow 标签数和 Docker 上 pull 的数量作为指标去开发我的 TOP5 NoSQL 数据库排名系统。 Indeed 上职位数量 我在 Indeed Jobs 上不区分地域搜索，结果除了 Amazon 的 DynamoDB 显示出的是排行榜的竞争者外，并没有新奇发现。 NOTE：把“PostgreSQL JSON”做为搜索条件很难得到准确的结果，因为很多招聘信息把“PostgreSQL” 作为一个要求，而不是它对 NoSQL 的支持。因此我搜索“postgres + json”。Xodus 是一家公司的名字，所以我添加“JetBrains”关键字来保证结果的准确。 GitHub Stars我搜索并找到了 5 个顶级（Star 最多）的 NoSQL 项目，分别是 Redis，MongoDB，ArangoDB，Neo4j 和 Cassandra。 注意: Cassandra, HBase 和 PostgreSQL 是镜像库。DynamoDB, Couchbase 和 FaunaDB 没有服务在 GitHub 上，因此，我统计他们的时候是基于他们的 Java 驱动。统计每个项目的 Java 驱动项目的星星数量是个好办法，但是 Redis 只有 11 颗星。 你可以使用 Tim Qian 的 历史 star 项目来查看这 5 个项目的 star 增长情况。 Stack Overflow 标签我在 StackOverflow 中搜索了上述每一个数据库的 tag，发现 MongoDB 和 PostgreSQL 是最受欢迎的，接下来是 Neo4j, Cassandra 和 Redis. Docker Pulls我在 Docker Hub 上搜索了相关的镜像，可以看到少部分数据库有 1000 万以上的 Docker Pull，Neo4j 有 500 万以上，其他的大多数也有 100 多万， FaunaDB 和 JetBrains Xodus 暂时没有可用的镜像 综合来看，这些数据和我的排名关系并不大，我觉得可能有两个原因，数据并不精确而且对于每一个数据库，并没有所谓标准的镜像 NoSQL 选项矩阵我创建了一个结合了职位数、星数和标签数的矩阵表格。我根据它们在每个类别的排名授予 1-5 分。如果一个选项没有进入前五，就得零分。结果排名前五的是 MongoDB、Redis、Cassandra、Neo4j 和 PostgreSQL，如下表所示。 NoSQL选项 职位 星 标签 合计 MongoDB 5 4 5 14 Redis 3 5 1 9 Cassandra 4 1 2 7 Neo4j 0 2 3 5 PostgreSQL 0 0 4 4 ArangoDB 0 3 0 3 HBase 2 0 0 2 DynamoDB 1 0 0 1 Couchbase 1 0 0 1 CouchDB 0 0 0 0 Hazelcast 0 0 0 0 JetBrains Xodus 0 0 0 0 FaunaDB 0 0 0 0 DB-Engines 排名的前五个选项是 PostgreSQL、MongoDB、Cassandra、Redis 和 HBase。 两个表格的前五排名非常接近！ NoSQL 选项概述由于我做出的前五个排名结果非常接近于 DB-Engines 的结果，所以我将使用我的前五个结果。下面是对每一个的概述，以及关于它们的 Spring Boot 支持的信息。 你可能会问“为什么是 Spring Boot？” 我的答案很简单：因为 Spring Boot 采用率很高。根据 Redmonk 对 Java 框架的最近的观察， Spring Boot 采用率从 2016 年 9 月到 2017 年 6 月增长了 76%。 自 6 月以来的增长速度并没有减缓： 到 2017 年 8月 Maven 下载量是 2220 万。 MongoDBMongoDB 在 2007 年由 DoubleClick、 ShopWiki 和 Gilt Groupe 的高级技术人员建立。它的源码在 GitHub 上，使用的是 Apache 和 GNU-APGL 许可证。它的众多大客户包括 Adobe、 eBay 和 eHarmony。 在 start.spring.io 上是否可用？ 是的，包括用于测试的嵌入式 MongoDB 。 是否能在 Spring Data 上获得支持？ 是的，通过 Spring Data MongoDB。 加分项： 为 Hibernate OGM、 NoSQLUnit 和 JHipster 所支持。 RedisRedis 代表 REmote Dictionary Server（远程字典服务器），由 Salvatore Sanfilippo 开创。它最初发布于 2009 年 4 月 10 日根据 redis.io 的描述，Redis 是采用 BSD 许可证的内存式数据结构存储，可以被用作数据库、缓存和消息代理。 使用 Redis 的知名企业 包括 Twitter、 GitHub、 Snapchat 和 Craigslist。 是否在 start.spring.io 上可用？ 是。 是否为 Spring Data 所支持？ 是的，通过 Spring Data Redis。 加分项： 为 NoSQLUnit 所支持。Hibernate ORM 支持正在进行中。 CassandraCassandra 是“一个管理结构化数据的分布式存储系统，其设计的目的是支持扩展到大数量级的商用服务器，并避免单点的失败” (引至 “Cassandra – 在 P2P 网络中的一种结构化存储系统” 在 Facebook 的工程博客上)。Facebook 最初开发 Cassandra 用于支持其收件箱的搜索功能。它的创始人，Avinash Lakshman (Amazon DynamoDB 的一位创始者) 和 Prashant Malik 在 2008 年七月把它作为开源项目发布。在 2009 年 3 月，Cassandra 成为了 Apache 的孵化器项目并在 2010 年 2 月成为了最高等级的项目。 除了 Facebook 之外， Cassandra 还帮助了许多企业实现网络规模的扩展。 关于其可扩展性的介绍在其主页上有很多惊人的数字。 其中一个最大的产品部署者是苹果公司，有超过 75000 个节点存储超过 10PB 的数据。其他大的 Cassandra 使用者包括 Netflix (2500 节点，420 TB，每天超过万亿的请求量)，中国的搜索引擎宜搜 (270 节点，300 TB，每天超过 8 亿请求)，eBay (超过 100 节点， 250 TB)。 start.spring.io 中是否支持? 是。 Spring Data 中是否支持? 是，通过 Spring Data Cassandra. 福利: NoSQLUnit 和 JHipster 已支持，Hibernate ORM 的支持正在进行中。 Neo4jNeo4j 可以作为基于 GPL3 许可的“社区版”使用，带有 Affero GPL 下的一些扩展。社区版被限制只能在一个节点上运行，并且不包括对集群或热备份的支持。Neo4J 的“企业版”支持横向扩展，内存页缓存和热备份。可以试用 30 天，没有提供定价。 Neo4j 是众所周知的图数据库，所有内容都是以一个边，节点，或者一个属性的方式存储。版本 1.0 在 2010 年二月份发布，自此以来由 Neo4j 公司开发。它的大客户包括 Walmart, Airbnb, Monsanto, 和eBay. 是否在 start.spring.io上可以使用？是。 Spring Data 是否支持 Neo4j ？ 是的，通过 Spring Data Neo4j. 加分项：Hibernate ORM 和 NoSQLUnit 也支持 Neo4j PostgreSQL JSONPostgreSQL 是一种传统的关系数据库管理系统（RDBMS），它通过其本地的 JSON 支持（在版本 9.2 中添加）来支持 NoSQL。 在 9.4 中，他们添加了对二进制 JSON（也称为JSONB）和索引的支持。 Leigh Halliday 在 2017 年 6 月的博文中解释了如何释放在 Postgres 中存储 JSON 的功能。Halliday进一步展示了如何使用 Ruby on Rails。 一篇来自 Umair Shahid 的博文展示了如何使用 Java 处理 PostgreSQL JSON 和 JSONB 数据。 我不确定 PostgreSQL 及其 JSON 支持是否应该被包括在推荐的 NoSQL 选项中。 但如果你已经在使用 PostgreSQL，并希望使你的数据架构能更自由流畅，那可以尝试这么做。 正如 Dj Walker-Morgan 所说：“PostgreSQL 9.5 不是你的下一个会选 JSON 数据库，但它是一个非常好的关系数据库，具有完整的 JSON 特性。” 在 start.spring.io 是否可用？是的。 是否由 Spring 数据支撑？是的，通过 Spring Data JPA。 结束语我对这个分析的结果感觉很满意，作为 JHipster 项目的提交者，我非常清楚该团队的实力，并认为它对 MongoDB 和 Cassandra 的支持就是对它们最好的认可。并且增加对 Couchbase 的支持的工作也在进行中。 此外，我还与我熟知的 Java 和 NoSQL 社区中几位专家分享了这一情况，并向他们询问了以下问题： 您是否同意我选出的前 5 个 NoSQL 选项（MongoDB，Redis，Cassandra，Neo4j 和 PostgreSQL 及其 JSON 支持）？ 在生产中使用这些数据库有什么好的坏的故事或经验分享吗？ 在这些数据库中，有没有特别难以开始使用或者在长期使用过程中难以维护的？ 你最喜欢的 NoSQL 数据库是什么？ 还有什么你想分享的？ 我将在几周后公布采访结果。届时我将会在博客中更新。如果你是 NoSQL 数据库的专家，欢迎与我取得联系！我很乐意将您的答案纳入面试。你只需发送消息到 Twitter 的 @mraible 或 matt.raible@okta.com。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://lvshen9.gitee.io/tags/数据库/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://lvshen9.gitee.io/tags/NoSQL/"}]},{"title":"红黑树学习","slug":"红黑树学习","date":"2017-10-25T02:33:42.000Z","updated":"2017-10-27T07:09:04.283Z","comments":true,"path":"2017/10/25/红黑树学习/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/25/红黑树学习/","excerpt":"欢迎关注： Lvshen’s Blog 什么是TreeMap首先我们来先说说HashMap与LinkedHashMap，它们保证了以$O(1)$的时间复杂度进行增、删、改、查，从存储角度考虑，这两种数据结构是非常优秀的。另外，LinkedHashMap还额外地保证了Map的遍历顺序可以与put顺序一致，解决了HashMap本身无序的问题。 尽管如此，HashMap与LinkedHashMap还是有自己的局限性—-它们不具备统计性能，或者说它们的统计性能时间复杂度并不是很好才更准确，所有的统计必须遍历所有Entry，因此时间复杂度为$O(N)$。比如Map的Key有1、2、3、4、5、6、7，我现在要统计： 所有Key比3大的键值对有哪些 Key最小的和Key最大的是哪两个","text":"欢迎关注： Lvshen’s Blog 什么是TreeMap首先我们来先说说HashMap与LinkedHashMap，它们保证了以$O(1)$的时间复杂度进行增、删、改、查，从存储角度考虑，这两种数据结构是非常优秀的。另外，LinkedHashMap还额外地保证了Map的遍历顺序可以与put顺序一致，解决了HashMap本身无序的问题。 尽管如此，HashMap与LinkedHashMap还是有自己的局限性—-它们不具备统计性能，或者说它们的统计性能时间复杂度并不是很好才更准确，所有的统计必须遍历所有Entry，因此时间复杂度为$O(N)$。比如Map的Key有1、2、3、4、5、6、7，我现在要统计： 所有Key比3大的键值对有哪些 Key最小的和Key最大的是哪两个 就类似这些操作，HashMap和LinkedHashMap做得比较差，此时我们可以使用TreeMap。TreeMap的Key按照自然顺序进行排序或者根据创建映射时提供的Comparator接口进行排序。TreeMap为增、删、改、查这些操作提供了$log(N)$的时间开销，从存储角度而言，这比HashMap与LinkedHashMap的$O(1)$时间复杂度要差些；但是在统计性能上，TreeMap同样可以保证$log(N)$的时间开销，这又比HashMap与LinkedHashMap的$O(N)$时间复杂度好不少。 因此总结而言：如果只需要存储功能，使用HashMap与LinkedHashMap是一种更好的选择；如果还需要保证统计性能或者需要对Key按照一定规则进行排序，那么使用TreeMap是一种更好的选择。 认识红黑树在讲TreeMap前还是先说一下红黑树的一些基本概念，这样可以更好地理解之后TreeMap的源代码。 二叉查找树是在生成的时候是非常容易失衡的，造成的最坏情况就是一边倒（即只有左子树/右子树），这样会导致树检索的效率大大降低。 红黑树是为了维护二叉查找树的平衡而产生的一种树，根据维基百科的定义，红黑树有五个特性，但我觉得讲得不太易懂，我自己总结一下，红黑树的特性大致有三个（换句话说，插入、删除节点后整个红黑树也必须满足下面的三个性质，如果不满足则必须进行旋转）： 根节点与叶节点都是黑色节点，其中叶节点为Null节点 每个红色节点的两个子节点都是黑色节点，换句话说就是不能有连续两个红色节点 从根节点到所有叶子节点上的黑色节点数量是相同的 上述的性质约束了红黑树的关键：从根到叶子的最长可能路径不多于最短可能路径的两倍长。得到这个结论的理由是： 红黑树中最短的可能路径是全部为黑色节点的路径 红黑树中最长的可能路径是红黑相间的路径 此时（2）正好是（1）的两倍长。结果就是这个树大致上是平衡的，因为比如插入、删除和查找某个值这样的操作最坏情况都要求与树的高度成比例，这个高度的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树，最终保证了红黑树能够以$O(log_2 n)$ 的时间复杂度进行搜索、插入、删除。 下面展示一张红黑树的实例图： 可以看到根节点到所有NULL LEAF节点（即叶子节点）所经过的黑色节点都是2个。 另外从这张图上我们还能得到一个结论：红黑树并不是高度的平衡树。所谓平衡树指的是一棵空树或它的左右两个子树的高度差的绝对值不超过1，但是我们看： 最左边的路径$0026–&gt;0017–&gt;0012–&gt;0010–&gt;0003–&gt;NULL LEAF$，它的高度为5 最后边的路径$0026–&gt;0041–&gt;0047–&gt;NULL LEAF$，它的高度为3 左右子树的高度差值为2，因此红黑树并不是高度平衡的，它放弃了高度平衡的特性而只追求部分平衡，这种特性降低了插入、删除时对树旋转的要求，从而提升了树的整体性能。而其他平衡树比如AVL树虽然查找性能为性能是$O(logn)$，但是为了维护其平衡特性，可能要在插入、删除操作时进行多次的旋转，产生比较大的消耗。 TreeMap相关特性 关 注 点 结 论 TreeMap是否允许键值对为空 Key不允许为空，Value允许为空 TreeMap是否允许重复数据 Key重复会覆盖，Value允许重复 TreeMap是否有序 按照Key的自然顺序排序或者Comparator接口指定的排序算法进行排序 TreeMap是否线程安全 非线程安全 TreeMap基本数据结构TreeMap基于红黑树实现，既然是红黑树，那么每个节点中除了Key–&gt;Value映射之外，必然存储了红黑树节点特有的一些内容，它们是： 父节点引用 左子节点引用 右子节点引用 节点颜色 TreeMap的节点Java代码定义为： 1234567891011static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; K key; V value; Entry&lt;K,V&gt; left = null; Entry&lt;K,V&gt; right = null; Entry&lt;K,V&gt; parent; boolean color = BLACK; ...&#125; 由于颜色只有红色和黑色两种，因此颜色可以使用布尔类型（boolean）来表示，黑色表示为true，红色为false。 TreeMap添加数据流程123456789101112131415161718public class MapTest &#123; @Test public void testTreeMap() &#123; TreeMap&lt;Integer, String&gt; treeMap = new TreeMap&lt;Integer, String&gt;(); treeMap.put(10, \"10\"); treeMap.put(85, \"85\"); treeMap.put(15, \"15\"); treeMap.put(70, \"70\"); treeMap.put(20, \"20\"); treeMap.put(60, \"60\"); treeMap.put(30, \"30\"); treeMap.put(50, \"50\"); for (Map.Entry&lt;Integer, String&gt; entry : treeMap.entrySet()) &#123; System.out.println(entry.getKey() + \":\" + entry.getValue()); &#125; &#125;&#125; 本文接下来的内容会给出插入每条数据之后红黑树的数据结构是什么样子的。首先看一下treeMap的put方法的代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); size++; modCount++; return null;&#125; 从这段代码，先总结一下TreeMap添加数据的几个步骤： 获取根节点，根节点为空，产生一个根节点，将其着色为黑色，退出余下流程 获取比较器，如果传入的Comparator接口不为空，使用传入的Comparator接口实现类进行比较；如果传入的Comparator接口为空，将Key强转为Comparable接口进行比较 从根节点开始逐一依照规定的排序算法进行比较，取比较值cmp，如果cmp=0，表示插入的Key已存在；如果cmp&gt;0，取当前节点的右子节点；如果cmp&lt;0，取当前节点的左子节点 排除插入的Key已存在的情况，第（3）步的比较一直比较到当前节点t的左子节点或右子节点为null，此时t就是我们寻找到的节点，cmp&gt;0则准备往t的右子节点插入新节点，cmp&lt;0则准备往t的左子节点插入新节点 new出一个新节点，默认为黑色，根据cmp的值向t的左边或者右边进行插入 插入之后进行修复，包括左旋、右旋、重新着色这些操作，让树保持平衡性 第1~第5步都没有什么问题，红黑树最核心的应当是第6步插入数据之后进行的修复工作，对应的Java代码是TreeMap中的fixAfterInsertion()方法，下面看一下put每个数据之后TreeMap都做了什么操作，借此来理清TreeMap的实现原理。 put(10, “10”) 首先是put(10, “10”)，由于此时TreeMap中没有任何节点，因此10为根且根节点为黑色节点，put(10, “10”)之后的数据结构为： put(85, “85”) 接着是put(85, “85”)，这一步也不难，85比10大，因此在10的右节点上，但是由于85不是根节点，因此会执行fixAfterInsertion()方法进行数据修正，看一下fixAfterInsertion()方法代码实现： 12345678910111213141516171819202122232425262728293031323334353637383940private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; else &#123; if (x == rightOf(parentOf(x))) &#123; x = parentOf(x); rotateLeft(x); &#125; setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; else &#123; Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; else &#123; if (x == leftOf(parentOf(x))) &#123; x = parentOf(x); rotateRight(x); &#125; setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; root.color = BLACK;&#125; 我们看第2行的代码，它将默认的插入的那个节点着色成为红色，这很好理解： 1根据红黑树的性质（3），红黑树要求从根节点到叶子所有叶子节点上经过的黑色节点个数是相同的，因此如果插入的节点着色为黑色，那必然有可能导致某条路径上的黑色节点数量大于其他路径上的黑色节点数量，因此默认插入的节点必须是红色的，以此来维持红黑树的性质（3） 当然插入节点着色为红色节点后，有可能导致的问题是违反性质（2），即出现连续两个红色节点，这就需要通过旋转操作去改变树的结构，解决这个问题。 接着看第4行的判断，前两个条件都满足，但是因为85这个节点的父节点是根节点的，根节点是黑色节点，因此这个条件不满足，while循环不进去，直接执行一次30行的代码给根节点着色为黑色（因为在旋转过程中有可能导致根节点为红色，而红黑树的根节点必须是黑色，因此最后不管根节点是不是黑色，都要重新着色确保根节点是黑色的）。 那么put(85, “85”)之后，整个树的结构变为： fixAfterInsertion方法流程在看put(15, “15”)之前，必须要先过一下fixAfterInsertion()方法。第5行～第21行的代码和第21行~第38行的代码是一样的，无非一个是操作左子树另一个是操作右子树而已，因此就看前一半： 1234567891011121314151617181920while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; else &#123; if (x == rightOf(parentOf(x))) &#123; x = parentOf(x); rotateLeft(x); &#125; setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; ....&#125; 第2行的判断注意一下，用语言描述出来就是：判断当前节点的父节点与当前节点的父节点的父节点的左子节点是否同一个节点。翻译一下就是：当前节点是否左子节点插入，关于这个不明白的我就不解释了，可以自己多思考一下。对这整段代码流程如下： 新插入节点命名为x，将x着色为红色 x不是根节点且x的父节点颜色为红色 x是否左子节点插入 否，走左子节点插入流程 是，获取x的叔父节点 x的叔父节点是否为红色 是，a、x的父节点着色为黑色；b、x的叔父节点着色为黑色；c、x的祖父节点着色为黑色；b、x赋值为其祖父节点用于while条件重新判断，保证不会连续出现两个红色节点。 否，x是否为左子树内侧插入 是，对x的父节点进行一次左旋 否，a、x的父节点着色为黑色；b、x的祖父节点着色为红色；c、对x的祖父节点进行一次右旋； 一次修正结果 这里有一个左子树内侧插入与左子树点外侧插入的概念，我用图表示一下： 其中左边的是左子树外侧插入，右边的是左子树内侧插入，可以从上面的流程图上看到，对于这两种插入方式的处理是不同的，区别是后者也就是左子树内侧插入多一步左旋操作。 能看出，红黑树的插入最多只需要进行两次旋转，至于红黑树的旋转，后面结合代码进行讲解。 put(15, “15”) 看完fixAfterInsertion方法流程之后，继续添加数据，这次添加的是put(15, “15”)，15比10大且比85小，因此15最终应当是85的左子节点，默认插入的是红色节点，因此首先将15作为红色节点插入85的左子节点后的结构应当是： 但是显然这里违反了红黑树的性质（2），即连续出现了两个红色节点，因此此时必须进行旋转。回看前面fixAfterInsertion的流程，上面演示的是左子树插入流程，右子树一样，可以看到这是右子树内侧插入，需要进行两次旋转操作： 对新插入节点的父节点进行一次右旋操作 新插入节点的父节点着色为黑色，新插入节点的祖父节点着色为红色 对新插入节点的祖父节点进行一次左旋操作 旋转是红黑树中最难理解也是最核心的操作，右旋和左旋是对称的操作，我个人的理解，以右旋为例，对某个节点x进行右旋，其实质是： 降低左子树的高度，增加右子树的高度 将x变为当前位置的右子节点 左旋是同样的道理，在旋转的时候一定要记住这两句话，这将会帮助我们清楚地知道在不同的场景下旋转如何进行。 先看一下（1）也就是”对新插入节点的父节点进行一次右旋操作”，源代码为rotateRight()方法： 123456789101112131415private void rotateRight(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; l = p.left; p.left = l.right; if (l.right != null) l.right.parent = p; l.parent = p.parent; if (p.parent == null) root = l; else if (p.parent.right == p) p.parent.right = l; else p.parent.left = l; l.right = p; p.parent = l; &#125;&#125; 右旋流程图： 对85这个节点进行右旋之后还有一次着色操作（2），分别是将x的父节点着色为黑色，将x的祖父节点着色为红色，那么此时的树形结构应当为： 然后对节点10进行一次左旋操作（3），左旋之后的结构为： 最后不管根节点是不是黑色，都将根节点着色为黑色，那么插入15之后的数据结构就变为了上图，满足红黑树的三条特性。 put(70, “70”) put(70, “70”)就很简单了，70是85的左子节点，由于70的父节点以及叔父节点都是红色节点，因此直接将70的父节点85、将70的叔父节点10着色为黑色即可，70这个节点着色为红色，即满足红黑树的特性，插入70之后的结构图为： put(20, “20”) put(20, “20”)，插入的位置应当是70的左子节点，默认插入红色，插入之后的结构图为： 问题很明显，出现了连续两个红色节点，20的插入位置是一种左子树外侧插入的场景，因此只需要进行着色+对节点85进行一次右旋即可，着色+右旋之后数据结构变为： put(60, “60”) 下面进行put(60, “60”)操作，节点60插入的位置是节点20的右子节点，由于节点60的父节点与叔父节点都是红色节点，因此只需要将节点60的父节点与叔父节点着色为黑色，将节点60的组父节点着色为红色即可。 那么put(60, “60”)之后的结构为： put(30, “30”) put(30, “30”)，节点30应当为节点60的左子节点，因此插入节点30之后应该是这样的： 显然这里违反了红黑树性质（2）即连续出现了两个红色节点，因此这里要进行旋转。 put(30, “30”)的操作和put(15, “15”)的操作类似，同样是右子树内侧插入的场景，那么需要进行两次旋转： 对节点30的父节点节点60进行一次右旋 右旋之后对节点60的祖父节点20进行一次左旋 右旋+着色+左旋之后，put(30, “30”)的结果应当为： put(50, “50”) 下一个操作是put(50, “50”)，节点50是节点60的左子节点，由于节点50的父亲节点与叔父节点都是红色节点，因此只需要将节点50的父亲节点与叔父节点着色为黑色，将节点50的祖父节点着色为红色即可： 节点50的父节点与叔父节点都是红色节点（注意不要被上图迷糊了！上图是重新着色之后的结构而不是重新着色之前的结构，重新着色之前的结构为上上图），因此插入节点50只需要进行着色，本身这样的操作是没有任何问题的，但问题的关键在于，着色之后出现了连续的红色节点，即节点30与节点70。这就是为什么fixAfterInsertion方法的方法体是while循环的原因： 12345678private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; ... &#125;&#125; 因为这种着色方式是将插入节点的祖父节点着色为红色，因此着色之后必须将当前节点指向插入节点的祖父节点，判断祖父节点与父节点是否连续红色的节点，是就进行旋转，重新让红黑树平衡。 接下来的问题就是怎么旋转了。我们可以把节点15–&gt;节点70–&gt;节点30连起来看，是不是很熟悉？这就是上面重复了两次的右子树内侧插入的场景，那么首先对节点70进行右旋，右旋后的结果为： 下一步，节点70的父节点着色为黑色，节点70的祖父节点着色为红色（这一步不理解或者忘了为什么的，可以去看一下之前对于fixAfterInsertion方法的解读），重新着色后的结构为： 最后一步，对节点70的父节点节点15进行一次左旋，左旋之后的结构为： 重新恢复红黑树的性质： 根节点为黑色节点 没有连续红色节点 根节点到所有叶子节点经过的黑色节点都是2个 后记本文通过不断向红黑树的右子树插入数据，演示了红黑树右侧插入时可能出现的各种情况且应当如何处理这些情况，左侧插入同理。 红黑树还是有点难，因此我个人建议在学习红黑树的时候一定要多画（像我个人就画了3张A4纸）+多想，这样才能更好地理解红黑树的原理，尤其是旋转的原理。 TreeMap的插入操作和旋转操作已经讲完，后文会着眼于TreeMap的删除操作以及一些统计操作（比如找到节点比50大的所有节点）是如何实现的。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"红黑树","slug":"红黑树","permalink":"http://lvshen9.gitee.io/tags/红黑树/"},{"name":"TreeMap","slug":"TreeMap","permalink":"http://lvshen9.gitee.io/tags/TreeMap/"}]},{"title":"14万程序员挑战过的算法趣题","slug":"14万程序员挑战过的算法趣题","date":"2017-10-24T07:54:28.000Z","updated":"2017-10-24T14:58:04.881Z","comments":true,"path":"2017/10/24/14万程序员挑战过的算法趣题/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/24/14万程序员挑战过的算法趣题/","excerpt":"计算机的世界每天都在发生着深刻的变化。新操作系统的发布、CPU性能的提升、智能手机和平板电脑的流行、存储介质的变化、云的普及……这样的变化数不胜数。 在这样日新月异的时代中，“算法”是不变的重要基石。要编写高效率的程序，就需要优化算法。无论开发工具如何进化，熟识并能灵活运用算法仍然是对程序员的基本要求。 本文为那些已经学习过排序、搜索等知名算法，并想要学习更多有趣的算法，进一步提升编程技巧的工程师准备了四道数学谜题形式的问题。这四道趣题分入门、初级、中级、高级，四种级别。 程序员都想挑战这四道算法趣题！通过挑战你也可以看到自己大体处于哪个级别。","text":"计算机的世界每天都在发生着深刻的变化。新操作系统的发布、CPU性能的提升、智能手机和平板电脑的流行、存储介质的变化、云的普及……这样的变化数不胜数。 在这样日新月异的时代中，“算法”是不变的重要基石。要编写高效率的程序，就需要优化算法。无论开发工具如何进化，熟识并能灵活运用算法仍然是对程序员的基本要求。 本文为那些已经学习过排序、搜索等知名算法，并想要学习更多有趣的算法，进一步提升编程技巧的工程师准备了四道数学谜题形式的问题。这四道趣题分入门、初级、中级、高级，四种级别。 程序员都想挑战这四道算法趣题！通过挑战你也可以看到自己大体处于哪个级别。 在挑战之前，先介绍下问题的具体形式： 每个问题大致分为“问题”和“详解”两部分。 请各位先通读问题描述，并动手编写程序尝试解题。在这个过程中，具体的实现方法是其次，更重要的是思考“通过哪些步骤来实现才能够解决问题”。 每个问题都有思路讲解和源代码示例。请留意自己编程时在处理速度、可读性等方面进行的优化，和本文的源代码示例有什么不同。如果事先看了思路讲解和答案，就会失去解题的乐趣，所以这里建议大家先编程解题，再看讲解。 为了大家更好的享受解题乐趣，把“详解”和“答案”放在了最后。 准备好了吗？我们开始答题吧！ $Q1$：入门 尝试用编程解决问题 难度系数：★ 优秀的扫地机器人（IQ：80 目标时间：20分钟） 现在有很多制造商都在卖扫地机器人，它非常有用，能为忙碌的我们分担家务负担。不过我们也很难理解为什么扫地机器人有时候会反复清扫某一个地方。 假设有一款不会反复清扫同一个地方的机器人，它只能前后左右移动。举个例子，如果第1 次向后移动，那么连续移动3 次时，就会有以下9 种情况（ 图6 ）。又因为第1 次移动可以是前后左右4 种情况，所以移动3 次时全部路径有$9×4 ＝ 36 $种。 ※ 最初的位置用0 表示，其后的移动位置用数字表示。 问题： 求这个机器人移动12 次时，有多少种移动路径？ $Q2$：初级 解决简单问题体会算法效果 难度系数：★★ 朋友的朋友也是朋友吗（IQ：90 目标时间：25分钟） “六度空间理论”非常有名。大概的意思是1 个人只需要通过6 个中间人就可以和世界上任何1 个人产生间接联系。本题将试着找出数字的好友（这里并不考虑亲密指数）。 假设拥有同样约数（不包括1）的数字互为“好友”，也就是说，如果两个数字的最大公约数不是1，那么称这两个数互为好友。 从1~N 中任意选取一个“合数”，求从它开始，要经历几层好友，才能和其他所有的数产生联系（所谓的“合数”是指“有除1 以及自身以外的约数的自然数”）。 举个例子，$N ＝ 10$ 时，1~10 的合数是4、6、8、9、10 这5 个。 如果选取的是10，那么10 的好友数字就是公约数为2 的4、6、8这3 个。而9 是6 的好友数字（公约数为3），所以10 只需要经过2 层就可以和9 产生联系（图5 ）。如果选取的是6，则只需经过1 层就可以联系到4、8、9、10 这些数字。因此$N ＝ 10 $时，无论最初选取的合数是什么，最多经过2 层就可以与其他所有数产生联系。 问题： 求从1~N 中选取7 个合数时，最多经过6 层就可以与其他所有数产生联系的最小的N。 $Q3$：中级 优化算法实现高速处理 难度系数：★★★ 优雅的IP 地址（IQ：100 目标时间：30分钟） 可能大部分读者都清楚，IPv4 中的IP 地址是二进制的32 位数值。不过，这样的数值对我们人类而言可读性比较差，所以我们通常会以8 位为1 组分割，用类似$192.168.1.2 $这种十进制数来表示它（ 图12 ）。 这里，我们思考一下十进制数0~9 这10 个数字各出现1 次的IP 地址（像正常情况一样，省略每组数字首位的0。也就是说，不能像$192.168.001.002 $这样表示，而要像192.168.1.2 这样来表示） 问题： 求用二进制数表示上述形式的IP 地址时，能使二进制数左右对称的IP 地址的个数（用二进制数表示时不省略0，用完整的32 位数表示）。 $Q4$：高级 改变思路让程序速度更快 难度系数：★★★★ 异性相邻的座次安排（IQ：130 目标时间：60分钟） 回想起学生时期调座位的时候，我们的心里总是会小鹿乱撞。想必很多人都对谁会坐自己旁边这件事莫名地激动吧？ 这里我们考虑一种“前后左右的座位上一定都是异性”的座次安排。也就是说，像图26 右侧那样，前后左右都是同性的座次安排是不符合要求的（男生用蓝色表示，女生用灰色表示）。 问题： 假设有一个男生和女生分别有15 人的班级，要像图26 那样，排出一个6×5的座次。求满足上述条件的座次安排共多少种（前后或者左右镜像的座次也看作不同的安排。另外，这里不在意具体某个学生坐哪里，只看男生和女生的座次安排）？ 答案及解析Q1-Q4 Q1解题思路用坐标(0, 0) 表示最初的位置。从这个原点开始，避开已经走过的坐标，使机器人前进。用深度优先搜索就可以实现逻辑，如代码清单08.01 所示。 Q1答案324932种。 Q2解题思路要解决这个问题，首先要正确理解问题中出现的词。首先是“合数”。 其次是“公约数”这个词。小学的时候，我们就做过求最大公约数的题。公约数的意思就是“共同的约数”。这里，拥有共同约数的数字互为“好友”，那么就需要求最大公约数非1 的情况。 从1~N 中选取7 个合数，且“最多经过6 层”，那么可以得知，我们要找的是“由2 个数相乘得到的数字”的组合。这样的话，乘法运算中的这2 个数就会成为公约数。 举个例子，选出a~h 这些数。简单地说就是，当7 个数字分别是以下的形式时，经过6 层就能与其他所有数产生联系。 $a × b, b× c, c× d, d × e, e × f, f× g, g ×h$ ※这里a~h 这些数字必须“互质”。 Point！ 更进一步考虑，也可以像本题中的例子一样，把第1 个数字设置成“平方数”（即4），也就是说变成下面这样的组合更好。 $a × a, a × b, b × c, c × d, d × e, e × f, f × g$ 末尾如果同样设置成平方数就会变得更小，也就是变成下面这样的组合。 $a × a, a × b, b × c, c × d, d × e, e × f, f × f$ 用Ruby 可以像代码清单19.01 这样实现。 Q2答案55 满足条件的组合为： $[4, 26, 39, 33, 55, 35, 49]$ Q3解题思路按照题意，用十进制数表示时要使用0~9 这10 个数字各1 次，那么最高位是除0 以外的9 种情况，而其他各个数位可分别使用0~9 这10个数字各1 次，其排列组合一共9!（9 的阶乘）种，所以总共要遍历$9×9!$ 种，也就是3265920 种情况。 要想求左右对称的二进制数，可以通过把16 位的二进制数逆序排列，并将结果与该16 位的二进制数本身拼合，即生成32 位数来求得。因为是16 位，所以全量搜索时只需要遍历65536 种情况即可。 然后，把这个二进制数转换成十进制数，分别使用0~9 这10 个数字各1 次即可。 用Ruby 实现时，代码如代码清单40.01 所示。 执行程序可得到正确答案“8”，因而符合条件的IP 地址有8 个，如表4 所示。 Point！ 用十进制数表示的时候，如果以点号分割的各部分左右对称，那么整体也就左右对称，因而只需要调查0~255 这些数对应的二进制数中左右对称的数就可以了。也就是说，A.B.C.D 这种形式中，A 要和D 对称，B 要和C 对称。 下面我们试着找出A~D 的各种组合中，0~9 这10 个数字各使用1次的组合。每组（A, D）,（ B, C）生成的IP地址有8 种情况，所以用组合数乘以8 就可以求出结果。 用Ruby 实现时，代码如代码清单40.02 所示。 Q3答案8个。 Q4解题思路如果完全按照问题描述实现，只需要遍历30 个座位中15 个男生的座次，满足条件就OK 了。如果不考虑可扩展性、处理速度等，只需要把不符合条件的情况排除就可以了，并不是很难。 这里，我们事先准备好要排除的座次安排，统计不在这个范围内的座次安排即可。用Ruby 实现时，如代码清单68.01 所示。 要想改善处理速度，就要考虑“如何缩小搜索范围”。基本的办法不外乎“剪枝”和“内存化”。 这里，我们事先准备前2 排的座次安排，然后生成下一排可能的安排，并递归地搜索下去。同时，把已经搜索过的结果保存到内存中，避免重复搜索（代码清单68.02）。 上面这个程序可以在2 秒左右求出正确答案。 Q4答案13374192种。 最后介绍一下文中出场人物： 参考书籍：程序员的算法趣题 作者：增井敏克 欢迎关注：Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"趣题","slug":"趣题","permalink":"http://lvshen9.gitee.io/tags/趣题/"}]},{"title":"【算法】字符串是否包含问题","slug":"【算法】字符串是否包含问题","date":"2017-10-19T05:51:23.000Z","updated":"2017-10-19T06:17:49.248Z","comments":true,"path":"2017/10/19/【算法】字符串是否包含问题/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/19/【算法】字符串是否包含问题/","excerpt":"转载至： 【算法】字符串是否包含问题 | iTimeTraveler 在网上看到这篇文章：一次谷歌面试趣事。觉得其中的算法题以及作者的解决思路很有趣，就拿来分享一下吧。 问题假设这有一个各种字母组成的字符串，假设这还有另外一个字符串，而且这个字符串里的字母数相对少一些。从算法是讲，什么方法能最快的查出所有小字符串里的字母在大字符串里都有？ 比如，如果是下面两个字符串： String 1: ABCDEFGHLMNOPQRSString 2: DCGSRQPO","text":"转载至： 【算法】字符串是否包含问题 | iTimeTraveler 在网上看到这篇文章：一次谷歌面试趣事。觉得其中的算法题以及作者的解决思路很有趣，就拿来分享一下吧。 问题假设这有一个各种字母组成的字符串，假设这还有另外一个字符串，而且这个字符串里的字母数相对少一些。从算法是讲，什么方法能最快的查出所有小字符串里的字母在大字符串里都有？ 比如，如果是下面两个字符串： String 1: ABCDEFGHLMNOPQRSString 2: DCGSRQPO 答案是true，所有在String2里的字母String1也都有。如果是下面两个字符串： String 1: ABCDEFGHLMNOPQRSString 2: DCGSRQPZ 答案是false，因为第二个字符串里的Z字母不在第一个字符串里。 解决方案1. 轮询对于这种操作最简单最幼稚的做法是轮询第二个字符串里的每个字母，看它是否同在第一个字符串里。从算法上讲，这需要O(n*m)次操作，其中n是string1的长度，m是string2的长度。就拿上面的例子来说，最坏的情况下将会有16*8 = 128次操作。 2. 排序一个稍微好一点的方案是先对这两个字符串的字母进行排序，然后同时对两个字串依次轮询。两个字串的排序需要O(m log m) + O(n log n)次操作（常规情况下），之后的线性扫描需要O(m+n)次操作。同样拿上面的字串做例子，将会需要164 + 83 = 88加上对两个字串线性扫描的16 + 8 = 24的操作。（随着字串长度的增长，你会发现这个算法的效果会越来越好） 不过，常规排序比如快排可以达到O(n log n)的时间复杂度，这里也可以选用用空间换时间的的基数排序、桶排序等线性时间复杂度的排序算法。 3. 哈希表哈希表Hashtable是一个只需要O(n+m)次操作的算法。方法就是，对第一个字串进行轮询，把其中的每个字母都放入一个Hashtable里（时间成本是O(n)，这里是16次操作）。然后轮询第二个字串，在Hashtable里查询每个字母，看能否找到。如果找不到，说明没有匹配成功。这将消耗掉8次操作 —— 这样两项操作加起来一共只有24次。不错吧，比前面两种方案都要好。 123456789101112131415161718/** * 哈希表Hashset */public static boolean isSubsetByHashset(String a, String b)&#123; char[] ca = a.toCharArray(); char[] cb = b.toCharArray(); HashSet&lt;Character&gt; set = new HashSet&lt;Character&gt;(); for(char c : ca)&#123; set.add(c); &#125; for(char c : cb)&#123; if(!set.contains(c))&#123; return false; &#125; &#125; return true;&#125; 4、Bitmap位图法这个解决方案思想和Hashtable一致，只不过使用的是Bitmap来为每一个字符保留一位。同样只需要O(n+m)次操作。 12345678910111213141516171819202122232425262728293031323334353637// 字母编码区间[A - z]:[65 - 122]public static final int LETTER_REGION = 122 - 65 + 1;/** * 比特位方案 */public static boolean isSubsetByBitmap(String a, String b)&#123; char[] ca = a.toCharArray(); char[] cb = b.toCharArray(); byte[] bitmap = new byte[LETTER_REGION / Byte.SIZE]; for(char c : ca)&#123; setBit(bitmap, c - 'A'); &#125; for(char c : cb)&#123; if(getBit(bitmap, c - 'A') == 0)&#123; System.out.println(\"No exist char in Bitmap: \" + c); return false; &#125; &#125; return true;&#125;/** * 写入指定位的比特 */public static void setBit(byte bitmap[], int k)&#123; bitmap[k / Byte.SIZE] |= (1 &lt;&lt; (k % Byte.SIZE));&#125;/** * 读取指定位的比特 */public static int getBit(byte bitmap[], int k)&#123; return (bitmap[k / Byte.SIZE] &amp; (1 &lt;&lt; (k % Byte.SIZE)));&#125; 到此为止，O(n+m)几乎是你能得到的最好的结果了，因为至少要对每个字母至少访问一次才能完成这项操作，而上述这两个方案是刚好是对每个字母只访问一次。下面看看文章中最后的这个素数方案。 5. 素数假设我们有一个一定个数的字母组成字串。我给每个字母分配一个素数，从2开始，往后类推。这样A将会是2，B将会是3，C将会是5，等等。现在我遍历第一个字串，把每个字母代表的素数相乘。最终会得到一个很大的整数，对吧？然后 —— 轮询第二个字符串，用每个字母除它。如果除的结果有余数，这说明有不匹配的字母。如果整个过程中没有余数，你应该知道它是第一个字串恰好的子集了。这样不行吗？ 12345678910111213141516171819202122232425262728293031323334public static int primes[] = &#123; 2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103, 107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211, 223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331, 337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449, 457,461,463,467,479,487,491,499,503,509,521,523,541,547,557,563,569,571,577,587, 593,599,601,607,613,617,619,631,641,643,647,653,659,661,673,677,683,691,701,709, 719,727,733,739,743,751,757,761,769,773,787,797,809,811,821,823,827,829,839,853, 857,859,863,877,881,883,887,907,911,919,929,937,941,947,953,967,971,977,983,991&#125;;// 字母编码区间[A - z]:[65 - 122]public static final int LETTER_REGION = 122 - 65 + 1;/** * 素数方案 */public static boolean isSubsetByPrimeNumber(String a, String b)&#123; char[] ca = a.toCharArray(); char[] cb = b.toCharArray(); // 防止乘积int溢出，使用BigInteger存储乘积结果 BigInteger p = BigInteger.ONE; for(char c : ca)&#123; p = p.multiply(BigInteger.valueOf(primes[c - 'A'])); &#125; System.out.println(\"乘积结果p = \" + p.toString()); for(char c : cb)&#123; if(!p.remainder(BigInteger.valueOf(primes[c - 'A'])).equals(BigInteger.ZERO))&#123; System.out.println(\"No exist char: \" + c); return false; &#125; &#125; return true;&#125; 测试代码123456789101112131415161718192021public class CharacterSubset &#123; /** * 假设你有一个一定长度的由字母组成的字符串。你还有另外一个，短些。你如何才能知道所有的在较短的字符串里的字母在长字符串里也有？ */ public static void main(String args[])&#123; String a1 = \"ABCDEFGHLMNOPQRS\"; String b1 = \"DCGSRQPOM\"; String a2 = \"ABCDEFGHLMNOPQRS\"; String b2 = \"DCGSRQPOZ\"; System.out.println(\"\\na1 and b1: \" + isSubsetByHashset(a1, b1)); System.out.println(\"\\na2 and b2: \" + isSubsetByHashset(a2, b2)); System.out.println(\"\\na1 and b1: \" + isSubsetByPrimeNumber(a1, b1)); System.out.println(\"\\na2 and b2: \" + isSubsetByPrimeNumber(a2, b2)); System.out.println(\"\\na1 and b1: \" + isSubsetByBitmap(a1, b1)); System.out.println(\"\\na2 and b2: \" + isSubsetByBitmap(a2, b2)); &#125;&#125; 总结就如文章中所说，素数方案在算法上并不能说就比哈希表好。而且在实际操作中，你很可能仍会使用哈希表的方案，因为它更通用，无需跟麻烦的大型数字打交道。但从”巧妙水平“上讲，Guy提供的素数方案是一种更、更、更有趣的方案。 欢迎关注我的博客：* Lvshen’s Blog 参考资料 一次谷歌面试趣事 程序员编程艺术：第二章、字符串是否包含问题","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"字符串","slug":"字符串","permalink":"http://lvshen9.gitee.io/tags/字符串/"}]},{"title":"分布式与集群","slug":"分布式与集群","date":"2017-10-17T02:14:01.000Z","updated":"2017-10-19T06:16:50.525Z","comments":true,"path":"2017/10/17/分布式与集群/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/17/分布式与集群/","excerpt":"1.分布式小明的公司有3个系统： 系统A、系统B和系统C ，这三个系统所做的业务不同，被部署在3个独立的机器上运行， 他们之间互相调用（当然是跨域网络的）， 通力合作完成公司的业务流程。 将不同的业务分布在不同的地方， 这就构成了一个分布式的系统，现在问题来了， 系统A是整个分布式系统的“脸面”， 用户直接访问，用户量访问大的时候要么是速度巨慢，要么直接挂掉， 怎么办？ 由于系统A只有一份， 所以会引起单点失败。","text":"1.分布式小明的公司有3个系统： 系统A、系统B和系统C ，这三个系统所做的业务不同，被部署在3个独立的机器上运行， 他们之间互相调用（当然是跨域网络的）， 通力合作完成公司的业务流程。 将不同的业务分布在不同的地方， 这就构成了一个分布式的系统，现在问题来了， 系统A是整个分布式系统的“脸面”， 用户直接访问，用户量访问大的时候要么是速度巨慢，要么直接挂掉， 怎么办？ 由于系统A只有一份， 所以会引起单点失败。 2.集群（Cluster）小明的公司不差钱，就多买几台机器吧， 小明把系统A一下子部署了好几份（例如下图的3个服务器），每一份都是系统A的一个实例， 对外提供同样的服务，这样能睡个安稳觉了，不怕其中一个坏掉了，我还有另外2个呢。 这3个服务器上的系统就组成了一个集群。 可是对用户来说，一下子出现这么系统A ，每个系统的IP地址都不一样， 到底访问哪一个？ 如果所有人都访问服务器1.1 ，那服务器1.1 会被累死， 剩下的三个闲死，成了浪费钱的摆设。 3.负载均衡（Load Balancer）小明要尽可能的让3个机器上的系统A 工作均衡一些， 比如有3万个请求，那就让3个服务器各处理1万个（当然，这是理想状况）， 这叫负载均衡。 很明显，这个负载均衡的工作最好独立出来， 放到独立的服务器上 （例如Ngnix）： 后来小明发现， 这个负载均衡的服务器虽然工作内容很简单，就是拿到请求，分发请求，但是它还是有可能挂掉啊， 单点失败还是会出现。 没办法，只好把负载均衡也搞成一个集群， 不过和系统A的集群有两点不同： 这个新的集群中虽然有两个机器，但我们可以用某种办法，让这个集群对外只提供一个IP地址， 也就是说用户看到的好像只有一个机器。 同一时刻，我们只让一个负载均衡的机器工作， 另外一个原地待命。 如果工作的那个挂掉了，待命的那个就顶上去。 4.弹性如果这3个系统A的实例还是满足不了大量的请求，那就再加服务器！ 双11来了，用户量是平时的10倍， 小明向领导申请费用又买了几十台服务器，一下子把系统A部署了几十份。 可是双11过后， 流量一下子降下来了，那几十个服务器用不上了，也变成了摆设！ 被领导批评以后，小明决定尝试一下云计算， 在云端可以轻松的创建、删除虚拟的服务器， 那样就可以轻松地随着用户的请求动态的增减服务器了。 双11来了就创建虚拟服务器，等到双11过去了就把不用的关掉， 省得浪费钱。 于是小明的系统具备了一定的弹性。 5.失效转移上面的系统看起来很美好，但是做了一个不切实际的假设： 所有的服务都是无状态的。 换句话说，假设用户的两次请求直接是没有关联的。 但是现实是，大部分服务都是有状态的， 例如购物车。 用户访问系统，在服务器1.1上创建了一个购物车，并向其中加入了几个商品， 然后 服务器1.1 挂掉了， 用户的后续访问就找不到服务器1.1了，这时候就要做失效转移，让另外几个服务器去接管、去处理用户的请求。 可是问题来了，在服务器1.2，1.3上有用户的购物车吗？ 如果没有， 用户就会抱怨，我刚创建的购物车哪里去了？ 还有更严重的，假设用户是在服务器1.1上登录的， 用户登录过的信息保存到了该服务器的session中， 现在这个服务器挂掉了， 用户的session自然也不见了，当用户被失效转移到其他服务器上的时候，其他服务器发现用户没有登录， 就把用户踢到了登录界面， 让用户再次登录！ 状态， 状态，状态！ 用户的登录信息，购物车等都是状态信息， 处理不好状态的问题，集群的威力就大打折扣，无法完成真正的失效转移， 甚至无法使用。 怎么办？ 一种办法是把状态信息在集群的各个服务器之间复制，让集群的各个服务器达成一致， 谁来干这个事情？ 只能是像Websphere, Weblogic这样的应用服务器了。 还有一种办法， 就是把状态信息集中存储在一个地方， 让集群的各个服务器都能访问到： 小明听说Redis 不错， 那就用Redis来保存吧 ！","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://lvshen9.gitee.io/tags/集群/"},{"name":"分布式","slug":"分布式","permalink":"http://lvshen9.gitee.io/tags/分布式/"}]},{"title":"全文搜索引擎Elasticsearch学习","slug":"全文搜索引擎Elasticsearch学习","date":"2017-10-17T01:26:31.000Z","updated":"2017-10-17T01:58:45.497Z","comments":true,"path":"2017/10/17/全文搜索引擎Elasticsearch学习/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/17/全文搜索引擎Elasticsearch学习/","excerpt":"作者：阮一峰 原文地址：http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html 全文搜索属于最常见的需求，开源的 Elasticsearch （以下简称 Elastic）是目前全文搜索引擎的首选。 它可以快速地储存、搜索和分析海量数据。维基百科、Stack Overflow、Github 都采用它。 Elastic 的底层是开源库 Lucene。但是，你没法直接用 Lucene，必须自己写代码去调用它的接口。Elastic 是 Lucene 的封装，提供了 REST API 的操作接口，开箱即用。 本文从零开始，讲解如何使用 Elastic 搭建自己的全文搜索引擎。每一步都有详细的说明，大家跟着做就能学会。","text":"作者：阮一峰 原文地址：http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html 全文搜索属于最常见的需求，开源的 Elasticsearch （以下简称 Elastic）是目前全文搜索引擎的首选。 它可以快速地储存、搜索和分析海量数据。维基百科、Stack Overflow、Github 都采用它。 Elastic 的底层是开源库 Lucene。但是，你没法直接用 Lucene，必须自己写代码去调用它的接口。Elastic 是 Lucene 的封装，提供了 REST API 的操作接口，开箱即用。 本文从零开始，讲解如何使用 Elastic 搭建自己的全文搜索引擎。每一步都有详细的说明，大家跟着做就能学会。 一、安装Elastic 需要 Java 8 环境。如果你的机器还没安装 Java，可以参考这篇文章，注意要保证环境变量JAVA_HOME正确设置。 安装完 Java，就可以跟着官方文档安装 Elastic。直接下载压缩包比较简单。 123$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.1.zip$ unzip elasticsearch-5.5.1.zip$ cd elasticsearch-5.5.1/ 接着，进入解压后的目录，运行下面的命令，启动 Elastic。 1$ ./bin/elasticsearch 如果这时报错&quot;max virtual memory areas vm.max*map*count [65530] is too low&quot;，要运行下面的命令。 1$ sudo sysctl -w vm.max_map_count=262144 如果一切正常，Elastic 就会在默认的9200端口运行。这时，打开另一个命令行窗口，请求该端口，会得到说明信息。 123456789101112131415$ curl localhost:9200&#123; \"name\" : \"atntrTf\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"tf9250XhQ6ee4h7YI11anA\", \"version\" : &#123; \"number\" : \"5.5.1\", \"build_hash\" : \"19c13d0\", \"build_date\" : \"2017-07-18T20:44:24.823Z\", \"build_snapshot\" : false, \"lucene_version\" : \"6.6.0\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; 上面代码中，请求9200端口，Elastic 返回一个 JSON 对象，包含当前节点、集群、版本等信息。 按下 Ctrl + C，Elastic 就会停止运行。 默认情况下，Elastic 只允许本机访问，如果需要远程访问，可以修改 Elastic 安装目录的config/elasticsearch.yml文件，去掉network.host的注释，将它的值改成0.0.0.0，然后重新启动 Elastic。 1network.host: 0.0.0.0 上面代码中，设成0.0.0.0让任何人都可以访问。线上服务不要这样设置，要设成具体的 IP。 二、基本概念2.1 Node 与 ClusterElastic 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个 Elastic 实例。 单个 Elastic 实例称为一个节点（node）。一组节点构成一个集群（cluster）。 2.2 IndexElastic 会索引所有字段，经过处理后写入一个反向索引（Inverted Index）。查找数据的时候，直接查找该索引。 所以，Elastic 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。 下面的命令可以查看当前节点的所有 Index。 1$ curl -X GET 'http://localhost:9200/_cat/indices?v' 2.3 DocumentIndex 里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。 Document 使用 JSON 格式表示，下面是一个例子。 12345&#123; \"user\": \"张三\", \"title\": \"工程师\", \"desc\": \"数据库管理\"&#125; 同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。 2.4 TypeDocument 可以分组，比如weather这个 Index 里面，可以按城市分组（北京和上海），也可以按气候分组（晴天和雨天）。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document。 不同的 Type 应该有相似的结构（schema），举例来说，id字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的一个区别。性质完全不同的数据（比如products和logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。 下面的命令可以列出每个 Index 所包含的 Type。 1$ curl 'localhost:9200/_mapping?pretty=true' 根据规划，Elastic 6.x 版只允许每个 Index 包含一个 Type，7.x 版将会彻底移除 Type。 三、新建和删除 Index新建 Index，可以直接向 Elastic 服务器发出 PUT 请求。下面的例子是新建一个名叫weather的 Index。 1$ curl -X PUT 'localhost:9200/weather' 服务器返回一个 JSON 对象，里面的acknowledged字段表示操作成功。 1234&#123; \"acknowledged\":true, \"shards_acknowledged\":true&#125; 然后，我们发出 DELETE 请求，删除这个 Index。 1$ curl -X DELETE 'localhost:9200/weather' 四、中文分词设置首先，安装中文分词插件。这里使用的是 ik，也可以考虑其他插件（比如 smartcn）。 1$ ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.5.1/elasticsearch-analysis-ik-5.5.1.zip 上面代码安装的是5.5.1版的插件，与 Elastic 5.5.1 配合使用。 接着，重新启动 Elastic，就会自动加载这个新安装的插件。 然后，新建一个 Index，指定需要分词的字段。这一步根据数据结构而异，下面的命令只针对本文。基本上，凡是需要搜索的中文字段，都要单独设置一下。 123456789101112131415161718192021222324$ curl -X PUT 'localhost:9200/accounts' -d '&#123; \"mappings\": &#123; \"person\": &#123; \"properties\": &#123; \"user\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\" &#125;, \"title\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\" &#125;, \"desc\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\" &#125; &#125; &#125; &#125;&#125;' 上面代码中，首先新建一个名称为accounts的 Index，里面有一个名称为person的 Type。person有三个字段。 user title desc 这三个字段都是中文，而且类型都是文本（text），所以需要指定中文分词器，不能使用默认的英文分词器。 Elastic 的分词器称为 analyzer。我们对每个字段指定分词器。 12345\"user\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\"&#125; 上面代码中，analyzer是字段文本的分词器，search_analyzer是搜索词的分词器。ik_max_word分词器是插件ik提供的，可以对文本进行最大数量的分词。 五、数据操作5.1 新增记录向指定的 /Index/Type 发送 PUT 请求，就可以在 Index 里面新增一条记录。比如，向/accounts/person发送请求，就可以新增一条人员记录。 123456$ curl -X PUT 'localhost:9200/accounts/person/1' -d '&#123; \"user\": \"张三\", \"title\": \"工程师\", \"desc\": \"数据库管理\"&#125;' 服务器返回的 JSON 对象，会给出 Index、Type、Id、Version 等信息。 123456789&#123; \"_index\":\"accounts\", \"_type\":\"person\", \"_id\":\"1\", \"_version\":1, \"result\":\"created\", \"_shards\":&#123;\"total\":2,\"successful\":1,\"failed\":0&#125;, \"created\":true&#125; 如果你仔细看，会发现请求路径是/accounts/person/1，最后的1是该条记录的 Id。它不一定是数字，任意字符串（比如abc）都可以。 新增记录的时候，也可以不指定 Id，这时要改成 POST 请求。 123456$ curl -X POST 'localhost:9200/accounts/person' -d '&#123; \"user\": \"李四\", \"title\": \"工程师\", \"desc\": \"系统管理\"&#125;' 上面代码中，向/accounts/person发出一个 POST 请求，添加一个记录。这时，服务器返回的 JSON 对象里面，_id字段就是一个随机字符串。 123456789&#123; \"_index\":\"accounts\", \"_type\":\"person\", \"_id\":\"AV3qGfrC6jMbsbXb6k1p\", \"_version\":1, \"result\":\"created\", \"_shards\":&#123;\"total\":2,\"successful\":1,\"failed\":0&#125;, \"created\":true&#125; 注意，如果没有先创建 Index（这个例子是accounts），直接执行上面的命令，Elastic 也不会报错，而是直接生成指定的 Index。所以，打字的时候要小心，不要写错 Index 的名称。 5.2 查看记录向/Index/Type/Id发出 GET 请求，就可以查看这条记录。 1$ curl 'localhost:9200/accounts/person/1?pretty=true' 上面代码请求查看/accounts/person/1这条记录，URL 的参数pretty=true表示以易读的格式返回。 返回的数据中，found字段表示查询成功，_source字段返回原始记录。 123456789101112&#123; \"_index\" : \"accounts\", \"_type\" : \"person\", \"_id\" : \"1\", \"_version\" : 1, \"found\" : true, \"_source\" : &#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理\" &#125;&#125; 如果 Id 不正确，就查不到数据，found字段就是false。 12345678$ curl 'localhost:9200/weather/beijing/abc?pretty=true'&#123; \"_index\" : \"accounts\", \"_type\" : \"person\", \"_id\" : \"abc\", \"found\" : false&#125; 5.3 删除记录删除记录就是发出 DELETE 请求。 1$ curl -X DELETE 'localhost:9200/accounts/person/1' 这里先不要删除这条记录，后面还要用到。 5.4 更新记录更新记录就是使用 PUT 请求，重新发送一次数据。 12345678910111213141516$ curl -X PUT 'localhost:9200/accounts/person/1' -d '&#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理，软件开发\"&#125;' &#123; \"_index\":\"accounts\", \"_type\":\"person\", \"_id\":\"1\", \"_version\":2, \"result\":\"updated\", \"_shards\":&#123;\"total\":2,\"successful\":1,\"failed\":0&#125;, \"created\":false&#125; 上面代码中，我们将原始数据从”数据库管理”改成”数据库管理，软件开发”。 返回结果里面，有几个字段发生了变化。 123\"_version\" : 2,\"result\" : \"updated\",\"created\" : false 可以看到，记录的 Id 没变，但是版本（version）从1变成2，操作类型（result）从created变成updated，created字段变成false，因为这次不是新建记录。 六、数据查询6.1 返回所有记录使用 GET 方法，直接请求/Index/Type/_search，就会返回所有记录。 1234567891011121314151617181920212223242526272829303132333435$ curl 'localhost:9200/accounts/person/_search'&#123; \"took\":2, \"timed_out\":false, \"_shards\":&#123;\"total\":5,\"successful\":5,\"failed\":0&#125;, \"hits\":&#123; \"total\":2, \"max_score\":1.0, \"hits\":[ &#123; \"_index\":\"accounts\", \"_type\":\"person\", \"_id\":\"AV3qGfrC6jMbsbXb6k1p\", \"_score\":1.0, \"_source\": &#123; \"user\": \"李四\", \"title\": \"工程师\", \"desc\": \"系统管理\" &#125; &#125;, &#123; \"_index\":\"accounts\", \"_type\":\"person\", \"_id\":\"1\", \"_score\":1.0, \"_source\": &#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理，软件开发\" &#125; &#125; ] &#125;&#125; 上面代码中，返回结果的 took字段表示该操作的耗时（单位为毫秒），timed_out字段表示是否超时，hits字段表示命中的记录，里面子字段的含义如下。 total：返回记录数，本例是2条。 max_score：最高的匹配程度，本例是1.0。 hits：返回的记录组成的数组。 返回的记录中，每条记录都有一个_score字段，表示匹配的程序，默认是按照这个字段降序排列。 6.2 全文搜索Elastic 的查询非常特别，使用自己的查询语法，要求 GET 请求带有数据体。 1234$ curl 'localhost:9200/accounts/person/_search' -d '&#123; \"query\" : &#123; \"match\" : &#123; \"desc\" : \"软件\" &#125;&#125;&#125;' 上面代码使用 Match 查询，指定的匹配条件是desc字段里面包含”软件”这个词。返回结果如下。 12345678910111213141516171819202122&#123; \"took\":3, \"timed_out\":false, \"_shards\":&#123;\"total\":5,\"successful\":5,\"failed\":0&#125;, \"hits\":&#123; \"total\":1, \"max_score\":0.28582606, \"hits\":[ &#123; \"_index\":\"accounts\", \"_type\":\"person\", \"_id\":\"1\", \"_score\":0.28582606, \"_source\": &#123; \"user\" : \"张三\", \"title\" : \"工程师\", \"desc\" : \"数据库管理，软件开发\" &#125; &#125; ] &#125;&#125; Elastic 默认一次返回10条结果，可以通过size字段改变这个设置。 12345$ curl 'localhost:9200/accounts/person/_search' -d '&#123; \"query\" : &#123; \"match\" : &#123; \"desc\" : \"管理\" &#125;&#125;, \"size\": 1&#125;' 上面代码指定，每次只返回一条结果。 还可以通过from字段，指定位移。 123456$ curl 'localhost:9200/accounts/person/_search' -d '&#123; \"query\" : &#123; \"match\" : &#123; \"desc\" : \"管理\" &#125;&#125;, \"from\": 1, \"size\": 1&#125;' 上面代码指定，从位置1开始（默认是从位置0开始），只返回一条结果。 6.3 逻辑运算如果有多个搜索关键字， Elastic 认为它们是or关系。 1234$ curl 'localhost:9200/accounts/person/_search' -d '&#123; \"query\" : &#123; \"match\" : &#123; \"desc\" : \"软件 系统\" &#125;&#125;&#125;' 上面代码搜索的是软件 or 系统。 如果要执行多个关键词的and搜索，必须使用布尔查询。 1234567891011$ curl 'localhost:9200/accounts/person/_search' -d '&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match\": &#123; \"desc\": \"软件\" &#125; &#125;, &#123; \"match\": &#123; \"desc\": \"系统\" &#125; &#125; ] &#125; &#125;&#125;' 七、参考链接 ElasticSearch 官方手册 A Practical Introduction to Elasticsearch","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://lvshen9.gitee.io/tags/Elasticsearch/"},{"name":"搜索","slug":"搜索","permalink":"http://lvshen9.gitee.io/tags/搜索/"}]},{"title":"【算法】快速排序","slug":"【算法】快速排序","date":"2017-10-04T14:19:04.000Z","updated":"2017-10-04T14:21:28.177Z","comments":true,"path":"2017/10/04/【算法】快速排序/","link":"","permalink":"http://lvshen9.gitee.io/2017/10/04/【算法】快速排序/","excerpt":"快速排序快速排序是一种比选择排序更优秀的排序算法，选择排序运行的时间为：$O(n^2)$，而快速排序法的运行时间为：$O(nlog_2n)$，快速排序使用了D&amp;C的思想（一种分而治之的思想）。下面我们来分析快速排序算法。 假设我们使用快速排序算法对数组进行排序，对排序算法来说，最简单的数组是什样子的呢？其实间的数组是不需要排序的数组。 所以，基线条件为数组为空或只包含一个元素，这样只需要返回数组即可。","text":"快速排序快速排序是一种比选择排序更优秀的排序算法，选择排序运行的时间为：$O(n^2)$，而快速排序法的运行时间为：$O(nlog_2n)$，快速排序使用了D&amp;C的思想（一种分而治之的思想）。下面我们来分析快速排序算法。 假设我们使用快速排序算法对数组进行排序，对排序算法来说，最简单的数组是什样子的呢？其实间的数组是不需要排序的数组。 所以，基线条件为数组为空或只包含一个元素，这样只需要返回数组即可。 123def quicksort(array): if len(array)&lt;2: return array 如果数组长度为2，只需要将数组的两个元素对调。 如果数组长度为3，那么我们就要使用D&amp;C，将数组做适当的分解，知道满足基线条件，所以首先，需要从数组中选择一个元素，这个元素称之为基准值(pivot)。 假设我们将数组的第一个元素用作基准值，接下来，找出比基准值小的元素以及比基准值大的元素。 这被称作分区（partitioning）。现在我们就有了满足快速排序的一些条件： 一个由所有小于基准值的数字组成的子数组； 基准值； 一个由所有大于基准值的数字组成的子数组； 虽然我们进行了分区，但得到的两个子数组是无序的。当然如果这两个数组是有序的，那对整个数组的排序将非常容易。 如果子数组是有序的，就可以像下面这样合并得到一个有序地数组：左边的数组 + 基准值 +右边的数组。在这里，就是$[10, 15] + [33] + [ ]$，结果为有序数组$[10, 15, 33]$。 现在u，我们需要将两个子数组进行快速排序，在合并结果，就能得到一个有序数组。 12qicksort([15,10] + [33] )+ quicksort([])&gt; [10,15,33] #一个有序数组 不管选取谁作为基准值，都适用。 总结一下，无论是什么长度的数组，进行快速排序都需要经历下面这几个步骤： (1) 选择基准值。(2) 将数组分成两个子数组：小于基准值的元素和大于基准值的元素。(3) 对这两个子数组进行快速排序。 代码实现下面我们来写一个快速排序的代码： 123456789def quicksort(array): if len(array) &lt; 2: return array #基线条件：为空或只包含一个元素的数组是“有序”的 else: pivot = array[0] #递归条 less = [i for i in array[1:] if i &lt;= pivot] #由所有小于基准值的元素组成的子数组 greater = [i for i in array[1:] if i &gt; pivot] #由所有大于基准值的元素组成的子数组 return quicksort(less) + [pivot] + quicksort(greater)print quicksort([10, 5, 2, 3]) 上面是一个python的代码，我们再来写一个Java的： 123456789101112131415161718192021222324252627282930313233343536public class QuickSort &#123; public static void sort(int a[], int low, int hight) &#123; int i, j, index; if (low &gt; hight) &#123; return; &#125; i = low; //首位 j = hight; //末位 index = a[i]; // 用子表的第一个记录做基准 while (i &lt; j) &#123; // 从表的两端交替向中间扫描 while (i &lt; j &amp;&amp; a[j] &gt;= index) j--; if (i &lt; j) a[i++] = a[j];// 用比基准小的记录替换低位记录 while (i &lt; j &amp;&amp; a[i] &lt; index) i++; if (i &lt; j) // 用比基准大的记录替换高位记录 a[j--] = a[i]; &#125; a[i] = index;// 将基准数值替换回 a[i] sort(a, low, i - 1); // 对低子表进行递归排序 sort(a, i + 1, hight); // 对高子表进行递归排序 &#125; public static void quickSort(int a[]) &#123; sort(a, 0, a.length - 1); &#125; //方法测试 public static void main(String[] args) &#123; int a[] = &#123; 2,1,3,5,4 &#125;; quickSort(a); System.out.println(Arrays.toString(a)); &#125;&#125; 上面代码的图解思路： 参考文献《算法图解》 【美】Aditya Bhargava 欢迎关注：Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://lvshen9.gitee.io/tags/排序/"}]},{"title":"缓存淘汰算法-LRU算法","slug":"缓存淘汰算法-LRU算法","date":"2017-09-30T07:22:13.000Z","updated":"2017-09-30T08:01:48.017Z","comments":true,"path":"2017/09/30/缓存淘汰算法-LRU算法/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/30/缓存淘汰算法-LRU算法/","excerpt":"最近在学习memcache缓存时，发现其s数据淘汰策略都是采用LRU算法进行缓存数据的处理。那么什么是LRU算法，这篇深度好文值得一看。 本文转载至缓存淘汰算法–LRU算法 - 小程故事多 - ITeye博客 1. LRU1.1. 原理LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 1.2. 实现最常见的实现是使用一个链表保存缓存数据，详细算法实现如下：","text":"最近在学习memcache缓存时，发现其s数据淘汰策略都是采用LRU算法进行缓存数据的处理。那么什么是LRU算法，这篇深度好文值得一看。 本文转载至缓存淘汰算法–LRU算法 - 小程故事多 - ITeye博客 1. LRU1.1. 原理LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 1.2. 实现最常见的实现是使用一个链表保存缓存数据，详细算法实现如下： 新数据插入到链表头部； 每当缓存命中（即缓存数据被访问），则将数据移到链表头部； 当链表满的时候，将链表尾部的数据丢弃。 1.3. 分析【命中率】 当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。 【复杂度】 实现简单。 【代价】 命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。 2. LRU-K2.1. 原理LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。 2.2. 实现相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。详细实现如下： 数据第一次被访问，加入到访问历史列表； 如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰； 当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序； 缓存数据队列中被再次访问后，重新排序； 需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。 LRU-K具有LRU的优点，同时能够避免LRU的缺点，实际应用中LRU-2是综合各种因素后最优的选择，LRU-3或者更大的K值命中率会高，但适应性差，需要大量的数据访问才能将历史访问记录清除掉。 2.3. 分析【命中率】 LRU-K降低了“缓存污染”带来的问题，命中率比LRU要高。 【复杂度】 LRU-K队列是一个优先级队列，算法复杂度和代价比较高。 【代价】 由于LRU-K还需要记录那些被访问过、但还没有放入缓存的对象，因此内存消耗会比LRU要多；当数据量很大的时候，内存消耗会比较可观。 LRU-K需要基于时间进行排序（可以需要淘汰时再排序，也可以即时排序），CPU消耗比LRU要高。 3. Two queues（2Q）3.1. 原理Two queues（以下使用2Q代替）算法类似于LRU-2，不同点在于2Q将LRU-2算法中的访问历史队列（注意这不是缓存数据的）改为一个FIFO缓存队列，即：2Q算法有两个缓存队列，一个是FIFO队列，一个是LRU队列。 3.2. 实现当数据第一次访问时，2Q算法将数据缓存在FIFO队列里面，当数据第二次被访问时，则将数据从FIFO队列移到LRU队列里面，两个队列各自按照自己的方法淘汰数据。详细实现如下： 新访问的数据插入到FIFO队列； 如果数据在FIFO队列中一直没有被再次访问，则最终按照FIFO规则淘汰； 如果数据在FIFO队列中被再次访问，则将数据移到LRU队列头部； 如果数据在LRU队列再次被访问，则将数据移到LRU队列头部； LRU队列淘汰末尾的数据。 注：上图中FIFO队列比LRU队列短，但并不代表这是算法要求，实际应用中两者比例没有硬性规定。 3.3. 分析【命中率】 2Q算法的命中率要高于LRU。 【复杂度】 需要两个队列，但两个队列本身都比较简单。 【代价】 FIFO和LRU的代价之和。 2Q算法和LRU-2算法命中率类似，内存消耗也比较接近，但对于最后缓存的数据来说，2Q会减少一次从原始存储读取数据或者计算数据的操作。 4. Multi Queue（MQ）4.1. 原理MQ算法根据访问频率将数据划分为多个队列，不同的队列具有不同的访问优先级，其核心思想是：优先缓存访问次数多的数据。 4.2. 实现MQ算法将缓存划分为多个LRU队列，每个队列对应不同的访问优先级。访问优先级是根据访问次数计算出来的，例如 详细的算法结构图如下，$$Q0，Q1….Qk$$代表不同的优先级队列，Q-history代表从缓存中淘汰数据，但记录了数据的索引和引用次数的队列： 如上图，算法详细描述如下： 新插入的数据放入Q0； 每个队列按照LRU管理数据； 当数据的访问次数达到一定次数，需要提升优先级时，将数据从当前队列删除，加入到高一级队列的头部； 为了防止高优先级数据永远不被淘汰，当数据在指定的时间里访问没有被访问时，需要降低优先级，将数据从当前队列删除，加入到低一级的队列头部； 需要淘汰数据时，从最低一级队列开始按照LRU淘汰；每个队列淘汰数据时，将数据从缓存中删除，将数据索引加入Q-history头部； 如果数据在Q-history中被重新访问，则重新计算其优先级，移到目标队列的头部； Q-history按照LRU淘汰数据的索引。 4.3. 分析【命中率】 MQ降低了“缓存污染”带来的问题，命中率比LRU要高。 【复杂度】 MQ需要维护多个队列，且需要维护每个数据的访问时间，复杂度比LRU高。 【代价】 MQ需要记录每个数据的访问时间，需要定时扫描所有队列，代价比LRU要高。 注：虽然MQ的队列看起来数量比较多，但由于所有队列之和受限于缓存容量的大小，因此这里多个队列长度之和和一个LRU队列是一样的，因此队列扫描性能也相近。 5. LRU类算法对比由于不同的访问模型导致命中率变化较大，此处对比仅基于理论定性分析，不做定量分析。 对比点 对比 命中率 LRU-2 &gt; MQ(2) &gt; 2Q &gt; LRU 复杂度 LRU-2 &gt; MQ(2) &gt; 2Q &gt; LRU 代价 LRU-2 &gt; MQ(2) &gt; 2Q &gt; LRU 实际应用中需要根据业务的需求和对数据的访问情况进行选择，并不是命中率越高越好。例如：虽然LRU看起来命中率会低一些，且存在”缓存污染“的问题，但由于其简单和代价小，实际应用中反而应用更多。 Java中最简单的LRU算法实现，就是利用jdk的LinkedHashMap，覆写其中的removeEldestEntry(Map.Entry)方法即可。 如果你去看LinkedHashMap的源码可知，LRU算法是通过双向链表来实现，当某个位置被命中，通过调整链表的指向将该位置调整到头位置，新加入的内容直接放在链表头，如此一来，最近被命中的内容就向链表头移动，需要替换时，链表最后的位置就是最近最少使用的位置。 基于双链表 的LRU实现传统意义的LRU算法是为每一个Cache对象设置一个计数器，每次Cache命中则给计数器+1，而Cache用完，需要淘汰旧内容，放置新内容时，就查看所有的计数器，并将最少使用的内容替换掉。 它的弊端很明显，如果Cache的数量少，问题不会很大， 但是如果Cache的空间过大，达到10W或者100W以上，一旦需要淘汰，则需要遍历所有计算器，其性能与资源消耗是巨大的。效率也就非常的慢了。 它的原理： 将Cache的所有位置都用双连表连接起来，当一个位置被命中之后，就将通过调整链表的指向，将该位置调整到链表头的位置，新加入的Cache直接加到链表头中。 这样，在多次进行Cache操作后，最近被命中的，就会被向链表头方向移动，而没有命中的，而想链表后面移动，链表尾则表示最近最少使用的Cache。 当需要替换内容时候，链表的最后位置就是最少被命中的位置，我们只需要淘汰链表最后的部分即可。 上面说了这么多的理论， 下面用代码来实现一个LRU策略的缓存。 我们用一个对象来表示Cache，并实现双链表， 12345678910111213141516//Java代码 public class LRUCache &#123; /** * 链表节点 * @author Administrator * */ class CacheNode &#123; …… &#125; private int cacheSize;//缓存大小 private Hashtable nodes;//缓存容器 private int currentSize;//当前缓存对象数量 private CacheNode first;//(实现双链表)链表头 private CacheNode last;//(实现双链表)链表尾 &#125; ​ 下面给出完整的实现，这个类也被Tomcat所使用（ org.apache.tomcat.util.collections.LRUCache），但是在tomcat6.x版本中，已经被弃用，使用另外其他的缓存类来替代它。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129public class LRUCache &#123;/** * 链表节点 * @author Administrator * */class CacheNode &#123; CacheNode prev;//前一节点 CacheNode next;//后一节点 Object value;//值 Object key;//键 CacheNode() &#123; &#125;&#125;public LRUCache(int i) &#123; currentSize = 0; cacheSize = i; nodes = new Hashtable(i);//缓存容器&#125;/** * 获取缓存中对象 * @param key * @return */public Object get(Object key) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node != null) &#123; moveToHead(node); return node.value; &#125; else &#123; return null; &#125;&#125;/** * 添加缓存 * @param key * @param value */public void put(Object key, Object value) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node == null) &#123; //缓存容器是否已经超过大小. if (currentSize &gt;= cacheSize) &#123; if (last != null)//将最少使用的删除 nodes.remove(last.key); removeLast(); &#125; else &#123; currentSize++; &#125; node = new CacheNode(); &#125; node.value = value; node.key = key; //将最新使用的节点放到链表头，表示最新使用的. moveToHead(node); nodes.put(key, node);&#125;/** * 将缓存删除 * @param key * @return */public Object remove(Object key) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node != null) &#123; if (node.prev != null) &#123; node.prev.next = node.next; &#125; if (node.next != null) &#123; node.next.prev = node.prev; &#125; if (last == node) last = node.prev; if (first == node) first = node.next; &#125; return node;&#125;public void clear() &#123; first = null; last = null;&#125;/** * 删除链表尾部节点 * 表示 删除最少使用的缓存对象 */private void removeLast() &#123; //链表尾不为空,则将链表尾指向null. 删除连表尾（删除最少使用的缓存对象） if (last != null) &#123; if (last.prev != null) last.prev.next = null; else first = null; last = last.prev; &#125;&#125;/** * 移动到链表头，表示这个节点是最新使用过的 * @param node */private void moveToHead(CacheNode node) &#123; if (node == first) return; if (node.prev != null) node.prev.next = node.next; if (node.next != null) node.next.prev = node.prev; if (last == node) last = node.prev; if (first != null) &#123; node.next = first; first.prev = node; &#125; first = node; node.prev = null; if (last == null) last = first;&#125;private int cacheSize;private Hashtable nodes;//缓存容器private int currentSize;private CacheNode first;//链表头private CacheNode last;//链表尾&#125; 最后欢迎关注我的博客：Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"LRU","slug":"LRU","permalink":"http://lvshen9.gitee.io/tags/LRU/"},{"name":"缓存","slug":"缓存","permalink":"http://lvshen9.gitee.io/tags/缓存/"}]},{"title":"JavaScript学习笔记","slug":"JavaScript学习笔记","date":"2017-09-23T14:23:23.000Z","updated":"2017-09-24T14:05:33.280Z","comments":true,"path":"2017/09/23/JavaScript学习笔记/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/23/JavaScript学习笔记/","excerpt":"一个完整的 JavaScript 实现是由以下 3 个不同部分组成的：核心（ECMAScript） 、文档对象模型（DOM） Document object model (整合js，css，html)、浏览器对象模型（BOM） Broswer object model（整合js和浏览器）、Javascript 在开发中绝大多数情况是基于对象的.也是面向对象的。 常用方法以下为JavaSrcipt常用方法","text":"一个完整的 JavaScript 实现是由以下 3 个不同部分组成的：核心（ECMAScript） 、文档对象模型（DOM） Document object model (整合js，css，html)、浏览器对象模型（BOM） Broswer object model（整合js和浏览器）、Javascript 在开发中绝大多数情况是基于对象的.也是面向对象的。 常用方法以下为JavaSrcipt常用方法 123456789101112131415161718192021x.length －－－－获取字符串的长度x.toLowerCase() －－－－转为小写x.toUpperCase() －－－－转为大写x.trim() －－－－去除字符串两边空格,但是不能去掉两边的换行符和制表符x.charAt(index) －－－－返回字符串中第index位置的字符x.indexOf(findstr) －－－－返回字符串中出现str的第一个位置(从前向后找)x.lastIndexOf(findstr,fromIndex) －－－－返回字符串中出现str的第一个位置(从后向前找) ==&gt; 用着有点不对x.substr(start) －－－－返回字符串从start位置开始到结尾的字符串x.substr(start, length) －－－－start表示开始位置，length表示截取长度 ==&gt; 前面是索引位置,后面是长度x.substring(start) －－－－返回字符串从start位置开始结尾的字符串x.substring(start,end) －－－－返回字符串从start位置开始,到索引end位置结束的字符串(左闭又开) ===&gt; 前面是索引位置,后面也是索引位置x.slice(start, end) －－－－切片操作字符串,(注意:无论下标是怎样的,查找的时候都是从前向后进行查找) [左闭右开]其中slice的用法和substring的用法基本相同.x.replace(findstr,tostr) －－－－ 字符串替换x.split(); －－－－分割字符串x.concat(addstr) －－－－ 拼接字符串 下面是一些常用代码示例： 代码示例： 1234567891011121314151617181920212223242526272829&lt;script&gt; var str1 = \"I love Java\" console.log(\"字符串的长度是:\"+str1.length) console.log(\"字符串转化为小写:\"+str1.toLowerCase()) console.log(\"字符串转化为大写:\"+str1.toUpperCase()) var str2 = \"Hadoop and Spark\" console.log(str2.trim()) console.log(\"字符串中第三个位置的字符是:\"+str1.charAt(3)) console.log(\"字符串中出现字母J的第一个位置是:\"+str1.indexOf(\"J\")) console.log(\"字符串中出现字符串Java的第一个位置是:\"+str1.indexOf(\"Java\")) console.log(\"字符串中从后向前出现字符串J的第一个位置是:\"+str1.lastIndexOf(\"J\")) console.log(\"返回字符串从第二个位置开始到结尾的字符串:\"+str2.substr(2)) console.log(\"返回字符串从第二个位置开始,并截取3个长度的串\"+str2.substr(2,3)) console.log(\"返回字符串从第二个位置开始到结尾的字符串\"+str2.substring(2)) console.log(\"返回字符串从第二个位置开始到第五个位置的字符串(左闭右开)\"+str2.substring(2,5)) //下面这两行是无效的 console.log(\"返回字符串从第二个位置开始到-1位置的字符串\"+str2.substring(1,-2)) console.log(\"返回字符串从-5位置开始到-1位置的字符串\"+str2.substring(-5,-2)) //切片的相关操作:看来切片的功能是最强大的 console.log(\"返回字符串从第二个位置开始到结尾的字符串\"+str2.slice(2)) console.log(\"返回字符串从第二个位置开始第五个位置的字符串(左闭右开)\"+str2.slice(2,5)) console.log(\"返回字符串从第二个位置开始到-1位置的字符串\"+str2.slice(1,-2)) console.log(\"返回字符串从-5位置开始到-1位置的字符串\"+str2.slice(-5,-2))&lt;/script&gt; 运行结果： 1234567891011121314151617181、Array.prototype.join(separator) :循环遍历数组中的每一个元素(数组中的元素可以是字符串, 也可以是数字),并用指定的分隔符separator将它们拼接起来,结果返回一个字符串。2、Array.prototype.concat:用于字符串的拼接的操作(当然也可以拼接数组)3、Array.prototype.sort:不是按照数字大小进行排序的,而是按照最高位的ASCII码排序的。(这是一个坑)如何将数字按照大小排序呢? function sort_arr(m,n) &#123; return n - m; &#125;然后sort中的参数写的是sort_arr这个函数。4、数组的切片操作和字符串的切片操作是一样的.5、数组中的push pop这两个方法模拟的是一个栈操作 x.push(value, ...) 压栈 x.pop() 弹栈 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;script&gt; var arr1 = [\"spark\",\"Hadoop\",10] var arr2 = new Array(\"spark\",\"Hadoop\",10) for (var i=0;i&lt;arr1.length;i++)&#123; console.log(arr1[i]) &#125; for (var j=0;j&lt;arr2.length;j++)&#123; console.log(arr2[j]) &#125; console.log(\"-------------\") str3 = arr1.join(\"_\") console.log(str3) str4 = arr2.join(\"-\") console.log(str4) console.log(\"-------------\") var a = [1,2,3] var b = a.concat([4,5]) var c = a.concat(7,8) console.log(a.toString()) console.log(b.toString()) console.log(c.toString()) console.log(\"-------------\") var d = [100,56,34,8,6,7] e = d.sort() //数组本身的顺序发生了变化 console.log(d) console.log(e) var arr4 = [\"abc\",\"hbfds\",\"dfe\",\"b\"] arr4.sort() console.log(arr4) function sort_arr(m,n) &#123; return n - m; &#125; var d2 = [100,56,34,8,6,7] d2.sort(sort_arr) console.log(d2) //数组中的切片方法,和我们字符串中的方法是一样的: var arr5 = [\"spark\",\"Hadoop\",\"hbase\",\"scala\",\"Django\"] console.log(\"返回数组中第1个索引位置之后的列表\"+arr5.slice(1)) console.log(\"返回数组中第1个索引位置到第四个索引位置之后的列表\"+arr5.slice(1,4)) console.log(\"返回数组中第1个索引位置到第-1个索引位置之后的列表\"+arr5.slice(1,-1)) console.log(\"返回数组中第-3个索引位置到第-1个索引位置之后的列表\"+arr5.slice(-3,-1)) //数组中的插入和删除的方法:push 和 pop var arr6 = [\"spark\",\"Hadoop\",\"hbase\",\"scala\",\"Django\"] arr6.push(\"dj\") console.log(arr6.toString()) arr6.pop(\"dj\") console.log(arr6.toString())&lt;/script&gt; 运行结果： 1234567891011获取日期和时间getDate() 获取日getDay () 获取星期getMonth () 获取月（0-11）getFullYear () 获取完整年份getYear () 获取年getHours () 获取小时getMinutes () 获取分钟getSeconds () 获取秒getMilliseconds () 获取毫秒getTime () 返回累计毫秒数(从1970/1/1午夜) 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;script&gt; &lt;!--构造一个函数,获取当前最新的时间--&gt; function getCurrrentDate() &#123; //1、创建Date对象 var date = new Date() console.log(date.toString()) //2、获取当前年份 var year = date.getFullYear() console.log(\"当前年份是:\"+year) //3、获取当前月份,js中月份是从0到11,所以我们要加1 var month = date.getMonth() + 1; console.log(\"当前月份是:\"+month) //4、获得当前日期(即几号) var day = date.getDate() console.log(\"当前日期是:\"+day) //5、获得当前小时 var hour = date.getHours() console.log(\"当前小时是:\"+hour) //6、获得当前分钟 var min = date.getMinutes() console.log(\"当前分钟是:\"+min) //7、获得当前秒 var sec = date.getSeconds(); console.log(\"当前秒是:\"+sec) //8、获得当前星期几 var week = date.getDay() //在js当中星期几是用数字表示的 console.log(\"当前星期几:\"+week) return year + \"年\" +changeNum(month)+\"月\"+day+\"日\"+hour+\"时\"+min+\"分\"+sec+\"秒\"+parseWeek(week) &#125; console.log(getCurrrentDate()) //解决:自动补齐两位数字的方法 function changeNum(num) &#123; if (num &lt; 10) return \"0\"+num; else return num; &#125; console.log(changeNum(6)) //解决:将数字0-6转换成星期日到星期六 function parseWeek(week) &#123; var arr = [\"星期日\",\"星期一\",\"星期二\",\"星期三\",\"星期四\",\"星期五\",\"星期六\"]; return arr[week]; &#125; console.log(parseWeek(0));&lt;/script&gt; 运行效果： 123456789101112function 函数名 (参数)&#123; &lt;br&gt; 函数体; return 返回值;&#125;功能说明：可以使用变量、常量或表达式作为函数调用的参数函数由关键字function定义函数名的定义规则与标识符一致，大小写是敏感的返回值必须使用returnFunction 类可以表示开发者定义的任何函数。函数的内置对象arguments:函数参数的集合 函数的内置对象arguments的相关应用12345678910111213141516171819202122&lt;script&gt; //内置对象arguments的应用1 function add(x,y) &#123; var sum = 0 for (var i=0;i&lt;arguments.length;i++) &#123; sum += arguments[i] console.log(arguments[i]) &#125; console.log(\"总和是:\"+sum) &#125; add(2,3) //内置对象arguments的应用2:判断函数参数的个数是否正确 function add_sum(a,b,c) &#123; if (arguments.length != 3) console.log(\"函数的参数个数不对!\") else alert(\"传入参数的个数success!\") &#125; 运行结果： 12342 3 总和是:5 函数的参数个数不对! 注意：jQuery当中没有定时器，只有Js当中有window对象：所有浏览器都支持 window 对象。概念上讲.一个html文档对应一个window对象.功能上讲: 控制浏览器窗口的.使用上讲: window对象不需要创建对象,直接使用即可. 1234567891011alert() 显示带有一段消息和一个确认按钮的警告框。confirm() 显示带有一段消息以及确认按钮和取消按钮的对话框。prompt() 显示可提示用户输入的对话框。//setInterval可以让一个函数循环往复的操作.setInterval(func,time)：按照指定的周期（以毫秒计）来调用函数或计算表达式,从而设置一个定时器。clearInterval(arg) 取消由 setInterval() 设置的定时器,arg的数值是setInterval()的返回值。//setTimeout只会让一个函数执行一次.setTimeout(func,time) ：在指定的毫秒数后调用函数或计算表达式。clearTimeout(arg) ：取消由 setTimeout() 方法设置的定时器,arg的数值是setTimeout()的返回值。12345678910111234567891011 示例程序1： 1234567891011121314151617181920&lt;script&gt; &lt;!--我们对一个BOM对象操作,实际上就是对一个窗口对象经操作--&gt;// alert的使用 aa = alert(\"确定\") console.log(aa)// confirm的使用 bb = confirm(\"是否确认操作?\") console.log(bb) if (bb) console.log(\"OK\") else console.log(\"False\")// prompt的使用：类似于Python中的Input按钮 cc = prompt(\"please input a number:\") console.log(\"用户输入的数值是:\"+cc)&lt;/script&gt; 示例程序2： 1234567891011121314151617&lt;script&gt; &lt;!--每隔一秒钟打一个OK--&gt; function print_ok() &#123; console.log(\"OK\") &#125; //注意:首次执行时间是2秒钟之后,而不是上来就开始执行 var ID = setInterval(print_ok,2000) console.log(\"ID的数值是:\"+ID) //print_ok还没有执行,就已经被取消了 clearInterval(ID) //注意:首次执行时间是3秒钟之后,而不是上来就开始执行,并且只会执行一次 var ID2 = setTimeout(print_ok,3000) console.log(\"ID2的数值是:\"+ID2) clearTimeout(ID2)&lt;/script&gt; 示例程序3：定时器的应用（很重要） 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; [type=\"text\"]&#123; width: 250px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;input type=\"text\"&gt;&amp;nbsp;&lt;button&gt;start&lt;/button&gt;&amp;nbsp;&lt;button&gt;stop&lt;/button&gt;&lt;/body&gt;&lt;script&gt; button_ele = document.getElementsByTagName(\"button\") input_ele = document.getElementsByTagName(\"input\")[0] //给标签按钮增加一个事件监听器 var ID; console.log(\"ID的初始数值是:\"+ID) button_ele[0].onclick = function()&#123; //一旦ID已经有了数值,用户的操作就置为无效:否则点一次开了一次定时器 if (ID == undefined)&#123; input_ele.value = new Date().toString() //1s钟之后就会周而复始的更新值 ID = setInterval(set_time,1000) &#125; &#125; button_ele[1].onclick = function()&#123; clearInterval(ID) console.log(\"ID此时的数值是:\"+ID) ID = undefined; &#125; function set_time() &#123; input_ele.value = new Date().toString() &#125;&lt;/script&gt;&lt;/html&gt; 部分截图： HTML DOM:HTML Document Object Model（文档对象模型）HTML DOM 定义了访问和操作HTML文档的标准方法HTML DOM 把 HTML 文档呈现为带有元素、属性和文本的树结构（节点树)document与element节点是重点 123456789101112131415161718直接查找节点：document.getElementById(“idname”)document.getElementsByTagName(“tagname”)document.getElementsByName(“name”)document.getElementsByClassName(“name”) ===&gt; 这个只有在属性中含有name属性的时候才可以用导航节点属性:parentElement 或者 parentNode // 父节点标签元素children // 所有子标签firstElementChild // 第一个子标签元素lastElementChild // 最后一个子标签元素nextElementtSibling // 下一个兄弟标签元素previousElementSibling // 上一个兄弟标签元素 节点的查找实际上分为两种方式：全部查找与局部查找12获取标签的第一种方法:通过document全局查找获取标签的第二种方法:获取父标签在父亲的局部范围内去查找 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"div1\"&gt; &lt;div name=\"yuan\"&gt;i am div2&lt;/div&gt; &lt;div class=\"div2\"&gt;i am div1&lt;/div&gt; &lt;div id=\"div3\"&gt;i am div3&lt;/div&gt; &lt;p&gt;hello p&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; div2 = document.getElementsByClassName(\"div2\")[0] console.log(div2) //父节点标签的查找方法：parentNode也可以 div2_par = div2.parentElement console.log(div2_par) div2_parr = div2.parentNode console.log(div2_parr) //子节点标签的查找方法:别用childNodes div2_par_child = div2_par.children console.log(div2_par_child) //第一个子标签元素:firstChild别用 div2_par_firstchild = div2_par.firstElementChild console.log(div2_par_firstchild) //最后一个子标签元素：lastChild别用 div2_par_lastchild = div2_par.lastElementChild console.log(div2_par_lastchild) div2_ele = document.getElementsByClassName(\"div2\")[0] //上一个兄弟标签 div2_ele_up = div2_ele.previousElementSibling console.log(div2_ele_up) //下一个兄弟标签 div2_ele_down = div2_ele.nextElementSibling console.log(div2_ele_down)&lt;/script&gt;&lt;/html&gt; 运行结果：​ 代码示例2：全局查找与局部查找 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"item\"&gt;&lt;/div&gt; &lt;div id=\"d1\"&gt; &lt;div class=\"item\"&gt;hello you&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; //获取标签的第一种方法:通过document全局查找 var eles = document.getElementsByClassName(\"item\") console.log(eles[1]) //获取标签的第二种方法:获取父标签在父亲的局部范围内去查找 var div_d1 = document.getElementById(\"d1\") //在div_d1的局部范围内去查找 var hello_div = div_d1.getElementsByClassName(\"item\") console.log(hello_div[0])&lt;/script&gt;&lt;/html&gt; 1234567方法1：onclick=&quot;fun1()&quot;方法2： item2_ele.onclick = function()&#123; alert(&quot;OK_two&quot;) &#125; 代码示例： 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;input type=\"button\" class=\"item1\" value=\"click_one\" onclick=\"fun1()\"&gt; &lt;input type=\"button\" class=\"item2\" value=\"click_two\"&gt;&lt;/body&gt;&lt;script&gt; function fun1() &#123; alert(\"OK_one!\") &#125; item2_ele = document.getElementsByClassName(\"item2\")[0] item2_ele.onclick = function()&#123; alert(\"OK_two\") &#125;&lt;/script&gt;&lt;/html&gt; 12345678910111213141516171819获取节点对应的文本值:当标签里面没有标签的时候，两个属性是没有区别的方法1:console.log(ele.innerText) ==&gt; 获取一个标签里面的所有文本方法2:console.log(ele.innerHTML) ==&gt; 获取一个标签里面的所有文本以及相应的内部标签两者的区别:innertText只获取标签内部对应的文本(仅获取文本,结果是一个字符串),而innerHTML将标签内部的标签都会给拿出来(识别标签)eg:PPP&lt;p&gt;PPP&lt;/p&gt;如何对标签内部的文本进行赋值:方法1:ele2[0].innerText = &quot;&lt;a href=&apos;&apos;&gt;点击&lt;/a&gt;&quot;方法2:ele2[0].innerHTML = &quot;&lt;a href=&apos;&apos;&gt;点击&lt;/a&gt;&quot;两者的区别:无论怎么赋值,都是用你当前当前的内容替换掉标签里面的所有的内容,但是前者文本渲染,后者按标签去渲染(即后者识别标签),所以通常后者用的多。但是我自己在操作的时候很少去赋值一个标签,基本上都是克隆。 示例1：获取节点对应的文本值 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"c1\"&gt;DIV&lt;/div&gt; &lt;div class=\"c2\"&gt; &lt;p&gt;PPP&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementsByClassName(\"c1\")[0] //打印出节点 console.log(ele) //获取节点对应的文本值 console.log(ele.innerText) console.log(ele.innerHTML) var ele2 = document.getElementsByClassName(\"c2\") //打印出节点 console.log(ele2[0]) //获取节点对应的文本值:innertText只获取标签内部对应的文本(仅获取文本,结果是一个字符串),而innerHTML将标签内部的 //标签都会给拿出来(识别标签) console.log(ele2[0].innerText) console.log(typeof ele2[0].innerText) console.log(ele2[0].innerHTML) console.log(typeof ele2[0].innerHTML)&lt;/script&gt;&lt;/html&gt; 效果： 示例2：如何对标签内部的文本值进行赋值（innerText） 12345678910111213141516&lt;body&gt; &lt;div class=\"c1\"&gt;DIV&lt;/div&gt; &lt;div class=\"c2\"&gt; &lt;p&gt;PPP&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementsByClassName(\"c1\")[0] var ele2 = document.getElementsByClassName(\"c2\") //如何对标签内部的文本进行赋值:此时将会对标签里面的所有内容进行赋值 ele2[0].innerText = \"&lt;a href=''&gt;点击&lt;/a&gt;\" console.log(ele2[0].innerText)&lt;/script&gt; 效果展示： 示例3：如何对标签内部的文本值进行赋值（innerHTML） 123456789101112131415161718&lt;body&gt; &lt;div class=\"c1\"&gt;DIV&lt;/div&gt; &lt;div class=\"c2\"&gt; &lt;p&gt;PPP&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementsByClassName(\"c1\")[0] var ele2 = document.getElementsByClassName(\"c2\") //如何对标签内部的文本进行赋值:此时将会对标签里面的所有内容进行赋值 ele2[0].innerHTML = \"&lt;a href=''&gt;点击&lt;/a&gt;\" console.log(ele2[0].innerHTML) console.log(ele2[0].innerText) //即无论怎么赋值,都是用你当前当前的内容替换掉标签里面的所有的内容,但是前者文本渲染,后者按标签去渲染&lt;/script&gt; 运行结果： 对于这个知识点，我当年学的时候遇到了很多的坑，每次遇到这里都是各种百度，总之就是各种坑………. 就是上面的这么简单，总结如下：在JavaScript中： 1234567获取属性值的操作：方法1：elementNode.getAttribute(属性名) 方法2：elementNode.属性名给属性赋值的操作：方法1：elementNode.setAttribute(属性名,value) 方法2：elementNode.属性名 = 属性值 到底啥是属性名和属性值啊？（呵呵） 示例程序： 123456789101112131415161718192021222324252627&lt;body&gt; &lt;input type=\"text\" id=\"t1\" value=\"123\"&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementById(\"t1\") //获取属性值 //第一种方法：elementNode.getAttribute(属性名) console.log(ele.getAttribute(\"value\")) console.log(ele.getAttribute(\"id\")) console.log(ele.getAttribute(\"type\")) //第二种方法：elementNode.属性名 console.log(ele.value) console.log(ele.id) console.log(ele.type) //设置属性值 //设置属性值1:elementNode.setAttribute(属性名,value) ele.setAttribute(\"value\",\"456\") ele.setAttribute(\"id\",\"t2\") ele.setAttribute(\"type\",\"button\") //设置属性值2:elementNode.属性名 = value ele.value = \"789\" ele.id = \"t6\" ele.type = \"button\"&lt;/script&gt; 123elementNode.className :查看标签对应的class名字(是个字符串,但是是个数组)elementNode.classList.add:向class列表中添加一个属性elementNode.classList.remove:向class列表中删掉一个属性 示例程序： 12345678910111213141516171819&lt;body&gt; &lt;input type=\"text\" class=\"d1 d2\" value=\"python\"&gt;&lt;/body&gt;&lt;script&gt; ele = document.getElementsByTagName(\"input\")[0] console.log(ele.className) console.log(typeof ele.className) //class属性对应的实际上是一个列表(数组) console.log(ele.classList) console.log(ele.classList[0]) console.log(ele.classList[1]) //给input标签的class增加一个属性 ele.classList.add(\"d3\") ele.classList.remove(\"d1\") //class列表中有则不添加,没有删除也不报错&lt;/script&gt; 效果展示： 示例2：class的一个应用（左侧菜单案例） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; .left_menu&#123; width:20%; height: 500px; background-color: wheat; float: left; &#125; .content_menu&#123; width: 80%; height: 500px; background-color: darkgray; float: left; &#125; .title&#123; /*将标题进行居中*/ text-align: center; background-color: crimson; line-height: 40px; color: white; &#125; /*含有con的属性会自动隐藏*/ .hide&#123; display: none; &#125; .item&#123; margin: 20px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"outer\"&gt; &lt;div class=\"left_menu\"&gt; &lt;div class=\"item\"&gt; &lt;div class=\"title\"&gt;菜单一&lt;/div&gt; &lt;div class=\"con \"&gt; &lt;p&gt;111&lt;/p&gt; &lt;p&gt;111&lt;/p&gt; &lt;p&gt;111&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;div class=\"title\"&gt;菜单二&lt;/div&gt; &lt;div class=\"con hide\"&gt; &lt;p&gt;222&lt;/p&gt; &lt;p&gt;222&lt;/p&gt; &lt;p&gt;222&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;div class=\"title\"&gt;菜单三&lt;/div&gt; &lt;div class=\"con hide\"&gt; &lt;p&gt;333&lt;/p&gt; &lt;p&gt;333&lt;/p&gt; &lt;p&gt;333&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"content_menu\"&gt;哈哈&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; var eles = document.getElementsByClassName(\"title\") for (var i=0;i&lt;eles.length;i++)&#123; eles[i].onclick = function()&#123; //将标签的class列表去掉hide这个值 this.nextElementSibling.classList.remove(\"hide\") //javascript当中不能拿到坑爹的兄弟标签 var arr_item = this.parentElement.parentElement.children console.log(arr_item) var ele_curr_p = this.parentElement for (var i=0;i&lt;arr_item.length;i++)&#123; console.log(arr_item[i])// 在这里面判断两个标签是否相同 if (arr_item[i] != ele_curr_p)&#123; arr_item[i].children[1].classList.add(\"hide\") &#125; &#125; &#125; &#125;&lt;/script&gt;&lt;/html&gt; 效果展示： 123456789101112131415161718JavaScript当中：创建节点:createElement(标签名) ：创建一个指定名称的元素.给节点增加属性,并进行赋值:elementNode.setAttribute(属性名,value)注意：elementNode.属性名 = 属性值 方法将失效添加节点:追加一个子节点（将作为最后的子节点）parentnode.appendChild(newnode)删除节点:parentnode.removeChild(子节点)：获得要删除的元素，通过父元素调用删除替换节点:parentnode.replaceChild(newnode, oldnode); 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; .parent_node&#123; width: 400px; height: 400px; background-color: wheat; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"parent_node\"&gt; &lt;h1&gt;hello 码农&lt;/h1&gt; &lt;/div&gt; &lt;button&gt;add_img&lt;/button&gt; &lt;button&gt;remove_h1&lt;/button&gt; &lt;button&gt;replace_h1&lt;/button&gt;&lt;/body&gt;&lt;script&gt; //获取到增加、删除、替换按钮 var add_button = document.getElementsByTagName(\"button\")[0] var remove_button = document.getElementsByTagName(\"button\")[1] var replace_button = document.getElementsByTagName(\"button\")[2] //获取父节点 var ele_div = document.getElementsByClassName(\"parent_node\")[0] add_button.onclick = function()&#123; //创建img节点 var img_ele = document.createElement(\"img\") //为节点的属性赋值 img_ele.setAttribute(\"src\",\"biancheng.png\") //添加节点 ele_div.appendChild(img_ele) //在创建一个input节点: &lt;input type=\"text\" id=\"t1\" value=\"123\" class=\"item\"&gt; var ele_input = document.createElement(\"input\") ele_input.setAttribute(\"type\",\"text\") ele_input.setAttribute(\"id\",\"t1\") ele_input.setAttribute(\"value\",\"123\") ele_input.setAttribute(\"class\",\"123\") //在添加节点 ele_div.appendChild(ele_input) &#125; remove_button.onclick = function () &#123; //找到h1节点 var h1_button = document.getElementsByTagName(\"h1\")[0] //进行删除操作 ele_div.removeChild(h1_button) &#125; replace_button.onclick = function () &#123; //找到h1节点 var h1_button = document.getElementsByTagName(\"h1\")[0] //创建一个input节点 var ele_input = document.createElement(\"input\") ele_input.setAttribute(\"type\",\"text\") ele_input.setAttribute(\"id\",\"t2\") ele_input.setAttribute(\"value\",\"456\") ele_input.setAttribute(\"class\",\"456\") //进行删除操作 ele_div.replaceChild(ele_input,h1_button) &#125;&lt;/script&gt;&lt;/html&gt; 效果展示： 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; .back&#123; width: 100%; height: 1200px; background-color: firebrick; &#125; .fade&#123; /*参照物是当前屏幕:绝对脱离文档流*/ position: fixed; /*满屏: 0 0 0 0 */ top:0; bottom: 0; left: 0; right: 0; background-color: darkgray; /*设置透明度*/ opacity: 0.8; &#125; .model&#123; /*绝对脱离文档流,参照物实际上是body*/ width: 400px; height: 200px; background-color: wheat; position: absolute; top:50%; left:50%; /*下面的两个值实际上是高和宽的一半*/ margin-left:-200px ; margin-top: -100px; border-radius: 5%; &#125; .hide&#123; display: none; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"back\"&gt; &lt;input type=\"button\" value=\"show\" id=\"show\"&gt; &lt;/div&gt; &lt;!--fade在这里面表示遮罩层:实际上就是一个大背景--&gt; &lt;div class=\"fade hide\"&gt;&lt;/div&gt; &lt;!--弹出框:--&gt; &lt;div class=\"model hide\"&gt; &lt;input type=\"button\" value=\"点击\" id=\"click\"&gt; &lt;/div&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementById(\"show\") var div_fade = document.getElementsByClassName(\"fade\")[0] var div_model = document.getElementsByClassName(\"model\")[0] var ele2 = document.getElementById(\"click\") ele.onclick = function()&#123; div_fade.classList.remove(\"hide\") div_model.classList.remove(\"hide\") &#125; ele2.onclick = function()&#123; //下面这种方式是推荐的 this.parentElement.classList.add(\"hide\") this.parentElement.previousElementSibling.classList.add(\"hide\") &#125;&lt;/script&gt;&lt;/html&gt; 效果展示： 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;button&gt;全选&lt;/button&gt; &lt;button&gt;反选&lt;/button&gt; &lt;button&gt;取消&lt;/button&gt; &lt;hr&gt; &lt;!--border可以设置边框--&gt; &lt;table border=\"1\"&gt; &lt;tr&gt; &lt;th&gt; &lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;th&gt;班级&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--checkbox代表复选框的意思--&gt; &lt;td&gt;&lt;input type=\"checkbox\"&gt;&lt;/td&gt; &lt;td&gt;111&lt;/td&gt; &lt;td&gt;111&lt;/td&gt; &lt;td&gt;111&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--checkbox代表复选框的意思--&gt; &lt;td&gt;&lt;input type=\"checkbox\"&gt;&lt;/td&gt; &lt;td&gt;222&lt;/td&gt; &lt;td&gt;222&lt;/td&gt; &lt;td&gt;222&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--checkbox代表复选框的意思--&gt; &lt;td&gt;&lt;input type=\"checkbox\"&gt;&lt;/td&gt; &lt;td&gt;333&lt;/td&gt; &lt;td&gt;333&lt;/td&gt; &lt;td&gt;333&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;script&gt; &lt;!--checked == true|\"checked\"表示复选框被选中--&gt; var button_eles = document.getElementsByTagName(\"button\") var ele_checkbox = document.getElementsByTagName(\"input\") for (var i=0;i&lt;button_eles.length;i++)&#123; button_eles[i].onclick = function()&#123; if (this.innerText == \"全选\") &#123; for (var j=0;j&lt;ele_checkbox.length;j++)&#123; ele_checkbox[j].checked = \"checked\" ele_checkbox[j].checked = true &#125; &#125; else if(this.innerText == \"反选\") &#123; for (var j=0;j&lt;ele_checkbox.length;j++)&#123; if (ele_checkbox[j].checked)&#123; ele_checkbox[j].checked = false &#125; else ele_checkbox[j].checked = true &#125; &#125; else&#123; for (var j=0;j&lt;ele_checkbox.length;j++)&#123; //复选框不选中的表达方式 ele_checkbox[j].checked = false &#125; &#125; &#125; &#125;&lt;/script&gt;&lt;/html&gt; 123&lt;p id=&quot;p2&quot;&gt;Hello world!&lt;/p&gt;document.getElementById(&quot;p2&quot;).style.color=&quot;blue&quot;; .style.fontSize=48px 代码示例： 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"d1\"&gt; &lt;div class=\"item\"&gt;hello you&lt;/div&gt; &lt;/div&gt; &lt;input type=\"button\" value=\"点我\"&gt;&lt;/body&gt;&lt;script&gt; div_item = document.getElementsByClassName(\"item\")[0] console.log(div_item) input_button = document.getElementsByTagName(\"input\")[0] console.log(input_button) //为点击按钮增加相应的事件监听器:点击字体之后变颜色 input_button.onclick = function()&#123; //注意:value值要加双引号 div_item.style.color = \"blue\"; div_item.style.fontSize=\"48px\"; div_item.style.backgroundColor = \"red\"; &#125;&lt;/script&gt;&lt;/html&gt; 效果展示： 123456789onsubmit：当表单在提交时触发,该属性也只能给form元素使用.应用场景: 在表单提交前验证用户输入是否正确.如果验证失败.在该方法中我们应该阻止表单的提交.(验证在前端与后端都要进行验证,在默认事件发生之前,先进行验证)默认submit作用：在form表单中,当点击这个按钮后,会将form表单中所有的数据打包然后发到server端,这个事件是这个按钮自带的一个事件(默认的提交事件)。阻止默认的提交事件的两种方法：return false;e.preventDefault() onsubmit代码示例（事件默认是这样子的）： 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"\" id=\"form\"&gt; 姓名:&lt;input type=\"text\"&gt;&lt;br&gt; 密码:&lt;input type=\"password\"&gt;&lt;br&gt; &lt;input type=\"submit\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementById(\"form\") //e指的是所有事件的状态：e实际上就是发生的事件:event对象封装了我们所有事件的状态 ele.onsubmit = function(e)&#123; alert(\"123\") //这一行代码可以理解为登陆验证 //通过return false可以阻止默认事件的发生(:向服务器端发送form表单的数据) //return false; //e.preventDefault() &#125;&lt;/script&gt;&lt;/html&gt; 放行之前的效果： 放行之后的效果： 从效果上我们可以看出，如过在前端验证未通过，数据包将不能发送到服务端。 1234onkeydown:Event 对象：Event 对象代表事件的状态，比如事件在其中发生的元素、键盘按键的状态、鼠标的位置、鼠标按钮的状态。事件通常与函数结合使用，函数不会在事件发生前被执行！event对象在事件发生时系统已经创建好了,并且会在事件函数被调用时传给事件函数.我们获得仅仅需要接收一下即可.比如onkeydown,我们想知道哪个键被按下了，需要问下event对象的属性，这里就时KeyCode. 代码示例： 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;input type=\"text\" id=\"test\"&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementById(\"test\") //按下鼠标之后的反应 ele.onkeyup = function(event)&#123; //先做兼容 event = event || window.event //keynum实际上是ASCII编码 var keynum = event.keyCode console.log(keynum) var keychar = String.fromCharCode(keynum) if (keychar == \"B\")&#123; alert(\"OK\") &#125; &#125;&lt;/script&gt;&lt;/html&gt; 获取焦点与失去焦点的主要作用是用于提示用户的相关操作 代码示例： 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!--placeholder在这里面实际上是一个提示的作用--&gt; &lt;input type=\"text\" placeholder=\"侣神\"&gt; &lt;input type=\"text\" value=\"侣神\" id=\"search\"&gt;&lt;/body&gt;&lt;script&gt; var ele = document.getElementById(\"search\") //获取焦点 ele.onfocus = function()&#123; this.value = \"\" &#125; //失去焦点 ele.onblur = function()&#123; if (!this.value.trim()) this.value = \"用户名\" &#125;&lt;/script&gt;&lt;/html&gt; OK，就写到这里！ 欢迎star 我的博客：Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lvshen9.gitee.io/tags/JavaScript/"},{"name":"html","slug":"html","permalink":"http://lvshen9.gitee.io/tags/html/"}]},{"title":"MySQL 索引设计概要","slug":"MySQL-索引设计概要","date":"2017-09-20T13:37:49.000Z","updated":"2017-09-20T13:46:40.513Z","comments":true,"path":"2017/09/20/MySQL-索引设计概要/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/20/MySQL-索引设计概要/","excerpt":"本文转载至MySQL 索引设计概要 在关系型数据库中设计索引其实并不是复杂的事情，很多开发者都觉得设计索引能够提升数据库的性能，相关的知识一定非常复杂。 Index-and-Performance 然而这种想法是不正确的，索引其实并不是一个多么高深莫测的东西，只要我们掌握一定的方法，理解索引的实现就能在不需要 DBA 的情况下设计出高效的索引。 本文会介绍 数据库索引设计与优化 中设计索引的一些方法，让各位读者能够快速的在现有的工程中设计出合适的索引。","text":"本文转载至MySQL 索引设计概要 在关系型数据库中设计索引其实并不是复杂的事情，很多开发者都觉得设计索引能够提升数据库的性能，相关的知识一定非常复杂。 Index-and-Performance 然而这种想法是不正确的，索引其实并不是一个多么高深莫测的东西，只要我们掌握一定的方法，理解索引的实现就能在不需要 DBA 的情况下设计出高效的索引。 本文会介绍 数据库索引设计与优化 中设计索引的一些方法，让各位读者能够快速的在现有的工程中设计出合适的索引。 磁盘 IO一个数据库必须保证其中存储的所有数据都是可以随时读写的，同时因为 MySQL 中所有的数据其实都是以文件的形式存储在磁盘上的，而从磁盘上随机访问对应的数据非常耗时，所以数据库程序和操作系统提供了缓冲池和内存以提高数据的访问速度。 Disk-IO 除此之外，我们还需要知道数据库对数据的读取并不是以行为单位进行的，无论是读取一行还是多行，都会将该行或者多行所在的页全部加载进来，然后再读取对应的数据记录；也就是说，读取所耗费的时间与行数无关，只与页数有关。 Page-DatabaseBufferPool 在 MySQL 中，页的大小一般为 16KB，不过也可能是 8KB、32KB 或者其他值，这跟 MySQL 的存储引擎对数据的存储方式有很大的关系，文中不会展开介绍，不过索引或行记录是否在缓存池中极大的影响了访问索引或者数据的成本。 随机读取数据库等待一个页从磁盘读取到缓存池的所需要的成本巨大的，无论我们是想要读取一个页面上的多条数据还是一条数据，都需要消耗约 10ms 左右的时间： Disk-Random-IO 10ms 的时间在计算领域其实是一个非常巨大的成本，假设我们使用脚本向装了 SSD 的磁盘上顺序写入字节，那么在 10ms 内可以写入大概 3MB 左右的内容，但是数据库程序在 10ms 之内只能将一页的数据加载到数据库缓冲池中，从这里可以看出随机读取的代价是巨大的。 Disk-IO-Total-Time 这 10ms 的一次随机读取是按照每秒 50 次的读取计算得到的，其中等待时间为 3ms、磁盘的实际繁忙时间约为 6ms，最终数据页从磁盘传输到缓冲池的时间为 1ms 左右，在对查询进行估算时并不需要准确的知道随机读取的时间，只需要知道估算出的 10ms 就可以了。 内存读取如果在数据库的缓存池中没有找到对应的数据页，那么会去内存中寻找对应的页面： Read-from-Memory 当对应的页面存在于内存时，数据库程序就会使用内存中的页，这能够将数据的读取时间降低一个数量级，将 10ms 降低到 1ms；MySQL 在执行读操作时，会先从数据库的缓冲区中读取，如果不存在与缓冲区中就会尝试从内存中加载页面，如果前面的两个步骤都失败了，最后就只能执行随机 IO 从磁盘中获取对应的数据页。 顺序读取从磁盘读取数据并不是都要付出很大的代价，当数据库管理程序一次性从磁盘中顺序读取大量的数据时，读取的速度会异常的快，大概在 40MB/s 左右。 Sequential-Reads-from-Disk 如果一个页面的大小为 4KB，那么 1s 的时间就可以读取 10000 个页，读取一个页面所花费的平均时间就是 0.1ms，相比随机读取的 10ms 已经降低了两个数量级，甚至比内存中读取数据还要快。 Random-to-Sequentia 数据页面的顺序读取有两个非常重要的优势： 同时读取多个界面意味着总时间的消耗会大幅度减少，磁盘的吞吐量可以达到 40MB/s； 数据库管理程序会对一些即将使用的界面进行预读，以减少查询请求的等待和响应时间； 小结数据库查询操作的时间大都消耗在从磁盘或者内存中读取数据的过程，由于随机 IO 的代价巨大，如何在一次数据库查询中减少随机 IO 的次数往往能够大幅度的降低查询所耗费的时间提高磁盘的吞吐量。 查询过程在上一节中，文章从数据页加载的角度介绍了磁盘 IO 对 MySQL 查询的影响，而在这一节中将介绍 MySQL 查询的执行过程中以及数据库中的数据的特征对最终查询性能的影响。 索引片（Index Slices）索引片其实就是 SQL 查询在执行过程中扫描的一个索引片段，在这个范围中的索引将被顺序扫描，根据索引片包含的列数不同，数据库索引设计与优化 书中对将索引分为宽索引和窄索引： Thin-Index-and-Fat-Index 主键列 id 在所有的 MySQL 索引中都是一定会存在的。 对于查询 SELECT id, username, age FROM users WHERE username=&quot;draven&quot; 来说，(id, username) 就是一个窄索引，因为该索引没有包含存在于 SQL 查询中的 age 列，而 (id, username, age) 就是该查询的一个宽索引了，它包含这个查询中所需要的全部数据列。 宽索引能够避免二次的随机 IO，而窄索引就需要在对索引进行顺序读取之后再根据主键 id 从主键索引中查找对应的数据： Thin-Index-and-Clustered-Index 对于窄索引，每一个在索引中匹配到的记录行最终都需要执行另外的随机读取从聚集索引中获得剩余的数据，如果结果集非常大，那么就会导致随机读取的次数过多进而影响性能。 过滤因子从上一小节对索引片的介绍，我们可以看到影响 SQL 查询的除了查询本身还与数据库表中的数据特征有关，如果使用的是窄索引那么对表的随机访问就不可避免，在这时如何让索引片变『薄』就是我们需要做的了。 一个 SQL 查询扫描的索引片大小其实是由过滤因子决定的，也就是满足查询条件的记录行数所占的比例： Filter-Facto 对于 users 表来说，sex=”male” 就不是一个好的过滤因子，它会选择整张表中一半的数据，所以在一般情况下我们最好不要使用 sex 列作为整个索引的第一列；而 name=”draven” 的使用就可以得到一个比较好的过滤因子了，它的使用能过滤整个数据表中 99.9% 的数据；当然我们也可以将这三个过滤进行组合，创建一个新的索引 (name, age, sex) 并同时使用这三列作为过滤条件： Combined-Filter-Facto 当三个过滤条件都是等值谓词时，几个索引列的顺序其实是无所谓的，索引列的顺序不会影响同一个 SQL 语句对索引的选择，也就是索引 (name, age, sex) 和 (age, sex, name) 对于上图中的条件来说是完全一样的，这两个索引在执行查询时都有着完全相同的效果。 组合条件的过滤因子就可以达到十万分之 6 了，如果整张表中有 10w 行数据，也只需要在扫描薄索引片后进行 6 次随机读取，这种直接使用乘积来计算组合条件的过滤因子其实有一个比较重要的问题：列与列之间不应该有太强的相关性，如果不同的列之间有相关性，那么得到的结果就会比直接乘积得出的结果大一些，比如：所在的城市和邮政编码就有非常强的相关性，两者的过滤因子直接相乘其实与实际的过滤因子会有很大的偏差，不过这在多数情况下都不是太大的问题。 对于一张表中的同一个列，不同的值也会有不同的过滤因子，这也就造成了同一列的不同值最终的查询性能也会有很大差别： Same-Columns-Filter-Facto 当我们评估一个索引是否合适时，需要考虑极端情况下查询语句的性能，比如 0% 或者 50% 等；最差的输入往往意味着最差的性能，在平均情况下表现良好的 SQL 语句在极端的输入下可能就完全无法正常工作，这也是在设计索引时需要注意的问题。 总而言之，需要扫描的索引片的大小对查询性能的影响至关重要，而扫描的索引记录的数量，就是总行数与组合条件的过滤因子的乘积，索引片的大小最终也决定了从表中读取数据所需要的时间。 匹配列与过滤列假设在 users 表中有 name、age 和 (name, sex, age) 三个辅助索引；当 WHERE 条件中存在类似 age = 21 或者 name = “draven” 这种等值谓词时，它们都会成为匹配列（Matching Column）用于选择索引树中的数据行，但是当我们使用以下查询时： 12SELECT * FROM usersWHERE name = &quot;draven&quot; AND sex = &quot;male&quot; AND age &gt; 20; 虽然我们有 (name, sex, age) 索引包含了上述查询条件中的全部列，但是在这里只有 name 和 sex 两列才是匹配列，MySQL 在执行上述查询时，会选择 name 和 sex 作为匹配列，扫描所有满足条件的数据行，然后将 age 当做过滤列（Filtering Column）： Match-Columns-Filter-Columns 过滤列虽然不能够减少索引片的大小，但是能够减少从表中随机读取数据的次数，所以在索引中也扮演着非常重要的角色。 索引的设计作者相信文章前面的内容已经为索引的设计提供了充足的理论基础和知识，从总体来看如何减少随机读取的次数是设计索引时需要重视的最重要的问题，在这一节中，我们将介绍 数据库索引设计与优化 一书中归纳出的设计最佳索引的方法。 三星索引三星索引是对于一个查询语句可能的最好索引，如果一个查询语句的索引是三星索引，那么它只需要进行一次磁盘的随机读及一个窄索引片的顺序扫描就可以得到全部的结果集；因此其查询的响应时间比普通的索引会少几个数量级；根据书中对三星索引的定义，我们可以理解为主键索引对于 WHERE id = 1 就是一个特殊的三星索引，我们只需要对主键索引树进行一次索引访问并且顺序读取一条数据记录查询就结束了。 Three-Star-Index 为了满足三星索引中的三颗星，我们分别需要做以下几件事情： 第一颗星需要取出所有等值谓词中的列，作为索引开头的最开始的列（任意顺序）； 第二颗星需要将 ORDER BY 列加入索引中； 第三颗星需要将查询语句剩余的列全部加入到索引中； 三星索引的概念和星级的给定来源于 数据库索引设计与优化 书中第四章三星索引一节。 如果对于一个查询语句我们依照上述的三个条件进行设计，那么就可以得到该查询的三星索引，这三颗星中的最后一颗星往往都是最容易获得的，满足第三颗星的索引也就是上面提到的宽索引，能够避免大量的随机 IO，如果我们遵循这个顺序为一个 SQL 查询设计索引那么我们就可以得到一个完美的索引了；这三颗星的获得其实也没有表面上这么简单，每一颗星都有自己的意义： Behind-Three-Star-Index 第一颗星不只是将等值谓词的列加入索引，它的作用是减少索引片的大小以减少需要扫描的数据行； 第二颗星用于避免排序，减少磁盘 IO 和内存的使用； 第三颗星用于避免每一个索引对应的数据行都需要进行一次随机 IO 从聚集索引中读取剩余的数据； 在实际场景中，问题往往没有这么简单，我们虽然可以总能够通过宽索引避免大量的随机访问，但是在一些复杂的查询中我们无法同时获得第一颗星和第二颗星。 1234SELECT id, name, age FROM usersWHERE age BETWEEN 18 AND 21 AND city = &quot;Beijing&quot;ORDER BY name; 在上述查询中，我们总可以通过增加索引中的列以获得第三颗星，但是如果我们想要获得第一颗星就需要最小化索引片的大小，这时索引的前缀必须为 (city, age)，在这时再想获得第三颗星就不可能了，哪怕在 age 的后面添加索引列 name，也会因为 name 在范围索引列 age 后面必须进行一次排序操作，最终得到的索引就是 (city, age, name, id)： Different-Stars-Index 如果我们需要在内存中避免排序的话，就需要交换 age 和 name 的位置了，在这时就可以得到索引 (city, name, age, id)，当一个 SQL 查询中同时拥有范围谓词和 ORDER BY 时，无论如何我们都是没有办法获得一个三星索引的，我们能够做的就是在这两者之间做出选择，是牺牲第一颗星还是第二颗星。 总而言之，在设计单表的索引时，首先把查询中所有的等值谓词全部取出以任意顺序放在索引最前面，在这时，如果索引中同时存在范围索引和 ORDER BY 就需要权衡利弊了，希望最小化扫描的索引片厚度时，应该将过滤因子最小的范围索引列加入索引，如果希望避免排序就选择 ORDER BY 中的全部列，在这之后就只需要将查询中剩余的全部列加入索引了，通过这种固定的方法和逻辑就可以最快地获得一个查询语句的二星或者三星索引了。 总结在单表上对索引进行设计其实还是非常容易的，只需要遵循固定的套路就能设计出一个理想的三星索引，在这里强烈推荐 数据库索引设计与优化 这本书籍，其中包含了大量与索引设计与优化的相关内容；在之后的文章中读者也会分析介绍书中提供的几种估算方法，来帮助我们通过预估问题设计出更高效的索引。 如果对文章内容的有疑问，可以在博客下面评论留言（评论系统使用 Disqus，需要翻墙）。 Follow: lvshen9· GitHub Reference 数据库索引设计与优化 File Space Management Inside of Hard Drive - YouTube Hard Disk Working - How does a hard disk work - Hard Drive - YouTube","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://lvshen9.gitee.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"http://lvshen9.gitee.io/tags/索引/"}]},{"title":"Zookeeper学习","slug":"Zookeeper学习","date":"2017-09-18T12:37:02.000Z","updated":"2017-09-18T13:18:13.543Z","comments":true,"path":"2017/09/18/Zookeeper学习/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/18/Zookeeper学习/","excerpt":"本文转载至ZooKeeper 基础知识、部署和应用程序 简介让我们首先讨论一下为什么想使用 ZooKeeper。ZooKeeper 是一个面向分布式系统的构建块。当设计一个分布式系统时，一般需要设计和开发一些协调服务： 名称服务— 名称服务是将一个名称映射到与该名称有关联的一些信息的服务。电话目录是将人的名字映射到其电话号码的一个名称服务。同样，DNS 服务也是一个名称服务，它将一个域名映射到一个 IP 地址。在分布式系统中，您可能想跟踪哪些服务器或服务在运行，并通过名称查看其状态。ZooKeeper 暴露了一个简单的接口来完成此工作。也可以将名称服务扩展到组成员服务，这样就可以获得与正在查找其名称的实体有关联的组的信息。 锁定— 为了允许在分布式系统中对共享资源进行有序的访问，可能需要实现分布式互斥（distributed mutexes）。ZooKeeper 提供一种简单的方式来实现它们。 同步— 与互斥同时出现的是同步访问共享资源的需求。无论是实现一个生产者-消费者队列，还是实现一个障碍，ZooKeeper 都提供一个简单的接口来实现该操作。您可以在 Apache ZooKeeper 维基上查看示例，了解如何做到这一点（参阅 参考资料）。 配置管理— 您可以使用 ZooKeeper 集中存储和管理分布式系统的配置。这意味着，所有新加入的节点都将在加入系统后就可以立即使用来自 ZooKeeper 的最新集中式配置。这还允许您通过其中一个 ZooKeeper 客户端更改集中式配置，集中地更改分布式系统的状态。 领导者选举— 分布式系统可能必须处理节点停机的问题，您可能想实现一个自动故障转移策略。ZooKeeper 通过领导者选举对此提供现成的支持。","text":"本文转载至ZooKeeper 基础知识、部署和应用程序 简介让我们首先讨论一下为什么想使用 ZooKeeper。ZooKeeper 是一个面向分布式系统的构建块。当设计一个分布式系统时，一般需要设计和开发一些协调服务： 名称服务— 名称服务是将一个名称映射到与该名称有关联的一些信息的服务。电话目录是将人的名字映射到其电话号码的一个名称服务。同样，DNS 服务也是一个名称服务，它将一个域名映射到一个 IP 地址。在分布式系统中，您可能想跟踪哪些服务器或服务在运行，并通过名称查看其状态。ZooKeeper 暴露了一个简单的接口来完成此工作。也可以将名称服务扩展到组成员服务，这样就可以获得与正在查找其名称的实体有关联的组的信息。 锁定— 为了允许在分布式系统中对共享资源进行有序的访问，可能需要实现分布式互斥（distributed mutexes）。ZooKeeper 提供一种简单的方式来实现它们。 同步— 与互斥同时出现的是同步访问共享资源的需求。无论是实现一个生产者-消费者队列，还是实现一个障碍，ZooKeeper 都提供一个简单的接口来实现该操作。您可以在 Apache ZooKeeper 维基上查看示例，了解如何做到这一点（参阅 参考资料）。 配置管理— 您可以使用 ZooKeeper 集中存储和管理分布式系统的配置。这意味着，所有新加入的节点都将在加入系统后就可以立即使用来自 ZooKeeper 的最新集中式配置。这还允许您通过其中一个 ZooKeeper 客户端更改集中式配置，集中地更改分布式系统的状态。 领导者选举— 分布式系统可能必须处理节点停机的问题，您可能想实现一个自动故障转移策略。ZooKeeper 通过领导者选举对此提供现成的支持。 虽然可以从头开始设计和实现所有这些服务，但调试任何问题、竞争条件或死锁都需要执行额外的工作，并且很难实现。就像您不会在代码中随处编写自己的随机数发生器或哈希函数一样，这里有一个要求：人们不应该在每次有需要时就到处从头编写自己的名称服务或领导者选举服务。此外，您可以相对容易地一起解决一个非常简单的组成员服务，但是，要编写它们来提供可靠性、复制和可扩展性，可能需要做更多的工作。这导致了 Apache ZooKeeper 的开发和开源，Apache ZooKeeper 是一个针对分布式系统的、开箱即用的、可靠的、可扩展的、高性能的协调服务。 InfoSphere® BigInsights™ Quick Start Edition 是 IBM 的大数据产品，以开源的 Apache Hadoop 项目为基础。它包括 ZooKeeper 和其他大数据技术，以及增加了该平台的价值的 IBM 技术。在本文中，我们只是使用了 ZooKeeper，但是，如欲了解有关 InfoSphere BigInsights 的更多信息，请参阅 参考资料，其中包括一个下载产品的链接。 ZooKeeper 虽然是一个针对分布式系统的协调服务，但它本身也是一个分布式应用程序。ZooKeeper 遵循一个简单的客户端-服务器模型，其中客户端 是使用服务的节点（即机器），而服务器 是提供服务的节点。ZooKeeper 服务器的集合形成了一个 ZooKeeper 集合体（ensemble）。在任何给定的时间内，一个 ZooKeeper 客户端可连接到一个 ZooKeeper 服务器。每个 ZooKeeper 服务器都可以同时处理大量客户端连接。每个客户端定期发送 ping 到它所连接的 ZooKeeper 服务器，让服务器知道它处于活动和连接状态。被询问的 ZooKeeper 服务器通过 ping 确认进行响应，表示服务器也处于活动状态。如果客户端在指定时间内没有收到服务器的确认，那么客户端会连接到集合体中的另一台服务器，而且客户端会话会被透明地转移到新的 ZooKeeper 服务器。 图 1 描述了 ZooKeeper 的客户端-服务器架构。 图1.ZooKeeper 的客户端-服务器架构 ZooKeeper 有一个类似于文件系统的数据模型，由 znodes 组成。可以将 znodes（ZooKeeper 数据节点）视为类似 UNIX 的传统系统中的文件，但它们可以有子节点。另一种方式是将它们视为目录，它们可以有与其相关的数据。每个这些目录都被称为一个 znode。图 2 显示的图代表与两个城市中的运动队相同的层次结构。 图 2. 该图表示了两个城市中的运动队的层次结构 图2.两个城市中的运动队的层次结构 znode 层次结构被存储在每个 ZooKeeper 服务器的内存中。这实现了对来自客户端的读取操作的可扩展的快速响应。每个 ZooKeeper 服务器还在磁盘上维护了一个事务日志，记录所有的写入请求。因为 ZooKeeper 服务器在返回一个成功的响应之前必须将事务同步到磁盘，所以事务日志也是 ZooKeeper 中对性能最重要的组成部分。可以存储在 znode 中的数据的默认最大大小为 1 MB。因此，即使 ZooKeeper 的层次结构看起来与文件系统相似，也不应该将它用作一个通用的文件系统。相反，应该只将它用作少量数据的存储机制，以便为分布式应用程序提供可靠性、可用性和协调。 当客户端请求读取特定 znode 的内容时，读取操作是在客户端所连接的服务器上进行的。因此，由于只涉及集合体中的一个服务器，所以读取是快速和可扩展的。然而，为了成功完成写入操作，要求 ZooKeeper 集合体的严格意义上的多数节点都是可用的。在启动 ZooKeeper 服务时，集合体中的某个节点被选举为领导者。当客户端发出一个写入请求时，所连接的服务器会将请求传递给领导者。此领导者对集合体的所有节点发出相同的写入请求。如果严格意义上的多数节点（也被称为法定数量（quorum））成功响应该写入请求，那么写入请求被视为已成功完成。然后，一个成功的返回代码会返回给发起写入请求的客户端。如果集合体中的可用节点数量未达到法定数量，那么 ZooKeeper 服务将不起作用。 InfoSphere BigInsights Quick Start Edition ZooKeeper 是 InfoSphere BigInsights（IBM 基于 Hadoop 的产品）中的一个组件。Quick Start Edition 是一个免费的、可下载的 InfoSphere BigInsights 版本。使用 Quick Start Edition，您可以尝试使用 ZooKeeper 和 IBM 开发的特性来提高开源 Hadoop 的价值，比如 Big SQL、文本分析和 BigSheets。引导式学习可让您的体验尽可能地顺畅，包括按部就班、自订进度的教程和视频，可帮助您开始让 Hadoop 为您所用。没有时间或数据限制，您可以自行安排时间，在大量数据上试验。请 观看视频、学习教程（PDF） 和 立刻下载 BigInsights Quick Start Edition。 法定数量是通过严格意义上的多数节点来表示的。在集合体中，可以包含一个节点，但它不是一个高可用和可靠的系统。如果在集合体中有两个节点，那么这两个节点都必须已经启动并让服务正常运行，因为两个节点中的一个并不是严格意义上的多数。如果在集合体中有三个节点，即使其中一个停机了，您仍然可以获得正常运行的服务（三个中的两个是严格意义上的多数）。出于这个原因，ZooKeeper 的集合体中通常包含奇数数量的节点，因为就容错而言，与三个节点相比，四个节点并不占优势，因为只要有两个节点停机，ZooKeeper 服务就会停止。在有五个节点的集群上，需要三个节点停机才会导致 ZooKeeper 服务停止运作。 现在，我们已经清楚地了解到，节点数量应该是奇数，让我们再来思考一下 ZooKeeper 集合体中需要有多少个节点。读取操作始终从连接到客户端的 ZooKeeper 服务器读取数据，所以它们的性能不会随着集合体中的服务器数量额变化而变化。但是，仅在写入法定数量的节点时，写入操作才是成功的。这意味着，随着在集合体中的节点数量的增加，写入性能会下降，因为必须将写入内容写入到更多的服务器中，并在更多服务器之间进行协调。 ZooKeeper 的美妙之处在于，想运行多少服务器完全由您自己决定。如果想运行一台服务器，从 ZooKeeper 的角度来看是没问题的；只是您的系统不再是高度可靠或高度可用的。三个节点的 ZooKeeper 集合体支持在一个节点故障的情况下不丢失服务，这对于大多数用户而言，这可能是没问题的，也可以说是最常见的部署拓扑。不过，为了安全起见，可以在您的集合体中使用五个节点。五个节点的集合体让您可以拿出一台服务器进行维护或滚动升级，并能够在不中断服务的情况下承受第二台服务器的意外故障。 因此，在 ZooKeeper 集合体中，三、五或七是最典型的节点数量。请记住，ZooKeeper 集合体的大小与分布式系统中的节点大小没有什么关系。分布式系统中的节点将是 ZooKeeper 集合体的客户端，每个 ZooKeeper 服务器都能够以可扩展的方式处理大量客户端。例如，HBase（Hadoop 上的分布式数据库）依赖于 ZooKeeper 实现区域服务器的领导者选举和租赁管理。您可以利用一个相对较少（比如说，五个）节点的 ZooKeeper 集合体运行有 50 个节点的大型 HBase 集群。 设置并部署 ZooKeeper 集合体现在让我们设置并部署有三个节点的 ZooKeeper 集合体。在这里，我们将使用撰写本文时的最新版的 ZooKeeper：3.4.5（请参阅 参考资料 获得有关的下载信息）。我们用于此演示的节点被命名为 zkserver1.mybiz.com、zkserver2.mybiz.com 和 zk3server3.mybiz.com。必须在每个节点上遵循下面的步骤来启动 ZooKeeper 服务器： 如果尚未安装 JDK，请下载安装它（参阅 参考资料）。这是必需的，因为 ZooKeeper 服务器在 JVM 上运行。 下载 ZooKeeper 3.4.5. tar.gz tarball 并将它解压缩到适当的位置。 清单 1. 下载 ZooKeeper tarball 并将它解压缩到适当的位置 1`wget``http://www.bizdirusa.com/mirrors/apache/ZooKeeper/stable/zookeeper3.4.5.``tar.gz tar xzvf zookeeper3.4.5.tar.gz` 创建一个目录，用它来存储与 ZooKeeper 服务器有关联的一些状态：mkdir /var/lib/zookeeper。您可能需要将这个目录创建为根目录，并在以后将这个目录的所有者更改为您希望运行 ZooKeeper 服务器的用户。 设置配置。创建或编辑 zookeeper3.4.5/conf/zoo.cfg 文件，使其与 清单 2 相似。 清单 2. 设置配置 1`tickTime=2000``dataDir=/var/lib/zookeeper clientPort=2181``initLimit=5 syncLimit=2``server.1=zkserver1.mybiz.com:2888:3888``server.2=zkserver2.mybiz.com:2888:3888``server.3=zkserver3.mybiz.com:2888:3888` ​ 值得重点注意的一点是，所有三个机器都应该打开端口 2181、2888 和 3888。在本例中，端口 2181 由 ZooKeeper 客户端使用，用于连接到 ZooKeeper 服务器；端口 2888 由对等 ZooKeeper 服务器使用，用于互相通信；而端口 3888 用于领导者选举。您可以选择自己喜欢的任何端口。通常建议在所有 ZooKeeper 服务器上使用相同的端口。 创建一个 /var/lib/zookeeper/myid 文件。此文件的内容将只包含 zkserver1.mybiz.com 上的数字 1、zkserver2.mybiz.com 上的数字 2 和 zkserver3.mybiz.com 上的数字 3。清单 3 显示了来自 zkserver1.mybiz.com 的此文件的 cat 输出。 清单 3. cat 输出 1`mark@zkserver1.mybiz.com:~# cat``/var/lib/zookeeper/myid 1` ​ 现在，您已经做好了在每台机器上启动 ZooKeeper 服务器的准备。 清单 4. 启动 ZooKeeper 服务器 1`zookeeper3.4.5/ bin/zkServer.sh``start` ​ 现在，您可以从其中一台正在运行 ZooKeeper 服务器的机器上启动一个 CLI 客户端。 清单 5. 启动 CLI 客户端 1`zookeeper3.4.5/ bin/zkCli.sh server``zkserver1.mybiz.com:2181,zkserver2.mybiz.com:2181,zkserver3.mybiz.com:2181` ​ 客户端提供一个服务器列表，可以任意选中一个进行连接。如果在连接过程中失去与该服务器的连接，则会选中列表中的另一台服务器，而且客户端会话也会转移到该服务器。一旦启动了客户端，您就可以创建、编辑和删除 znode。让我们在/mynode创建一个znode，使用 helloworld 作为关联的数据。 清单 6. 在 /mynode 上创建一个 znode 1`[zk:127.0.0.1:2181(CONNECTED) 2] create /mynode``helloworld Created /mynode` ​ ​ 现在，让我们在/mynode验证和检索数据。 清单 7. 在 /mynode 验证和检索数据 1`[zk:127.0.0.1:2181(CONNECTED) 6] get /mynode``helloworld cZxid = 0x200000005 ctime = Sat Jul 20``19:53:52 PDT 2013 mZxid = 0x200000005 mtime = Sat``Jul 20 19:53:52 PDT 2013 pZxid = 0x200000005``cversion = 0 dataVersion = 0 aclVersion = 0``ephemeralOwner = 0x0 dataLength = 11 numChildren =``0` ​ 您会发现，在获取一个 znode 数据时，客户端也返回了一些与 znode 有关的元数据。此元数据中的一些重要字段包括，与创建和最后修改 znode 的时间有关的阶段时间戳（ctime和mtime）、每次修改数据都会更改的数据版本（ dataVersion）、数据长度（dataLength）、这个 znode 的子节点的数量（numChildren）。我们现在可以删除 znode。 清单 8. 删除 znode 1`[zk:127.0.0.1:2181(CONNECTED) 7]``rmr /mynode` ​ 让我们在/mysecondnode创建另一个 znode。 清单 9. 创建另一个 znode 1`[zk:127.0.0.1:2181(CONNECTED) 10] create``/mysecondnode hello Created /mysecondnode` ​ 现在，让我们在/mysecondnode验证和检索数据。这一次，我们在最后提供了一个可选参数1。此参数为 /mysecondnode上的数据设置了一个一次性的触发器（名称为watch）。如果另一个客户端在/mysecondnode 上修改数据，该客户端将会获得一个异步通知。请注意，该通知只发送一次，除非 watch 被重新设置，否则不会因数据发生改变而再次发送通知。 清单 10. 在 /mysecondnode 上验证和检索数据 1`[zk:127.0.0.1:2181(CONNECTED) 12] get``/mysecondnode 1 hello cZxid = 0x200000007 ctime =``Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000007``mtime = Sat Jul 20 19:58:27 PDT 2013 pZxid =``0x200000007 cversion = 0 dataVersion = 0``aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5``numChildren = 0` ​ 现在，从不同的客户端（比如，从不同的机器）更改与/mysecondnode有关联的数据的值。 清单 11. 更改与 /mysecondnode 有关联的数据的值 1`[zk: localhost:2181(CONNECTED)``1] set /mysecondnode hello2 cZxid = 0x200000007``ctime = Sat Jul 20 19:58:27 PDT 2013 mZxid =``0x200000009 mtime = Sat Jul 20 20:02:37 PDT 2013``pZxid = 0x200000007 cversion = 0 dataVersion = 1``aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6``numChildren = 0` 您会发现，在第一个客户端上获得了一个 watch 通知。 清单 12. 在第一个客户端上获得了一个 watch 通知 1`[zk:127.0.0.1:2181(CONNECTED) 13] WATCHER::``WatchedEvent state:SyncConnected``type:NodeDataChanged path:/mysecondnode` 继续下去，因为 znode 形成了一个分层命名空间，所以您还可以创建子节点。 清单 13. 创建子节点 1`[zk:``localhost:2181(CONNECTED) 2] create /mysecondnode/``subnode 123 Created /mysecondnode/ subnode` 您可以获得关于某个 znode 的其他统计元数据。 清单 14. 获得关于某个 znode 的其他统计元数据 1`[zk:127.0.0.1:2181(CONNECTED)``14] stat /mysecondnode cZxid = 0x200000007 ctime =``Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000009``mtime = Sat Jul 20 20:02:37 PDT 2013 pZxid =``0x20000000a cversion = 1 dataVersion = 1``aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6``numChildren = 1` ​ 在上面的示例中，我们使用了 ZooKeeper 的 CLI 客户端与 ZooKeeper 服务器进行交互。ZooKeeper 提供了 Java™、C、Python 和其他绑定。您可以通过这些绑定调用客户端 API，将 Java、C 或 Python 应用程序转换为 ZooKeeper 客户端。 ZooKeeper 的应用程序由于 ZooKeeper 在分布式系统中提供了一些多功能的用例，ZooKeeper 有一组不同的实用应用程序。我们将在这里列出部分这些应用程序。这些应用程序大多取自 Apache ZooKeeper 维基，那里还提供了一个更完整的最新列表。请参阅 参考资料，获得这些技术的链接： Apache Hadoop 依靠 ZooKeeper 来实现 Hadoop HDFS NameNode 的自动故障转移，以及 YARN ResourceManager 的高可用性。 Apache HBase 是构建于 Hadoop 之上的分布式数据库，它使用 ZooKeeper 来实现区域服务器的主选举（master election）、租赁管理以及区域服务器之间的其他通信。 Apache Accumulo 是构建于 Apache ZooKeeper（和 Apache Hadoop）之上的另一个排序分布式键/值存储。 Apache Solr 使用 ZooKeeper 实现领导者选举和集中式配置。 Apache Mesos 是一个集群管理器，提供了分布式应用程序之间高效的资源隔离和共享。Mesos 使用 ZooKeeper 实现了容错的、复制的主选举。 Neo4j 是一个分布式图形数据库，它使用 ZooKeeper 写入主选择和读取从协调（read slave coordination）。 Cloudera Search 使用 ZooKeeper（通过 Apache Solr）集成了搜索功能与 Apache Hadoop，以实现集中式配置管理。 结束语实现您自己的协议来协调分布式系统，这可能是一个令人感到沮丧的费时的过程。这正是 ZooKeeper 发挥其作用的地方。ZooKeeper 是一个稳定的、简单的、高性能的协调服务，为您提供编写正确的分布式应用程序所需的工具，而无需担心竞争条件、死锁和不一致。在下一次编写分布式应用程序时，您就可以利用 ZooKeeper 支持所有协调需求。 相关知识链接 了解有关在 IBM 的 InfoSphere BigInsights 产品中 使用 ZooKeeper 的更多信息。 遵循来自 ZooKeeper 维基的 Programming ZooKeeper 教程。 图 1 摘自 Apache.org ZooKeeper 维基。 请务必阅读 “构建服务器集群感知的 Java 应用程序”。 从 Wikipedia 了解 生产者-消费者问题。 从 Wikipedia 了解 障碍。 阅读 Hive 简介。 了解 Hive DDL 和 Hive Standard UDF 与 UDAF。 阅读 Writing and compiling Java programs。 查看 Big Data Glossary，作者 Pete Warden，O’Reilly Media，ISBN:1449314597，2011 年。 访问 developerWorks 开源专区，查找广泛的 how-to 信息、工具和项目更新，帮助您用开源技术进行开发，并与 IBM 产品结合使用它们。 您可以下载 ZooKeeper release tarball。 获取 Java 7 JDK。 Apache Hadoop 依靠 ZooKeeper 实现了 Hadoop HDFS NameNode 的自动故障转移以及 YARN ResourceManager 的高可用性。 Apache HBase 是构建于 Hadoop 之上的分布式数据库，它使用 ZooKeeper 实现区域服务器的主选举、租赁管理和区域服务器之间的其他通信。 Apache Accumulo 是构建于 Apache ZooKeeper（和 Apache Hadoop）之上的另一个排序分布式键/值存储。 Apache Solr 使用 ZooKeeper 实现领导者选举和集中式配置。 Apache Mesos 是一个集群管理器，提供了分布式应用程序之间高效的资源隔离和共享。Mesos 使用 ZooKeeper 实现了容错的复制的主选举。 Neo4j 是一个分布式图形数据库，它使用 ZooKeeper 写入主选择和读取从协调。 Cloudera Search 使用 ZooKeeper（通过 Apache Solr）集成搜索功能与 Apache Hadoop，以实现集中式配置管理。 在 Big Data University 参加这个关于 Hadoop Reporting and Analysis 的课程（要求登录）。学习如何使用相关的 Hadoop 技术（如 HBase、Hive 等）构建自己的 Hadoop /大数据报告，并获取有关如何选择各种报告技术的指导：Direct Batch Reports、Live Exploration 和 Indirect Batch Analysis。 通过 Big Data University 的这个免费 Hadoop Fundamentals 课程学习 Hadoop 的基本知识（要求登录）。了解 Hadoop 架构、HDFS、MapReduce、Pig、Hive、JAQL、Flume 和其他许多相关的 Hadoop 技术。使用以下方法，通过动手实验室在 Hadoop 集群上练习：在云上，使用所提供的 VMware 镜像，或在本地安装。 通过 Big Data University 的这个 免费课程，在 IBM SmartCloud Enterprise 上创建自己的 Hadoop 集群（要求登录）。 查找帮助您开始使用 InfoSphere BigInsights 的资源，InfoSphere BigInsights 是 IBM 的基于 Hadoop 的产品，通过 Big SQL、文本分析和 BigSheets 等特性可以提高开源 Hadoop 的价值。 下载 InfoSphere BigInsights Quick Start Edition，以本机软件安装或 VMware 镜像的形式提供它。 下载 InfoSphere Streams，以本机软件安装或 VMware 镜像的形式提供。 在 IBM SmartCloud Enterprise 上使用 InfoSphere Streams。 在 developerWorks Information Management 专区，了解关于信息管理的更多信息，获取技术文档、how-to 文章、培训、下载、产品信息以及其他资源。 在 developerWorks 的大数据内容专区 了解关于大数据的更多信息。查找技术文档、how-to 文章、教育、下载、产品信息，等等。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://lvshen9.gitee.io/tags/Zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"http://lvshen9.gitee.io/tags/分布式/"}]},{"title":"Servlet性能优化","slug":"Servlet性能优化","date":"2017-09-16T10:21:04.000Z","updated":"2017-09-16T10:23:44.989Z","comments":true,"path":"2017/09/16/Servlet性能优化/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/16/Servlet性能优化/","excerpt":"你的J2EE应用是不是运行的很慢？它们能不能承受住不断上升的访问量？本文讲述了开发高性能、高弹性的JSP页面和Servlet的性能优化技术。其意思是建立尽可能快的并能适应数量增长的用户及其请求。在本文中，我将带领你学习已经实践和得到证实的性能调整技术，它将大大地提高你的servlet和jsp页面的性能，进而提升J2EE的性能。这些技术的部分用于开发阶段，例如，设计和编码阶段。另一部分技术则与配置相关。 技术1：在HttpServlet init()方法中缓存数据服务器会在创建servlet实例之后和servlet处理任何请求之前调用servlet的init()方法。该方法在servlet的生命周期中仅调用一次。为了提高性能，在init()中缓存静态数据或完成要在初始化期间完成的代价昂贵的操作。例如，一个最佳实践是使用实现了javax.sql.DataSource接口的JDBC连接池。DataSource从JNDI树中获得。每调用一次SQL就要使用JNDI查找DataSource是非常昂贵的工作，而且严重影响了应用的性能。Servlet的init()方法可以用于获取DataSource并缓存它以便之后的重用：","text":"你的J2EE应用是不是运行的很慢？它们能不能承受住不断上升的访问量？本文讲述了开发高性能、高弹性的JSP页面和Servlet的性能优化技术。其意思是建立尽可能快的并能适应数量增长的用户及其请求。在本文中，我将带领你学习已经实践和得到证实的性能调整技术，它将大大地提高你的servlet和jsp页面的性能，进而提升J2EE的性能。这些技术的部分用于开发阶段，例如，设计和编码阶段。另一部分技术则与配置相关。 技术1：在HttpServlet init()方法中缓存数据服务器会在创建servlet实例之后和servlet处理任何请求之前调用servlet的init()方法。该方法在servlet的生命周期中仅调用一次。为了提高性能，在init()中缓存静态数据或完成要在初始化期间完成的代价昂贵的操作。例如，一个最佳实践是使用实现了javax.sql.DataSource接口的JDBC连接池。DataSource从JNDI树中获得。每调用一次SQL就要使用JNDI查找DataSource是非常昂贵的工作，而且严重影响了应用的性能。Servlet的init()方法可以用于获取DataSource并缓存它以便之后的重用： 1234567891011121314151617181920public class ControllerServlet extends HttpServlet&#123; private javax.sql.DataSource testDS=null; public void init(Servlet Config config) throws Servlet Exception&#123; super.init(config); Context ctx=null; try&#123; ctx = new InitialContext(); testDS = (javax.sql.DataSource)ctx.lookup(\"jdbc/testDS\"); &#125;catch(NamingException ne)&#123; ne.printStackTrace(); &#125;catch(Exceptione)&#123; e.printStackTrace(); &#125; &#125; public javax.sql.DataSource getTestDS()&#123; return testDS; &#125; ... ...&#125; 技术2：禁用servlet和Jsp的自动装载功能当每次修改了Servlet/JSP之后，你将不得不重新启动服务器。由于自动装载功能减少开发时间，该功能被认为在开发阶段是非常有用的。但是，它在运行阶段是非常昂贵的；servlet/JSP由于不必要的装载，增加类装载器的负担而造成很差的性能。同样，这会使你的应用由于已被某种类装载器装载的类不能和当前类装载器装载的类不能相互协作而出现奇怪的冲突现象。因此，在运行环境中为了得到更好的性能，关闭servlet/JSP的自动装载功能。 技术3：控制HttpSession许多应用需要一系列客户端的请求，因此他们能互相相关联。由于HTTP协议是无状态的，所以基于Web的应用需要负责维护这样一个叫做session的状态。为了支持必须维护状态的应用，Java servlet技术提供了管理session和允许多种机制实现session的API。HttpSession对象扮演了session，但是使用它需要成本。无论何时HttpSession被使用和重写，它都由servlet读取。你可以通过使用下面的技术来提高性能：在JSP页面中不要创建默认的HttpSession:默认情况下，JSP页面创建HttpSession。如果你在JSP页面中不用HttpSession，为了节省性能开销，使用下边的页面指令可以避免自动创建HttpSession对象： 1＜%@pagesession=\"false\"%＞ 1) 不要将大的对象图存储在HttpSession中：如果你将数据当作一个大的对象图存储在HttpSession中，应用服务器每次将不得不处理整个HttpSession对象。这将迫使Java序列化和增加计算开销。由于序列化的开销，随着存储在HttpSession对象中数据对象的增大，系统的吞吐量将会下降。2) 用完后释放HttpSession：当不再使用HttpSession时，使用HttpSession.invalidate()方法使sesion失效。3) 设置超时值：一个servlet引擎有一个默认的超时值。如果你不删除session或者一直把session用到它超时的时候，servlet引擎将把session从内存中删除。由于在内存和垃圾收集上的开销，session的超时值越大，它对系统弹性和性能的影响也越大。试着将session的超时值设置的尽可能低。 技术4：使用gzip压缩压缩是删除冗余信息的作法，用尽可能小的空间描述你的信息。使用gzip（GNUzip）压缩文档能有效地减少下载HTML文件的时间。你的信息量越小，它们被送出的速度越快。因此，如果你压缩了由你web应用产生的内容，它到达用户并显示在用户屏幕上的速度就越快。不是任何浏览器都支持gzip压缩的，但检查一个浏览器是否支持它并发送gzip压缩内容到浏览器是很容易的事情。下边的代码段说明了如何发送压缩的内容。 1234567891011121314151617181920public void doGet(HttpServletRequest request,HttpServletResponse response)throws IOException,ServletException&#123; OutputStream out = null; //Check the Accepting-Encoding header from the HTTPrequest. //If the header includes gzip,choose GZIP. //If the header includes compress,choose ZIP. //Otherwise choose no compression. String encoding = request.getHeader(\"Accept-Encoding\"); if(encoding != null&amp;&amp;encoding.indexOf(\"gzip\") != -1)&#123; response.setHeader(\"Content-Encoding\",\"gzip\"); out = new GZIPOutputStream(response.getOutputStream()); &#125;else if(encoding!=null&amp;&amp;encoding.indexOf(\"compress\")!=-1)&#123; response.setHeader(\"Content-Encoding\",\"compress\"); out=newZIPOutputStream(response.getOutputStream()); &#125;else&#123; out=response.getOutputStream(); &#125; ... ...&#125; 技术5：不要使用Single Thread ModelSingle Thread Model保证servlet一次仅处理一个请求。如果一个servlet实现了这个接口，servlet引擎将为每个新的请求创建一个单独的servlet实例，这将引起大量的系统开销。如果你需要解决线程安全问题，请使用其他的办法替代这个接口。Single Thread Model在Servlet2.4中是不再提倡使用。 技术6：使用线程池servlet引擎为每个请求创建一个单独的线程，将该线程指派给service()方法，然后在service()方法执行完后删除该线程。默认情况下，servlet引擎可能为每个请求创建一个新的线程。由于创建和删除线程的开销是很昂贵的，于是这种默认行为降低了系统的性能。我们可以使用线程池来提高性能。根据预期的并发用户数量，配置一个线程池，设置好线程池里的线程数量的最小和最大值以及增长的最小和最大值。起初，servlet引擎创建一个线程数与配置中的最小线程数量相等的线程池。然后servlet引擎把池中的一个线程指派给一个请求而不是每次都创建新的线程，完成操作之后，servlet引擎把线程放回到线程池中。使用线程池，性能可以显著地提高。如果需要，根据线程的最大数和增长数，可以创建更多的线程。 技术7：选择正确的包括机制在JSP页面中，有两中方式可以包括文件：包括指令(＜%@includefile=&quot;test.jsp&quot;%＞)和包括动作(＜jsp:includepage=&quot;test.jsp&quot;flush=&quot;true&quot;/＞)。包括指令在编译阶段包括一个指定文件的内容；例如，当一个页面编译成一个servlet时。包括动作是指在请求阶段包括文件内容；例如，当一个用户请求一个页面时。包括指令要比包括动作快些。因此除非被包括的文件经常变动，否则使用包括指令将会获得更好的性能。 技术8：在useBean动作中使用合适的范围使用JSP页面最强大方式之一是和JavaBean组件协同工作。JavaBean使用＜jsp:useBean＞标签可以嵌入到JSP页面中。语法如下： 123＜jsp:useBeanid=\"name\"scope=\"page|request|session|application\"class=\"package.className\"type=\"typeName\"＞＜/jsp:useBean＞ scope属性说明了bean的可见范围。scope属性的默认值是page。你应该根据你应用的需求选择正确的范围，否则它将影响应用的性能。例如，如果你需要一个专用于某些请求的对象，但是你把范围设置成了session，那么那个对象将在请求结束之后还保留在内存中。它将一直保留在内存中除非你明确地把它从内存中删除、使session无效或session超时。如果你没有选择正确的范围属性，由于内存和垃圾收集的开销将会影响性能。因此为对象设置合适的范围并在用完它们之后立即删除。 杂项技术1) 避免字符串连接：由于String对象是不可变对象，使用“＋”操作符将会导致创建大量的零时对象。你使用的“＋”越多，产出的零时对象就越多，这将影响性能。当你需要连接字符串时，使用StringBuffer替代“＋”操作。2) 避免使用System.out.println：System.out.println同步处理磁盘输入/输出，这大大地降低了系统吞吐量。尽可能地避免使用System.out.println。尽管有很多成熟的调试工具可以用，但有时System.out.println为了跟踪、或调试的情况下依然很有用。你应该配置System.out.println仅在错误和调试阶段打开它。使用finalBoolean型的变量，当配置成false时，在编译阶段完成优化检查和执行跟踪输出。3) ServletOutputStream与PrintWriter比较：由于字符输出流和把数据编码成字节，使用PrintWriter引入了小的性能开销。因此，PrintWriter应该用在所有的字符集都正确地转换做完之后。另一方面，当你知道你的servlet仅返回二进制数据，使用ServletOutputStream，因为servlet容器不编码二进制数据，这样你就能消除字符集转换开销。总结本文的目的是展示给你一些实践的和已经证实的用于提高servlet和JSP性能的性能优化技术，这些将提高你的J2EE应用的整体性能。下一步应该观察其他相关技术的性能调整，如EJB、JMS和JDBC等。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Servlet","slug":"Servlet","permalink":"http://lvshen9.gitee.io/tags/Servlet/"},{"name":"J2EE","slug":"J2EE","permalink":"http://lvshen9.gitee.io/tags/J2EE/"}]},{"title":"Redis对象类型底层简介","slug":"Redis对象类型底层简介","date":"2017-09-15T12:50:15.000Z","updated":"2017-09-15T14:22:51.982Z","comments":true,"path":"2017/09/15/Redis对象类型底层简介/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/15/Redis对象类型底层简介/","excerpt":"Redis对象类型Redis是一种key/value型数据库，其中，每个key和value都是使用对象表示的。比如，我们执行以下代码： 1redis&gt;SET message \"hello redis\" 其中的key是message，是一个包含了字符串”message”的对象。而value是一个包含了”hello redis”的对象。 redis共有五种对象的类型，分别是： 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 Redis中的一个对象的结构体表示如下：","text":"Redis对象类型Redis是一种key/value型数据库，其中，每个key和value都是使用对象表示的。比如，我们执行以下代码： 1redis&gt;SET message \"hello redis\" 其中的key是message，是一个包含了字符串”message”的对象。而value是一个包含了”hello redis”的对象。 redis共有五种对象的类型，分别是： 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 Redis中的一个对象的结构体表示如下： 123456789101112131415161718/* Redis 对象 */ typedef struct redisObject &#123; // 类型 unsigned type:4; // 不使用(对齐位) unsigned notused:2; // 编码方式 unsigned encoding:4; // LRU 时间（相对于 server.lruclock） unsigned lru:22; // 引用计数 int refcount; // 指向对象的值 void *ptr; &#125; robj; type表示了该对象的对象类型，即上面五个中的一个。但为了提高存储效率与程序执行效率，每种对象的底层数据结构实现都可能不止一种。encoding就表示了对象底层所使用的编码。下面先介绍每种底层数据结构的实现，再介绍每种对象类型都用了什么底层结构并分析他们之间的关系。 Redis对象底层数据结构底层数据结构共有八种，如下表所示： 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long 类型的整数 REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 字符串对象字符串对象的编码可以是int、raw或者embstr。 如果一个字符串的内容可以转换为long，那么该字符串就会被转换成为long类型，对象的ptr就会指向该long，并且对象类型也用int类型表示。 普通的字符串有两种，embstr和raw。embstr应该是Redis 3.0新增的数据结构,在2.8中是没有的。如果字符串对象的长度小于39字节，就用embstr对象。否则用传统的raw对象。可以从下面这段代码看出： 1234567#define REDIS_ENCODING_EMBSTR_SIZE_LIMIT 39 robj *createStringObject(char *ptr, size_t len) &#123; if (len &lt;= REDIS_ENCODING_EMBSTR_SIZE_LIMIT) return createEmbeddedStringObject(ptr,len); else return createRawStringObject(ptr,len); &#125; embstr的好处有如下几点： embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为objet分配对象，embstr省去了第一次）。 相对地，释放内存的次数也由两次变为一次。 embstr的objet和sds放在一起，更好地利用缓存带来的优势。 需要注意的是，redis并未提供任何修改embstr的方式，即embstr是只读的形式。对embstr的修改实际上是先转换为raw再进行修改。 raw和embstr的区别可以用下面两幅图所示： 列表对象列表对象的编码可以是ziplist或者linkedlist。 ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储。但当数据量过大时就ziplist就不是那么好用了。因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。如下图所示，对象结构中ptr所指向的就是一个ziplist。整个ziplist只需要malloc一次，它们在内存中是一块连续的区域。 img linkedlist是一种双向链表。它的结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息。当每增加一个node的时候，就需要重新malloc一块内存。 img 哈希对象哈希对象的底层实现可以是ziplist或者hashtable。 ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储的。当对象数目不多且内容不大时，这种方式效率是很高的。 hashtable的是由dict这个结构来实现的 1234567typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ int iterators; /* number of iterators currently running */ &#125; dict; dict是一个字典，其中的指针dicht ht[2] 指向了两个哈希表 1234567891011typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; &#125; dictht; dicht[0] 是用于真正存放数据，dicht[1]一般在哈希表元素过多进行rehash的时候用于中转数据。 dictht中的table用语真正存放元素了，每个key/value对用一个dictEntry表示，放在dictEntry数组中。 img 集合对象集合对象的编码可以是intset或者hashtable。 intset是一个整数集合，里面存的为某种同一类型的整数，支持如下三种长度的整数： 12345#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t)) intset是一个有序集合，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作。比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配，这时插入的复杂度就为O(N)了。是intset不支持降级操作。 有序集合对象有序集合的编码可能两种，一种是ziplist，另一种是skiplist与dict的结合。 ziplist作为集合和作为哈希对象是一样的，member和score顺序存放。按照score从小到大顺序排列。它的结构不再复述。 skiplist是一种跳跃表，它实现了有序集合中的快速查找，在大多数情况下它的速度都可以和平衡树差不多。但它的实现比较简单，可以作为平衡树的替代品。它的结构比较特殊。下面分别是跳跃表skiplist和它内部的节点skiplistNode的结构体： 123456789101112131415161718192021222324252627282930/* 跳跃表 */ typedef struct zskiplist &#123; // 头节点，尾节点 struct zskiplistNode *header, *tail; // 节点数量 unsigned long length; // 目前表内节点的最大层数 int level; &#125; zskiplist; /* ZSETs use a specialized version of Skiplists */ /* 跳跃表节点 */ typedef struct zskiplistNode &#123; // member 对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 这个层跨越的节点数量 unsigned int span; &#125; level[]; &#125; zskiplistNode; head和tail分别指向头节点和尾节点，然后每个skiplistNode里面的结构又是分层的(即level数组) 用图表示，大概是下面这个样子： img 每一列都代表一个节点，保存了member和score，按score从小到大排序。每个节点有不同的层数，这个层数是在生成节点的时候随机生成的数值。每一层都是一个指向后面某个节点的指针。这种结构使得跳跃表可以跨越很多节点来快速访问。 前面说到了，有序集合ZSET是有跳跃表和hashtable共同形成的。 123456typedef struct zset &#123; // 字典 dict *dict; // 跳跃表 zskiplist *zsl; &#125; zset; 为什么要用这种结构呢。试想如果单一用hashtable，那可以快速查找、添加和删除元素，但没法保持集合的有序性。如果单一用skiplist，有序性可以得到保障，但查找的速度太慢O（logN）。 结尾简单介绍了Redis的五种对象类型和它们的底层实现。事实上，Redis的高效性和灵活性正是得益于对于同一个对象类型采取不同的底层结构，并在必要的时候对二者进行转换；以及各种底层结构对内存的合理利用。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://lvshen9.gitee.io/tags/Redis/"},{"name":"底层Redis","slug":"底层Redis","permalink":"http://lvshen9.gitee.io/tags/底层Redis/"}]},{"title":"深入学习ConcurrentHashMap","slug":"深入学习ConcurrentHashMap","date":"2017-09-14T10:22:39.000Z","updated":"2017-09-14T11:25:08.756Z","comments":true,"path":"2017/09/14/深入学习ConcurrentHashMap/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/14/深入学习ConcurrentHashMap/","excerpt":"本文作者： JoonWhee 本文链接： http://opiece.me/2017/04/08/study-concurrentHashMap/ 近期深入学习了ConcurrentHashMap，便整理成一篇博文记录一下，请注意：此博文针对的是JDK1.6，因此如果你看到的源码跟我文中的不同，则可能是由于版本不一样。 ConcurrentHashMap的锁分段技术HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程必须竞争同一把锁。如果容器里有多把锁，每一把锁用于锁容器的其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 ConcurrentHashMap的结构我们通过ConcurrentHashMap的类图来分析ConcurrentHashMap的结构。","text":"本文作者： JoonWhee 本文链接： http://opiece.me/2017/04/08/study-concurrentHashMap/ 近期深入学习了ConcurrentHashMap，便整理成一篇博文记录一下，请注意：此博文针对的是JDK1.6，因此如果你看到的源码跟我文中的不同，则可能是由于版本不一样。 ConcurrentHashMap的锁分段技术HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程必须竞争同一把锁。如果容器里有多把锁，每一把锁用于锁容器的其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 ConcurrentHashMap的结构我们通过ConcurrentHashMap的类图来分析ConcurrentHashMap的结构。 [ img](http://opiece.me/images/article/study-concurrentHashMap-1.png) ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构，一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。[ img](http://opiece.me/images/article/study-concurrentHashMap-2.png) ConcurrentHashMap方法源码解读请注意，如果一个方法中我贴了几段代码，那么一般是：第一段代码为方法的入口，其他的为被入口方法调用过的方法。 初始化方法12345678910111213141516171819202122232425262728293031public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; segmentShift = 32 - sshift; segmentMask = ssize - 1; this.segments = Segment.newArray(ssize); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = 1; while (cap &lt; c) cap &lt;&lt;= 1; for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);&#125; 代码中的第一个while循环是用来计算segments数组的大小ssize（必须为2的N次方）。segmentShift和segmentMask是用来定位当前元素在哪个segment，前者用于移位，后者用于进行位与运算。第二个while循环是用来计算每个segment中HashEntry数组的大小cap（必须为2的N次方），最后对segments数组进行初始化。 1234Segment(int initialCapacity, float lf) &#123; loadFactor = lf; setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity));&#125; 1234void setTable(HashEntry&lt;K,V&gt;[] newTable) &#123; threshold = (int)(newTable.length * loadFactor); table = newTable;&#125; 123static final &lt;K,V&gt; HashEntry&lt;K,V&gt;[] newArray(int i) &#123; return new HashEntry[i];&#125; 对segments数组进行初始化的同时，也对segment类里面的HashEntry进行初始化，并给loadFactor和threshold赋值。 get方法1234public V get(Object key) &#123; int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash);&#125; 根据key的hashcode重新计算hash值（主要是为了减少hash冲突），通过segmentFor方法定位到具体的哪个segment，然后调用segment的get方法。 123final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; segmentFor方法是用来定位到具体的segment的，主要是通过使用hash值的高位与掩码进行位运算，segmentShift和segmentMask是通过上文初始化方法计算而来。 123456789101112131415V get(Object key, int hash) &#123; if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if (v != null) return v; return readValueUnderLock(e); // recheck &#125; e = e.next; &#125; &#125; return null;&#125; 1234HashEntry&lt;K,V&gt; getFirst(int hash) &#123; HashEntry&lt;K,V&gt;[] tab = table; return tab[hash &amp; (tab.length - 1)];&#125; 根据hash值跟数组长度-1进行位与运算，定位到具体的HashEntry（getFirst方法），遍历该HashEntry链表，找到链表中某个元素的hash值与传入的hash值相同并且使用equals方法比较key相同的元素，如果该元素的value不为空，返回value值；如果为空，则尝试在加锁的情况下再读一次。get操作的高效之处在于整个get过程不需要加锁，除非读到的值是空的才会加锁重读，我们知道HashTable容器的get方法是需要加锁的，那么ConcurrentHashMap的get操作是如何做到不加锁的呢？原因是它的get方法里将要使用的共享变量都定义成volatile，如用于统计当前Segement大小的count字段和用于存储值的HashEntry的value，定义成volatile的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在get操作里只需要读不需要写共享变量count和value，所以可以不用加锁。之所以不会读到过期的值，是根据Java内存模型的happen before原则，对volatile字段的写入操作先于读操作，即使两个线程同时修改和获取volatile变量，get操作也能拿到最新的值，这是用volatile替换锁的经典应用场景。 123456789101112131415/** * Reads value field of an entry under lock. Called if value * field ever appears to be null. This is possible only if a * compiler happens to reorder a HashEntry initialization with * its table assignment, which is legal under memory model * but is not known to ever occur. */V readValueUnderLock(HashEntry&lt;K,V&gt; e) &#123; lock(); try &#123; return e.value; &#125; finally &#123; unlock(); &#125;&#125; readValueUnderLock：在有锁的状态下再读一次。这似乎有些费解，理论上结点的值不可能为空，这是因为put的时候就进行了判断，如果为空就要抛NullPointerException。空值的唯一源头就是HashEntry中的默认值，因为HashEntry中的value不是final的，非同步读取有可能读取到空值。仔细看下put操作的语句：tab[index] = new HashEntry(key, hash, first, value)，在这条语句中，HashEntry构造函数中对value的赋值以及对tab[index]的赋值可能被重新排序（方法上面的一大段注释有提到，英语好的可以直接读注释），这就可能导致结点的值为空。这里当value为空时，可能是一个线程正在改变节点，而之前的get操作都未进行锁定，根据bernstein条件，读后写或写后读都会引起数据的不一致，所以这里要对这个e重新上锁再读一遍，以保证得到的是正确值。 put方法123456public V put(K key, V value) &#123; if (value == null) throw new NullPointerException(); int hash = hash(key.hashCode()); return segmentFor(hash).put(key, hash, value, false);&#125; 根据key的hashcode重新计算hash值（跟get方法一样），通过segmentFor方法定位到具体的哪个segment，然后调用segment的put方法。 123456789101112131415161718192021222324252627282930V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; lock(); try &#123; int c = count; if (c++ &gt; threshold) // ensure capacity rehash(); HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; if (e != null) &#123; oldValue = e.value; if (!onlyIfAbsent) e.value = value; &#125; else &#123; oldValue = null; ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; // write-volatile &#125; return oldValue; &#125; finally &#123; unlock(); &#125;&#125; 加锁进行以下操作：判断是否需要扩容，如果需要则调用rehash方法（下面有介绍）。根据hash值跟数组长度-1进行位与运算，定位到具体的HashEntry，遍历该HashEntry，根据传入的的key，使用equals方法找到需要的元素。如果能找到，则将该元素的value值覆盖为传入的value，否则将传入的key、value、hash值作为一个新元素放在该HashEntry的头部，最后进行解锁。入参中的onlyIfAbsent为true时，表示如果该key已经存在value值，则不会覆盖原value值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void rehash() &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity &gt;= MAXIMUM_CAPACITY) return; /* * Reclassify nodes in each list to new Map. Because we are * using power-of-two expansion, the elements from each bin * must either stay at same index, or move with a power of two * offset. We eliminate unnecessary node creation by catching * cases where old nodes can be reused because their next * fields won't change. Statistically, at the default * threshold, only about one-sixth of them need cloning when * a table doubles. The nodes they replace will be garbage * collectable as soon as they are no longer referenced by any * reader thread that may be in the midst of traversing table * right now. */ HashEntry&lt;K,V&gt;[] newTable = HashEntry.newArray(oldCapacity&lt;&lt;1); //新表扩容为原来大小的2倍 threshold = (int)(newTable.length * loadFactor); //重新计算阀值 int sizeMask = newTable.length - 1; //新表的掩码值还是为表长度-1 for (int i = 0; i &lt; oldCapacity ; i++) &#123; // We need to guarantee that any existing reads of old Map can // proceed. So we cannot yet null out each bin. HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; //元素e的下一个元素 int idx = e.hash &amp; sizeMask; //计算元素e在新表中的索引位位置 // Single node on list if (next == null) //如果当前位置只有一个元素，则直接移动到新表的对应位置 newTable[idx] = e; else &#123; // Reuse trailing consecutive sequence at same slot HashEntry&lt;K,V&gt; lastRun = e; //lastRun：最后一个需要处理的元素，初始值为元素e int lastIdx = idx; //lastIdx：最后一个需要处理的元素的索引位置，初始值为元素e在新表中的索引值 for (HashEntry&lt;K,V&gt; last = next; //遍历该链表，找到最后一个需要处理的元素 last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; //如果当前元素的索引位置跟lastIdx不一致，则将lastIdx和lastRun替换成当前元素的相应值 lastIdx = k; lastRun = last; &#125; &#125; newTable[lastIdx] = lastRun; //将最后一个需要处理的元素放到新表中 // Clone all remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123;//遍历处理lastRun之前的所有元素 int k = p.hash &amp; sizeMask; //计算当前遍历元素p在新表的索引k HashEntry&lt;K,V&gt; n = newTable[k]; //取到新表中索引位置k的链表头元素赋值给n newTable[k] = new HashEntry&lt;K,V&gt;(p.key, p.hash, n, p.value); //将当前遍历元素p复制到新表的索引位置k的链表头部，next属性指向新表该索引位置原来的链表头n &#125; &#125; &#125; &#125; table = newTable; //将新表赋值给table&#125; lastRun：最后一个需要处理的元素的意思就是该元素之后的所有元素都跟该元素有相同的索引值(对于新表)，所以只需要将该元素放到新表的对应位置，该元素之后的所有元素也就跟着到了新表的对应位置。相当于直接将该链表的最后一截（可能包含若干个元素）直接一次性移到了新表的某个位置。如果整个循环结束，if (k != lastIdx) 语句没有成立过，就代表当前位置（oldTable[i]）的整个HashEntry在新表中的索引位置是一致的，只需要移动一次即可将整个链表移到新表上。根据rehash方法中的那一大段注释提到的“ Statistically, at the default threshold, only about one-sixth of them need cloning when a table doubles”（据统计，在默认阈值下，当表扩大为原来的两倍时，只有约六分之一的元素需要克隆），可以想象，这个if语句没有成立过的可能性应该是挺大的。 remove方法1234public V remove(Object key) &#123;int hash = hash(key.hashCode()); return segmentFor(hash).remove(key, hash, null);&#125; 根据key的hashcode重新计算hash值（跟get方法一样），通过segmentFor方法定位到具体的哪个segment，然后调用segment的remove方法。 123456789101112131415161718192021222324252627282930313233V remove(Object key, int hash, Object value) &#123; lock(); try &#123; int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; V v = e.value; if (value == null || value.equals(v)) &#123; oldValue = v; // All entries following removed node can stay // in list, but all preceding ones need to be // cloned. ++modCount; HashEntry&lt;K,V&gt; newFirst = e.next; for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; count = c; // write-volatile &#125; &#125; return oldValue; &#125; finally &#123; unlock(); &#125;&#125; 加锁进行以下操作：根据hash值跟数组长度-1进行位运算,定位到具体的HashEntry，遍历该HashEntry，根据传入的的key，使用equals方法找到需要的元素，进行以下操作。 12345HashEntry&lt;K,V&gt; newFirst = e.next;for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value);tab[index] = newFirst; 该段代码是remove方法中的片段，过程比较特殊，拿出来单独讨论。因为HashEntry使用final修饰，这意味着在第一次设置了next域之后便不能再改变它，因此，此处的remove操作是新建一个HashEntry并将它之前的节点全都克隆一次。至于HashEntry为什么要设置为不变性，这跟不变性的访问不需要同步从而节省时间有关。用实际例子看上面这段代码更容易懂：假设1：此时HashEntry为：1 2 3 4 5 6,其中1为链表头,并且1.next = 2，2.next = 3以此类推。假设2：此时e = 4，即根据key匹配到的元素4是即将remove掉的。则上面这段代码有以下流程：HashEntry newFirst = 4.next = 5for( p = 1; p != 4; p++)newFirst = new HashEntry(p.key, p.hash, newFirst, p.value);此循环如下：p = 1：newFirst = new HashEntry(1.key, 1.hash, 5, 1.value)p = 2：newFirst = new HashEntry(2.key, 2.hash, 1, 2.value)p = 3：newFirst = new HashEntry(3.key, 3.hash, 2, 3.value)p = 4：结束循环tab[index] = 3;index为当前链表在HashEntry中的索引位置，所以此时HashEntry为：3 2 1 5 6，被remove的元素之前的元素顺序颠倒了。 remove方法中还有以下这句代码，这句代码在代码中出现非常多次，主要是起什么作用？ 1HashEntry&lt;K,V&gt;[] tab = table; 这句代码是将table赋给一个局部变量tab，这是因为table是 volatile变量，读写volatile变量的开销很大，编译器也不能对volatile变量的读写做任何优化，直接多次访问非volatile实例变量没有多大影响，编译器会做相应优化。 replace方法123456public boolean replace(K key, V oldValue, V newValue) &#123; if (oldValue == null || newValue == null) throw new NullPointerException(); int hash = hash(key.hashCode()); return segmentFor(hash).replace(key, hash, oldValue, newValue);&#125; 根据key的hashcode重新计算hash值（跟get方法一样），通过segmentFor方法定位到具体的哪个segment，然后调用segment的replace方法。 1234567891011121314151617boolean replace(K key, int hash, V oldValue, V newValue) &#123; lock(); try &#123; HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; boolean replaced = false; if (e != null &amp;&amp; oldValue.equals(e.value)) &#123; replaced = true; e.value = newValue; &#125; return replaced; &#125; finally &#123; unlock(); &#125;&#125; 加锁进行以下操作：根据hash值跟数组长度-1进行位运算，定位到具体的HashEntry（getFirst方法），遍历该HashEntry，使用equals方法比较传入的key和链表中元素中的key，找到所需元素。如果能找到并且该元素的value跟传入的oldValue相等，则将该元素的value替换成newValue。 clear方法1234public void clear() &#123; for (int i = 0; i &lt; segments.length; ++i) segments[i].clear();&#125; 1234567891011121314void clear() &#123; if (count != 0) &#123; lock(); try &#123; HashEntry&lt;K,V&gt;[] tab = table; for (int i = 0; i &lt; tab.length ; i++) tab[i] = null; ++modCount; count = 0; // write-volatile &#125; finally &#123; unlock(); &#125; &#125;&#125; 遍历segments，对每一个segment进行清空操作：加锁进行以下操作，遍历HashEntry数组，将每个HashEntry设置为null，并将count设置为0。 size方法1234567891011121314151617181920212223242526272829303132333435363738394041public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; long sum = 0; long check = 0; int[] mc = new int[segments.length]; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) &#123; check = 0; sum = 0; int mcsum = 0; for (int i = 0; i &lt; segments.length; ++i) &#123;//第一次统计 sum += segments[i].count; mcsum += mc[i] = segments[i].modCount; &#125; if (mcsum != 0) &#123; for (int i = 0; i &lt; segments.length; ++i) &#123;//第二次统计 check += segments[i].count; if (mc[i] != segments[i].modCount) &#123;//modCount发生该变则结束当次尝试 check = -1; // force retry break; &#125; &#125; &#125; if (check == sum) break; &#125; if (check != sum) &#123; // Resort to locking all segments sum = 0; for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); for (int i = 0; i &lt; segments.length; ++i) sum += segments[i].count; for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); &#125; if (sum &gt; Integer.MAX_VALUE) return Integer.MAX_VALUE; else return (int)sum;&#125; 先在不加锁的情况下尝试进行统计，如果两次统计结果相同，并且两次统计之间没有任何对segment的修改操作（即每个segment的modCount没有改变），则返回统计结果。否则，对每个segment进行加锁，然后统计出结果，返回结果。 containsValue方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public boolean containsValue(Object value) &#123; if (value == null) throw new NullPointerException(); // See explanation of modCount use above final Segment&lt;K,V&gt;[] segments = this.segments; int[] mc = new int[segments.length]; // Try a few times without locking for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) &#123; int sum = 0; int mcsum = 0; for (int i = 0; i &lt; segments.length; ++i) &#123; int c = segments[i].count; mcsum += mc[i] = segments[i].modCount; if (segments[i].containsValue(value))//遍历该segment里面的所有HashEntry的所有元素 return true; &#125; boolean cleanSweep = true; if (mcsum != 0) &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; int c = segments[i].count; if (mc[i] != segments[i].modCount) &#123;//如果modCount发生改变则结束尝试，进行加锁操作 cleanSweep = false; break; &#125; &#125; &#125; if (cleanSweep) //cleanSweep为true表示所有segment的modCount没有发生过改变 return false; &#125; // Resort to locking all segments for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); //对所有segment进行加锁 boolean found = false; try &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; if (segments[i].containsValue(value)) &#123;//遍历该segment里面的所有HashEntry的所有元素 found = true; break; &#125; &#125; &#125; finally &#123; for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); &#125; return found;&#125; 12345678910111213141516boolean containsValue(Object value) &#123; if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt;[] tab = table; int len = tab.length; for (int i = 0 ; i &lt; len; i++) &#123; //遍历所有HashEntry for (HashEntry&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; //遍历每个HashEntry的所有元素 V v = e.value; if (v == null) // recheck v = readValueUnderLock(e); if (value.equals(v)) return true; &#125; &#125; &#125; return false;&#125; 先在不加锁的情况下尝试进行查找，遍历所有segment的所有HashEntry的所有元素，如果找到则返回true，如果找不到且在遍历期间没有任何对segment的修改操作（即每个segment的modCount没有改变）则返回false。如果在遍历期间segment进行过修改操作，则结束不加锁的尝试。循环对每个segment进行加锁，然后进行遍历查找是否存在。 参考：JDK1.6源码Java集合—-ConcurrentHashMap原理分析","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"http://lvshen9.gitee.io/tags/ConcurrentHashMap/"},{"name":"map","slug":"map","permalink":"http://lvshen9.gitee.io/tags/map/"}]},{"title":"解析ConcurrentHashMapp","slug":"解析ConcurrentHashMapp","date":"2017-09-13T13:20:10.000Z","updated":"2017-09-14T03:01:28.062Z","comments":true,"path":"2017/09/13/解析ConcurrentHashMapp/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/13/解析ConcurrentHashMapp/","excerpt":"在多线程情况下，我们可能会使用Hashtable 或者Collections.synchronizedMap(hashMap)，这两种方式基本都是对整个 hash 表结构做锁定操作的，这样在锁表的期间，别的线程就需要等待了，无疑性能不高。 那么怎样解决这个问题呢，这样就需要引入ConcurrentHashMap了。 ConcurrentHashMap结构解析ConcurrentHashMap也是由数组和链表组成，其实在ConcurrentHashMap 的成员变量中，包含了一个 Segment 的数组（final Segment&lt;K,V&gt;[] segments;），而 Segment 是 ConcurrentHashMap 的内部类，然后在 Segment 这个类中，包含了一个 HashEntry 的数组（transient volatile HashEntry&lt;K,V&gt;[] table;）。而 HashEntry 也是 ConcurrentHashMap 的内部类。HashEntry 中，包含了 key 和 value 以及 next 指针（类似于 HashMap 中 Entry），所以 HashEntry 可以构成一个链表。 ConcurrentHashMap 数据结构为一个 Segment 数组，每个Segment 数组存入的是HashEntry 键值对，和链表指针。","text":"在多线程情况下，我们可能会使用Hashtable 或者Collections.synchronizedMap(hashMap)，这两种方式基本都是对整个 hash 表结构做锁定操作的，这样在锁表的期间，别的线程就需要等待了，无疑性能不高。 那么怎样解决这个问题呢，这样就需要引入ConcurrentHashMap了。 ConcurrentHashMap结构解析ConcurrentHashMap也是由数组和链表组成，其实在ConcurrentHashMap 的成员变量中，包含了一个 Segment 的数组（final Segment&lt;K,V&gt;[] segments;），而 Segment 是 ConcurrentHashMap 的内部类，然后在 Segment 这个类中，包含了一个 HashEntry 的数组（transient volatile HashEntry&lt;K,V&gt;[] table;）。而 HashEntry 也是 ConcurrentHashMap 的内部类。HashEntry 中，包含了 key 和 value 以及 next 指针（类似于 HashMap 中 Entry），所以 HashEntry 可以构成一个链表。 ConcurrentHashMap 数据结构为一个 Segment 数组，每个Segment 数组存入的是HashEntry 键值对，和链表指针。 HashEntryHashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。其类的定义为： 1234567891011121314151617static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; HashEntry(int hash, K key, V value, HashEntry&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; ... ...&#125; HashEntry 的学习可以类比着 HashMap 中的 Entry。我们的存储键值对的过程中，散列的时候如果发生“碰撞”，将采用“分离链表法”来处理碰撞：把碰撞的 HashEntry 对象链接成一个链表。 如下图，我们在一个空桶中插入 A、B、C 两个 HashEntry 对象后的结构图（其实应该为键值对，在这进行了简化以方便更容易理解）： 图1 SegmentSegment 的类定义为static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable。其继承于 ReentrantLock 类，从而使得 Segment 对象可以充当锁的角色。Segment 中包含HashEntry 的数组，其可以守护其包含的若干个桶（HashEntry的数组）。Segment 在某些意义上有点类似于 HashMap了，都是包含了一个数组，而数组中的元素可以是一个链表。 table:table 是由 HashEntry 对象组成的数组如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表，table数组的数组成员代表散列映射表的一个桶，每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分，如果并发级别为 16，table 则守护 ConcurrentHashMap 包含的桶总数的 1/16。 count 变量是计算器，表示每个 Segment 对象管理的 table 数组（若干个 HashEntry 的链表）包含的HashEntry 对象的个数。之所以在每个Segment对象中包含一个 count 计数器，而不在 ConcurrentHashMap 中使用全局的计数器，是为了避免出现“热点域”而影响并发性。 1234567891011121314151617181920212223/** * Segments are specialized versions of hash tables. This * subclasses from ReentrantLock opportunistically, just to * simplify some locking and avoid separate construction. */static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; /** * The per-segment table. Elements are accessed via * entryAt/setEntryAt providing volatile semantics. */ transient volatile HashEntry&lt;K,V&gt;[] table; /** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */ transient int count; transient int modCount; /** * 装载因子 */ final float loadFactor;&#125; 我们通过下图来展示一下插入 ABC 三个节点后，Segment 的示意图： 图2 总体来看，Segment结构是与HashMap很像的。 ConcurrentHashMapConcurrentHashMap 的结构中包含的 Segment 的数组，在默认的并发级别会创建包含 16 个 Segment 对象的数组。通过我们上面的知识，我们知道每个 Segment 又包含若干个散列表的桶，每个桶是由 HashEntry 链接起来的一个链表。如果 key 能够均匀散列，每个 Segment 大约守护整个散列表桶总数的 1/16。 下面我们还有通过一个图来演示一下 ConcurrentHashMap 的结构： 图3 并发写操作在 ConcurrentHashMap 中，当执行 put 方法的时候，会需要加锁来完成。我们通过代码来解释一下具体过程： 当我们 new 一个 ConcurrentHashMap 对象，并且执行put操作的时候，首先会执行 ConcurrentHashMap 类中的 put 方法，该方法源码为： 12345678910111213141516171819202122232425/** * Maps the specified key to the specified value in this table. * Neither the key nor the value can be null. * * &lt;p&gt; The value can be retrieved by calling the &lt;tt&gt;get&lt;/tt&gt; method * with a key that is equal to the original key. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt; * @throws NullPointerException if the specified key or value is null */ @SuppressWarnings(\"unchecked\") public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); return s.put(key, hash, value, false); &#125; 我们通过注释可以了解到，ConcurrentHashMap 不允许空值。该方法首先有一个 Segment 的引用 s，然后会通过 hash() 方法对 key 进行计算，得到哈希值；继而通过调用 Segment 的 put(K key, int hash, V value, boolean onlyIfAbsent)方法进行存储操作。该方法源码为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //加锁，这里是锁定的Segment而不是整个ConcurrentHashMap HashEntry&lt;K,V&gt; node = tryLock() ? null :scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; //得到hash对应的table中的索引index int index = (tab.length - 1) &amp; hash; //找到hash对应的是具体的哪个桶，也就是哪个HashEntry链表 HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; //解锁 unlock(); &#125; return oldValue;&#125; 关于该方法的某些关键步骤，在源码上加上了注释。 需要注意的是：加锁操作是针对的 hash 值对应的某个 Segment，而不是整个 ConcurrentHashMap。因为 put 操作只是在这个 Segment 中完成，所以并不需要对整个 ConcurrentHashMap 加锁。所以，此时，其他的线程也可以对另外的 Segment 进行 put 操作，因为虽然该 Segment 被锁住了，但其他的 Segment 并没有加锁。同时，读线程并不会因为本线程的加锁而阻塞。 正是因为其内部的结构以及机制，所以 ConcurrentHashMap 在并发访问的性能上要比Hashtable和同步包装之后的HashMap的性能提高很多。在理想状态下，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设置为 16），及任意数量线程的读操作。 总结在实际的应用中，散列表一般的应用场景是：除了少数插入操作和删除操作外，绝大多数都是读取操作，而且读操作在大多数时候都是成功的。正是基于这个前提，ConcurrentHashMap 针对读操作做了大量的优化。通过 HashEntry 对象的不变性和用 volatile 型变量协调线程间的内存可见性，使得 大多数时候，读操作不需要加锁就可以正确获得值。这个特性使得 ConcurrentHashMap 的并发性能在分离锁的基础上又有了近一步的提高。 ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。相比于 HashTable 和用同步包装器包装的 HashMap（Collections.synchronizedMap(new HashMap())），ConcurrentHashMap 拥有更高的并发性。在 HashTable 和由同步包装器包装的 HashMap 中，使用一个全局的锁来同步不同线程间的并发访问。同一时间点，只能有一个线程持有锁，也就是说在同一时间点，只能有一个线程能访问容器。这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成串行化的了。 ConcurrentHashMap 的高并发性主要来自于三个方面： 用分离锁实现多个线程间的更深层次的共享访问。 用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。 通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。 使用分离锁，减小了请求 同一个锁的频率。 通过 HashEntery 对象的不变性及对同一个 Volatile 变量的读 / 写来协调内存可见性，使得 读操作大多数时候不需要加锁就能成功获取到需要的值。由于散列映射表在实际应用中大多数操作都是成功的 读操作，所以 2 和 3 既可以减少请求同一个锁的频率，也可以有效减少持有锁的时间。通过减小请求同一个锁的频率和尽量减少持有锁的时间 ，使得 ConcurrentHashMap 的并发性相对于 HashTable 和用同步包装器包装的 HashMap有了质的提高。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"http://lvshen9.gitee.io/tags/ConcurrentHashMap/"},{"name":"map","slug":"map","permalink":"http://lvshen9.gitee.io/tags/map/"}]},{"title":"什么是REST，什么是RESTful","slug":"什么是REST，什么是RESTful","date":"2017-09-12T07:32:31.000Z","updated":"2017-09-12T08:23:22.595Z","comments":true,"path":"2017/09/12/什么是REST，什么是RESTful/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/12/什么是REST，什么是RESTful/","excerpt":"面试被问到什么是REST，什么是RESTful风格。一下懵逼，以前只对RESTful稍有了解，对REST没有多大的概念。于是查查有关方面的知识。 REST – REpresentational State Transfer 直接翻译：表现层状态转移(其实就是资源在网络中以某种表现形式进行状态转移)。这个词太术语化。用通俗易懂的话来说，URL定位资源，用HTTP动词（GET,POST,DELETE,PUT）描述操作。 那么，到底什么是RESTREST描述的是在网络中client和server的一种交互形式；REST本身不实用，实用的是如何设计 RESTful API（REST风格的网络接口）。 Server提供的RESTful API中，URL中只使用名词来指定资源，原则上不使用动词。“资源”是REST架构或者说整个网络处理的核心。比如： lvshen9.github.com/v1/mybook：获取我的book(地址是我瞎写的) lvshen9.github.com/v1/myfrends：获取我的好友列表 …","text":"面试被问到什么是REST，什么是RESTful风格。一下懵逼，以前只对RESTful稍有了解，对REST没有多大的概念。于是查查有关方面的知识。 REST – REpresentational State Transfer 直接翻译：表现层状态转移(其实就是资源在网络中以某种表现形式进行状态转移)。这个词太术语化。用通俗易懂的话来说，URL定位资源，用HTTP动词（GET,POST,DELETE,PUT）描述操作。 那么，到底什么是RESTREST描述的是在网络中client和server的一种交互形式；REST本身不实用，实用的是如何设计 RESTful API（REST风格的网络接口）。 Server提供的RESTful API中，URL中只使用名词来指定资源，原则上不使用动词。“资源”是REST架构或者说整个网络处理的核心。比如： lvshen9.github.com/v1/mybook：获取我的book(地址是我瞎写的) lvshen9.github.com/v1/myfrends：获取我的好友列表 … 用HTTP协议里的动词来实现资源的添加，修改，删除等操作。即通过HTTP动词来实现资源的状态扭转：GET 用来获取资源，POST 用来新建资源（也可以用于更新资源），PUT 用来更新资源，DELETE 用来删除资源。 好了就介绍到这里了，有关RESTful风格的详细知识可以参考[RESTful 架构风格概述]","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"WebService","slug":"WebService","permalink":"http://lvshen9.gitee.io/tags/WebService/"},{"name":"restful","slug":"restful","permalink":"http://lvshen9.gitee.io/tags/restful/"}]},{"title":"RESTful 架构风格概述","slug":"RESTful-架构风格概述","date":"2017-09-11T12:35:33.000Z","updated":"2017-09-11T12:45:27.833Z","comments":true,"path":"2017/09/11/RESTful-架构风格概述/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/11/RESTful-架构风格概述/","excerpt":"本文转载于Gevin’s Blog原文地址 在移动互联网的大潮下，随着docker等技术的兴起，『微服务』的概念也越来越被大家接受并应用于实践，日益增多的web service逐渐统一于RESTful 架构风格，如果开发者对RESTful 架构风格不甚了解，则开发出的所谓RESTful API总会貌合神离，不够规范。 本文是我对RESTful 架构风格的一些理解，和大家分享一下，如果有问题，欢迎讨论。 Restful Style","text":"本文转载于Gevin’s Blog原文地址 在移动互联网的大潮下，随着docker等技术的兴起，『微服务』的概念也越来越被大家接受并应用于实践，日益增多的web service逐渐统一于RESTful 架构风格，如果开发者对RESTful 架构风格不甚了解，则开发出的所谓RESTful API总会貌合神离，不够规范。 本文是我对RESTful 架构风格的一些理解，和大家分享一下，如果有问题，欢迎讨论。 Restful Style 1. RESTful架构风格RESTful架构风格最初由Roy T. Fielding（HTTP/1.1协议专家组负责人）在其2000年的博士学位论文中提出。HTTP就是该架构风格的一个典型应用。从其诞生之日开始，它就因其可扩展性和简单性受到越来越多的架构师和开发者们的青睐。一方面，随着云计算和移动计算的兴起，许多企业愿意在互联网上共享自己的数据、功能；另一方面，在企业中，RESTful API（也称RESTful Web服务）也逐渐超越SOAP成为实现SOA的重要手段之一。时至今日，RESTful架构风格已成为企业级服务的标配。 REST即Representational State Transfer的缩写，可译为”表现层状态转化”。REST最大的几个特点为：资源、统一接口、URI和无状态。 1.1 RESTful架构风格的特点1.1.1 资源所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。资源总要通过某种载体反应其内容，文本可以用txt格式表现，也可以用HTML格式、XML格式表现，甚至可以采用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现；JSON是现在最常用的资源表示格式。 结合我的开发实践，我对资源和数据理解如下： 资源是以json(或其他Representation)为载体的、面向用户的一组数据集，资源对信息的表达倾向于概念模型中的数据： 资源总是以某种Representation为载体显示的，即序列化的信息 常用的Representation是json(推荐)或者xml（不推荐）等 Represntation 是REST架构的表现层 相对而言，数据（尤其是数据库）是一种更加抽象的、对计算机更高效和友好的数据表现形式，更多的存在于逻辑模型中 资源和数据关系如下： resource vs data 1.1.2 统一接口RESTful架构风格规定，数据的元操作，即CRUD(create, read, update和delete,即数据的增删查改)操作，分别对应于HTTP方法：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源，这样就统一了数据操作的接口，仅通过HTTP方法，就可以完成对数据的所有增删查改工作。 即： GET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供完整资源数据）。 PATCH（UPDATE）：在服务器更新资源（客户端提供需要修改的资源数据）。 DELETE（DELETE）：从服务器删除资源。 1.1.3 URI可以用一个URI（统一资源定位符）指向资源，即每个URI都对应一个特定的资源。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或识别符。 一般的，每个资源至少有一个URI与之对应，最典型的URI即URL。 1.1.4 无状态所谓无状态的，即所有的资源，都可以通过URI定位，而且这个定位与其他资源无关，也不会因为其他资源的变化而改变。有状态和无状态的区别，举个简单的例子说明一下。如查询员工的工资，如果查询工资是需要登录系统，进入查询工资的页面，执行相关操作后，获取工资的多少，则这种情况是有状态的，因为查询工资的每一步操作都依赖于前一步操作，只要前置操作不成功，后续操作就无法执行；如果输入一个url即可得到指定员工的工资，则这种情况是无状态的，因为获取工资不依赖于其他资源或状态，且这种情况下，员工工资是一个资源，由一个url与之对应，可以通过HTTP中的GET方法得到资源，这是典型的RESTful风格。 state stateless 1.2 ROA、SOA、REST与RPCROA即Resource Oriented Architecture，RESTful 架构风格的服务是围绕资源展开的，是典型的ROA架构（虽然“A”和“架构”存在重复，但说无妨），虽然ROA与SOA并不冲突，甚至把ROA看做SOA的一种也未尝不可，但由于RPC也是SOA，比较久远一点点论文、博客或图书也常把SOA与RPC混在一起讨论，因此，RESTful 架构风格的服务通常被称之为ROA架构，很少提及SOA架构，以便更加显式的与RPC区分。 RPC风格曾是Web Service的主流，最初是基于XML-RPC协议（一个远程过程调用（remote procedure call，RPC)的分布式计算协议），后来渐渐被SOAP协议（简单对象访问协议（Simple Object Access Protocol））取代；RPC风格的服务，不仅可以用HTTP，还可以用TCP或其他通信协议。但RPC风格的服务，受开发服务采用语言的束缚比较大，如.NET框架中，开发web service的传统方式是使用WCF，基于WCF开发的服务即RPC风格的服务，使用该服务的客户端通常要用C#来实现，如果使用python或其他语言，很难实现可以直接与服务通信客户端；进入移动互联网时代后，RPC风格的服务很难在移动终端使用，而RESTful风格的服务，由于可以直接以json或xml为载体承载数据，以HTTP方法为统一接口完成数据操作，客户端的开发不依赖于服务实现的技术，移动终端也可以轻松使用服务，这也加剧了REST取代RPC成为web service的主导。 RPC与RESTful的区别如下面两个图所示： blog-post-REST-vs-RPC1 blog-post-REST-vs-RPC2 1.3 本真REST与hybrid风格通常开发者做服务相关的客户端开发时，使用的所谓RESTful服务，基本可分为本真REST和hybrid风格两类。本真REST即我上文阐述的RESTful架构风格，具有上述的4个特点，是真正意义上的RESTful风格；而hybrid风格，只是借鉴了RESTful的一些优点，具有一部分RESTful的特点，但对外依然宣称是RESTful风格的服务。（窃以为，正是由于hybrid风格服务混淆了RESTful的概念，才在RESTful架构风格提出了本真REST的概念，以为了划分界限 :P） hybrid风格的最主流的用法是，使用GET方法获取资源，用POST方法实现资源的创建、修改和删除。hybrid风格之所以存在，据我了解有两种来源：一种情况是因为，某些开发者并没有真正理解何为RESTful架构风格，导致开发的服务貌合神离；而主流的原因是由于历史包袱 —— 服务本来是RPC风格的，由于上文提到的RPC的劣势及RESTful的优势，开发者在RPC风格的服务上又包装了一层RESTful的外壳，通常这层外壳只为获取资源服务，因此会按RESTful风格实现GET方法，如果客户端提出一些简单的创建、修改或删除数据的需求，则通过HTTP协议中最常用的POST方法实现相应功能。 因此，开发RESTful 服务，如果没有历史包袱，不建议使用hybrid风格。 2. 认证机制 stateless-auth 由于RESTful风格的服务是无状态的，认证机制尤为重要。例如上文提到的员工工资，这应该是一个隐私资源，只有员工本人或其他少数有权限的人有资格看到，如果不通过权限认证机制对资源做一层限制，那么所有资源都以公开方式暴露出来，这是不合理的，也是很危险的。 认证机制解决的问题是，确定访问资源的用户是谁；权限机制解决的问题是，确定用户是否被许可使用、修改、删除或创建资源。权限机制通常与服务的业务逻辑绑定，因此权限机制需要在每个系统内部定制，而认证机制基本上是通用的，常用的认证机制包括 session auth(即通过用户名密码登录)，basic auth，token auth和OAuth，服务开发中常用的认证机制为后三者。 2.1 Basic Auth HTTP Basic authentication (BA) implementation is the simplest technique for enforcing access controls to web resources because it doesn’t require cookies, session identifier and login pages. Rather, HTTP Basic authentication uses static, standard fields in the HTTP header which means that no handshakes have to be done in anticipation. Visit Wikipedia To Read More 简言之，Basic Auth是配合RESTful API 使用的最简单的认证方式，只需提供用户名密码即可，但由于有把用户名密码暴露给第三方客户端的风险，在生产环境下被使用的越来越少。因此，在开发对外开放的RESTful API时，尽量避免采用Basic Auth 2.2 Token AuthToken Auth并不常用，它与Basic Auth的区别是，不将用户名和密码发送给服务器做用户认证，而是向服务器发送一个事先在服务器端生成的token来做认证。因此Token Auth要求服务器端要具备一套完整的Token创建和管理机制，该机制的实现会增加大量且非必须的服务器端开发工作，也不见得这套机制足够安全和通用，因此Token Auth用的并不多。 本文不在展开介绍Token Auth，我个人对这套机制也了解有限，有兴趣了解这套机制的同学不妨从Stack Overflow上的这篇讨论入手。 2.3 OAuth OAuth is an open standard for authorization. OAuth provides client applications a ‘secure delegated access’ to server resources on behalf of a resource owner. It specifies a process for resource owners to authorize third-party access to their server resources without sharing their credentials. Designed specifically to work with Hypertext Transfer Protocol (HTTP), OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner. The client then uses the access token to access the protected resources hosted by the resource server. OAuth is commonly used as a way for Internet users to log into third party websites using their Microsoft, Google, Facebook or Twitter accounts without exposing their password. OAuth is a service that is complementary to and distinct from OpenID. OAuth is also distinct from OATH, which is a reference architecture for authentication, not a standard for authorization. However, OAuth is directly related to OpenID Connect (OIDC) since OIDC is an authentication layer built on top of OAuth 2.0. Visit Wikipedia To Read More OAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在某一web服务上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。 OAuth允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的第三方系统（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容。 正是由于OAUTH的严谨性和安全性，现在OAUTH已成为RESTful架构风格中最常用的认证机制，和RESTful架构风格一起，成为企业级服务的标配。 目前OAuth已经从OAuth1.0发展到OAuth2.0，但这二者并非平滑过渡升级，OAuth2.0在保证安全性的前提下大大减少了客户端开发的复杂性，因此，Gevin建议在实战应用中采用OAuth2.0认证机制。 现在网上关于OAuth的资料非常丰富，也有大量开源的第三方库实现了OAuth机制，不熟悉OAuth的同学从OAuth官网入手即可。 3. 总结 本真REST + OAuth是RESTful 是微服务的标配 Basic Auth只在开发环境中使用 设计合理的资源 用正确的HTTP方法对数据发正确的请求","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"WebService","slug":"WebService","permalink":"http://lvshen9.gitee.io/tags/WebService/"},{"name":"restful","slug":"restful","permalink":"http://lvshen9.gitee.io/tags/restful/"}]},{"title":"Why We Need DI ?","slug":"Why-We-Need-DI","date":"2017-09-09T14:01:43.000Z","updated":"2017-09-11T12:04:49.392Z","comments":true,"path":"2017/09/09/Why-We-Need-DI/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/09/Why-We-Need-DI/","excerpt":"依赖注入（Dependency Injection）是用于实现控制反转（Inversion of Control）的最常见的方式之一。本文主要介绍依赖注入原理和常见的实现方式。 我们为什么需要依赖注入控制反转用于解耦，解的究竟是谁和谁的耦？这是我在最初了解依赖注入时候产生的第一个问题。 Martin Flower在解释依赖注入时，用了一段简短的代码解释了这个问题。","text":"依赖注入（Dependency Injection）是用于实现控制反转（Inversion of Control）的最常见的方式之一。本文主要介绍依赖注入原理和常见的实现方式。 我们为什么需要依赖注入控制反转用于解耦，解的究竟是谁和谁的耦？这是我在最初了解依赖注入时候产生的第一个问题。 Martin Flower在解释依赖注入时，用了一段简短的代码解释了这个问题。 1234567891011121314151617181920public class MovieLister &#123; private MovieFinder finder; public MovieLister() &#123; finder = new MovieFinderImpl(); &#125; public Movie[] moviesDirectedBy(String arg) &#123; List allMovies = finder.findAll(); for (Iterator it = allMovies.iterator(); it.hasNext();) &#123; Movie movie = (Movie)it.next(); if(!movie.getDirector().equals(arg)) it.remove(); &#125; return (Movie[])allMovies.toArray(new Movie[allMovies.size()]); &#125; ...&#125;public interface MovieFinder &#123; List findAll();&#125; 我们创建了一个名为MovieLister的类来提供需要的电影列表，它moviesDirectedBy方法提供根据导演名来搜索电影的方式。真正负责搜索电影的是实现了MovieFinder接口的MovieFinderImpl，我们的MovieLister类在构造函数中创建了一个MovieFinderImpl的对象。 目前看来，一切都不错。但是，当我们希望修改finder，将finder替换为一种新的实现时（比如为MovieFinder增加一个参数表明Movie数据的来源是哪个数据库），我们不仅需要修改MovieFinderImpl类，还需要修改我们MovieLister中创建MovieFinderImpl的代码。 这就是依赖注入要处理的耦合。这种在MovieLister中创建MovieFinderImpl的方式，使得MovieLister不仅仅依赖于MovieFinder这个接口，它还依赖于MovieListImpl这个实现。 这种在一个类中直接创建另一个类的对象的代码，和硬编码（hard-coded strings)以及硬编码的数字（magic numbers）一样，是一种导致耦合的坏味道，我们可以把这种坏味道称为硬初始化（hard init）。同时，我们也应该像记住硬编码一样记住，new（对象创建）是有毒的。 Hard Init带来的主要坏处有两个方面：1）上文所述的修改其实现时，需要修改创建处的代码；2）不便于测试，这种方式创建的类（上文中的MovieLister）无法单独被测试，其行为和MovieFinderImpl紧紧耦合在一起，同时，也会导致代码的可读性问题（“如果一段代码不便于测试，那么它一定不便于阅读。”）。 我们怎样依赖注入简单介绍一下依赖注入的三种方式。 构造函数注入（Contructor Injection）例如改造上面的代码，将MovieFinderImpl的实现在MovieLister类之外创建。这样，MovieLister就只依赖于我们定义的MovieFinder接口，而不依赖于MovieFinder的实现了。 1234567public class MovieLister &#123; private MovieFinder finder; public MovieLister(MovieFinder finder) &#123; this.finder =finder; &#125; ...&#125; setter注入我们也可以增加一个setter函数来传入创建好的MovieFinder对象，这样同样可以避免在MovieFinder中hard init这个对象。 12345public class MovieLister &#123; public void setFinder(MovieFinder finder) &#123; this.finder =finder; &#125;&#125; 接口注入接口注入使用接口来提供setter方法，其实现方式如下。首先要创建一个注入使用的接口。 12345public interface InjectFinder &#123; void injectFinder(MovieFinder finder);&#125; 然后让MovieLister实现接口。 1234567class MovieLister implements InjectFinder &#123; ... public void injectFinder(MovieFinder finder) &#123; this.finder =finder; &#125; ...&#125; 最后，我们需要根据不同的框架创建被依赖的MovieFinder的实现。 其实 依赖注入只是控制反转的一种实现方式。控制反转还有一种常见的实现方式称为依赖查找。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lvshen9.gitee.io/tags/Spring/"},{"name":"DI","slug":"DI","permalink":"http://lvshen9.gitee.io/tags/DI/"}]},{"title":"排序算法","slug":"排序算法","date":"2017-09-09T02:58:42.000Z","updated":"2017-09-09T03:40:22.356Z","comments":true,"path":"2017/09/09/排序算法/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/09/排序算法/","excerpt":"Java中有对于排序封装的方法，Arrays.sort()大家肯定不陌生。但对于算法的原理可能有人不知道。 下面我们讲解一下选择排序与冒泡排序实现原理： 选择排序 选择排序图解 如图，选择排序的原理就是数组中的一个元素分别和其他所有元素两两比较，把最大值或者最小值赋给这个元素，从而实现排序。","text":"Java中有对于排序封装的方法，Arrays.sort()大家肯定不陌生。但对于算法的原理可能有人不知道。 下面我们讲解一下选择排序与冒泡排序实现原理： 选择排序 选择排序图解 如图，选择排序的原理就是数组中的一个元素分别和其他所有元素两两比较，把最大值或者最小值赋给这个元素，从而实现排序。 相关代码如下 12345678910//升序排序(选择排序法)for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = i + 1; j &lt; arr.length; j++) &#123; if (arr[i] &gt; arr[j]) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; &#125; 冒泡排序这种排序方法经常会被问道，也算是明星排序算法了，其原理就是，循环比较相邻元素的值，然后把较大值或者较小值放到最右边，实现排序。 冒泡排序图解 代码如下 123456789for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - i; j++) &#123; if (arr[j] &gt; arr[j+1]) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; &#125; 本文彩蛋二分查找法 二分法查找 二分查找法要求数组或集合是有序的。通过不断查找中间值，来与要查找的值比较，从而确定该值的位置。 代码如下 12345678910111213141516171819202122//key为需要查找的值private static int binarySearch(int[] arr,int key) &#123; int min = 0; int max = arr.length - 1; while (min&lt;=max) &#123; int mid = (min + max) &gt;&gt; 1; if (arr[mid] == key) &#123; // 说明key找到 return mid; &#125; if (arr[mid] &gt; key) &#123; max = mid - 1; &#125; if (arr[mid] &lt; key) &#123; max = mid + 1; &#125; &#125; return -1;&#125; 以上就是相关的查找方法 欢迎关注我的博客：Lvshen’s Blog","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"冒泡","slug":"冒泡","permalink":"http://lvshen9.gitee.io/tags/冒泡/"}]},{"title":"What's Ajax ?","slug":"What-s-Ajax","date":"2017-09-08T12:06:00.000Z","updated":"2017-09-09T15:44:14.896Z","comments":true,"path":"2017/09/08/What-s-Ajax/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/08/What-s-Ajax/","excerpt":"什么是 Ajax ?曾经有人面试被问到Ajax的全称是什么？不得不说这个问题很无语，开发了这么久，早忘了Ajax的全称了。最近上网逛了逛博客，详细的了解了下Ajax，特来分享一下。 AJAX全称为“Asynchronous JavaScript and XML”（异步JavaScript和XML），是一种创建交互式网页应用的网页开发技术。它使用： 使用XHTML+CSS来标准化呈现； 使用XML和XSLT进行数据交换及相关操作； 使用XMLHttpRequest对象与Web服务器进行异步数据通信； 使用Javascript操作Document Object Model进行动态显示及交互； 使用JavaScript绑定和处理所有数据。 对于后端开发的我了解它是前端用来和后端异步通信的一种技术。或许有人会问什么是异步？有异步是否意味着有同步？书到用时用时方恨少了吧。下面是一个简洁的比较：","text":"什么是 Ajax ?曾经有人面试被问到Ajax的全称是什么？不得不说这个问题很无语，开发了这么久，早忘了Ajax的全称了。最近上网逛了逛博客，详细的了解了下Ajax，特来分享一下。 AJAX全称为“Asynchronous JavaScript and XML”（异步JavaScript和XML），是一种创建交互式网页应用的网页开发技术。它使用： 使用XHTML+CSS来标准化呈现； 使用XML和XSLT进行数据交换及相关操作； 使用XMLHttpRequest对象与Web服务器进行异步数据通信； 使用Javascript操作Document Object Model进行动态显示及交互； 使用JavaScript绑定和处理所有数据。 对于后端开发的我了解它是前端用来和后端异步通信的一种技术。或许有人会问什么是异步？有异步是否意味着有同步？书到用时用时方恨少了吧。下面是一个简洁的比较： 同步：提交请求-&gt;等待服务器处理-&gt;处理完毕返回 这个期间客户端浏览器不能干任何事 异步 : 请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕 相对于传统的Web一个用来说，AJAX应用可以仅向服务器发送并取回必需的数据，它使用SOAP或其它一些基于XML的Web Service接口，并在客户端采用JavaScript处理来自服务器的响应。因为在服务器和浏览器之间交换的数据大量减少，结果我们就能看到响应更快的应用。同时很多的处理工作可以在发出请求的客户端机器上完成，所以Web服务器的处理时间也减少了。 Ajax工作原理Ajax的工作原理相当于在用户和服务器之间加了—个中间层(AJAX引擎)，使用户操作与服务器响应异步化。然而不是所有的用户请求都提交给服务器，像—些数据验证和数据处理等都交给Ajax引擎自己来做, 只有确定需要从服务器读取新数据时再由Ajax引擎代为向服务器提交请求。 Ajax其核心有JavaScript、XMLHTTPRequest、DOM对象组成，通过XmlHttpRequest对象来向服务器发异步请求，从服务器获得数据，然后用JavaScript来操作DOM而更新页面。这其中最关键的一步就是从服务器获得请求数据。让我们来了解这几个对象。 一般在开发中使用jQuery来进行开发，其具体使用就不在这里说啦。 Ajax的模板代码如下： 12345678910111213141516171819202122232425262728$.ajax(&#123; url:'这里写一个路径', type:'POST', //GET，这里是提交方式 async:true, //或false,是否异步 data:&#123; name:'yang',age:25 //数据的传输，Json格式 &#125;, timeout:5000, //超时时间 dataType:'json', //返回的数据格式：json/xml/html/script/jsonp/text beforeSend:function(xhr)&#123; console.log(xhr) console.log('发送前') &#125;, //下面是日志的提交 success:function(data,textStatus,jqXHR)&#123; console.log(data) console.log(textStatus) console.log(jqXHR) &#125;, error:function(xhr,textStatus)&#123; console.log('错误') console.log(xhr) console.log(textStatus) &#125;, complete:function()&#123; console.log('结束') &#125;&#125;) Ajax的优缺点优点1.无刷新的更新数据AJAX最大优点就是能在不刷新整个页面的前提下与服务器通信维护数据。这使得Web应用程序更为迅捷地响应用户交互，并避免了在网络上发送那些没有改变的信息，减少用户等待时间，带来非常好的用户体验。 2.异步与服务器的通信AJAX使用异步方式与服务器通信，不需要打断用户的操作，具有更加迅速的响应能力。优化了Browser和Server之间的沟通，减少不必要的数据传输、时间及降低网络上数据流量。 3.前端与后端的负载均衡AJAX可以把以前一些服务器负担的工作转嫁到客户端，利用客户端闲置的能力来处理，减轻服务器和带宽的负担，节约空间和宽带租用成本。并且减轻服务器的负担，AJAX的原则是“按需取数据”，可以最大程度的减少冗余请求和响应对服务器造成的负担，提升站点性能。 缺点1.AJAX干掉了Back和History功能，即对浏览器机制的破坏在动态更新页面的情况下，用户无法回到前一个页面状态，因为浏览器仅能记忆历史记录中的静态页面。一个被完整读入的页面与一个已经被动态修改过的页面之间的差别非常微妙；用户通常会希望单击后退按钮能够取消他们的前一次操作，但是在Ajax应用程序中，这将无法实现。 后退按钮是一个标准的web站点的重要功能，但是它没法和js进行很好的合作。这是Ajax所带来的一个比较严重的问题，因为用户往往是希望能够通过后退来取消前一次操作的。那么对于这个问题有没有办法？答案是肯定的，用过Gmail的知道，Gmail下面采用的Ajax技术解决了这个问题，在Gmail下面是可以后退的，但是，它也并不能改变Ajax的机制，它只是采用的一个比较笨但是有效的办法，即用户单击后退按钮访问历史记录时，通过创建或使用一个隐藏的IFRAME来重现页面上的变更。（例如，当用户在Google Maps中单击后退时，它在一个隐藏的IFRAME中进行搜索，然后将搜索结果反映到Ajax元素上，以便将应用程序状态恢复到当时的状态。） 但是，虽然说这个问题是可以解决的，但是它所带来的开发成本是非常高的，并与Ajax框架所要求的快速开发是相背离的。这是Ajax所带来的一个非常严重的问题。 一个相关的观点认为，使用动态页面更新使得用户难于将某个特定的状态保存到收藏夹中。该问题的解决方案也已出现，大部分都使用URL片断标识符（通常被称为锚点，即URL中#后面的部分）来保持跟踪，允许用户回到指定的某个应用程序状态。（许多浏览器允许JavaScript动态更新锚点，这使得Ajax应用程序能够在更新显示内容的同时更新锚点。）这些解决方案也同时解决了许多关于不支持后退按钮的争论。 2.Ajax不安全AJAX技术给用户带来很好的用户体验的同时也对IT企业带来了新的安全威胁，Ajax技术就如同对企业数据建立了一个直接通道。这使得开发者在不经意间会暴露比以前更多的数据和服务器逻辑。Ajax的逻辑可以对客户端的安全扫描技术隐藏起来，允许黑客从远端服务器上建立新的攻击。还有Ajax也难以避免一些已知的安全弱点，诸如跨站点脚步攻击、SQL注入攻击和基于Credentials的安全漏洞等等。 3.对搜索引擎的支持较弱对搜索引擎的支持比较弱。如果使用不当，AJAX会增大网络数据的流量，从而降低整个系统的性能。 4.违背URL和资源定位的原则例如，我给你一个URL地址，如果采用了Ajax技术，也许你在该URL地址下面看到的和我在这个URL地址下看到的内容是不同的。这个和资源定位的初衷是相背离的。 5.AJAX不能很好支持移动设备一些手持设备（如手机、PDA等）现在还不能很好的支持Ajax，比如说我们在手机的浏览器上打开采用Ajax技术的网站时，它目前是不支持的。 使用Ajax需要注意的点Ajax开发时，网络延迟——即用户发出请求到服务器发出响应之间的间隔——需要慎重考虑。不给予用户明确的回应，没有恰当的预读数据，或者对XMLHttpRequest的不恰当处理，都会使用户感到延迟，这是用户不希望看到的，也是他们无法理解的。通常的解决方案是，使用一个可视化的组件来告诉用户系统正在进行后台操作并且正在读取数据和内容。 Ajax的使用场景 表单驱动的交互 深层次的树的导航 快速的用户与用户间的交流响应 类似投票、yes/no等无关痛痒的场景 对数据进行过滤和操纵相关数据的场景 普通的文本输入提示和自动完成的场景 Ajax的不适用场景 部分简单的表单 搜索 基本的导航 替换大量的文本 对呈现的操纵 好了，今天的分享就到这里了，关于Ajax的探索之路还很长… —–Start Me on Github","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lvshen9.gitee.io/tags/JavaScript/"},{"name":"Web","slug":"Web","permalink":"http://lvshen9.gitee.io/tags/Web/"}]},{"title":"JVM调优笔记","slug":"JVM调优笔记","date":"2017-09-06T08:26:29.000Z","updated":"2017-09-06T08:30:49.334Z","comments":true,"path":"2017/09/06/JVM调优笔记/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/06/JVM调优笔记/","excerpt":"内存分代不同对象的生命周期不同，所以垃圾回收的方式也会不同，这样做是有助于提高回收的效率 虚拟机内存划分为三个代年轻代（Young Generation）、年老代（Old Generation）和持久代（Permanent Generation） 其中年轻代与老年代属于堆内存中，垃圾回收主要针对于这两个代 年轻代有一个Eden区和两个或两个以上的Survivor区，对象先存在Eden区，当Eden区满了后，再存在Survivor区，都满了，说明对象生命周期较长，会存在老年代。","text":"内存分代不同对象的生命周期不同，所以垃圾回收的方式也会不同，这样做是有助于提高回收的效率 虚拟机内存划分为三个代年轻代（Young Generation）、年老代（Old Generation）和持久代（Permanent Generation） 其中年轻代与老年代属于堆内存中，垃圾回收主要针对于这两个代 年轻代有一个Eden区和两个或两个以上的Survivor区，对象先存在Eden区，当Eden区满了后，再存在Survivor区，都满了，说明对象生命周期较长，会存在老年代。 GC类型Scavenge GC：作用在Eden区，针对于无法在Eden区存活的对象 Full GC：作用于整个堆；触发Full GC的条件为 · 年老代（Tenured）被写满 · 持久代（Perm）被写满 · System.gc()被显示调用 ·上一次GC之后Heap的各域分配策略动态变化 选择合适的垃圾回收算法串行收集器单处理器的机器：选择串行收集器，可以使用-XX:+UseSerialGC打开。 并行处理器多线程多处理器机器：对年轻代进行并行垃圾回收，用-XX:+UseParallelGC.打开；如果对年老代垃圾采用并行收集，用-XX:+UseParallelOldGC打开。 使用-XX:ParallelGCThreads=设置并行垃圾回收的线程数。此值可以设置与机器处理器数量相等。 推荐并行收集器配置 最大垃圾回收暂停:指定垃圾回收时的最长暂停时间，通过-XX:MaxGCPauseMillis=指定。为毫秒.如果指定了此值的话，堆大小和垃圾回收相关参数会进行调整以达到指定值。设定此值可能会减少应用的吞吐量。 吞吐量:吞吐量为垃圾回收时间与非垃圾回收时间的比值，通过-XX:GCTimeRatio=来设定，公式为1/（1+N）。例如，-XX:GCTimeRatio=19时，表示5%的时间用于垃圾回收。默认情况为99，即1%的时间用于垃圾回收。 并发收集器保证大部分工作都并发进行（应用不停止），垃圾回收只暂停很少的时间，此收集器适合对响应时间要求比较高的中、大规模应用。使用-XX:+UseConcMarkSweepGC打开。 处理要点：降低垃圾回收是暂停的时间。 为什么会有停顿？ 在每个年老代垃圾回收周期中，在收集初期并发收集器 会对整个应用进行简短的暂停，在收集中还会再暂停一次。第二次暂停会比第一次稍长，在此过程中多个线程同时进行垃圾回收工作。 浮动垃圾：有些垃圾可能在垃圾回收运行之后产生，这样的垃圾称为浮动垃圾，这些垃圾要在下个周期才能被处理。所以并发收集器需要有20%的空间来处理这些垃圾。 Concurrent Mode Failure：如果再回收垃圾时，堆没有足够的空间，并发模式失败，应用会被停止，只进行垃圾回收。 如何解决Concurrent Mode Failure? 通过设置-XX:CMSInitiatingOccupancyFraction=指定还有多少剩余堆时开始执行并发收集 关于GC处理器的总结串行处理器： –适用情况：数据量比较小（100M左右）；单处理器下并且对响应时间无要求的应用。–缺点：只能用于小型应用 并行处理器： –适用情况：“对吞吐量有高要求”，多CPU、对应用响应时间无要求的中、大型应用。举例：后台处理、科学计算。–缺点：垃圾收集过程中应用响应时间可能加长 并发处理器： –适用情况：“对响应时间有高要求”，多CPU、对应用响应时间有较高要求的中、大型应用。举例：Web服务器/应用服务器、电信交换、集成开发环境。 针对垃圾回收算法，可以有以下的推荐配置 堆大小配置JVM最大堆的限制：32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制 典型设置123456789java -Xmx3550m -Xms3550m -Xmn2g –Xss128k-Xmx3550m：设置JVM最大可用内存为3550M。-Xms3550m：设置JVM促使内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。-Xmn2g：设置年轻代大小为2G。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。-Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 123456789java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6-XX:MaxPermSize=16m:设置持久代大小为16m。-XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 回收器的选择吞吐量优先的并行收集器典型配置 12345java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 1234java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。 123java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100-XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。 1234java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。 响应时间优先的并发收集器典型配置： 123456java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC-XX:+UseConcMarkSweepGC：**设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。-XX:+UseParNewGC: 设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 123456java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片。 辅助信息JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些： -XX:+PrintGC：输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] -XX:+PrintGCDetails：输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationConcurrentTime：打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用。输出形式：Application time: 0.5291524 seconds -XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用。输出形式：Total time for which application threads were stopped: 0.0468229 seconds -XX:PrintHeapAtGC: 打印GC前后的详细堆栈信息。输出形式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464734.702: [GC &#123;Heap before gc invocations=7:def new generation total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000)eden space 49152K, 99% used [0x1ebd0000, 0x21bce430, 0x21bd0000)from space 6144K, 55% used [0x221d0000, 0x22527e10, 0x227d0000)to space 6144K, 0% used [0x21bd0000, 0x21bd0000, 0x221d0000)tenured generation total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000)the space 69632K, 3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000)compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations=8:def new generation total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000)eden space 49152K, 0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000) from space 6144K, 55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000) to space 6144K, 0% used [0x221d0000, 0x221d0000, 0x227d0000)tenured generation total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000)the space 69632K, 4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000)compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)&#125;, 0.0757599 secs] -Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。 调优原则年轻代大小选择响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。 吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。 年老代大小选择响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可能会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得： 并发垃圾收集信息 持久代并发收集次数 传统GC信息 花在年轻代和年老代回收上的时间比例 减少年轻代和年老代花费的时间，一般会提高应用的效率 较小堆引起的碎片问题因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置： ​ 1. -XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。 ​ 2. -XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩 传统垃圾回收存在的问题Full GC 会使应用带来暂停。如果应用的实时性要求很高，GC的暂停会带来很大的损失。分代垃圾回收对于应用的暂停处理不尽人意。为了达到实时性的要求。需要新的垃圾回收机制，它需要有如下的功能: 既支持短的暂停时间，有支持大的内存空间分配 增量收集增量收集的方式在理论上可以解决传统分代方式带来的问题。增量收集把对堆空间划分成一系列内存块，使用时，先使用其中一部分（不会全部用完），垃圾收集时把之前用掉的部分中的存活对象再放到后面没有用的空间中，这样可以实现一直边使用边收集的效果，避免了传统分代方式整个使用完了再暂停的回收的情况。 当然，传统分代收集方式也提供了并发收集，但是他有一个很致命的地方，就是把整个堆做为一个内存块，这样一方面会造成碎片（无法压缩），另一方面他的每次收集都是对整个堆的收集，无法进行选择，在暂停时间的控制上还是很弱。而增量方式，通过内存空间的分块，恰恰可以解决上面问题。 G1算法关于增量收集，涉及到Garbage Firest（G1）算法，读者可以参考这篇文章 还是做一个G1算法的简介吧： 他吸取了增量收集优点，把整个堆划分为一个一个等大小的区域（region）。内存的回收和划分都以region为单位；同时，他也吸取了CMS的特点，把这个垃圾回收过程分为几个阶段，分散一个垃圾回收过程；而且，G1也认同分代垃圾回收的思想，认为不同对象的生命周期不同，可以采取不同收集方式，因此，它也支持分代的垃圾回收。为了达到对回收时间的可预计性，G1在扫描了region以后，对其中的活跃对象的大小进行排序，首先会收集那些活跃对象小的region，以便快速回收空间（要复制的活跃对象少了），因为活跃对象小，里面可以认为多数都是垃圾，所以这种方式被称为Garbage First（G1）的垃圾回收算法，即：垃圾优先的回收。 缺点：在性能上有一些损失 G1的回收步骤为： 初始标记（Initial Marking）→并发标记（Concurrent Marking）→最终标记暂停（Final Marking Pause）→存活对象计算及清除（Live Data Counting and Cleanup） 调优工具参考Jconsole : jdk自带，功能简单，但是可以在系统有一定负荷的情况下使用。对垃圾回收算法有很详细的跟踪。详细说明参考这里 JProfiler：商业软件，需要付费。功能强大。详细说明参考这里 VisualVM：JDK自带，功能强大，与JProfiler类似。推荐 如何用工具调优 主要观察内存的释放情况 堆信息查看 可查看堆空间大小分配（年轻代、年老代、持久代分配） 提供即时的垃圾回收功能 垃圾监控（长时间监控回收情况） 查看堆内类、对象信息查看：数量、类型等 对象引用情况查看 这些工具主要是为了获取堆信息，通过这些信息可以解决以下几个问题： 年老代年轻代大小划分是否合理 内存泄漏 垃圾回收算法设置是否合理 线程监控 线程信息监控：系统线程数量。 线程状态监控：各个线程都处在什么样的状态下 Dump线程详细信息：查看线程内部运行情况 死锁检查 热点分析 CPU热点：检查系统哪些方法占用的大量CPU时间 内存热点：检查哪些对象在系统中数量最大（一定时间内存活对象和销毁对象一起统计） 快照快照是系统运行到某一时刻的一个定格。在我们进行调优的时候，不可能用眼睛去跟踪所有系统变化，依赖快照功能，我们就可以进行系统两个不同运行时刻，对象（或类、线程等）的不同，以便快速找到问题 举例说，我要检查系统进行垃圾回收以后，是否还有该收回的对象被遗漏下来的了。那么，我可以在进行垃圾回收前后，分别进行一次堆情况的快照，然后对比两次快照的对象情况。 内存泄漏检查内存泄漏一般可以理解为系统资源（各方面的资源，堆、栈、线程等）在错误使用的情况下，导致使用完毕的资源无法回收（或没有回收），从而导致新的资源分配请求无法完成，引起系统错误。 年老代堆空间被占满异常： java.lang.OutOfMemoryError: Java heap space 说明： 这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机无法再在分配新空间。 如上图所示，这是非常典型的内存泄漏的垃圾回收情况图。所有峰值部分都是一次垃圾回收点，所有谷底部分表示是一次垃圾回收后剩余的内存。连接所有谷底的点，可以发现一条由底到高的线，这说明，随时间的推移，系统的堆空间被不断占满，最终会占满整个堆空间。因此可以初步认为系统内部可能有内存泄漏。（上面的图仅供示例，在实际情况下收集数据的时间需要更长，比如几个小时或者几天） 解决： ​ 一般就是根据垃圾回收前后情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。 持久代被占满异常：java.lang.OutOfMemoryError: PermGen space 说明： ​ Perm空间被占满。无法为新的class分配存储空间而引发的异常。这个异常以前是没有的，但是在Java反射大量使用的今天这个异常比较常见了。主要原因就是大量动态反射生成的类不断被加载，最终导致Perm区被占满。 ​ 更可怕的是，不同的classLoader即便使用了相同的类，但是都会对其进行加载，相当于同一个东西，如果有N个classLoader那么他将会被加载N次。因此，某些情况下，这个问题基本视为无解。当然，存在大量classLoader和大量反射类的情况其实也不多。 解决： ​ 1. -XX:MaxPermSize=16m ​ 2. 换用JDK。比如JRocket 线程堆栈满异常：Fatal: Stack size too small 说明：java中一个线程的空间大小是有限制的。JDK5.0以后这个值是1M。与这个线程相关的数据将会保存在其中。但是当线程空间满了以后，将会出现上面异常。 解决： 增加线程栈大小。-Xss2m。但这个配置无法解决根本问题，还要看代码部分是否有造成泄漏的部分。 系统内存被占满异常：java.lang.OutOfMemoryError: unable to create new native thread 说明： ​ 这个异常是由于操作系统没有足够的资源来产生这个线程造成的。系统创建线程时，除了要在Java堆中分配内存外，操作系统本身也需要分配资源来创建线程。因此，当线程数量大到一定程度以后，堆中或许还有空间，但是操作系统分配不出资源来了，就出现这个异常了。 分配给Java虚拟机的内存愈多，系统剩余的资源就越少，因此，当系统内存固定时，分配给Java虚拟机的内存越多，那么，系统总共能够产生的线程也就越少，两者成反比的关系。同时，可以通过修改-Xss来减少分配给单个线程的空间，也可以增加系统总共内生产的线程数。 解决： ​ 1. 重新设计系统减少线程数量。 ​ 2. 线程数量不能减少的情况下，通过-Xss减小单个线程大小。以便能生产更多的线程。 参考资料： JVM调优总结","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"堆栈","slug":"堆栈","permalink":"http://lvshen9.gitee.io/tags/堆栈/"},{"name":"JVM","slug":"JVM","permalink":"http://lvshen9.gitee.io/tags/JVM/"}]},{"title":"读书笔记：《锋利的jQuery》","slug":"读书笔记：《锋利的jQuery》","date":"2017-09-05T06:25:40.000Z","updated":"2017-09-05T06:47:08.028Z","comments":true,"path":"2017/09/05/读书笔记：《锋利的jQuery》/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/05/读书笔记：《锋利的jQuery》/","excerpt":"本文作者： Cherry 本文链接： http://cherryblog.site/sharp-jquery.html 锋利的jQuery 前一段在当当和京东上趁着打折买了十几本编程的书，励志要全部看完！在此立一个 flag，最近也是一直在读书，发现书中更能深入的学到系统的知识。并且如果再能将书中的内容用自己的语言表达出来那就更好了。 书名：《锋利的 jQuery》 简介：这本书适合初学 JS 的童靴看~内容比较基础，我是想看 JQ 源码，然后发现和源码没有半毛钱关系，只是比较全的介绍 jQuery 的用法。对没有系统看过 jQuery 用法的，或者 js 的初学者还是有一定帮助的，但是如果你有一定的 js 基础，还是不要浪费时间了。其实 jQuery 好多的用法我们并不清楚，只是将 jQuery 当做方便的元素选择器来使用，其实 jQuery 能做的远比这多得多。 推荐指数：☆☆☆","text":"本文作者： Cherry 本文链接： http://cherryblog.site/sharp-jquery.html 锋利的jQuery 前一段在当当和京东上趁着打折买了十几本编程的书，励志要全部看完！在此立一个 flag，最近也是一直在读书，发现书中更能深入的学到系统的知识。并且如果再能将书中的内容用自己的语言表达出来那就更好了。 书名：《锋利的 jQuery》 简介：这本书适合初学 JS 的童靴看~内容比较基础，我是想看 JQ 源码，然后发现和源码没有半毛钱关系，只是比较全的介绍 jQuery 的用法。对没有系统看过 jQuery 用法的，或者 js 的初学者还是有一定帮助的，但是如果你有一定的 js 基础，还是不要浪费时间了。其实 jQuery 好多的用法我们并不清楚，只是将 jQuery 当做方便的元素选择器来使用，其实 jQuery 能做的远比这多得多。 推荐指数：☆☆☆ jQuery 的优势 强大的选择器 出色的 DOM 操作的封装 可靠的事件处理机制 完善的 Ajax 不污染顶级变量 出色的浏览器兼容性 链式操作方式 隐式迭代 行为层与结构层分离 丰富的插件支持 完善的文档 开源 不污染顶级变量jQuery 只建立一个名为 jQuery 的对象，其所有的函数方法都在这个对象之下。其别名 $ 也可以随时交出控制权，绝对不会污染其他变量。该特性使 jQuery 可以与其他 JavaScript 库共存。 链式操作方式jQuery 的链式操作方式：对放生在同一个 jQuery 对象上的一组动作，可以直接连写而无需重复获取对象。 隐式迭代当用 jQuery 找到带有 “.myClass” 类的全部元素，然后隐藏它们时，无需循环遍历每一个返回的元素。jQuery 里的方法都被设计成自动操作对象集合，而不是单独的对象 jQuery 代码的编写在 jQuery 库中，$ 就是 jQuery 的一个简写形式，例如 $(#.foo) 与 jQuery(#.foo) 是等价的 window.onload 和 $(document).ready() 对比 – window.onload $(document).ready() 执行时间 必须等待网页中所有的内容加载完毕（）包括图片才执行 只需要 DOM 加载完就执行（不包括图片等） 编写个数 不能同时编写多个 能同时编写多个 简化写法 无 $(document).ready(function(){}) 可以简写成 $(function(){}) jQuery 的链式操作风格jQuery 的链式操作方式：对放生在同一个 jQuery 对象上的一组动作，可以直接连写而无需重复获取对象。例如： 1$(this).addClass(\"current\").next().show().parent().siblings().children(\"a\").removeClass(\"current\").next().hide(); 为了阅读方便，也可以将代码改为如下格式： 1234$(this).addClass(\"current\") // 给当前元素添加 \"current\" 样式.next().show() // 下一个元素显示.parent().siblings().children(\"a\").removeClass(\"current\") // 父元素的同辈元素的子元素 &lt;a&gt; 移除 \"current\" 样式.next().hide(); // 他们的下一个元素隐藏 jQuery 对象和 DOM 对象DOM 对象就是 DOM 树种的节点，通过原生 JavaScript 的 getElementsByTagName 或者getElementsByTagId 等获取，DOM 对象可以使用 JavaScript 中的方法。 jQuery 对象是通过 jQuery 包装 DOM 过后的对象。 在 jQuery 对象上无法使用 DOM 对象的任何方法，同理，也不能在 DOM 对象上使用任何 jQuery 的方法啊。所以我们要区分什么是 jQuery 的方法，什么是 JS 原生的方法。例如，下面这些都是错误的 123$(\"#id\").innerHTML$(\"#id\").checkeddocument.getElementById(\"id\").html() jQuery 对象和 DOM 对象相互转换为了能更好的区分哪些是 jQuery 哪些是 DOM 对象，我们约定俗成使用 jQuery 获取的对象我们在变量前面加上 $ 符号。 jQuery 对象转化为 DOM 对象 [index] 方法，就是在 jQuery 对象后面加上索引，比如： 123var $cr = $(#cr); // jQuery 对象var cr = $cr[0]; // 将 jQuery 转化为 DOM 对象alert( cr.checked ); // 检查是否转化成功 get(index) 方法 123var $cr = $(#cr); // jQuery 对象var cr = $cr.get(0); // 将 jQuery 转化为 DOM 对象alert( cr.checked ); // 检查是否转化成功 DOM 对象转化为 jQuery 对象DOM 对象转化为 jQuery 对象很简单，只需要用 $() 将 DOM 对象包装起来就好。 12var cr = document.getElmentByID(\"cr\"); // DOM 对象var $cr = $(cr) // 将 DOM 对象转为 jQuery 对象 解决 jQuery 和其他库的冲突之前遇到过类似的问题，是使用的插件需要较低版本的 jQuery（因为不进行维护了），然后和项目中使用的较高版本的 jQuery 不兼容，所以在网上查到了一个项目中是可以使用两个不同版本的 jQuery 的。 在 jQuery 库中，几乎所有的插件都被限制在它的命名空间里。通常，全局对象都被很好地储存在 jQuery 的命名空间里。因此和其他库一起使用时，不会引起冲突。 默认情况下，jQuery 用 $ 作为自身的快捷方式。 jQuery 库在其他库之后导入在其他库和 jQuery 库都被加载完毕后，可以在任何时候调用 jQuery.noConflict()函来将变量 $ 的控制权移交给其他 JavaScript 库。 12345678910// 引入 其他 JS 库// 引入 jQuery&lt;script&gt; jQuery.noConflict(); // 将变量 $ 的控制权移交给其他 JS 库 jQuery(function()&#123; jQuery(\"p\").click(function)&#123; alert( jQuery(this).text() ); &#125; &#125;)&lt;/script&gt; 也可以自定义一个快捷方式： 12345678910// 引入 其他 JS 库// 引入 jQuery&lt;script&gt; $j.noConflict(); // 将变量 $ 的控制权移交给其他 JS 库 $j(function()&#123; $j(\"p\").click(function)&#123; alert( $j(this).text() ); &#125; &#125;)&lt;/script&gt; 如果你还想继续使用 $ 而不管其他函数的 $() 方法，同时又不想与其他库冲突，那么你可以 123456jQuery.noConflict(); // 将变量 $ 的控制权移交给其他 JS 库(function( $ )&#123; // 定义匿名函数并设置形参 $ $(\"p\").click(function)&#123; alert( $(this).text() ); &#125;;&#125;(jQuery)); // 执行匿名函数并设置形参 jQuery jQuery 库在其他库之前导入如果 jQuery 库在其他库之前导入，那么就可以直接使用“jQuery”来做一些 jQuery 的工作，同时可以使用 $() 方法作为其他库的快捷方式（也就是说不需要写 jQuery.noConflict();） jQuery 选择器基本选择器 选择器 描述 返回 #id 根据给定的 ID 匹配一个元素 单个元素 .class 根据给定的类名匹配一个元素 集合元素 element 根据给定的元素名匹配一个元素（相当于 tagName ） 集合元素 * 匹配所有元素 集合元素 select1,select2,select3 将每一个选择器匹配到的元素合并后一起返回 集合元素 层次选择器 选择器 描述 返回 ancestor descendant(空格) 选取 ancestor 元素里所有的 descendant（后代）元素 集合元素 parent &gt; child 选取子元素 集合元素 prev + next 选取紧接在 prev 元素后面的 next 元素 集合元素 prev + siblings 选取 prev 元素之后的所有 siblings 元素 集合元素 过滤选择器 选择器 描述 返回 :first 选取第一个元素 单个元素 :last 选取最后一个元素 单个元素 :not(selector) 去除所有与给定选择器匹配的元素 集合元素 :even 索引为偶数（索引从 0 开始） 集合元素 :odd 索引为奇数（索引从 0 开始） 集合元素 :eq(index) 索引等于 index 的元素（index 从 0 开始） 单个元素 :gt(index) 索引大于 index 集合元素 :lt(index) 索引小于 index 集合元素 :header(index) 所有的标题元素 h1、h2、h3 等 集合元素 :animated 正在执行动画的所有元素 集合元素 :focus 当前获取焦点的元素 集合元素 内容过滤选择器 选择器 描述 返回 :contains(text) 文本中含有 “text” 的元素 集合元素 :empty 不包含子元素或者文本的空元素 集合元素 :has(selector) 含有选择器所匹配的元素 集合元素 :parent 含有子元素或文本 集合元素 :hidden 选取所有不可见的元素 集合元素 :visible 选取所有可见的元素 集合元素 属性过滤选择器 选择器 描述 返回 示例 [attribute] 拥有此属性的元素 集合元素 $(&quot;div[id]&quot;) 选择所有拥有 id 属性的 div [attribute=value] 属性的值为 value 的元素 集合元素 $(&quot;div[tittle = test]&quot;) 属性title 为 test的 div [attribute!=value] 属性的值不为 value 的元素 集合元素 $(&quot;div[tittle != test]&quot;) 属性title 不为test 的 div [attribute^=value] 属性的值以 value 开始的元素 集合元素 $(&quot;div[tittle^ = test]&quot;) 属性title 以 test开始的 div [attribute$=value] 属性的值为 value 结束的元素 集合元素 [attribute*=value] 属性的值含有 value 的元素 集合元素 [attribute\\ =value] 属性的值等于或者以该字符串为前缀（该字符后跟 -字符）的元素 value 的元素 集合元素 [attribute~=value] 属性的用空格分隔的值中包含一个给定的 value 集合元素 [attribute][attrubute][attribute] 用属性选择器合并成一个复合属性选择器，满足多个条件，每选择一次，缩小一次范围 集合元素 子元素过滤选择器 选择器 描述 返回 :nth-child(index/even/odd/equation) 选取每个父元素下的第 index 个子元素或者奇偶元素（index 从 1 开始） 集合元素 :first-child 选取每个父元素第一个子元素 集合元素 :last-child 选取每个父元素最后一个子元素 集合元素 :only-child 如果某个元素是它父元素中唯一的子元素，则会被匹配 集合元素 表单过滤选择器 选择器 描述 返回 :enabled 选取所有可用元素 集合元素 :disable 选取所有不可用元素 集合元素 :checked 选取所有被选中元素（复选框、单选框） 集合元素 :selected 选取所有被选中元素（下拉列表） 集合元素 表单选择器 选择器 描述 返回 :input 选取所有的 集合元素 :text 选择所有单行文本框 集合元素 :password 选择所有的密码框 集合元素 :radio 选择所有的单选框 集合元素 :checkout 选择所有的多选框 集合元素 :submit 选择所有的提交按钮 集合元素 :image 选择所有的图像按钮 集合元素 :reset 选择所有的重置按钮 集合元素 :button 选择所有的按钮 集合元素 :file 选择所有的上传域 集合元素 :hidden 选择所有的不可见元素 集合元素 jQuery 选择器完善的处理机制 如果元素不存在时，JS 不会保存阻塞其他代码的运行。 $(#ID) 或者其他选择器获取的永远是对象，即使网页上没有此元素。使用 jQuery 检查某个元素是否存在要不能使用 123if( $(#tt) )&#123; dosomething&#125; 而是根据元素是否有长度判断： 123if( $(#tt).length &gt; 0 )&#123; dosomething&#125; 或者转化为 DOM 元素来判断 123if( $(#tt)[0] )&#123; dosomething&#125; jQuery 中的 DOM 操作HTML DOM 操作插入节点 方法 描述 示例 append() 向每个匹配的元素内部追加内容 $(A).append(B) 将 B 追加到 A 中 appendTo() 将所有匹配的元素追加到指定元素中 $(B).appendTo(A) 将 B 追加到 A 中 prepend() 向每个匹配的元素内部前置内容 after() 在每个匹配的元素之后插入内容 $(A).after(B) 将 B 插入到 A 后面 insertAfter() 将所有匹配的元素插入到指定元素的后面 $(B).insert After(A) 将 B 插入到 A 后 before() 在每个匹配的元素之前插入内容 $(A).before(B) 将 B 插入在 A 的前面 insertBefore() 将所有匹配的元素插入到指定元素的前面 $(B).insertBefore(A) 将 B 插入在 A 的前面 删除节点remove()从 DOM 中删除所有匹配的元素，传入的参数用于根据 jQuery 表达式来删选元素 12$(\"ul li:eq(1)\").remove(); // 获取第二个 &lt;li&gt; 元素节点后，将它从网页中删除$li.appendTo(\"ul\"); // 把刚才删除的元素添加到 &lt;ul&gt; 元素中 这个方法的返回值是一个指向已被删除的节点的引用，因此可以将其保存在一个变量中，以后还可以使用。 detach()detach() 和 delete() 一样，也是从 DOM 中去掉所有匹配的元素，但是两者的区别是，这个方法不会把匹配的元素从 jQuery 对象中删除，去掉的元素的所有绑定的事件、附加的数据等都会保留下来。 empty()清空元素中所有的后代节点。注意是清空元素内的所有节点，并不清除选中的元素 复制节点复制节点可以使用 clone() 方法 123$(\"ul li\").click(function()&#123; $(this).clone().appendTo(\"ul\");&#125;) 但是这样复制的节点，被复制的新元素并不具有任何行为，如果需要新元素也具有相同的行为，那么就需要在 clone() 方法中传入参数 true 123$(\"ul li\").click(function()&#123; $(this).clone(true).appendTo(\"ul\");&#125;) 其他方法 方法名 描述 replaceWith() 将所有匹配的元素都替换成 HTML 或者 DOM 元素，绑定的事件将会消失 replaceAll() 和 replaceWith() 相反 wrap() 将所有的元素单独包裹 wrapAll() 将所有匹配的元素用一个元素来包裹 如果被包裹的元素中间有其他的元素，那么其他的元素会被放到包裹元素之后 wrapInner() 将每一个匹配的元素的字内容（包括文本节点）用其他结构化的标记包裹起来 attr() 获取和设置元素属性，传递一个参数为获取元素属性，传递两个参数为设置元素属性 removeAttr() 删除文档中某个元素的特定属性 addClass() 追加样式 removeClass() 移除样式 如果参数为空，则清空该元素的所有 class toggleClass() 切换样式 如果类名存在则删除，如果类名不存在则添加 hasClass() 是否含有某个样式，返回布尔值 html() 读取或者设置某个元素中的 HTML 内容 传递一个参数为获取 HTML 中的内容，传递两个参数为设置 HTML 的内容 text() 读取或者设置某个元素中的文本内容 传递一个参数为获取文本内容，传递两个参数为设置文本内容 val() 读取或设置元素的值 在用于表单元素时，可以设置相应的元素被选中 children() 获得匹配元素的子元素的集合 （子元素非后代元素） next() 获得匹配元素后面紧邻的同辈元素 prev() 获得匹配元素前面紧邻的同辈元素 siblings() 获得匹配元素前后面紧邻的同辈元 closest() 取得最近的匹配元素 parent() 获得集合中每个元素的父级元素 parents() 获得集合中每个元素的祖先元素 closest() 从元素本身开始，逐级向上级元素匹配，并返回最先匹配的祖先元素 CSS DOM 操作 方法 描述 css() 读取和设置 style 对象的各种属性（如果值是数字，将会自动转化为像素值，样式名不带 “”样式使用驼峰写法）offset() | 获取元素在当前视窗的相对偏移，返回的对象包含两个属性 top、leftposition() | 获取元素相对于最近一个 position 样式属性设置为 relation 或者 absolute 的父节点的相对偏移scrollTop() 、scrollLeft() | 获取元素滚动条距离顶端的距离和距离左侧的距离 JS 中的事件事件绑定1bind(type [, date ], fn ) 第一个参数是事件类型，类型包括：blur focus load resize scroll unload cliock``dblclick mousedown mouseup mouseover mouseout mouseenter mouseleave change``select submit keyup keydown keypress keyup error 第二个参数为可选参数，作为 event.data 属性值传递给事件对象的额外数据对象 第三个参数是用来绑定的处理函数 jQuery 的事件处理函数比 JS 原生的事件处理函数少了个 on 像 click mouseover mouseout 这类事件，可以直接简写 合成事件jQuery 中有两个合成事件，hover() toggle() hover()1hover(enter,leave) hover(fn1,fn2,...fnN) 方法用于模拟光标悬停事件，当光标移动到元素上时，会触发第一个函数（enter），当光标移出这个元素时会触发第二个函数（leave） toggle()toggle() 方法用于模拟鼠标的连续点击事件，第一次单击元素，触发第一个函数，第二次单击同一个元素，会触发第二个函数，如果有更多的函数，则依次触发，直到最后一个。 事件冒泡假设网页上有两个元素，其中一个嵌套在另一个元素里面，并且都被绑定了 click 事件。同时 &lt;body&gt; 元素上也绑定了 click 事件，这样的话，点击最内层的元素，会触发三次 click 事件。这是因为 JavaScript 的事件冒泡机制。 在 jQuery 中，提供了 stopPropagation() 方法来停止冒泡。 阻止默认行为网页中有自己的默认行为，例如单击超链接会跳转，单击“提交”按钮后表单会提交，有时需要阻止默认行为。 jQuery 提供了 preventDefault() 方法来阻止元素的默认行为。 事件对象的属性 方法名称 描述 event.type 获取到事件的类型 event.preventDefault() 阻止默认的事件行为 stopPropagation() 阻止事件冒泡 event.tagent() 获取到触发事件的元素 event.relatedTarget() mousover 和 mouseout 所发生的元素 event.pageX event.pageY 获取到光标相对于页面的 x 坐标和 y 坐标 event.which() 鼠标单击事件中获取到的左、中、右键，在键盘事件中获取键盘的按键 event.metaKey() 为键盘事件获取 ctrl 键 移除事件1unbind([type],[data]) 第一个参数是事件类型，第二个参数是要移除的函数。如果没有参数，则删除所有的绑定事件 one() 方法对于只要触发一次，随后要立即解除绑定的情况，jQuery 提供了 one() 方法。当处理函数触发一次后，立即被删除。 模拟操作trigger() 方法完成模拟操作， 1trigger(type,[data]) 第一个参数是要触发的事件类型，第二个参数是要传递给事件处理函数的附加参数，可以通过传递的参数来区分这次事件是代码触发还是用户触发的 jQuery 中的动画 方法名 说明 hide() show() 同时修改多个样式属性，即高度、宽度和不透明度 fadeIn() fadeOut() 只改变不透明度 slideUp() slideDown() 只改变高度 toggle() 用来代替 hide() 和 show() 方法 slideToggle() 用来代替 slideUp() 和 slideDown() fadeToggle() 用来代替 fadeIn() 和 fadeOut() animate() 属于自定义动画的方法 jQuery 中的任何动画效果，都可以指定三种速度参数，slow、normal、fast，对应的时间长度分别是 0.6 秒，0.4 秒和 0.2 秒，也可以传入参数，传入数字作为参数不需要加引号，使用关键字需要加引号。 动画队列当一个 animate() 方法中应用多个属性时，动画是同时发生的。当以链式方法调用时，动画是按顺序发生（除非 queue 选项为 false）。默认情况下，动画都是同时发生的。当以回调的形式应用动画方式时，按照回调顺序发生。 停止动画1stop([clearQueue,gotoEnd]) clearQueue 是否要清空未执行的动画队列gotoEnd 是否直接跳转到末状态 判断元素是否处于动画状态要始终避免动画累计而导致的动画与用户行为不一样的情况。当用户快速在某个元素上执行 animate()时，就会出现动画累加。 解决方法是判断元素是否处于动画状态，如果用户不处于动画状态，才为元素添加新的动画，否则不添加。 延迟动画在动画执行的过程中，如果想对动画进行延迟操作，那么可以使用 delay() 方法。 jQuery 与 AjaxAjax 的优势 不需要插件的支持 优秀的用户体验 提高 Web 程序的性能 减轻服务器和带宽的负担 Ajax 的不足 浏览器对 XMLHttpRequest 对象的支持度不足 破坏浏览器前进后退按钮的正常功能 对搜索引擎的支持程度不够 开发和调试工具的缺乏 使用原生 JS 写一个 Ajax 定义一个函数，通过该函数来获取异步信息 123function Ajax()&#123; // 定义一个函数，通过该函数来获取异步信息 &#125; 声明一个空对象来装入 XMLHttpRequest 对象 1var xmlHttpReq = null; // 声明一个空对象来装入 XMLHttpRequest 对象 实例化一个 XMLHttpRequest 对象 123if(window.XMLHttpRequest)&#123; xmlHttpReq = new XMLHttpRequest(); // 实例化一个 XMLHttpRequest 对象&#125; 使用 open() 方法初始化 XMLHttpRequest 对象，指定 HTTP 方法和要使用的服务器 URL; 1xmlHttpReq.open(\"GET\",\"test.php\",true); // 调用 open() 方法并采用异步方式 使用 onreadystatechange 属性来注册该回调事件处理器，当 readystatus 状态改变时，会激发 onreadystatechange 事件然后调用回调函数。 1xmlHttpReq.onreadystatechange = RequestCallBack; 使用 send() 方法发送请求，使用 GET 方式可以不指定参数或者使用 null 参数 1xmlHttpReq.send(null); 当请求状态改变时，XMLHttpRequest 对象调用 onreadystatechange 属性注册的事件处理器，在处理响应之前，事件处理器应该首先检查 readyStatus 的值和 HTTP 状态。当请求完成加载（readyStatus == 4）并且响应已经成功（HTTP 状态值为 200），就可以处理响应内容； 1234567function RequestCallBack() &#123; if(xmlHttpReq.readyState == 4)&#123; if(xmlHttpReq.status == 200)&#123; document.getElementById(\"resText\").innerHTML = xmlHttpReq.responseText; &#125; &#125;&#125; jQuery 中的 AjaxjQuery 对 Ajax 操作进行封装，在 jQuery 中，$.ajax() 是最底层的方法，第二层是load()、$.get()、$.post()、$.grtJSON()。 load() 方法载入 HTML 文档1load( url [,data] [,callback]) 参数列表 类型 说明 url String 请求 HTML 页面的 URL 地址 data Object 发送至服务器的 key/value 数据 callback Function 请求完成时的回调函数，无论请求失败或成功 比如说我们要将一个页面追加到另一个页面，被追加的文件为 inner.html，内容如下 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;测试&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 内容只有一个 &lt;p&gt; 标签，然后我们创建另一个页面，用来触发 Ajax 事件，并用来显示追加的 HTML，页面内容如下： 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"../jQuery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;input type=\"button\" id=\"send\" value=\"获取\"&gt;&lt;div id=\"resText\"&gt;&lt;/div&gt;&lt;script&gt; $(function () &#123; $('#send').click(function () &#123; $('#resText').load('inner.html') &#125;) &#125;)&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 当，点击按钮时，页面如下：[ load() 方法](http://img.blog.csdn.net/20170821122356450?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc3Vuc2hpbmU5NDAzMjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 载入部分 HTML 文档当前我们也可能载入部分的 HTML 文档，例如只需要载入 inner.html 中的 test 类，那么： 1$('#resText').load('inner.html .test') 传递方式，如果没有设置传递方式，那么使用 GET 方式，如果有传递参数，那么为 POST 方式。回调12345$('#resText').load('inner.html .test', functiong(responseText,textStatus,XMLHttpRequest)&#123; // responseText : 请求返回的内容 // textStatus : success、error、notmodified、timeout // XMLHttpRequest : XMLHttpRequest 对象&#125;) $.get() 方法$.get() 方法使用 GET 方式来进行异步请求 1$.get( url [, data] [, callback] [, type]) 参数名称 类型 说明 url String 请求 HTML 页的 URL 地址 data（可选） Object 发送至服务器的 key/value 数据会作为 QueryString 附加到请求 URL 中 callback（可选） Function 载入成功时回调函数（只有当 Reaponse 的返回状态是 success 才调用）自动将请求的结果和状态传递给方法 type（可选） String 服务器端返回内容的格式，包括 xml、html、script、json、text、_default $.post() 方法$.post() 方法使用 GET 方式来进行异步请求 1$.post( url [, data] [, callback] [, type]) GET 方式和 POST 请求方式的区别 GET 请求将参数跟在 URL 后进行传递，POST 则作为 HTTP 消息的实体内容发送给 web 服务器， GET 方式通常传递的数据不超过 2kb，POST 方式理论上没有限制 GET 方式请求的数据会被浏览器缓存起来， $.ajax() 方法$.ajax() 方法是 jQuery 最底层的 Ajax 实现， 1$.ajax(option) 参数名称 类型 说明 url String 发送请求的 URL（默认为当前页面） type String 请求方式，默认为 GET timeout Number 设置请求超时时间（毫秒） data Object 或 String 发送到服务器的数据 dataTpye String 预期服务器返回的数据类型 beforeSend Function 发送请求前可以修改 XMLHttpResponse 对象的函数 complete Function 请求完成后调用的回调函数（请求失败或者成功均调用） success Function 请求成功后调用的回调函数 error Function 请求失败后调用的回调函数 global Function 默认为 true。是否触发全局 Ajax 事件 序列化元素serialize() 方法能够将 DOM 元素内容序列化为字符串，用于 Ajax 请求。即使在表单中再增加字段，脚本仍然能够使用。并且不需要做其他多余工作。 serializeArray() 方法，该方法不是返回字符串，是将 DOM 序列化后，返回 JSON 格式的数据。 $.param() 方法，用来对一个数组或对象按照 key/value 进行序列化。 123var obj = &#123;a:1,b:2,c:3&#125;;var k = $.param(obj);alert(k); // 输出 a=1&amp;b=2&amp;c=3 jQuery 性能优化使用合适的选择器 $(“#id”) id 选择器无疑是最佳提高性能的方式。因为 jQuery 底层直接调用本地方法document.getElementById()，直接通过 id 返回对应的元素可以有效的缩小你定位的 DOM 元素，建议从最近的 ID 元素开始往下搜索。 $(“p”)、$(“div”)、$(“input”) 标签选择器是性能优化第二选择，因为 jQuery 也是直接调用 JS 原生方法 $(“.class”) 这是 jQuery 封装的函数，ie9+ 以上是使用 JS 的原生方法，ie9 一下是使用 DOM 搜索方式来实现 $(“[attribute=value]”)：利用属性来定位 DOM 元素，大部分都是使用 DOM 搜索方式来达到效果。所以性能并不是很理想 $(“:hidden”)：这和上面利用属性类似，并且 jQuery 需要搜索每一个元素来定位这个选择器，所以尽量不要使用。 缓存对象我们可以将经常用的对象使用变量缓存起来，因为 jQuery 会在创建每一个选择器的过程中，查找 DOM。不要让相同的选择器在你的代码中出现多次。 循环时的 DOM 操作在一些循环时，例如 for()、while()、$.each() 使用这些方法处理 DOM 元素时，要尽可能的减少操作 DOM，可以使用变量将来储存元素，最后一次性将生产的 DOM 插入或者删除。 数组方式使用 jQuery 对象使用 jQuery 选择器获得的结果是一个 jQuery 对象，然而，jQuery 类库会让你感觉你正在使用一个定义了索引和长度的数组。在性能方面，建议使用 for 或者 while 循环来处理，而不是 $.each() 事件代理每一个 JavaScript 事件（例如：click、mouseover 等）都会冒泡到父节点，当我们需要给多个元素调用同个函数时会很有用。 比如，我们要单击表格的行使得改行背景颜色改变 123$(\"myTable td\").click(function()&#123; $(this).css(\"background\",'red')&#125;) 如果你是这样写的话，那么恭喜你，提供了一个错误的示例，🎉🎉。这样的弊端是，假使总共有 100 个 td，那么在使用以上方式的时候，你绑定了 100 个事件，天辣，是不是很恐怖。 正确的姿势是，只需要向他们的父节点绑定一次事件，然后通过 event.target 获取到当前点击的元素。 1234$(\"myTable\").click(function()&#123; var $clicked = $(e.target); // 捕捉到触发的目标元素 $clicked.css(\"background\",'red');&#125;) 也可以这样写 123$(\"myTable td\").on('click','td', function()&#123; $(this).css(\"background\",'red')&#125;)","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lvshen9.gitee.io/tags/JavaScript/"},{"name":"jQuery","slug":"jQuery","permalink":"http://lvshen9.gitee.io/tags/jQuery/"}]},{"title":"【Java】泛型详解","slug":"【Java】泛型详解","date":"2017-09-05T06:08:16.000Z","updated":"2017-09-05T06:22:29.777Z","comments":true,"path":"2017/09/05/【Java】泛型详解/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/05/【Java】泛型详解/","excerpt":"本文来自 Itimetraveler’s Blog： 【Java】泛型详解 一. 为什么需要泛型？首先，我们看下下面这段简短的代码: 1234567891011121314public class GenericTest &#123; public static void main(String[] args) &#123; List list = new ArrayList(); list.add(\"qqyumidi\"); list.add(\"corn\"); list.add(100); for (int i = 0; i &lt; list.size(); i++) &#123; String name = (String) list.get(i); // ① 错误 System.out.println(\"name:\" + name); &#125; &#125;&#125; 定义了一个List类型的集合，先向其中加入了两个字符串类型的值，随后加入一个Integer类型的值。这是完全允许的，因为此时list默认的类型为Object类型。在之后的循环中，由于忘记了之前在list中也加入了Integer类型的值或其他编码原因，很容易出现类似于//①中的错误。因为编译阶段正常，而运行时会出现“java.lang.ClassCastException”异常。因此，导致此类错误编码过程中不易发现。","text":"本文来自 Itimetraveler’s Blog： 【Java】泛型详解 一. 为什么需要泛型？首先，我们看下下面这段简短的代码: 1234567891011121314public class GenericTest &#123; public static void main(String[] args) &#123; List list = new ArrayList(); list.add(\"qqyumidi\"); list.add(\"corn\"); list.add(100); for (int i = 0; i &lt; list.size(); i++) &#123; String name = (String) list.get(i); // ① 错误 System.out.println(\"name:\" + name); &#125; &#125;&#125; 定义了一个List类型的集合，先向其中加入了两个字符串类型的值，随后加入一个Integer类型的值。这是完全允许的，因为此时list默认的类型为Object类型。在之后的循环中，由于忘记了之前在list中也加入了Integer类型的值或其他编码原因，很容易出现类似于//①中的错误。因为编译阶段正常，而运行时会出现“java.lang.ClassCastException”异常。因此，导致此类错误编码过程中不易发现。 在如上的编码过程中，我们发现主要存在两个问题： 当我们将一个对象放入集合中，集合不会记住此对象的类型，当再次从集合中取出此对象时，改对象的编译类型变成了Object类型，但其运行时类型任然为其本身类型。 因此，//① 处取出集合元素时需要人为的强制类型转化到具体的目标类型，且很容易出现“java.lang.ClassCastException”异常。 那么有没有什么办法可以使集合能够记住集合内元素各类型，且能够达到只要编译时不出现问题，运行时就不会出现“java.lang.ClassCastException”异常呢？答案就是使用泛型。 二. 什么是泛型？泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 看着好像有点复杂，首先我们看下上面那个例子采用泛型的写法。 123456789101112131415161718192021public class GenericTest &#123; public static void main(String[] args) &#123; /* List list = new ArrayList(); list.add(\"qqyumidi\"); list.add(\"corn\"); list.add(100); */ List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"qqyumidi\"); list.add(\"corn\"); //list.add(100); // 1 提示编译错误 for (int i = 0; i &lt; list.size(); i++) &#123; String name = list.get(i); // 2 无须进行强制类型转换 System.out.println(\"name:\" + name); &#125; &#125;&#125; 采用泛型写法后，在//1处想加入一个Integer类型的对象时会出现编译错误，通过List，直接限定了list集合中只能含有String类型的元素，从而在//2 处无须进行强制类型转换，因为此时，集合能够记住元素的类型信息，编译器已经能够确认它是String类型了。 结合上面的泛型定义，我们知道在List中，String是类型实参，也就是说，相应的List接口中肯定含有类型形参。且get()方法的返回结果也直接是此形参类型（也就是对应的传入的类型实参）。下面就来看看List接口的的具体定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); Iterator&lt;E&gt; iterator(); Object[] toArray(); &lt;T&gt; T[] toArray(T[] a); boolean add(E e); boolean remove(Object o); boolean containsAll(Collection&lt;?&gt; c); boolean addAll(Collection&lt;? extends E&gt; c); boolean addAll(int index, Collection&lt;? extends E&gt; c); boolean removeAll(Collection&lt;?&gt; c); boolean retainAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); E get(int index); E set(int index, E element); void add(int index, E element); E remove(int index); int indexOf(Object o); int lastIndexOf(Object o); ListIterator&lt;E&gt; listIterator(); ListIterator&lt;E&gt; listIterator(int index); List&lt;E&gt; subList(int fromIndex, int toIndex);&#125; 我们可以看到，在List接口中采用泛型化定义之后，&lt;E&gt;中的 E 表示类型形参，可以接收具体的类型实参，并且此接口定义中，凡是出现E的地方均表示相同的接受自外部的类型实参。 自然的，ArrayList作为List接口的实现类，其定义形式是： 123456789101112131415161718public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; public E get(int index) &#123; rangeCheck(index); checkForComodification(); return ArrayList.this.elementData(offset + index); &#125; //...省略掉其他具体的定义过程&#125; 由此，我们从源代码角度明白了为什么//1处加入Integer类型对象编译错误，且//2处get()到的类型直接就是String类型了。 三. 自定义泛型接口、泛型类和泛型方法从上面的内容中，大家已经明白了泛型的具体运作过程。也知道了接口、类和方法也都可以使用泛型去定义，以及相应的使用。是的，在具体使用时，可以分为泛型接口、泛型类和泛型方法。 自定义泛型接口、泛型类和泛型方法与上述Java源码中的List、ArrayList类似。如下，我们看一个最简单的泛型类和方法定义： 123456789101112131415161718192021222324252627public class GenericTest &#123; public static void main(String[] args) &#123; Box&lt;String&gt; name = new Box&lt;String&gt;(\"corn\"); System.out.println(\"name:\" + name.getData()); &#125;&#125;class Box&lt;T&gt; &#123; private T data; public Box() &#123; &#125; public Box(T data) &#123; this.data = data; &#125; public T getData() &#123; return data; &#125;&#125; 在泛型接口、泛型类和泛型方法的定义过程中，我们常见的如T、E、K、V等形式的参数常用于表示泛型形参，由于接收来自外部使用时候传入的类型实参。那么对于不同传入的类型实参，生成的相应对象实例的类型是不是一样的呢？ 1234567891011121314public class GenericTest &#123; public static void main(String[] args) &#123; Box&lt;String&gt; name = new Box&lt;String&gt;(\"corn\"); Box&lt;Integer&gt; age = new Box&lt;Integer&gt;(712); System.out.println(\"name class:\" + name.getClass()); // com.qqyumidi.Box System.out.println(\"age class:\" + age.getClass()); // com.qqyumidi.Box System.out.println(name.getClass() == age.getClass()); // true &#125;&#125; 由此，我们发现，在使用泛型类时，虽然传入了不同的泛型实参，但并没有真正意义上生成不同的类型，传入不同泛型实参的泛型类在内存上只有一个，即还是原来的最基本的类型（本实例中为Box），当然，在逻辑上我们可以理解成多个不同的泛型类型。 究其原因，在于Java中的泛型这一概念提出的目的，导致其只是作用于代码编译阶段，在编译过程中，对于正确检验泛型结果后，会将泛型的相关信息擦出，也就是说，成功编译过后的class文件中是不包含任何泛型信息的。泛型信息不会进入到运行时阶段。 对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。 四. 类型通配符接着上面的结论，我们知道，Box&lt;Number&gt;和Box&lt;Integer&gt;实际上都是Box类型，现在需要继续探讨一个问题，那么在逻辑上，类似于Box&lt;Number&gt;和Box&lt;Integer&gt;是否可以看成具有父子关系的泛型类型呢？ 为了弄清这个问题，我们继续看下下面这个例子: 1234567891011121314151617181920public class GenericTest &#123; public static void main(String[] args) &#123; Box&lt;Number&gt; name = new Box&lt;Number&gt;(99); Box&lt;Integer&gt; age = new Box&lt;Integer&gt;(712); getData(name); //The method getData(Box&lt;Number&gt;) in the type GenericTest is //not applicable for the arguments (Box&lt;Integer&gt;) getData(age); // 1 &#125; public static void getData(Box&lt;Number&gt; data)&#123; System.out.println(\"data :\" + data.getData()); &#125;&#125; 我们发现，在代码//1 处出现了错误提示信息：The method getData(Box) in the t ype GenericTest is not applicable for the arguments (Box)。显然，通过提示信息，我们知道Box&lt;Number&gt;在逻辑上不能视为Box&lt;Integer&gt;的父类。那么，原因何在呢？ 1234567891011121314151617181920212223242526272829303132333435363738public class GenericTest &#123; public static void main(String[] args) &#123; Box&lt;Integer&gt; a = new Box&lt;Integer&gt;(712); Box&lt;Number&gt; b = a; // 1 Box&lt;Float&gt; f = new Box&lt;Float&gt;(3.14f); b.setData(f); // 2 &#125; public static void getData(Box&lt;Number&gt; data) &#123; System.out.println(\"data :\" + data.getData()); &#125;&#125;class Box&lt;T&gt; &#123; private T data; public Box() &#123; &#125; public Box(T data) &#123; setData(data); &#125; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125;&#125; 这个例子中，显然//1 和//2 处肯定会出现错误提示的。在此我们可以使用反证法来进行说明。 假设Box&lt;Number&gt;在逻辑上可以视为Box&lt;Integer&gt;的父类，那么//1和//2处将不会有错误提示了，那么问题就出来了，通过getData()方法取出数据时到底是什么类型呢？Integer? Float? 还是Number？且由于在编程过程中的顺序不可控性，导致在必要的时候必须要进行类型判断，且进行强制类型转换。显然，这与泛型的理念矛盾，因此，在逻辑上Box不能视为Box的父类。 好，那我们回过头来继续看“类型通配符”中的第一个例子，我们知道其具体的错误提示的深层次原因了。那么如何解决呢？总部能再定义一个新的函数吧。这和Java中的多态理念显然是违背的，因此，我们需要一个在逻辑上可以用来表示同时是Box&lt;Integer&gt;和Box&lt;Number&gt;的父类的一个引用类型，由此，类型通配符应运而生。 类型通配符一般是使用 ? 代替具体的类型实参。注意了，此处是类型实参，而不是类型形参！且Box&lt;?&gt;在逻辑上是Box&lt;Integer&gt;、Box&lt;Number&gt;…等所有Box&lt;具体类型实参&gt;的父类。由此，我们依然可以定义泛型方法，来完成此类需求。 123456789101112131415161718public class GenericTest &#123; public static void main(String[] args) &#123; Box&lt;String&gt; name = new Box&lt;String&gt;(\"corn\"); Box&lt;Integer&gt; age = new Box&lt;Integer&gt;(712); Box&lt;Number&gt; number = new Box&lt;Number&gt;(314); getData(name); getData(age); getData(number); &#125; public static void getData(Box&lt;?&gt; data) &#123; System.out.println(\"data :\" + data.getData()); &#125;&#125; 有时候，我们还可能听到类型通配符上限和类型通配符下限。具体有是怎么样的呢？ 在上面的例子中，如果需要定义一个功能类似于getData()的方法，但对类型实参又有进一步的限制：只能是Number类及其子类。此时，需要用到类型通配符上限。 1234567891011121314151617181920212223242526public class GenericTest &#123; public static void main(String[] args) &#123; Box&lt;String&gt; name = new Box&lt;String&gt;(\"corn\"); Box&lt;Integer&gt; age = new Box&lt;Integer&gt;(712); Box&lt;Number&gt; number = new Box&lt;Number&gt;(314); getData(name); getData(age); getData(number); //getUpperNumberData(name); // 1 getUpperNumberData(age); // 2 getUpperNumberData(number); // 3 &#125; public static void getData(Box&lt;?&gt; data) &#123; System.out.println(\"data :\" + data.getData()); &#125; public static void getUpperNumberData(Box&lt;? extends Number&gt; data)&#123; System.out.println(\"data :\" + data.getData()); &#125;&#125; 此时，显然，在代码//1处调用将出现错误提示，而//2 //3处调用正常。 类型通配符上限通过形如Box&lt;? extends Number&gt;形式定义，相对应的，类型通配符下限为Box&lt;? super Number&gt;形式，其含义与类型通配符上限正好相反，在此不作过多阐述了。 五. 话外篇本文中的例子主要是为了阐述泛型中的一些思想而简单举出的，并不一定有着实际的可用性。另外，一提到泛型，相信大家用到最多的就是在集合中，其实，在实际的编程过程中，自己可以使用泛型去简化开发，且能很好的保证代码质量。并且还要注意的一点是，Java中没有所谓的泛型数组一说。 对于泛型，最主要的还是需要理解其背后的思想和目的。 【参考资料】 Java总结篇系列：Java泛型","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://lvshen9.gitee.io/tags/Java/"},{"name":"泛型","slug":"泛型","permalink":"http://lvshen9.gitee.io/tags/泛型/"}]},{"title":"【Java】设计模式：深入理解单例模式","slug":"【Java】设计模式：深入理解单例模式","date":"2017-09-04T13:21:41.000Z","updated":"2017-09-04T13:27:06.057Z","comments":true,"path":"2017/09/04/【Java】设计模式：深入理解单例模式/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/04/【Java】设计模式：深入理解单例模式/","excerpt":"什么是设计模式？简单的理解就是前人留下来的一些经验总结而已，然后把这些经验起了个名字叫Design Pattern，翻译过来就是设计模式，通过使用设计模式可以让我们的代码复用性更高，可维护性更高，让你的代码写的更优雅。设计模式理论上有23种，今天就先来分享下最常用的单例模式。 引言对于单例模式，有工作经验的人基本上都使用过。面试的时候提到设计模式基本上都会提到单例模式，但是很多人对单例模式也是一知半解，当然也包括我哈哈哈=_=。所以我们有必要深入理解一下所谓的「单例模式」。 单例模式定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 单例模式结构图： [ img](http://img.blog.csdn.net/20160908131425758)","text":"什么是设计模式？简单的理解就是前人留下来的一些经验总结而已，然后把这些经验起了个名字叫Design Pattern，翻译过来就是设计模式，通过使用设计模式可以让我们的代码复用性更高，可维护性更高，让你的代码写的更优雅。设计模式理论上有23种，今天就先来分享下最常用的单例模式。 引言对于单例模式，有工作经验的人基本上都使用过。面试的时候提到设计模式基本上都会提到单例模式，但是很多人对单例模式也是一知半解，当然也包括我哈哈哈=_=。所以我们有必要深入理解一下所谓的「单例模式」。 单例模式定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 单例模式结构图： [ img](http://img.blog.csdn.net/20160908131425758) 使用单例的优点： 单例类只有一个实例 共享资源，全局使用 节省创建时间，提高性能 它的七种写法单例模式有多种写法各有利弊，现在我们来看看各种模式写法。 1、饿汉式12345678public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123; &#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 这种方式和名字很贴切，饥不择食，在类装载的时候就创建，不管你用不用，先创建了再说，如果一直没有被使用，便浪费了空间，典型的空间换时间，每次调用的时候，就不需要再判断，节省了运行时间。 Java Runtime就是使用这种方式，它的源代码如下： 1234567891011121314151617181920public class Runtime &#123; private static Runtime currentRuntime = new Runtime(); /** * Returns the runtime object associated with the current Java application. * Most of the methods of class &lt;code&gt;Runtime&lt;/code&gt; are instance * methods and must be invoked with respect to the current runtime object. * * @return the &lt;code&gt;Runtime&lt;/code&gt; object associated with the current * Java application. */ public static Runtime getRuntime() &#123; return currentRuntime; &#125; /** Don't let anyone else instantiate this class */ private Runtime() &#123;&#125; //以下代码省略&#125; 总结：「饿汉式」是最简单的实现方式，这种实现方式适合那些在初始化时就要用到单例的情况，这种方式简单粗暴，如果单例对象初始化非常快，而且占用内存非常小的时候这种方式是比较合适的，可以直接在应用启动时加载并初始化。 但是，如果单例初始化的操作耗时比较长而应用对于启动速度又有要求，或者单例的占用内存比较大，再或者单例只是在某个特定场景的情况下才会被使用，而一般情况下是不会使用时，使用「饿汉式」的单例模式就是不合适的，这时候就需要用到「懒汉式」的方式去按需延迟加载单例。 2、懒汉式（非线程安全）1234567891011public class Singleton &#123; private static Singleton instance; private Singleton ()&#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 懒汉模式申明了一个静态对象，在用户第一次调用时初始化，虽然节约了资源，但第一次加载时需要实例化，反映稍慢一些，而且在多线程不能正常工作。在多线程访问的时候，很可能会造成多次实例化，就不再是单例了。 「懒汉式」与「饿汉式」的最大区别就是将单例的初始化操作，延迟到需要的时候才进行，这样做在某些场合中有很大用处。比如某个单例用的次数不是很多，但是这个单例提供的功能又非常复杂，而且加载和初始化要消耗大量的资源，这个时候使用「懒汉式」就是非常不错的选择。 3、懒汉式（线程安全）1234567891011public class Singleton &#123; private static Singleton instance; private Singleton ()&#123; &#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这两种「懒汉式」单例，名字起的也很贴切，一直等到对象实例化的时候才会创建，确实够懒，不用鞭子抽就不知道走了，典型的时间换空间，每次获取实例的时候才会判断，看是否需要创建，浪费判断时间，如果一直没有被使用，就不会被创建，节省空间。 因为这种方式在getInstance()方法上加了同步锁，所以在多线程情况下会造成线程阻塞，把大量的线程锁在外面，只有一个线程执行完毕才会执行下一个线程。 Android中的 InputMethodManager 使用了这种方式，我们看看它的源码： 1234567891011121314151617181920public final class InputMethodManager &#123; static InputMethodManager sInstance; /** * Retrieve the global InputMethodManager instance, creating it if it * doesn't already exist. * @hide */ public static InputMethodManager getInstance() &#123; synchronized (InputMethodManager.class) &#123; if (sInstance == null) &#123; IBinder b = ServiceManager.getService(Context.INPUT_METHOD_SERVICE); IInputMethodManager service = IInputMethodManager.Stub.asInterface(b); sInstance = new InputMethodManager(service, Looper.getMainLooper()); &#125; return sInstance; &#125; &#125;&#125; 4、双重校验锁（DCL）上面的方法「懒汉式（线程安全）」毫无疑问存在性能的问题 — 如果存在很多次getInstance()的调用，那性能问题就不得不考虑了！ 让我们来分析一下，究竟是整个方法都必须加锁，还是仅仅其中某一句加锁就足够了？我们为什么要加锁呢？分析一下出现lazy loaded的那种情形的原因。原因就是检测null的操作和创建对象的操作分离了。如果这两个操作能够原子地进行，那么单例就已经保证了。于是，我们开始修改代码，就成了下面的双重校验锁（Double Check Lock）： 123456789101112131415161718192021public class Singleton &#123; /** * 注意此处使用的关键字 volatile， * 被volatile修饰的变量的值，将不会被本地线程缓存， * 所有对该变量的读写都是直接操作共享内存，从而确保多个线程能正确的处理该变量。 */ private volatile static Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 这种写法在getSingleton()方法中对singleton进行了两次判空，第一次是为了不必要的同步，第二次是在singleton等于null的情况下才创建实例。在这里用到了volatile关键字，不了解volatile关键字的可以查看 Java多线程（三）volatile域 和 java中volatile关键字的含义 两篇文章，可以看到双重检查模式是正确使用volatile关键字的场景之一。 「双重校验锁」：既可以达到线程安全，也可以使性能不受很大的影响，换句话说在保证线程安全的前提下，既节省空间也节省了时间，集合了「饿汉式」和两种「懒汉式」的优点，取其精华，去其槽粕。 对于volatile关键字，还是存在很多争议的。由于volatile关键字可能会屏蔽掉虚拟机中一些必要的代码优化，所以运行效率并不是很高。也就是说，虽然可以使用“双重检查加锁”机制来实现线程安全的单例，但并不建议大量采用，可以根据情况来选用。 还有就是在java1.4及以前版本中，很多JVM对于volatile关键字的实现的问题，会导致“双重检查加锁”的失败，因此“双重检查加锁”机制只只能用在java1.5及以上的版本。 5、静态内部类另外，在很多情况下JVM已经为我们提供了同步控制，比如： 在static {...}区块中初始化的数据 访问final字段时 因为在JVM进行类加载的时候他会保证数据是同步的，我们可以这样实现：采用内部类，在这个内部类里面去创建对象实例。这样的话，只要应用中不使用内部类 JVM 就不会去加载这个单例类，也就不会创建单例对象，从而实现「懒汉式」的延迟加载和线程安全。 12345678910public class Singleton &#123; private Singleton()&#123; &#125; public static Singleton getInstance()&#123; return SingletonHolder.sInstance; &#125; private static class SingletonHolder &#123; private static final Singleton sInstance = new Singleton(); &#125; &#125; 第一次加载Singleton类时并不会初始化sInstance，只有第一次调用getInstance方法时虚拟机加载SingletonHolder 并初始化sInstance ，这样不仅能确保线程安全也能保证Singleton类的唯一性，所以推荐使用静态内部类单例模式。 然而这还不是最简单的方式，《Effective Java》中作者推荐了一种更简洁方便的使用方式，就是使用「枚举」。 6、枚举《Java与模式》中，作者这样写道，使用枚举来实现单实例控制会更加简洁，而且无偿地提供了序列化机制，并由JVM从根本上提供保障，绝对防止多次实例化，是更简洁、高效、安全的实现单例的方式。 12345678public enum Singleton &#123; //定义一个枚举的元素，它就是 Singleton 的一个实例 INSTANCE; public void doSomeThing() &#123; // do something... &#125; &#125; 使用方法如下： 1234public static void main(String args[]) &#123; Singleton singleton = Singleton.instance; singleton.doSomeThing();&#125; 枚举单例的优点就是简单，但是大部分应用开发很少用枚举，可读性并不是很高，不建议用。 7. 使用容器12345678910111213public class SingletonManager &#123; private static Map&lt;String, Object&gt; objMap = new HashMap&lt;String,Object&gt;(); private Singleton() &#123; &#125; public static void registerService(String key, Objectinstance) &#123; if (!objMap.containsKey(key) ) &#123; objMap.put(key, instance) ; &#125; &#125; public static ObjectgetService(String key) &#123; return objMap.get(key) ; &#125;&#125; 这种事用SingletonManager 将多种单例类统一管理，在使用时根据key获取对象对应类型的对象。这种方式使得我们可以管理多种类型的单例，并且在使用时可以通过统一的接口进行获取操作，降低了用户的使用成本，也对用户隐藏了具体实现，降低了耦合度。 总结对于以上七种单例，分别是「饿汉式」、「懒汉式(非线程安全)」、「懒汉式(线程安全)」、「双重校验锁」、「静态内部类」、「枚举」和「容器类管理」。很多时候取决人个人的喜好，虽然双重检查有一定的弊端和问题，但我就是钟爱双重检查，觉得这种方式可读性高、安全、优雅（个人观点）。所以代码里常常默写这样的单例，写的时候真感觉自己是个伟大的建筑师哈哈哈哈（真不要脸(￢_￢)（逃。 [ 嘻嘻嘻](http://img.blog.csdn.net/20160909190409989) 【参考资料】：1、Android设计模式之单例模式2、十分钟认识单例模式的多种姿势3、设计模式（二）单例模式的七种写法4、深入Java单例模式5、java中volatile关键字的含义 本文来自 Itimetraveler’s Blog： 【Java】设计模式：深入理解单例模式","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://lvshen9.gitee.io/tags/设计模式/"},{"name":"单列","slug":"单列","permalink":"http://lvshen9.gitee.io/tags/单列/"}]},{"title":"Google 面试题 | 判断字符串是否可由重复子字符串组成","slug":"Google-面试题-判断字符串是否可由重复子字符串组成","date":"2017-09-04T13:12:05.000Z","updated":"2017-09-04T13:14:15.158Z","comments":true,"path":"2017/09/04/Google-面试题-判断字符串是否可由重复子字符串组成/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/04/Google-面试题-判断字符串是否可由重复子字符串组成/","excerpt":"题目描述对于一个非空字符串，判断其是否可由一个子字符串重复多次组成。字符串只包含小写字母且长度不超过10000。 样例1 输入： “abab” 输出： True 样例解释： 输入可由”ab”重复两次组成 样例 2 输入： “aba” 输出： False 样例 3 输入： “abcabcabcabc” 输出： True 样例解释：输入可由”abc”重复四次组成","text":"题目描述对于一个非空字符串，判断其是否可由一个子字符串重复多次组成。字符串只包含小写字母且长度不超过10000。 样例1 输入： “abab” 输出： True 样例解释： 输入可由”ab”重复两次组成 样例 2 输入： “aba” 输出： False 样例 3 输入： “abcabcabcabc” 输出： True 样例解释：输入可由”abc”重复四次组成 解题思路1. 一个简单的思路枚举子字符串的长度lenSub &lt; len(len为原字符串长度)，将原字符串分成多个子字符串，每个子字符串长度为lenSub（由此可见，lenSub整除len），再判断这些子字符串是否全部相等，若全部相等，则返回True，如果对于所有lenSub均不满足该条件，则返回False。时间复杂度为O(len*v(len))，其中v(len)为len的因数个数（因为我们只需要对整除len的lenSub进行进一步判断）。 2. 下面再说一种神奇的方法由kmp算法中的next数组实现。 字符串s的下标从0到n-1，n为字符串长度，记s(i)表示s的第i位字符，s(i,j)表示从s的第i位到第j位的子字符串，若i&gt;j，则s(i,j)=””(空串）。 next数组的定义为：next(i)=p，表示p为小于i且满足s(0 , p) = s(i-p , i)的最大的p，如果不存在这样的p，则next(i) = -1，显然next(0) = -1。我们可以用O(n)的时间计算出next数组。假设我们已知next(0)，next(1)，……，next(i-1) ，现在要求next(i)，不妨设next(i-1) = j0，则由next数组定义可知s(0 , j0) = s(i-1-j0 , i-1)。 若s(j0+1) = s(i)，则结合s(0 , j0) = s(i-1-j0 , i-1)可知s(0 , j0+1) = s(i - (j0+1) , i)，由此可知，next(i)=j0+1。 若s(j0+1)!=s(i)但s(next(j0)+1)=s(i)，记j1=next(j0)，则s(j1+1)=s(i)，由next数组的定义，s(0 , j1) = s(j0 - j1 , j0) = s(i - 1 - j1 , i - 1)，即s(0，j1) = s(i - 1 - j1 , i - 1)，由假设s(j1+1) = s(i)，则s(0 , j1+1) = s(i - (j1+1) , i)，故next(i) = j1+1。 同前两步的分析，如果我们能找到一个k，使得对于所有小于k的k0，s(j(k0)+1)!=s(i)，但有s(j(k)+1) = s(i)，则由next数组的定义可以得到next(i)=j(k)+1，否则需进一步考虑j(k+1) = next(j(k))，如果我们找不到这样的k，则next(i)=-1。 对于字符串s，如果j满足，0&lt;=j&lt;=n-1，且s(0，j) = s(n-1-j，n-1)，令k=n-1-j，若k整除n，不妨设n=mk，则s(0，(m-1)k - 1) = s(k，mk - 1)，即s(0，k-1) = s(k，2k-1) = …… = s((m-1)k - 1，mk - 1)，即s满足题设条件。故要判断s是否为重复子串组成，只需找到满足上述条件的j，且k整除n，即说明s满足条件，否则不满足。 利用已算出的next(n-1)，令k=n-1-next(n-1)，由c可知，若k整除n，且k &lt; n，则s满足条件，否则不满足。上述算法的复杂度可证明为O(n)。 参考代码参考代码给出了利用next数组求解的代码。来自九章算法答案 12345678910111213141516171819public class Solution &#123; public boolean repeatedSubstringPattern(String s) &#123; int l = s.length(); int[] next = new int[l]; next[0] = -1; int i, j = -1; for (i = 1; i &lt; l; i++) &#123; while (j &gt;= 0 &amp;&amp; s.charAt(i) != s.charAt(j + 1)) &#123; j = next[j]; &#125; if (s.charAt(i) == s.charAt(j + 1)) &#123; j++; &#125; next[i] = j; &#125; int lenSub = l - 1 - next[l - 1]; return lenSub != l &amp;&amp; l % lenSub ==0; &#125;&#125; 面试官角度分析这道题的第一种解法比较简单，考察穷举和字符串处理的能力，给出第一种方法并正确分析时间复杂度基本可以达到hire；如果面试者对KMP算法有了解，可以给出第二种next数组的算法可以达到strong hire。 本文来自九章算法公众号 Google 面试题 | 重复子字符串模式","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"字符串","slug":"字符串","permalink":"http://lvshen9.gitee.io/tags/字符串/"}]},{"title":"【machine Learning】机器学习：简明入门指南”","slug":"【Learning】机器学习：简明入门指南”","date":"2017-09-04T11:53:07.000Z","updated":"2017-09-04T12:05:30.691Z","comments":true,"path":"2017/09/04/【Learning】机器学习：简明入门指南”/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/04/【Learning】机器学习：简明入门指南”/","excerpt":"本文是一篇转载自伯乐在线的译文，英文原文是这里：Machine Learning is Fun! — by Adam Geitgey 在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！ 本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习” ——维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。 本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。","text":"本文是一篇转载自伯乐在线的译文，英文原文是这里：Machine Learning is Fun! — by Adam Geitgey 在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！ 本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习” ——维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。 本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。 何为机器学习？机器学习这个概念认为，对于待解问题，你无需编写任何专门的程序代码，遗传算法（generic algorithms）能够在数据集上为你得出有趣的答案。对于遗传算法，不用编码，而是将数据输入，它将在数据之上建立起它自己的逻辑。 举个例子，有一类算法称为分类算法，它可以将数据划分为不同的组别。一个用来识别手写数字的分类算法，不用修改一行代码，就可以用来将电子邮件分为垃圾邮件和普通邮件。算法没变，但是输入的训练数据变了，因此它得出了不同的分类逻辑。 [ 机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。](http://img.blog.csdn.net/20160814170910665) 机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。 “机器学习”是一个涵盖性术语，覆盖了大量类似的遗传算法。 两类机器学习算法你可以认为机器学习算法分为两大类：监督式学习（Supervised Learning）和非监督式学习（Unsupervised Learning）。两者区别很简单，但却非常重要。 监督式学习假设你是一名房产经纪，生意越做越大，因此你雇了一批实习生来帮你。但是问题来了——你可以看一眼房子就知道它到底值多少钱，实习生没有经验，不知道如何估价。 为了帮助你的实习生（也许是为了解放你自己去度个假），你决定写个小软件，可以根据房屋大小、地段以及类似房屋的成交价等因素来评估你所在地区房屋的价值。 你把3个月来城里每笔房屋交易都写了下来，每一单你都记录了一长串的细节——卧室数量、房屋大小、地段等等。但最重要的是，你写下了最终的成交价： 这是我们的“训练数据”:[ img](http://img.blog.csdn.net/20160814171156602) 我们要利用这些训练数据来编写一个程序来估算该地区其他房屋的价值： [ img](http://img.blog.csdn.net/20160814171239543) 这就称为监督式学习。你已经知道每一栋房屋的售价，换句话说，你知道问题的答案，并可以反向找出解题的逻辑。 为了编写软件，你将包含每一套房产的训练数据输入你的机器学习算法。算法尝试找出应该使用何种运算来得出价格数字。 这就像是算术练习题，算式中的运算符号都被擦去了：[ img](http://img.blog.csdn.net/20160814171313166) 天哪！一个阴险的学生将老师答案上的算术符号全擦去了。 看了这些题，你能明白这些测验里面是什么样的数学问题吗？你知道，你应该对算式左边的数字“做些什么”以得出算式右边的答案。 在监督式学习中，你是让计算机为你算出数字间的关系。而一旦你知道了解决这类特定问题所需要的数学方法后，你就可以解答同类的其它问题了。 非监督式学习让我们回到开头那个房地产经纪的例子。要是你不知道每栋房子的售价怎么办？即使你所知道的只是房屋的大小、位置等信息，你也可以搞出很酷的花样。这就是所谓的非监督式学习。 [ 即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。](http://img.blog.csdn.net/20160814171439231) 即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。 这就有点像有人给你一张纸，上面列出了很多数字，然后对你说:“我不知道这些数字有什么意义，也许你能从中找出规律或是能将它们分类，或是其它什么-祝你好运！” 你该怎么处理这些数据呢？首先，你可以用个算法自动地从数据中划分出不同的细分市场。也许你会发现大学附近的买房者喜欢户型小但卧室多的房子，而郊区的买房者偏好三卧室的大户型。这些信息可以直接帮助你的营销。 你还可以作件很酷的事，自动找出房价的离群数据，即与其它数据迥异的值。这些鹤立鸡群的房产也许是高楼大厦，而你可以将最优秀的推销员集中在这些地区，因为他们的佣金更高。 本文余下部分我们主要讨论监督式学习，但这并不是因为非监督式学习用处不大或是索然无味。实际上，随着算法改良，不用将数据和正确答案联系在一起，因此非监督式学习正变得越来越重要。 老学究请看:还有很多其它种类的机器学习算法。但初学时这样理解不错了。 太酷了，但是评估房价真能被看作“学习”吗？作为人类的一员，你的大脑可以应付绝大多数情况，并且没有任何明确指令也能够学习如何处理这些情况。如果你做房产经纪时间很长，你对于房产的合适定价、它的最佳营销方式以及哪些客户会感兴趣等等都会有一种本能般的“感觉”。强人工智能（Strong AI）研究的目标就是要能够用计算机复制这种能力。 但是目前的机器学习算法还没有那么好——它们只能专注于非常特定的、有限的问题。也许在这种情况下，“学习”更贴切的定义是“在少量范例数据的基础上找出一个等式来解决特定的问题”。 不幸的是，“机器在少量范例数据的基础上找出一个等式来解决特定的问题”这个名字太烂了。所以最后我们用“机器学习”取而代之。 当然，要是你是在50年之后来读这篇文章，那时我们已经得出了强人工智能算法，而本文看起来就像个老古董。未来的人类，你还是别读了，叫你的机器仆人给你做份三明治吧。 让我们写代码吧!前面例子中评估房价的程序，你打算怎么写呢？往下看之前，先思考一下吧。 如果你对机器学习一无所知，很有可能你会尝试写出一些基本规则来评估房价，如下： 123456789101112131415161718192021222324252627def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # In my area, the average house costs $200 per sqft price_per_sqft = 200 if neighborhood == &quot;hipsterton&quot;: # but some areas cost a bit more price_per_sqft = 400 elif neighborhood == &quot;skid row&quot;: # and some areas cost less price_per_sqft = 100 # start with a base price estimate based on how big the place is price = price_per_sqft * sqft # now adjust our estimate based on the number of bedrooms if num_of_bedrooms == 0: # Studio apartments are cheap price = price — 20000 else: # places with more bedrooms are usually # more valuable price = price + (num_of_bedrooms * 1000) return price 假如你像这样瞎忙几个小时，也许会取得一点成效，但是你的程序永不会完美，而且当价格变化时很难维护。 如果能让计算机找出实现上述函数功能的办法，这样岂不更好？只要返回的房价数字正确，谁会在乎函数具体干了些什么呢？ 1234def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = &lt;computer, plz do some math for me&gt; return price 考虑这个问题的一种角度是将房价看做一碗美味的汤，而汤中成分就是卧室数、面积和地段。如果你能算出每种成分对最终的价格有多大影响，也许就能得到各种成分混合起来形成最终价格的具体比例。 这样可以将你最初的程序（全是疯狂的if else语句）简化成类似如下的样子： 12345678910111213141516def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # a little pinch of this price += num_of_bedrooms * .841231951398213 # and a big pinch of that price += sqft * 1231.1231231 # maybe a handful of this price += neighborhood * 2.3242341421 # and finally, just a little extra salt for good measure price += 201.23432095 return price 请注意那些用粗体标注的神奇数字——.841231951398213, 1231.1231231,2.3242341421, 和201.23432095。它们称为权重。如果我们能找出对每栋房子都适用的完美权重，我们的函数就能预测所有的房价！ 找出最佳权重的一种笨办法如下所示： 步骤1：首先，将每个权重都设为1.0： 12345678910111213141516def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # a little pinch of this price += num_of_bedrooms * 1.0 # and a big pinch of that price += sqft * 1.0 # maybe a handful of this price += neighborhood * 1.0 # and finally, just a little extra salt for good measure price += 1.0 return price 步骤2：将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度： [ 运用你的程序预测房屋价格。](http://img.blog.csdn.net/20160814172040052) 运用你的程序预测房屋价格。运用你的程序预测房屋价格。 例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，这一套房产你就差了7.2万。 再将你的数据集中的每套房产估价偏离值平方后求和。假设数据集中有500套房产交易，估价偏离值平方求和总计为86,123,373美元。这就反映了你的函数现在的“正确”程度。 现在，将总计值除以500，得到每套房产的估价偏离平均值。将这个平均误差值称为你函数的代价。 如果你能调整权重使得这个代价变为0，你的函数就完美了。它意味着，根据输入的数据，你的程序对每一笔房产交易的估价都是分毫不差。而这就是我们的目标——尝试不同的权重值以使代价尽可能的低。 步骤3：不断重复步骤2，尝试所有可能的权重值组合。哪一个组合使得代价最接近于0，它就是你要使用的，你只要找到了这样的组合，问题就得到了解决! 思想扰动时间这太简单了，对吧？想一想刚才你做了些什么。你取得了一些数据，将它们输入至三个通用的简单步骤中，最后你得到了一个可以对你所在区域的房屋进行估价的函数。房价网，要当心咯！但是下面的事实可能会扰乱你的思想： 1.过去40年来，很多领域（如语言学/翻译学）的研究表明，这种通用的“搅动数据汤”（我编造的词）式的学习算法已经胜过了需要利用真人明确规则的方法。机器学习的“笨”办法最终打败了人类专家。 2.你最后写出的函数真是笨，它甚至不知道什么是“面积”和“卧室数”。它知道的只是搅动，改变数字来得到正确的答案。 3.很可能你都不知道为何一组特殊的权重值能起效。所以你只是写出了一个你实际上并不理解却能证明的函数。 4.试想一下，你的程序里没有类似“面积”和“卧室数”这样的参数，而是接受了一组数字。假设每个数字代表了你车顶安装的摄像头捕捉的画面中的一个像素，再将预测的输出不称为“价格”而是叫做“方向盘转动度数”，这样你就得到了一个程序可以自动操纵你的汽车了！ 太疯狂了，对吧？ 步骤3中的“尝试每个数字”怎么回事？好吧，当然你不可能尝试所有可能的权重值来找到效果最好的组合。那可真要花很长时间，因为要尝试的数字可能无穷无尽。 为避免这种情况，数学家们找到了很多聪明的办法（比如Gradient descent算法）来快速找到优秀的权重值，而不需要尝试过多。下面是其中一种： 首先，写出一个简单的等式表示前述步骤2，这是你的代价函数： [ img](http://img.blog.csdn.net/20160814172434798) 接着，让我们将这同一个等式用机器学习的数学术语（现在你可以忽略它们）进行重写： [ img](http://img.blog.csdn.net/20160814172527111) θ表示当前的权重值。 J(θ) 意为“当前权重值对应的代价”。 这个等式表示我们的估价程序在当前权重值下偏离程度的大小。如果将所有赋给卧室数和面积的可能权重值以图形形式显示，我们会得到类似下图的图表： [ img](http://img.blog.csdn.net/20160814172601908) 代价函数的图形像一支碗。纵轴表示代价。 图中蓝色的最低点就是代价最低的地方——即我们的程序偏离最小。最高点意味着偏离最大。所以，如果我们能找到一组权重值带领我们到达图中的最低点，我们就找到了答案！ [ img](http://img.blog.csdn.net/20160814172634361) 因此，我们只需要调整权重值使我们在图上能向着最低点“走下坡路”。如果对于权重的细小调节能一直使我们保持向最低点移动，那么最终我们不用尝试太多权重值就能到达那里。 如果你还记得一点微积分的话，你也许记得如果你对一个函数求导，结果会告诉你函数在任一点的斜率。换句话说，对于图上给定一点，它告诉我们那条路是下坡路。我们可以利用这一点朝底部进发。 所以，如果我们对代价函数关于每一个权重求偏导，那么我们就可以从每一个权重中减去该值。这样可以让我们更加接近山底。一直这样做，最终我们将到达底部，得到权重的最优值。（读不懂？不用担心，接着往下读）。 这种找出最佳权重的办法被称为批量梯度下降，上面是对它的高度概括。如果想搞懂细节，不要害怕，继续深入下去吧。 当你使用机器学习算法库来解决实际问题，所有这些都已经为你准备好了。但明白一些具体细节总是有用的。 还有什么你随便就略过了？上面我描述的三步算法被称为多元线性回归。你估算等式是在求一条能够拟合所有房价数据点的直线。然后，你再根据房价在你的直线上可能出现的位置用这个等式来估算从未见过的房屋的价格。这个想法威力强大，可以用它来解决“实际”问题。 但是，我为你展示的这种方法可能在简单的情况下有效，它不会在所有情况下都有用。原因之一是因为房价不会一直那么简单地跟随一条连续直线。 但是，幸运的是，有很多办法来处理这种情况。对于非线性数据，很多其他类型的机器学习算法可以处理（如神经网络或有核向量机）。还有很多方法运用线性回归更灵活，想到了用更复杂的线条来拟合。在所有的情况中，寻找最优权重值这一基本思路依然适用。 还有，我忽略了过拟合的概念。很容易碰上这样一组权重值，它们对于你原始数据集中的房价都能完美预测，但对于原始数据集之外的任何新房屋都预测不准。这种情况的解决之道也有不少（如正则化以及使用交叉验证数据集）。学会如何处理这一问题对于顺利应用机器学习至关重要。 换言之，基本概念非常简单，要想运用机器学习得到有用的结果还需要一些技巧和经验。但是，这是每个开发者都能学会的技巧。 机器学习法力无边吗？一旦你开始明白机器学习技术很容易应用于解决貌似很困难的问题（如手写识别），你心中会有一种感觉，只要有足够的数据，你就能够用机器学习解决任何问题。只需要将数据输入进去，就能看到计算机变戏法一样找出拟合数据的等式。 但是很重要的一点你要记住，机器学习只能对用你占有的数据实际可解的问题才适用。 例如，如果你建立了一个模型来根据每套房屋内盆栽数量来预测房价，它就永远不会成功。房屋内盆栽数量和房价之间没有任何的关系。所以，无论它怎么去尝试，计算机也推导不出两者之间的关系。 [ img](http://img.blog.csdn.net/20160814172839065) 你只能对实际存在的关系建模。 怎样深入学习机器学习我认为，当前机器学习的最大问题是它主要活跃于学术界和商业研究组织中。对于圈外想要有个大体了解而不是想成为专家的人们，简单易懂的学习资料不多。但是这一情况每一天都在改善。 吴恩达教授（Andrew Ng）在Coursera上的机器学习免费课程非常不错。我强烈建议由此入门。任何拥有计算机科学学位、还能记住一点点数学的人应该都能理解。 另外，你还可以下载安装SciKit-Learn，用它来试验成千上万的机器学习算法。它是一个python框架，对于所有的标准算法都有“黑盒”版本。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://lvshen9.gitee.io/tags/机器学习/"}]},{"title":"You don't know Js","slug":"You-don-t-know-Js","date":"2017-09-03T14:56:21.000Z","updated":"2017-09-03T15:14:43.520Z","comments":true,"path":"2017/09/03/You-don-t-know-Js/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/03/You-don-t-know-Js/","excerpt":"作用域 一门语言需要一套设计良好的规则来存储变量，并且之后可以方便的找到这些变量，这逃规则被称为作用域。 这也意味着当我们访问一个变量的时候，决定这个变量能否访问到的依据就是这个作用域。 词法作用域作用域共有两种主要的工作模型，第一种是最为普通的，被大多数编程语言（包括javascript）采用的词法作用域，另一种叫做动态作用域。而我们平时所提及的作用域，就是这里所说的词法作用域。 要了解词法作用域，必须要了解javascript引擎以及编译器的大概工作方式。一般程序中的源码在执行前会进行编译三步骤。 分词/语法分析 解析/语法分析 代码生成 而在分词/词法分析这个步骤，就已经确定了词法作用域。也就说作用域在我们书写代码的时候就已经确定了，引用书中的文字","text":"作用域 一门语言需要一套设计良好的规则来存储变量，并且之后可以方便的找到这些变量，这逃规则被称为作用域。 这也意味着当我们访问一个变量的时候，决定这个变量能否访问到的依据就是这个作用域。 词法作用域作用域共有两种主要的工作模型，第一种是最为普通的，被大多数编程语言（包括javascript）采用的词法作用域，另一种叫做动态作用域。而我们平时所提及的作用域，就是这里所说的词法作用域。 要了解词法作用域，必须要了解javascript引擎以及编译器的大概工作方式。一般程序中的源码在执行前会进行编译三步骤。 分词/语法分析 解析/语法分析 代码生成 而在分词/词法分析这个步骤，就已经确定了词法作用域。也就说作用域在我们书写代码的时候就已经确定了，引用书中的文字 词法作用域就是定义在词法阶段的作用域，换句话说，词法作用域是由你在写代码时将变量和块作用域写在哪里来决定的。 具体结合编译器、作用域、引擎来讲，编译器在分词阶段，针对特定的环境就会生成一个词法作用域，然后对源代码中的var a = 3；类似的声明进行识别，当遇到var a，编译器会询问作用域中是否有a变量，若无，则在作用域中新增一个a变量。编译完成之后，引擎执行编译后的代码，引擎在执行的过程中遇到a变量，会去作用域中查找是否有a变量，若有，则将a赋值2。对于var a = 2；一条语句会在两个过程中操作，正是变量提升现象的原因。（稍后讲到） 那什么时候会生成一个词法作用域呢？ 函数作用域 img 这幅图所展示的三个气泡，就代表了三个作用域，而编译器遇到一个函数定义，就会生成一个作用域。例如当编译器遇到foo函数，会创建一个作用域，再将这个函数内部的标识符（a/b/bar）放到词法作用域中。这个步骤在编译阶段就完成了。当js引擎执行foo函数的时候，遇到a变量，就会去询问早就创建好的作用域是否有a变量存在。 在作用域外，是无法访问作用域内的变量的。 例如 1234function foo() &#123; var a = 3;&#125;console.log(a); //undefied 正是这个特性，可以被用来实现隐藏内部变量将重要变量声明放入一个函数声明的作用域中，可以防止被作用域外部的语句所引用甚至更改。 根据函数作用域，可以引申出如何判断一个函数是函数声明还是一个函数表达式。最重要的区别是他们的名称标识符将会绑定在何处。 先声明一点，任何匿名函数都是可以添加名称标识符的。例如 123setTimeout(function timer() &#123; console.log(1)&#125;, 1000) 对于函数声明，名称标识符是绑定在当前作用域上的。即可在函数当前作用域调用这个名称标识符。 而函数表达式，名称标识符是绑定在自身的函数作用域中的。 按照这个区别，来看以下几个函数。 12function foo1() &#123;console.log(1)&#125;foo1(); // 1 12var bar = function foo2() &#123;console.log(1)&#125;foo2() // undefined 12(function foo3() &#123;console.log(1)&#125;)()foo3() // undefined 以上的函数就只有foo1是函数声明。 块作用域在js语言中，除了函数，创建作用域的方式还可以通过块作用域。对于js而言，循环、ifelse块并没有创建块作用域的功能。 通过ES3规范的try/catch的catch语句可以创建一个块作用域，其中声明的变量仅在catch中有效。而try-catch也正是let关键字的向前兼容方。 123456try &#123; undefined(); // 执行一个非法操作来强制制造一个异常&#125; catch(err) &#123; console.log(err);&#125;console.log(err); // err not found ES6引入了let关键字，提供了除var以外的另一种变量声明方式，let为其声明的变量隐式地劫持了所在的块作用域。 12345678if (true) &#123; &#123; let bar = 3; bar = someting(bar); console.log(bar) &#125;&#125;console.log(bar) // undefined 作于的一个中括号起到划分块作用域的作用，显示的区别于var等变量。我们可能在之后会修改代码，看到这个中括号会直白的认识到这个是一个块作用域。 变量提升在第一节我已经提到了，对于var a = 3;这样一条语句，编译器通过分词、解析、最后生成机器可以读的代码。 而javascript实际上会将其看成两个声明：var a、a = 3。第一个声明在编译阶段进行，第二个赋值声明会留在原地等待执行。 所以在引擎工作去执行代码时，进入到函数作用域内时，首先会执行var a操作，而这个过程就好像变量从原先的位置被移动作用域最上面一样。 12console.log(a); // undefinedvar a = 3; 相当于 123var a;console.log(a); // undefineda = 3; 另外函数声明也会发生变量提升的现象（连实际函数值也提升，即可以在函数声明前调用）。而行数表达式var a = function foo1() {}发生提升的是a变量，函数本身不会发生提升。 12foo(); // 不是ReferenceError 而是 TypeErrorvar foo = function bar() &#123;&#125; ReferenceError TypeError这是两个错误标记，第一个错误标记是查询变量时，若在作用域中查找不到这个变量则发出，第二个标记是能查找到变量（即使是endefined），但是这个变量被错误的调用（比如对null，undefined进行调用），发出。 作用域闭包经典的闭包 闭包是基于词法作用域书写代码时所产生的自然结果。 基于词法作用域产生的结果，这有点类似于词法作用域的产生条件。这也意味着闭包在书写代码的时候就已经形成了。 看一个最经典的闭包例子 123456789function foo () &#123; var a = 1; function bar () &#123; console.log(a); //1 &#125; return bar;&#125;var baz = foo();baz(); 基于这个经典的例子，结合书中的话 一个函数在定义时的词法作用域以外的地方被调用，可以记住并访问原先所在的词法作用域时，就产生了闭包。也即被返回出去的函数被调用时依然持有对该作用域的引用。这个引用就是闭包。 先确定一点，javascript中函数是可以作为值被传递的。基于这个特性，有多种方法可以行成闭包。只要在一个作用域中，将函数作为值传递到另一个词法作用域中并调用，就会形成闭包。 1234567891011function foo() &#123; var a = 2; function baz() &#123; console.log(a); &#125; bar(baz);&#125;function bar(fn) &#123; fn();&#125;// 回调传递函数 1234567891011121314var fn;function foo() &#123; var a = 2; function baz() &#123; console.log(a); &#125; fn = baz;&#125;function bar() &#123; fn();&#125;foo();bar(); //2// 间接传递函数 无论通过何种手段将内部函数传递到所在的词法作用域以外，它都会持有对原始定义作用域的引用，无论在何处执行这个函数都会使用闭包。 回调 == 闭包再看上一节，回调中传递函数的例子。 1234567891011function foo() &#123; var a = 2; function baz() &#123; console.log(a); &#125; bar(baz);&#125;function bar(fn) &#123; fn();&#125;// 回调传递函数 是将函数当做值并作为参数传递给函数。再来看 123456function wait(message) &#123; setTimeout(function timer () &#123; console.log(message); // hello world &#125;, 1000)&#125;wait(&apos;hello world&apos;); setTimeout作为js内置的工具函数，将timer 函数当做值传进去，在setTimeout定义函数内对传进来的timer进行了调用。类似于 1234function setTimeout(fn) &#123; // 延迟多少毫秒 fn();&#125; 回调函数timer在另一个词法作用域内调用，但是能访问原先作用域内的参数（message）。 类似jquery中的事件绑定，涉及到传递回调函数，就都有闭包的产生！ 闭包在循环中的表现最令人困惑的闭包表现就是在循环中了。像我们刚刚提及到的setTimeout、事件绑定等回调函数都会产生闭包。 12345for(var i = 1; i &lt;= 5; i++) &#123; setTimeout(function timer() &#123; console.log(i); &#125;, i*1000)&#125; 这个循环的本意是想间隔1秒打印1、2、3、4、5，结果却每隔1秒输出了5次6！结合在第二节中对setTimeout函数的解析，这个误区将很快解开。 首先要明白for循环没有块作用域的概念，即在这个循环中5次迭代都是在同一个作用域中进行的。要清楚timer函数不是在这个作用域中被调用的，它作为参数在其他的作用域中调用。 123function timer() &#123; console.log(i);&#125; 这个函数包括其中的形式参数i原原本本的被传递，在迭代过程中i不会被赋值。而五次迭代完成后，共用的作用域中的i的值已经变成了6 。在其他作用域中的timer函数调用过程中需要查询i，因为产生了闭包，i的值会去原始的作用域中查找，即全是6。 得不到预期效果的错其实都在于for循环中共用一个作用域。想改进也很简单，即在迭代的过程中，创建对应的作用域。另外值得注意的一点是需要把每次迭代的i值传到作用域内。 1234567for(var i = 1; i &lt;= 5; i++) &#123; (function (j) &#123; setTimeout(function timer () &#123; console.log(j) &#125;, j* 1000) &#125;)(i)&#125; 闭包的垃圾回收本来一个变量被使用完之后就可以利用垃圾回收机制进行垃圾回收，但因为闭包的产生，阻止了这一行为。 1234567function process(data) &#123; //&#125;var someReallyBigData = &#123;&#125;;process( someReallyBigData );var $btn = $(&apos;.j_Btn&apos;);$btn.on(&apos;click&apos;, function clicker() &#123;&#125;); 这个例子中就是因为事件绑定机制中的传入了clicker回调函数，产生了闭包，引用着clicker所在的作用域，所以此处的someReallyBigData数据无法从内存中释放。 解决办法也有，声明一个块作用域，让引擎清楚的知道没有必要保存someReallyBigData饿了。 123456789function process(data) &#123; //&#125;&#123; let someReallyBigData = &#123;&#125;; process( someReallyBigData );&#125;var $btn = $(&apos;.j_Btn&apos;);$btn.on(&apos;click&apos;, function clicker() &#123;&#125;);","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lvshen9.gitee.io/tags/JavaScript/"},{"name":"作用域","slug":"作用域","permalink":"http://lvshen9.gitee.io/tags/作用域/"}]},{"title":"死锁的那点事儿","slug":"死锁的那点事儿","date":"2017-09-02T13:14:54.000Z","updated":"2017-09-04T08:56:55.349Z","comments":true,"path":"2017/09/02/死锁的那点事儿/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/02/死锁的那点事儿/","excerpt":"本文我们将研究什么是死锁以及怎么避免死锁 什么死锁简单来说，多线程在高并发访问系统资源时，出于安全目的，会给线程枷锁。然而在线程安全的同时会带来一个头疼的问题，死锁。那么，什么是死锁，就是多个线程在竞争系统资源时产生的一种僵局，若无外力作用，线程将无法推进。 比如，两人相向过独木桥，都要等对方过来，才能过去。这样的结果是谁都过不去，白白消耗了时间。 为什么会产生死锁1) 系统资源的竞争通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在 运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。只有对不可剥夺资源的竞争 才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。","text":"本文我们将研究什么是死锁以及怎么避免死锁 什么死锁简单来说，多线程在高并发访问系统资源时，出于安全目的，会给线程枷锁。然而在线程安全的同时会带来一个头疼的问题，死锁。那么，什么是死锁，就是多个线程在竞争系统资源时产生的一种僵局，若无外力作用，线程将无法推进。 比如，两人相向过独木桥，都要等对方过来，才能过去。这样的结果是谁都过不去，白白消耗了时间。 为什么会产生死锁1) 系统资源的竞争通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在 运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。只有对不可剥夺资源的竞争 才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。 2) 进程推进顺序非法进程在运行过程中，请求和释放资源的顺序不当，也同样会导致死锁。例如，并发进程 P1、P2分别保持了资源R1、R2，当进程P1申请资源R2，而进程P2申请资源R1时，两者都会因为所需资源被占用而阻塞。 信号使用不当也会造成死锁。进程间彼此相互等待对方发来的消息，结果也会使得这 些进程间无法继续向前推进。例如，进程A等待进程B发的消息，进程B又在等待进程A 发的消息，可以看出进程A和B不是因为竞争同一资源，而是在等待对方的资源导致死锁。 3) 死锁产生的必要条件产生死锁必须同时满足以下四个条件，只要其中任一条件不成立，死锁就不会发生。 互斥条件：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。 不剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放)。 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待状态的进程集合{Pl, P2, …, Pn}，其中Pi等待的资源被P(i+1)占有（i=0, 1, …, n-1)，Pn等待的资源被P0占有，如图2-15所示。 直观上看，循环等待条件似乎和死锁的定义一样，其实不然。按死锁定义构成等待环所 要求的条件更严，它要求Pi等待的资源必须由P(i+1)来满足，而循环等待条件则无此限制。 例如，系统中有两台输出设备，P0占有一台，PK占有另一台，且K不属于集合{0, 1, …, n}。 Pn等待一台输出设备，它可以从P0获得，也可能从PK获得。因此，虽然Pn、P0和其他 一些进程形成了循环等待圈，但PK不在圈内，若PK释放了输出设备，则可打破循环等待, 如图2-16所示。因此循环等待只是死锁的必要条件。 资源分配图含圈而系统又不一定有死锁的原因是同类资源数大于1。但若系统中每类资源都只有一个资源，则资源分配图含圈就变成了系统出现死锁的充分必要条件。 这是一段死锁的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** *一个简单的死锁类 *当DeadLock类的对象flag==1时（td1），先锁定o1,睡眠500毫秒 *而td1在睡眠的时候另一个flag==0的对象（td2）线程启动，先锁定o2,睡眠500毫秒 *td1睡眠结束后需要锁定o2才能继续执行，而此时o2已被td2锁定； *td2睡眠结束后需要锁定o1才能继续执行，而此时o1已被td1锁定； *td1、td2相互等待，都需要得到对方锁定的资源才能继续执行，从而死锁。 */ public class DeadLock implements Runnable &#123; public int flag = 1; //静态对象是类的所有对象共享的 private static Object o1 = new Object(), o2 = new Object(); @Override public void run() &#123; System.out.println(\"flag=\" + flag); if (flag == 1) &#123; synchronized (o1) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o2) &#123; System.out.println(\"1\"); &#125; &#125; &#125; if (flag == 0) &#123; synchronized (o2) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o1) &#123; System.out.println(\"0\"); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; DeadLock td1 = new DeadLock(); DeadLock td2 = new DeadLock(); td1.flag = 1; td2.flag = 0; //td1,td2都处于可执行状态，但JVM线程调度先执行哪个线程是不确定的。 //td2的run()可能在td1的run()之前运行 new Thread(td1).start(); new Thread(td2).start(); &#125; &#125; 怎样避免死锁在有些情况下死锁是可以避免的。三种用于避免死锁的技术： 加锁顺序（线程按照一定的顺序加锁） 加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁） 死锁检测 加锁顺序当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。 如果能确保所有的线程都是按照相同的顺序获得锁，那么死锁就不会发生。看下面这个例子： 123456789101112Thread 1: lock A lock BThread 2: wait for A lock C (when A locked)Thread 3: wait for A wait for B wait for C 如果一个线程（比如线程3）需要一些锁，那么它必须按照确定的顺序获取锁。它只有获得了从顺序上排在前面的锁之后，才能获取后面的锁。 例如，线程2和线程3只有在获取了锁A之后才能尝试获取锁C(译者注：获取锁A是获取锁C的必要条件)。因为线程1已经拥有了锁A，所以线程2和3需要一直等到锁A被释放。然后在它们尝试对B或C加锁之前，必须成功地对A加了锁。 按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁(译者注：并对这些锁做适当的排序)，但总有些时候是无法预知的。 加锁时限另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行(译者注：加锁超时后可以先继续运行干点其它事情，再回头来重复之前加锁的逻辑)。 以下是一个例子，展示了两个线程以不同的顺序尝试获取相同的两个锁，在发生超时后回退并重试的场景： 12345678910111213Thread 1 locks AThread 2 locks BThread 1 attempts to lock B but is blockedThread 2 attempts to lock A but is blockedThread 1&apos;s lock attempt on B times outThread 1 backs up and releases A as wellThread 1 waits randomly (e.g. 257 millis) before retrying.Thread 2&apos;s lock attempt on A times outThread 2 backs up and releases B as wellThread 2 waits randomly (e.g. 43 millis) before retrying. 在上面的例子中，线程2比线程1早200毫秒进行重试加锁，因此它可以先成功地获取到两个锁。这时，线程1尝试获取锁A并且处于等待状态。当线程2结束时，线程1也可以顺利的获得这两个锁（除非线程2或者其它线程在线程1成功获得两个锁之前又获得其中的一些锁）。 需要注意的是，由于存在锁的超时，所以我们不能认为这种场景就一定是出现了死锁。也可能是因为获得了锁的线程（导致其它线程超时）需要很长的时间去完成它的任务。 此外，如果有非常多的线程同一时间去竞争同一批资源，就算有超时和回退机制，还是可能会导致这些线程重复地尝试但却始终得不到锁。如果只有两个线程，并且重试的超时时间设定为0到500毫秒之间，这种现象可能不会发生，但是如果是10个或20个线程情况就不同了。因为这些线程等待相等的重试时间的概率就高的多（或者非常接近以至于会出现问题）。 (译者注：超时和重试机制是为了避免在同一时间出现的竞争，但是当线程很多时，其中两个或多个线程的超时时间一样或者接近的可能性就会很大，因此就算出现竞争而导致超时后，由于超时时间一样，它们又会同时开始重试，导致新一轮的竞争，带来了新的问题。) 这种机制存在一个问题，在Java中不能对synchronized同步块设置超时时间。你需要创建一个自定义锁，或使用Java5中java.util.concurrent包下的工具。写一个自定义锁类不复杂，但超出了本文的内容。后续的Java并发系列会涵盖自定义锁的内容。 死锁检测死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。 每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。 当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。例如，线程A请求锁7，但是锁7这个时候被线程B持有，这时线程A就可以检查一下线程B是否已经请求了线程A当前所持有的锁。如果线程B确实有这样的请求，那么就是发生了死锁（线程A拥有锁1，请求锁7；线程B拥有锁7，请求锁1）。 当然，死锁一般要比两个线程互相持有对方的锁这种情况要复杂的多。线程A等待线程B，线程B等待线程C，线程C等待线程D，线程D又在等待线程A。线程A为了检测死锁，它需要递进地检测所有被B请求的锁。从线程B所请求的锁开始，线程A找到了线程C，然后又找到了线程D，发现线程D请求的锁被线程A自己持有着。这是它就知道发生了死锁。 下面是一幅关于四个线程（A,B,C和D）之间锁占有和请求的关系图。像这样的数据结构就可以被用来检测死锁。 检测死锁 那么当检测出死锁时，这些线程该做些什么呢？ 一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞争同一批锁，它们还是会重复地死锁（编者注：原因同超时类似，不能从根本上减轻竞争）。 一个更好的方案是给这些线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这个问题，可以在死锁发生的时候设置随机的优先级。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://lvshen9.gitee.io/tags/多线程/"},{"name":"死锁","slug":"死锁","permalink":"http://lvshen9.gitee.io/tags/死锁/"}]},{"title":"How to learning Shiro(2)","slug":"How-to-learning-Shiro-2","date":"2017-09-01T12:52:05.000Z","updated":"2017-09-01T13:41:20.286Z","comments":true,"path":"2017/09/01/How-to-learning-Shiro-2/","link":"","permalink":"http://lvshen9.gitee.io/2017/09/01/How-to-learning-Shiro-2/","excerpt":"前面我们学习了Shiro的基本架构，以及Shiro的认证和授权机制，今天我们聊聊Shiro在xml文件中的配置 Shiro的配置主要有如下几个部分： 对象和属性的定义与配置 URL的过滤器配置 静态用户配置 静态角色配置 其中，用户与角色一般有后台操作，其数据是动态的，所以xml的配置主要包含前两项。 我们主要讲解Spring XML的文件配置。","text":"前面我们学习了Shiro的基本架构，以及Shiro的认证和授权机制，今天我们聊聊Shiro在xml文件中的配置 Shiro的配置主要有如下几个部分： 对象和属性的定义与配置 URL的过滤器配置 静态用户配置 静态角色配置 其中，用户与角色一般有后台操作，其数据是动态的，所以xml的配置主要包含前两项。 我们主要讲解Spring XML的文件配置。 Shiro对象的配置主要是对Shiro各个组件的实现进行定义配置 1234567&lt;bean id=\"securityManager\" class=\"org.apache.shiro.mgt.DefaultSecurityManager\"&gt; &lt;property name=\"cacheManager\" ref=\"cacheManager\"/&gt; &lt;property name=\"sessionMode\" value=\"native\"/&gt; &lt;!-- Single realm app. If you have multiple realms, use the 'realms' property instead. --&gt; &lt;property name=\"realm\" ref=\"myRealm\"/&gt; &lt;property name=\"sessionManager\" ref=\"sessionManager\"/&gt; &lt;/bean&gt; Shiro过滤器的配置Shiro主要是通过URL(粗粒度的权限控制)过滤来进行安全管理，这里的配置便是指定具体授权规则定义。 123456789101112131415&lt;bean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt; &lt;property name=\"loginUrl\" value=\"/login.jsp\"/&gt; &lt;property name=\"successUrl\" value=\"/home.jsp\"/&gt; &lt;property name=\"unauthorizedUrl\" value=\"/unauthorized.jsp\"/&gt; --&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; &lt;!--some example chain definitions:--&gt; /admin/** = authc, roles[admin] /docs/** = authc, perms[document:read] /** = authc &lt;!--more URL-to-FilterChain definitions here--&gt; &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; URL过滤器配置说明Shiro可以通过配置文件实现基于URL的授权验证。FilterChain定义格式：URL_Ant_Path_Expression = Path_Specific_Filter_Chain每个URL配置，表示匹配该URL的应用程序请求将由对应的过滤器进行验证。例如： 1234567[urls] /index.html = anon /user/create = anon /user/** = authc /admin/** = authc, roles[administrator] /rest/** = authc, rest /remoting/rpc/** = authc, perms[\"remote:invoke\"] URL表达式说明1、URL目录是基于HttpServletRequest.getContextPath()此目录设置2、URL可使用通配符，**代表任意子目录3、Shiro验证URL时，URL匹配成功便不再继续匹配查找。所以要注意配置文件中的URL顺序，尤其在使用通配符时。 Filter Chain定义说明1、一个URL可以配置多个Filter，使用逗号分隔2、当设置多个过滤器时，全部验证通过，才视为通过3、部分过滤器可指定参数，如perms，roles Shiro与Spring整合在web.xml中添加shiro过滤器1234567891011&lt;!-- Shiro filter--&gt; &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt; org.springframework.web.filter.DelegatingFilterProxy &lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 在Spring的applicationContext.xml中添加shiro配置1、添加shiroFilter定义 12345678910111213141516171819202122&lt;!-- Shiro Filter --&gt; &lt;bean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\" /&gt; &lt;property name=\"loginUrl\" value=\"/login\" /&gt; &lt;property name=\"successUrl\" value=\"/user/list\" /&gt; &lt;property name=\"unauthorizedUrl\" value=\"/login\" /&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; /login = anon /user/** = authc /role/edit/* = perms[role:edit] /role/save = perms[role:edit] /role/list = perms[role:view] /** = authc &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;!-- shiroFilter 中 loginUrl 为登录页面地址， successUrl 为登录成功页面地址（如果首先访问受保护 URL 登录成功，则跳转到实际访问页面）， unauthorizedUrl 认证未通过访问的页面（前面提到的“未经授权页面”）。 --&gt; 2、添加securityManager定义 123&lt;bean id=\"securityManager\" class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\"&gt; &lt;property name=\"realm\" ref=\"myRealm\" /&gt; &lt;/bean&gt; 3、添加realm定义 1&lt;bean id=\" myRealm\" class=\"com...MyRealm\" /&gt; 实现MyRealm：继承AuthorizingRealm，并重写认证授权方法1234567891011121314151617181920212223242526272829303132333435363738394041public class MyRealm extends AuthorizingRealm&#123; private AccountManager accountManager; public void setAccountManager(AccountManager accountManager) &#123; this.accountManager = accountManager; &#125; /** * 授权信息 */ protected AuthorizationInfo doGetAuthorizationInfo( PrincipalCollection principals) &#123; String username=(String)principals.fromRealm(getName()).iterator().next(); if( username != null )&#123; User user = accountManager.get( username ); if( user != null &amp;&amp; user.getRoles() != null )&#123; SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); for( SecurityRole each: user.getRoles() )&#123; info.addRole(each.getName()); info.addStringPermissions(each.getPermissionsAsString()); &#125; return info; &#125; &#125; return null; &#125; /** * 认证信息 */ protected AuthenticationInfo doGetAuthenticationInfo( AuthenticationToken authcToken ) throws AuthenticationException &#123; UsernamePasswordToken token = (UsernamePasswordToken) authcToken; String userName = token.getUsername(); if( userName != null &amp;&amp; !\"\".equals(userName) )&#123; User user = accountManager.login(token.getUsername(), String.valueOf(token.getPassword())); if( user != null ) return new SimpleAuthenticationInfo( user.getLoginName(),user.getPassword(), getName()); &#125; return null; &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"http://lvshen9.gitee.io/tags/Shiro/"},{"name":"权限","slug":"权限","permalink":"http://lvshen9.gitee.io/tags/权限/"}]},{"title":"How to learning Shiro","slug":"Shiro学习","date":"2017-08-31T14:47:25.000Z","updated":"2017-08-31T14:49:31.578Z","comments":true,"path":"2017/08/31/Shiro学习/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/31/Shiro学习/","excerpt":"今天我们来聊聊Shiro的那些事。 Shiro的基本介绍1.Shiro是什么？很多人对Shiro并不了解，Shiro是Apache(这公司啥玩意都做)公司发布的一款安全框架，主要用于Java，Shiro具有以下功能： 认证 - 用户身份识别，常被称为用户“登录”； 授权 - 访问控制； 密码加密 - 保护或隐藏数据防止被偷窥； 会话管理 - 每个用户相关的时间敏感的状态。 Shiro可以提供安全而全面的管理服务，广泛应用与JavaEE后台的权限管理。Shiro相对于其他的安全框架(如：Spring Security）更加轻量级。","text":"今天我们来聊聊Shiro的那些事。 Shiro的基本介绍1.Shiro是什么？很多人对Shiro并不了解，Shiro是Apache(这公司啥玩意都做)公司发布的一款安全框架，主要用于Java，Shiro具有以下功能： 认证 - 用户身份识别，常被称为用户“登录”； 授权 - 访问控制； 密码加密 - 保护或隐藏数据防止被偷窥； 会话管理 - 每个用户相关的时间敏感的状态。 Shiro可以提供安全而全面的管理服务，广泛应用与JavaEE后台的权限管理。Shiro相对于其他的安全框架(如：Spring Security）更加轻量级。 2.关于Shiro的组成Shiro拥有三大核心组件：Subject， SecurityManager 和 Realms。如图： Shiro三大组件 下面我们对三大组件做一个简单的了解： Subject：即“当前操作用户”。但是，在Shiro中，Subject这一概念并不仅仅指人，也可以是第三方进程、后台帐户（Daemon Account）或其他类似事物。它仅仅意味着“当前跟软件交互的东西”。但考虑到大多数目的和用途，你可以把它认为是Shiro的“用户”概念。 Subject代表了当前用户的安全操作，SecurityManager则管理所有用户的安全操作。 SecurityManager：它是Shiro框架的核心，Shiro通过SecurityManager来管理内部组件实例，并通过它来提供安全管理的各种服务。 Realm： Realm充当了Shiro与应用安全数据间的“桥梁”或者“连接器”。也就是说，当对用户执行认证（登录）和授权（访问控制）验证时，Shiro会从应用配置的Realm中查找用户及其权限信息。 给Shiro。当配置Shiro时，你必须至少指定一个Realm，用于认证和（或）授权。配置多个Realm是可以的，但是至少需要一个。 Shiro内置了可以连接大量安全数据源（又名目录）的Realm，如LDAP、关系数据库（JDBC）、类似INI的文本配置资源以及属性文件等。如果缺省的Realm不能满足需求，你还可以插入代表自定义数据源的自己的Realm实现。 Shiro完整架构图 其实，Shiro组件还包括： Authenticator ：认证就是核实用户身份的过程。这个过程的常见例子是大家都熟悉的“用户/密码”组合。多数用户在登录软件系统时，通常提供自己的用户名（当事人）和支持他们的密码（证书）。如果存储在系统中的密码（或密码表示）与用户提供的匹配，他们就被认为通过认证。 Authorizer ：授权实质上就是访问控制 - 控制用户能够访问应用中的哪些内容，比如资源、Web页面等等。 SessionManager ：在安全框架领域，Apache Shiro提供了一些独特的东西：可在任何应用或架构层一致地使用Session API。即，Shiro为任何应用提供了一个会话编程范式 - 从小型后台独立应用到大型集群Web应用。这意味着，那些希望使用会话的应用开发者，不必被迫使用Servlet或EJB容器了。或者，如果正在使用这些容器，开发者现在也可以选择使用在任何层统一一致的会话API，取代Servlet或EJB机制。 CacheManager ：对Shiro的其他组件提供缓存支持。 Shiro的认证认证就是验证用户身份的过程。在认证过程中，用户需要提交实体信息(Principals)和凭据信息(Credentials)以检验用户是否合法。最常见的“实体/凭证”组合便是“用户名/密码”组合。 1.实体/凭证的获取1234//Example using most common scenario of username/password pair: UsernamePasswordToken token = new UsernamePasswordToken(username, password); //”Remember Me” built-in: token.setRememberMe(true); 到这里，系统记住了用户的相关信息，但是它并非是完全认证通过的用户，当你访问需要认证用户的功能时，你仍然需要重新提交认证信息。 如你登陆某网站，网站会默认记住登录的用户，再次访问网站时，对于非敏感的页面功能，页面上会显示记住的用户信息，但是当你访问网站敏感(如账户信息)信息信息时仍然需要再次进行登录认证。 2.实体/凭证的提交12Subject currentUser = SecurityUtils.getSubject(); currentUser.login(token); 3.认证处理1234567891011try &#123; currentUser.login(token); &#125; catch ( UnknownAccountException uae ) &#123; ... &#125; catch ( IncorrectCredentialsException ice ) &#123; ... &#125; catch ( LockedAccountException lae ) &#123; ... &#125; catch ( ExcessiveAttemptsException eae ) &#123; ... &#125; ... catch your own ... &#125; catch ( AuthenticationException ae ) &#123; //unexpected error? &#125; 如果login方法执行完毕且没有抛出任何异常信息，那么便认为用户认证通过。之后在应用程序任意地方调用SecurityUtils.getSubject() 都可以获取到当前认证通过的用户实例，使用subject.isAuthenticated()判断用户是否已验证都将返回true.相反，如果login方法执行过程中抛出异常，那么将认为认证失败。Shiro有着丰富的层次鲜明的异常类来描述认证失败的原因，如代码示例。 4.登出操作登出操作可以通过调用subject.logout()来删除你的登录信息，如： 1currentUser.logout(); //removes all identifying information and invalidates their session too 5.认证内部处理机制下面将详细解说Shiro认证的内部处理机制。 认证处理 如图，Shiro有着这样的执行顺序： 1、应用程序构建了一个终端用户认证信息的AuthenticationToken 实例后，调用Subject.login方法。2、Subject的实例通常是DelegatingSubject类（或子类）的实例对象，在认证开始时，会委托应用程序设置的securityManager实例调用securityManager.login(token)方法。3、SecurityManager接受到token(令牌)信息后会委托内置的Authenticator的实例（通常都是ModularRealmAuthenticator类的实例）调用authenticator.authenticate(token). ModularRealmAuthenticator在认证过程中会对设置的一个或多个Realm实例进行适配，它实际上为Shiro提供了一个可拔插的认证机制。4、如果在应用程序中配置了多个Realm，ModularRealmAuthenticator会根据配置的AuthenticationStrategy(认证策略)来进行多Realm的认证过程。在Realm被调用后，AuthenticationStrategy将对每一个Realm的结果作出响应。注：如果应用程序中仅配置了一个Realm，Realm将被直接调用而无需再配置认证策略。5、判断每一个Realm是否支持提交的token，如果支持，Realm将调用getAuthenticationInfo(token); getAuthenticationInfo 方法就是实际认证处理，我们通过覆盖Realm的doGetAuthenticationInfo方法来编写我们自定义的认证处理。 Shiro的授权授权即访问控制，它将判断用户在应用程序中对资源是否拥有相应的访问权限。如，判断一个用户有查看页面的权限，编辑数据的权限，拥有某一按钮的权限，以及是否拥有打印的权限等等。 授权的三要素授权有着三个核心元素：权限、角色和用户。 权限权限是Apache Shiro安全机制最核心的元素。它在应用程序中明确声明了被允许的行为和表现。一个格式良好好的权限声明可以清晰表达出用户对该资源拥有的权限。大多数的资源会支持典型的CRUD操作（create,read,update,delete）,但是任何操作建立在特定的资源上才是有意义的。因此，权限声明的根本思想就是建立在资源以及操作上。而我们通过权限声明仅仅能了解这个权限可以在应用程序中做些什么，而不能确定谁拥有此权限。于是，我们就需要在应用程序中对用户和权限建立关联。通常的做法就是将权限分配给某个角色，然后将这个角色关联一个或多个用户。 权限声明及粒度Shiro权限声明通常是使用以冒号分隔的表达式。就像前文所讲，一个权限表达式可以清晰的指定资源类型，允许的操作，可访问的数据。同时，Shiro权限表达式支持简单的通配符，可以更加灵活的进行权限设置。下面以实例来说明权限表达式。可查询用户数据User:view可查询或编辑用户数据User:view,edit可对用户数据进行所有操作User:* 或 user可编辑id为123的用户数据User:edit:123 角色Shiro支持两种角色模式：1、传统角色：一个角色代表着一系列的操作，当需要对某一操作进行授权验证时，只需判断是否是该角色即可。这种角色权限相对简单、模糊，不利于扩展。2、权限角色：一个角色拥有一个权限的集合。授权验证时，需要判断当前角色是否拥有该权限。这种角色权限可以对该角色进行详细的权限描述，适合更复杂的权限设计。下面将详细描述对两种角色模式的授权实现。 授权实现Shiro支持三种方式实现授权过程： 编码实现 注解实现 JSP Taglig实现 1、基于编码的授权实现 1.1基于传统角色授权实现 当需要验证用户是否拥有某个角色时，可以调用Subject 实例的hasRole*方法验证。 123456Subject currentUser = SecurityUtils.getSubject(); if (currentUser.hasRole(\"administrator\")) &#123; //show the admin button &#125; else &#123; ​ //don't show the button? Grey it out? &#125; 相关验证方法如下： Subject方法 描述 hasRole(String roleName) 当用户拥有指定角色时，返回true hasRoles(List roleNames) 按照列表顺序返回相应的一个boolean值数组 hasAllRoles(Collection roleNames) 如果用户拥有所有指定角色时，返回true 断言支持 Shiro还支持以断言的方式进行授权验证。断言成功，不返回任何值，程序继续执行；断言失败时，将抛出异常信息。使用断言，可以使我们的代码更加简洁。 12345Subject currentUser = SecurityUtils.getSubject(); //guarantee that the current user is a bank teller and //therefore allowed to open the account: currentUser.checkRole(\"bankTeller\"); openBankAccount(); 断言的相关方法： Subject方法 描述 checkRole(String roleName) 断言用户是否拥有指定角色 checkRoles(Collection roleNames) 断言用户是否拥有所有指定角色 checkRoles(String… roleNames) 对上一方法的方法重载 1.2 基于权限角色授权实现 相比传统角色模式，基于权限的角色模式耦合性要更低些，它不会因角色的改变而对源代码进行修改，因此，基于权限的角色模式是更好的访问控制方式。 它的代码实现有以下几种实现方式： a.基于权限对象的实现 创建org.apache.shiro.authz.Permission的实例，将该实例对象作为参数传递给Subject.isPermitted（）进行验证。 1234567891011121314Permission printPermission = new PrinterPermission(\"laserjet4400n\", \"print\"); Subject currentUser = SecurityUtils.getSubject(); if (currentUser.isPermitted(printPermission)) &#123; //show the Print button &#125; else &#123; //don't show the button? Grey it out? &#125; Permission printPermission = new PrinterPermission(\"laserjet4400n\", \"print\"); Subject currentUser = SecurityUtils.getSubject(); if (currentUser.isPermitted(printPermission)) &#123; //show the Print button &#125; else &#123; //don't show the button? Grey it out? &#125; 相关方法如下： Subject方法 描述 isPermitted(Permission p) Subject拥有制定权限时，返回treu isPermitted(List perms) 返回对应权限的boolean数组 isPermittedAll(Collection perms) Subject拥有所有制定权限时，返回true 2、 基于字符串的实现 相比笨重的基于对象的实现方式，基于字符串的实现便显得更加简洁。 123456Subject currentUser = SecurityUtils.getSubject(); if (currentUser.isPermitted(\"printer:print:laserjet4400n\")) &#123; //show the Print button &#125; else &#123; //don't show the button? Grey it out? &#125; 使用冒号分隔的权限表达式是org.apache.shiro.authz.permission.WildcardPermission 默认支持的实现方式。 这里分别代表了 资源类型：操作：资源ID 类似基于对象的实现相关方法，基于字符串的实现相关方法： isPermitted(String perm)、isPermitted(String... perms)、isPermittedAll(String... perms) a.基于权限对象的断言实现 123456Subject currentUser = SecurityUtils.getSubject(); //guarantee that the current user is permitted //to open a bank account: Permission p = new AccountPermission(\"open\"); currentUser.checkPermission(p); openBankAccount(); b.基于字符串的断言实现 12345Subject currentUser = SecurityUtils.getSubject(); //guarantee that the current user is permitted //to open a bank account: currentUser.checkPermission(\"account:open\"); openBankAccount(); 断言实现的相关方法 Subject方法 说明 checkPermission(Permission p) 断言用户是否拥有制定权限 checkPermission(String perm) 断言用户是否拥有制定权限 checkPermissions(Collection perms) 断言用户是否拥有所有指定权限 checkPermissions(String… perms) 断言用户是否拥有所有指定权限 3、基于注解的授权实现 Shiro注解支持AspectJ、Spring、Google-Guice等，可根据应用进行不同的配置。 相关的注解： 1@ RequiresAuthentication 可以用户类/属性/方法，用于表明当前用户需是经过认证的用户。 123456@RequiresAuthentication public void updateAccount(Account userAccount) &#123; //this method will only be invoked by a //Subject that is guaranteed authenticated ... &#125; 1234@ RequiresGuest表明该用户需为”guest”用户 @ RequiresPermissions当前用户需拥有制定权限 123456@RequiresPermissions(\"account:create\") public void createAccount(Account account) &#123; //this method will only be invoked by a Subject //that is permitted to create an account ... &#125; 1234@RequiresRoles 当前用户需拥有制定角色 @ RequiresUser 当前用户需为已认证用户或已记住用户 3、基于JSP TAG的授权实现 Shiro提供了一套JSP标签库来实现页面级的授权控制。 在使用Shiro标签库前，首先需要在JSP引入shiro标签： 1&lt;%@ taglib prefix=\"shiro\" uri=\"http://shiro.apache.org/tags\" %&gt; 下面一一介绍Shiro的标签： guest标签 验证当前用户是否为“访客”，即未认证（包含未记住）的用户 123&lt;shiro:guest&gt; Hi there! Please &lt;a href=\"login.jsp\"&gt;Login&lt;/a&gt; or &lt;a href=\"signup.jsp\"&gt;Signup&lt;/a&gt; today! &lt;/shiro:guest&gt; user标签 认证通过或已记住的用户 123&lt;shiro:user&gt; Welcome back John! Not John? Click &lt;a href=\"login.jsp\"&gt;here&lt;a&gt; to login. &lt;/shiro:user&gt; authenticated标签 已认证通过的用户。不包含已记住的用户，这是与user标签的区别所在。 123&lt;shiro:authenticated&gt; &lt;a href=\"updateAccount.jsp\"&gt;Update your contact information&lt;/a&gt;. &lt;/shiro:authenticated&gt; notAuthenticated标签 未认证通过用户，与authenticated标签相对应。与guest标签的区别是，该标签包含已记住用户。 12&lt;shiro:notAuthenticated&gt; Please &lt;a href=\"login.jsp\"&gt;login&lt;/a&gt; in order to update your credit card information. &lt;/shiro:notAuthenticated&gt; Shiro授权的内部处理机制 img 1、在应用程序中调用授权验证方法(Subject的isPermitted或hasRole等)2、Sbuject的实例通常是DelegatingSubject类（或子类）的实例对象，在认证开始时，会委托应用程序设置的securityManager实例调用相应的isPermitted或hasRole方法。3、接下来SecurityManager会委托内置的Authorizer的实例（默认是ModularRealmAuthorizer 类的实例，类似认证实例，它同样支持一个或多个Realm实例认证）调用相应的授权方法。4、每一个Realm将检查是否实现了相同的 Authorizer 接口。然后，将调用Reaml自己的相应的授权验证方法。 当使用多个Realm时，不同于认证策略处理方式，授权处理过程中：1、当调用Realm出现异常时，将立即抛出异常，结束授权验证。2、只要有一个Realm验证成功，那么将认为授权成功，立即返回，结束认证。 ​ …未完待续！","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"http://lvshen9.gitee.io/tags/Shiro/"},{"name":"权限","slug":"权限","permalink":"http://lvshen9.gitee.io/tags/权限/"}]},{"title":"我在Github上一个关于俄罗斯方块的项目","slug":"我在Github上一个关于俄罗斯方块的项目","date":"2017-08-30T00:50:44.000Z","updated":"2019-01-17T06:51:18.709Z","comments":true,"path":"2017/08/30/我在Github上一个关于俄罗斯方块的项目/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/30/我在Github上一个关于俄罗斯方块的项目/","excerpt":"Hi，这是我在Github上一个关于俄罗斯方块的项目，欢迎star和fork，下面做一个简短的介绍 项目地址：myTetris 项目特色:本项目基于Java开发，SQL Server做数据库，JDBC实现数据库与游戏实体通信，界面主要采用Java的awt,swing包开发。","text":"Hi，这是我在Github上一个关于俄罗斯方块的项目，欢迎star和fork，下面做一个简短的介绍 项目地址：myTetris 项目特色:本项目基于Java开发，SQL Server做数据库，JDBC实现数据库与游戏实体通信，界面主要采用Java的awt,swing包开发。 可切换主题。 可自定义控制按键。 每升一级会自动切换一张背景图。 每升一级会加快方块下落速度。 方块的旋转采用笛卡尔坐标90°旋转公式 主题 主题一 主题2 游戏开始界面 游戏开始界面 暂停界面 暂停界面 控制设置 控制设置 皮肤设置 皮肤设置 游戏架构 游戏架构 游戏等级与方块下落时间公式 游戏等级与方块下落时间公式 方块旋转公式 上面就是这款游戏的介绍，大家如果有兴趣可以去下载玩。","categories":[{"name":"游戏","slug":"游戏","permalink":"http://lvshen9.gitee.io/categories/游戏/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://lvshen9.gitee.io/tags/Github/"},{"name":"俄罗斯方块","slug":"俄罗斯方块","permalink":"http://lvshen9.gitee.io/tags/俄罗斯方块/"}]},{"title":"JavaScript常用代码集合","slug":"JavaScript常用代码集合","date":"2017-08-29T07:37:05.000Z","updated":"2017-08-29T07:51:17.819Z","comments":true,"path":"2017/08/29/JavaScript常用代码集合/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/29/JavaScript常用代码集合/","excerpt":"手机类型判断 1234567var BrowserInfo = &#123; userAgent: navigator.userAgent.toLowerCase() isAndroid: Boolean(navigator.userAgent.match(/android/ig)), isIphone: Boolean(navigator.userAgent.match(/iphone|ipod/ig)), isIpad: Boolean(navigator.userAgent.match(/ipad/ig)), isWeixin: Boolean(navigator.userAgent.match(/MicroMessenger/ig)),&#125;","text":"手机类型判断 1234567var BrowserInfo = &#123; userAgent: navigator.userAgent.toLowerCase() isAndroid: Boolean(navigator.userAgent.match(/android/ig)), isIphone: Boolean(navigator.userAgent.match(/iphone|ipod/ig)), isIpad: Boolean(navigator.userAgent.match(/ipad/ig)), isWeixin: Boolean(navigator.userAgent.match(/MicroMessenger/ig)),&#125; 返回字符串长度，汉字计数为2 12345678910function strLength(str) &#123; var a = 0; for (var i = 0; i &lt; str.length; i++) &#123; if (str.charCodeAt(i) &gt; 255) a += 2;//按照预期计数增加2 else a++; &#125; return a; &#125; 获取url中的参数 12345function GetQueryStringRegExp(name,url) &#123;var reg = new RegExp(\"(^|\\\\?|&amp;)\" + name + \"=([^&amp;]*)(\\\\s|&amp;|$)\", \"i\"); if (reg.test(url)) return decodeURIComponent(RegExp.$2.replace(/\\+/g, \" \")); &#125; js 绑定事件 适用于任何浏览器的元素绑定 12345678910function eventBind(obj, eventType, callBack) &#123; if (obj.addEventListener) &#123; obj.addEventListener(eventType, callBack, false); &#125;else if (window.attachEvent) &#123; obj.attachEvent('on' + eventType, callBack); &#125;else &#123; obj['on' + eventType] = callBack; &#125;&#125;;eventBind(document, 'click', bodyClick); 获得当前浏览器JS的版本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546function getjsversion()&#123; var n = navigator; var u = n.userAgent; var apn = n.appName; var v = n.appVersion; var ie = v.indexOf('MSIE '); if (ie &gt; 0)&#123; apv = parseInt(i = v.substring(ie + 5)); if (apv &gt; 3) &#123; apv = parseFloat(i); &#125; &#125; else &#123; apv = parseFloat(v); &#125; var isie = (apn == 'Microsoft Internet Explorer'); var ismac = (u.indexOf('Mac') &gt;= 0); var javascriptVersion = \"1.0\"; if (String &amp;&amp; String.prototype) &#123; javascriptVersion = '1.1'; if (javascriptVersion.match) &#123; javascriptVersion = '1.2'; var tm = new Date; if (tm.setUTCDate) &#123; javascriptVersion = '1.3'; if (isie &amp;&amp; ismac &amp;&amp; apv &gt;= 5) javascriptVersion = '1.4'; var pn = 0; if (pn.toPrecision) &#123; javascriptVersion = '1.5'; a = new Array; if (a.forEach) &#123; javascriptVersion = '1.6'; i = 0; o = new Object; tcf = new Function('o', 'var e,i=0;try&#123;i=new Iterator(o)&#125;catch(e)&#123;&#125;return i'); i = tcf(o); if (i &amp;&amp; i.next) &#123; javascriptVersion = '1.7'; &#125; &#125; &#125; &#125; &#125; &#125; return javascriptVersion;&#125; 获取当前点击事件的Object对象 1234567891011121314151617function getEvent() &#123; if (document.all) &#123; return window.event; //如果是ie &#125; func = getEvent.caller; while (func != null) &#123; var arg0 = func.arguments[0]; if (arg0) &#123; if ((arg0.constructor == Event || arg0.constructor == MouseEvent)|| (typeof (arg0) == \"object\" &amp;&amp; arg0.preventDefault &amp;&amp; arg0.stopPropagation)) &#123; return arg0; &#125; &#125; func = func.caller; &#125; return null;&#125;; 字符串截取方法 123456789101112131415161718192021getCharactersLen: function (charStr, cutCount) &#123; if (charStr == null || charStr == '') return ''; var totalCount = 0; var newStr = ''; for (var i = 0; i &lt; charStr.length; i++) &#123; var c = charStr.charCodeAt(i); if (c &lt; 255 &amp;&amp; c &gt; 0) &#123; totalCount++; &#125; else &#123; totalCount += 2; &#125; if (totalCount &gt;= cutCount) &#123; newStr += charStr.charAt(i); break; &#125;else &#123; newStr += charStr.charAt(i); &#125; &#125; return newStr;&#125; JS 弹出新窗口全屏 12345678910111213var tmp = window.open(\"about:blank\", \"\", \"fullscreen=1\")tmp.moveTo(0, 0);tmp.resizeTo(screen.width + 20, screen.height);tmp.focus();tmp.location.href = 'http://www.che168.com/pinggu/eva_' + msgResult.message[0] + '.html';var config_ = \"left=0,top=0,width=\" + (window.screen.Width) + \",height=\" + (window.screen.Height); window.open('http://www.che168.com/pinggu/eva_' + msgResult.message[0] + '.html', \"winHanle\", config_);//模拟form提交打开新页面var f = document.createElement(\"form\");f.setAttribute('action', 'http://www.che168.com/pinggu/eva_' + msgResult.message[0] + '.html');f.target = '_blank';document.body.appendChild(f);f.submit(); 全选/全不选 123456789function selectAll(objSelect) &#123; if (objSelect.checked == true) &#123; $(\"input[name='chkId']\").attr(\"checked\", true); $(\"input[name='chkAll']\").attr(\"checked\", true); &#125;else if (objSelect.checked == false) &#123; $(\"input[name='chkId']\").attr(\"checked\", false); $(\"input[name='chkAll']\").attr(\"checked\", false); &#125;&#125; js 判断浏览器 12345678910111213141516171819202122232425判断是否是 IE 浏览器if (document.all)&#123; alert(”IE浏览器”); &#125;else&#123; alert(”非IE浏览器”); &#125; if (!!window.ActiveXObject)&#123; alert(”IE浏览器”); &#125;else&#123; alert(”非IE浏览器”); &#125; 判断是IE几var isIE=!!window.ActiveXObject; var isIE6=isIE&amp;&amp;!window.XMLHttpRequest; var isIE8=isIE&amp;&amp;!!document.documentMode; var isIE7=isIE&amp;&amp;!isIE6&amp;&amp;!isIE8; if (isIE)&#123; if (isIE6)&#123; alert(”ie6″); &#125;else if (isIE8)&#123; alert(”ie8″); &#125;else if (isIE7)&#123; alert(”ie7″); &#125; &#125; 判断浏览器 12345678910111213141516function getOs() &#123; if (navigator.userAgent.indexOf(\"MSIE 8.0\") &gt; 0) &#123; return \"MSIE8\";&#125;else if (navigator.userAgent.indexOf(\"MSIE 6.0\") &gt; 0) &#123; return \"MSIE6\";&#125;else if (navigator.userAgent.indexOf(\"MSIE 7.0\") &gt; 0) &#123; return \"MSIE7\";&#125;else if (isFirefox = navigator.userAgent.indexOf(\"Firefox\") &gt; 0) &#123; return \"Firefox\";&#125;if (navigator.userAgent.indexOf(\"Chrome\") &gt; 0) &#123; return \"Chrome\";&#125;else &#123; return \"Other\"; &#125;&#125; JS判断两个日期大小 1234567891011121314//得到日期值并转化成日期格式//replace(/\\-/g, \"\\/\")是根据验证表达式把日期转化成长日期格式//这样再进行判断就好判断了function ValidateDate() &#123; var beginDate = $(\"#t_datestart\").val(); var endDate = $(\"#t_dateend\").val(); if (beginDate.length &gt; 0 &amp;&amp; endDate.length&gt;0) &#123; var sDate = new Date(beginDate.replace(/\\-/g, \"\\/\")); var eDate= new Date(endDate.replace(/\\-/g, \"\\/\")); if (sDate &gt; eDate) &#123; alert('开始日期要小于结束日期'); return false; &#125; &#125;&#125; 移除事件 12345678910this.moveBind = function (objId, eventType, callBack) &#123; var obj = document.getElementById(objId); if (obj.removeEventListener) &#123; obj.removeEventListener(eventType, callBack, false); &#125;else if (window.detachEvent) &#123; obj.detachEvent('on' + eventType, callBack); &#125;else &#123; obj['on' + eventType] = null; &#125;&#125; 回车提交 1234567$(\"id\").onkeypress = function (event) &#123; event = (event) ? event : ((window.event) ? window.event : \"\") keyCode = event.keyCode ? event.keyCode : (event.which ? event.which : event.charCode); if (keyCode == 13) &#123; $(\"SubmitLogin\").onclick(); &#125;&#125; JS 执行计时器 123timeStart = new Date().getTime();timesEnd = new Date().getTime();document.getElementById(\"time\").innerHTML = timesEnd - timeStart; JS 写Cookie 12345678910111213141516171819202122232425function setCookie(name, value, expires, path, domain) &#123; if (!expires) expires = -1; if (!path) path = \"/\"; var d = \"\" + name + \"=\" + value; var e; if (expires &lt; 0) &#123; e = \"\"; &#125;else if (expires == 0) &#123; var f = new Date(1970, 1, 1); e = \";expires=\" + f.toUTCString(); &#125;else &#123; var now = new Date(); var f = new Date(now.getTime() + expires * 1000); e = \";expires=\" + f.toUTCString(); &#125; var dm; if (!domain) &#123; dm = \"\"; &#125;else &#123; dm = \";domain=\" + domain; &#125; document.cookie = name + \"=\" + value + \";path=\" + path + e + dm;&#125;; JS 读Cookie 123456789101112function readCookie(name) &#123; var nameEQ = name + \"=\"; var ca = document.cookie.split(';'); for (var i = 0; i &lt; ca.length; i++) &#123; var c = ca[i]; while (c.charAt(0) == ' ') c = c.substring(1, c.length); if (c.indexOf(nameEQ) == 0) &#123; return decodeURIComponent(c.substring(nameEQ.length, c.length)) &#125; &#125; return null&#125; Ajax 请求 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152C.ajax = function (args) &#123; var self = this; this.options = &#123; type: 'GET', async: true, contentType: 'application/x-www-form-urlencoded', url: 'about:blank', data: null, success: &#123;&#125;, error: &#123;&#125; &#125;; this.getXmlHttp = function () &#123; var xmlHttp; try &#123; xmlhttp = new XMLHttpRequest(); &#125;catch (e) &#123; try &#123; xmlhttp = new ActiveXObject(\"Msxml2.XMLHTTP\"); &#125;catch (e) &#123; xmlHttp = new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125; &#125;if (!xmlhttp) &#123; alert('您的浏览器不支持AJAX'); return false; &#125; return xmlhttp; &#125;; this.send = function () &#123; C.each(self.options, function (key, val) &#123; self.options[key] = (args[key] == null) ? val : args[key]; &#125;); var xmlHttp = new self.getXmlHttp(); if (self.options.type.toUpperCase() == 'GET') &#123; xmlHttp.open(self.options.type, self.options.url + (self.options.data == null ? \"\" : ((/[?]$/.test(self.options.url) ? '&amp;' : '?') + self.options.data)), self.options.async); &#125;else &#123; xmlHttp.open(self.options.type, self.options.url, self.options.async); xmlHttp.setRequestHeader('Content-Length', self.options.data.length); &#125; xmlHttp.setRequestHeader('Content-Type', self.options.contentType); xmlHttp.onreadystatechange = function () &#123; if (xmlHttp.readyState == 4) &#123; if (xmlHttp.status == 200 || xmlHttp.status == 0) &#123; if (typeof self.options.success == 'function') self.options.success(xmlHttp.responseText); xmlHttp = null; &#125;else &#123; if (typeof self.options.error == 'function') self.options.error('Server Status: ' + xmlHttp.status); &#125; &#125; &#125;; xmlHttp.send(self.options.type.toUpperCase() == 'POST' ? self.options.data.toString() : null); &#125;; this.send();&#125;; JS StringBuilder 用法 123456789function StringBuilder() &#123;this.strings = new Array;&#125;;StringBuilder.prototype.append = function (str) &#123;this.strings.push(str);&#125;;StringBuilder.prototype.toString = function () &#123;return this.strings.join('');&#125;; JS 加载到顶部LoadJS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354function loadJS (url, fn) &#123; var ss = document.getElementsByName('script'), loaded = false; for (var i = 0, len = ss.length; i &lt; len; i++) &#123; if (ss[i].src &amp;&amp; ss[i].getAttribute('src') == url) &#123; loaded = true; break; &#125; &#125; if (loaded) &#123; if (fn &amp;&amp; typeof fn != 'undefined' &amp;&amp; fn instanceof Function) fn(); return false; &#125; var s = document.createElement('script'), b = false; s.setAttribute('type', 'text/javascript'); s.setAttribute('src', url); s.onload = s.onreadystatechange = function () &#123; if (!b &amp;&amp; (!this.readyState || this.readyState == 'loaded' || this.readyState == 'complete')) &#123; b = true; if (fn &amp;&amp; typeof fn != 'undefined' &amp;&amp; fn instanceof Function) fn(); &#125; &#125;; document.getElementsByTagName('head')[0].appendChild(s); &#125;,bind: function (objId, eventType, callBack) &#123; //适用于任何浏览器的绑定 var obj = document.getElementById(objId); if (obj.addEventListener) &#123; obj.addEventListener(eventType, callBack, false); &#125;else if (window.attachEvent) &#123; obj.attachEvent('on' + eventType, callBack); &#125;else &#123; obj['on' + eventType] = callBack; &#125;&#125;function JSLoad (args) &#123; s = document.createElement(\"script\"); s.setAttribute(\"type\", \"text/javascript\"); s.setAttribute(\"src\", args.url); s.onload = s.onreadystatechange = function () &#123; if (!s.readyState || s.readyState == \"loaded\" || s.readyState == \"complete\") &#123; if (typeof args.callback == \"function\") args.callback(this, args); s.onload = s.onreadystatechange = null; try &#123; s.parentNode &amp;&amp; s.parentNode.removeChild(s); &#125; catch (e) &#123; &#125; &#125; &#125;; document.getElementsByTagName(\"head\")[0].appendChild(s); &#125; 清空 LoadJS 加载到顶部的js引用 12345678910function ClearHeadJs (src) &#123; var js = document.getElementsByTagName('head')[0].children; var obj = null; for (var i = 0; i &lt; js.length; i++) &#123; if (js[i].tagName.toLowerCase() == \"script\" &amp;&amp; js[i].attributes['src'].value.indexOf(src) &gt; 0) &#123; obj = js[i]; &#125; &#125; document.getElementsByTagName('head')[0].removeChild(obj);&#125;; JS 替换非法字符主要用在密码验证上出现的特殊字符 123function URLencode(sStr) &#123;return escape(sStr).replace(/\\+/g, '%2B').replace(/\\\"/g, '%22').replace(/\\'/g, '%27').replace(/\\//g, '%2F');&#125;; 按Ctrl + Entert 直接提交表单 12345678document.body.onkeydown = function (evt) &#123; evt = evt ? evt : (window.event ? window.event : null); if (13 == evt.keyCode &amp;&amp; evt.ctrlKey) &#123; evt.returnValue = false; evt.cancel = true; PostData(); &#125;&#125;; 获取当前时间 123456789101112131415function GetCurrentDate() &#123; var d = new Date(); var y = d.getYear()+1900; month = add_zero(d.getMonth() + 1), days = add_zero(d.getDate()), hours = add_zero(d.getHours()); minutes = add_zero(d.getMinutes()), seconds = add_zero(d.getSeconds()); var str = y + '-' + month + '-' + days + ' ' + hours + ':' + minutes + ':' + seconds; return str; &#125;; function add_zero(temp) &#123; if (temp &lt; 10) return \"0\" + temp; else return temp;&#125; Js 去掉空格方法 123456789String.prototype.Trim = function()&#123; return this.replace(/(^\\s*)|(\\s*$)/g, \"\"); &#125;String.prototype.LTrim = function()&#123; return this.replace(/(^\\s*)/g, \"\"); &#125;String.prototype.RTrim = function()&#123; return this.replace(/(\\s*$)/g, \"\"); &#125; js 动态移除 head 里的 js 引用 12345678910this.ClearHeadJs = function (src) &#123; var js = document.getElementsByTagName('head')[0].children; var obj = null; for (var i = 0; i &lt; js.length; i++) &#123; if (js[i].tagName.toLowerCase() == \"script\" &amp;&amp; js[i].attributes['src'].value.indexOf(src) &gt; 0) &#123; obj = js[i]; &#125; &#125; document.getElementsByTagName('head')[0].removeChild(obj);&#125;; 整个URL 点击事件 加在URL里的onclick里 1234567891011121314function CreateFrom(url, params) &#123; var f = document.createElement(\"form\"); f.setAttribute(\"action\", url); for (var i = 0; i &lt; params.length; i++) &#123; var input = document.createElement(\"input\"); input.setAttribute(\"type\", \"hidden\"); input.setAttribute(\"name\", params[i].paramName); input.setAttribute(\"value\", params[i].paramValue); f.appendChild(input); &#125; f.target = \"_blank\"; document.body.appendChild(f); f.submit();&#125;; 判断浏览器使用的是哪个 JS 版本 12345678910111213&lt;script language=\"javascript\"&gt; var jsversion = 1.0; &lt;/script&gt; &lt;script language=\"javascript1.1\"&gt; jsversion = 1.1; &lt;/script&gt; &lt;script language=\"javascript1.2\"&gt; jsversion = 1.2; &lt;/script&gt; ...... ...... &lt;script language=\"javascript1.9\"&gt; jsversion = 1.9; &lt;/script&gt; &lt;script language=\"javascript2.0\"&gt; jsversion = 2.0; &lt;/script&gt; alert(jsversion);","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lvshen9.gitee.io/tags/JavaScript/"},{"name":"前端","slug":"前端","permalink":"http://lvshen9.gitee.io/tags/前端/"}]},{"title":"如何在MySQL中使用索引","slug":"如何在MySQL中使用索引","date":"2017-08-29T00:23:33.000Z","updated":"2017-08-29T02:23:09.686Z","comments":true,"path":"2017/08/29/如何在MySQL中使用索引/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/29/如何在MySQL中使用索引/","excerpt":"概述为了在数据库中快速查找我们要的记录，通常会使用索引。合理的使用索引能大大的提高数据库的访问性能。本文主要介绍如何在MySQL数据库中使用索引，以及如何创建高效的索引。 索引的优点 大大减轻了服务器需要扫描的数据量，从而提高了数据的检索速度 帮助服务器避免排序和临时表 可以将随机I/O变为顺序I/O 索引类型","text":"概述为了在数据库中快速查找我们要的记录，通常会使用索引。合理的使用索引能大大的提高数据库的访问性能。本文主要介绍如何在MySQL数据库中使用索引，以及如何创建高效的索引。 索引的优点 大大减轻了服务器需要扫描的数据量，从而提高了数据的检索速度 帮助服务器避免排序和临时表 可以将随机I/O变为顺序I/O 索引类型 1.主键索引1ALTER TABLE '表名' ADD PRIMARY KEY '索引名' ('column'); 2.唯一索引1ALTER TABLE 'table_name' ADD UNIQUE 'index_name' ('column'); 3.普通索引1ALTER TABLE 'table_name' ADD INDEX 'index_name' ('column'); 4.全文索引1ALTER TABLE 'table_name' ADD FULLTEXT 'index_name' ('column'); 5.组合1ALTER TABLE 'table_name' ADD INDEX 'index_name' ('column1', 'column2', ...); 有效索引首先创建一个测试表 12345678910DROP TABLE IF EXISTS user_test;CREATE TABLE user_test( id int AUTO_INCREMENT PRIMARY KEY, user_name varchar(30) NOT NULL, sex bit(1) NOT NULL DEFAULT b'1', city varchar(50) NOT NULL, age int NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8; 在创建一个组合索引 1ALTER TABLE user_test ADD INDEX idx_user (user_name , city , age); 1.全值匹配全值匹配指的是和索引中的所有列进行匹配，如：以上面创建的索引为例，在where条件后可同时查询（user_name，city，age）为条件的数据。 1SELECT * FROM user_test WHERE user_name = 'feinik' AND age = 26 AND city = '广州'; 2.匹配列前缀指匹配列值的开头部分，如：查询用户名以feinik开头的所有用户 1SELECT * FROM user_test WHERE user_name LIKE 'feinik%'; 注：如果where查询条件中有某个列的范围查询，则其右边的所有列都无法使用索引优化查询 1SELECT * FROM user_test WHERE user_name = 'feinik' AND city LIKE '广州%' AND age = 26; 高效索引策略1.前缀索引如果索引的字符列很长，会造成索引失效。解决方法之一；使用哈希索引；之二：使用前缀索引。前缀索引是选择字符列的前n个字符作为索引，这样可以大大节约索引空间，从而提高索引效率。 首先：确定前缀索引的长度 前缀索引要选择足够长的前缀以保证高的选择性，同时又不能太长，我们可以通过以下方式来计算出合适的前缀索引的选择长度值： 1SELECT COUNT(DISTINCT index_column)/COUNT(*) FROM table_name; -- index_column代表要添加前缀索引的列 注：比值越大，索引的效率越高 确定前缀索引长度后，创建前缀索引 1ALTER TABLE table_name ADD INDEX index_name (index_column(length)); 注：MySql无法使用前缀索引做ORDER BY 和 GROUP BY以及使用前缀索引做覆盖扫描 2.覆盖索引如果一个索引（如：组合索引）中包含所有要查询的字段的值，那么就称之为覆盖索引，如： 1SELECT user_name, city, age FROM user_test WHERE user_name = 'feinik' AND age &gt; 25; 因为要查询的字段（user_name, city, age）都包含在组合索引的索引列中，所以就使用了覆盖索引查询，查看是否使用了覆盖索引可以通过执行计划中的Extra中的值为Using index则证明使用了覆盖索引，覆盖索引可以极大的提高访问性能。 使用索引排序使用索引来排序极大的提高了排序速度，其需要满足以下条件即可: 1、ORDER BY子句后的列顺序要与组合索引的列顺序一致，且所有排序列的排序方向（正序/倒序）需一致 2、所查询的字段值需要包含在索引列中，及满足覆盖索引 举个栗子： 首先创建一个组合索引 1ALTER TABLE user_test ADD INDEX index_user(user_name , city , age); 那么我们就可以使用索引排序了 12345671、SELECT user_name, city, age FROM user_test ORDER BY user_name;2、SELECT user_name, city, age FROM user_test ORDER BY user_name, city;3、SELECT user_name, city, age FROM user_test ORDER BY user_name DESC, city DESC;4、SELECT user_name, city, age FROM user_test WHERE user_name = 'feinik' ORDER BY city; 注：第4点说明—-如果where查询条件为索引列的第一列，且为常量条件，那么也可以使用到索引 但下面的例子就会使索引排序失效 1、sex不在索引列中 1SELECT user_name, city, age FROM user_test ORDER BY user_name, sex; 2、排序列的方向不一致 1SELECT user_name, city, age FROM user_test ORDER BY user_name ASC, city DESC; 3、所要查询的字段列sex没有包含在索引列中 1SELECT user_name, city, age, sex FROM user_test ORDER BY user_name; 4、where查询条件后的user_name为范围查询，所以无法使用到索引的其他列 1SELECT user_name, city, age FROM user_test WHERE user_name LIKE 'feinik%' ORDER BY city; 5、多表连接查询时，只有当ORDER BY后的排序字段都是第一个表中的索引列（需要满足以上索引排序的两个规则）时，方可使用索引排序。如：再创建一个用户的扩展表user_test_ext，并建立uid的索引。 12345678910111213DROP TABLE IF EXISTS user_test_ext;CREATE TABLE user_test_ext( id int AUTO_INCREMENT PRIMARY KEY, uid int NOT NULL, u_password VARCHAR(64) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;ALTER TABLE user_test_ext ADD INDEX index_user_ext(uid); 索引排序有效 1SELECT user_name, city, age FROM user_test u LEFT JOIN user_test_ext ue ON u.id = ue.uid ORDER BY u.user_name; 索引排序无效 1SELECT user_name, city, age FROM user_test u LEFT JOIN user_test_ext ue ON u.id = ue.uid ORDER BY ue.uid; 总结本文讲解了索引规则，不同索引的创建，以及如何正确的创建出高效的索引技巧来尽可能的提高查询速度，当然了关于索引的使用技巧不单单只有这些，关于索引的更多技巧还需平时不断的积累相关经验。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://lvshen9.gitee.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"http://lvshen9.gitee.io/tags/索引/"},{"name":"数据库","slug":"数据库","permalink":"http://lvshen9.gitee.io/tags/数据库/"}]},{"title":"遗传算法的基本概念和Java实现","slug":"遗传算法的基本概念和Java实现","date":"2017-08-28T01:24:57.000Z","updated":"2017-08-28T01:33:45.424Z","comments":true,"path":"2017/08/28/遗传算法的基本概念和Java实现/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/28/遗传算法的基本概念和Java实现/","excerpt":"本文来自 Itimetraveler’s Blog： 遗传算法的基本概念和Java实现 基因遗传算法是一种灵感源于达尔文自然进化理论的启发式搜索算法。该算法反映了自然选择的过程，即最适者被选定繁殖，并产生下一代。本文简要地介绍了遗传算法的基本概念和实现，希望能为读者展示启发式搜索的魅力。 [ 如上图（左）所示，遗传算法的个体由多条染色体组成，每条染色体由多个基因组成。上图（右）展示了染色体分割和组合的方式。](https://itimetraveler.github.io/gallery/genetic-algorithms/1-BYDJpa6M2rzWNSurvspf8Q.png)","text":"本文来自 Itimetraveler’s Blog： 遗传算法的基本概念和Java实现 基因遗传算法是一种灵感源于达尔文自然进化理论的启发式搜索算法。该算法反映了自然选择的过程，即最适者被选定繁殖，并产生下一代。本文简要地介绍了遗传算法的基本概念和实现，希望能为读者展示启发式搜索的魅力。 [ 如上图（左）所示，遗传算法的个体由多条染色体组成，每条染色体由多个基因组成。上图（右）展示了染色体分割和组合的方式。](https://itimetraveler.github.io/gallery/genetic-algorithms/1-BYDJpa6M2rzWNSurvspf8Q.png) 遗传算法的概念**自然选择的过程从选择群体中最适应环境的个体开始。后代继承了父母的特性，并且这些特性将添加到下一代中。如果父母具有更好的适应性，那么它们的后代将更易于存活。迭代地进行该自然选择的过程，最终，我们将得到由最适应环境的个体组成的一代。 这一概念可以被应用于搜索问题中。我们考虑一个问题的诸多解决方案，并从中搜寻出最佳方案。 遗传算法含以下五步： 初始化 个体评价（计算适应度函数） 选择运算 交叉运算 变异运算 初始化该过程从种群的一组个体开始，且每一个体都是待解决问题的一个候选解。 个体以一组参数（变量）为特征，这些特征被称为基因，串联这些基因就可以组成染色体（问题的解）。 在遗传算法中，单个个体的基因组以字符串的方式呈现，通常我们可以使用二进制（1 和 0 的字符串）编码，即一个二进制串代表一条染色体串。因此可以说我们将基因串或候选解的特征编码在染色体中。 [ *种群、染色体和基因*](https://itimetraveler.github.io/gallery/genetic-algorithms/1-vIrsxg12DSltpdWoO561yA.png) 个体评价（计算适应度函数）个体评价利用适应度函数评估了该个体对环境的适应度（与其它个体竞争的能力）。每一个体都有适应度评分，个体被选中进行繁殖的可能性取决于其适应度评分。适应度函数值越大，解的质量就越高。适应度函数是遗传算法进化的驱动力，也是进行自然选择的唯一标准，它的设计应结合求解问题本身的要求而定。 选择运算选择运算的目的是选出适应性最好的个体，并使它们将基因传到下一代中。基于其适应度评分，我们选择多对较优个体（父母）。适应度高的个体更易被选中繁殖，即将较优父母的基因传递到下一代。 交叉运算交叉运算是遗传算法中最重要的阶段。对每一对配对的父母，基因都存在随机选中的交叉点。 举个例子，下图的交叉点为 3： [ Crossover point](https://itimetraveler.github.io/gallery/genetic-algorithms/1-Wi6ou9jyMHdxrF2dgczz7g.png) 父母间在交叉点之前交换基因，从而产生了后代。 [ Exchanging genes among parents](https://itimetraveler.github.io/gallery/genetic-algorithms/1-eQxFezBtdfdLxHsvSvBNGQ.png) 父母间交换基因，然后产生的新后代被添加到种群中。 [ New offspring](https://itimetraveler.github.io/gallery/genetic-algorithms/1-_Dl6Hwkay-UU24DJ_oVrLw.png) 变异运算在某些形成的新后代中，它们的某些基因可能受到低概率变异因子的作用。这意味着二进制位串中的某些位可能会翻转。 [ 变异运算前后](https://itimetraveler.github.io/gallery/genetic-algorithms/1-CGt_UhRqCjIDb7dqycmOAg.png) 变异运算可用于保持种群内的多样性，并防止过早收敛。 终止在群体收敛的情况下（群体内不产生与前一代差异较大的后代）该算法终止。也就是说遗传算法提供了一组问题的解。 案例实现种群的规模恒定。新一代形成时，适应度最差的个体凋亡，为后代留出空间。这些阶段的序列被不断重复，以产生优于先前的新一代。 这一迭代过程的伪代码： 12345678910STARTGenerate the initial populationCompute fitnessREPEAT Selection Crossover Mutation Compute fitnessUNTIL population has convergedSTOP Java 中的实例实现以下展示的是遗传算法在 Java 中的示例实现，我们可以随意调试和修改这些代码。给定一组五个基因，每一个基因可以保存一个二进制值 0 或 1。这里的适应度是基因组中 1 的数量。如果基因组内共有五个 1，则该个体适应度达到最大值。如果基因组内没有 1，那么个体的适应度达到最小值。该遗传算法希望最大化适应度，并提供适应度达到最大的个体所组成的群体。注意：本例中，在交叉运算与突变运算之后，适应度最低的个体被新的，适应度最高的后代所替代。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233import java.util.Random;/** * * @author Vijini *///Main classpublic class SimpleDemoGA &#123; Population population = new Population(); Individual fittest; Individual secondFittest; int generationCount = 0; public static void main(String[] args) &#123; Random rn = new Random(); SimpleDemoGA demo = new SimpleDemoGA(); //Initialize population demo.population.initializePopulation(10); //Calculate fitness of each individual demo.population.calculateFitness(); System.out.println(\"Generation: \" + demo.generationCount + \" Fittest: \" + demo.population.fittest); //While population gets an individual with maximum fitness while (demo.population.fittest &lt; 5) &#123; ++demo.generationCount; //Do selection demo.selection(); //Do crossover demo.crossover(); //Do mutation under a random probability if (rn.nextInt()%7 &lt; 5) &#123; demo.mutation(); &#125; //Add fittest offspring to population demo.addFittestOffspring(); //Calculate new fitness value demo.population.calculateFitness(); System.out.println(\"Generation: \" + demo.generationCount + \" Fittest: \" + demo.population.fittest); &#125; System.out.println(\"\\nSolution found in generation \" + demo.generationCount); System.out.println(\"Fitness: \"+demo.population.getFittest().fitness); System.out.print(\"Genes: \"); for (int i = 0; i &lt; 5; i++) &#123; System.out.print(demo.population.getFittest().genes[i]); &#125; System.out.println(\"\"); &#125; //Selection void selection() &#123; //Select the most fittest individual fittest = population.getFittest(); //Select the second most fittest individual secondFittest = population.getSecondFittest(); &#125; //Crossover void crossover() &#123; Random rn = new Random(); //Select a random crossover point int crossOverPoint = rn.nextInt(population.individuals[0].geneLength); //Swap values among parents for (int i = 0; i &lt; crossOverPoint; i++) &#123; int temp = fittest.genes[i]; fittest.genes[i] = secondFittest.genes[i]; secondFittest.genes[i] = temp; &#125; &#125; //Mutation void mutation() &#123; Random rn = new Random(); //Select a random mutation point int mutationPoint = rn.nextInt(population.individuals[0].geneLength); //Flip values at the mutation point if (fittest.genes[mutationPoint] == 0) &#123; fittest.genes[mutationPoint] = 1; &#125; else &#123; fittest.genes[mutationPoint] = 0; &#125; mutationPoint = rn.nextInt(population.individuals[0].geneLength); if (secondFittest.genes[mutationPoint] == 0) &#123; secondFittest.genes[mutationPoint] = 1; &#125; else &#123; secondFittest.genes[mutationPoint] = 0; &#125; &#125; //Get fittest offspring Individual getFittestOffspring() &#123; if (fittest.fitness &gt; secondFittest.fitness) &#123; return fittest; &#125; return secondFittest; &#125; //Replace least fittest individual from most fittest offspring void addFittestOffspring() &#123; //Update fitness values of offspring fittest.calcFitness(); secondFittest.calcFitness(); //Get index of least fit individual int leastFittestIndex = population.getLeastFittestIndex(); //Replace least fittest individual from most fittest offspring population.individuals[leastFittestIndex] = getFittestOffspring(); &#125;&#125;//Individual classclass Individual &#123; int fitness = 0; int[] genes = new int[5]; int geneLength = 5; public Individual() &#123; Random rn = new Random(); //Set genes randomly for each individual for (int i = 0; i &lt; genes.length; i++) &#123; genes[i] = rn.nextInt() % 2; &#125; fitness = 0; &#125; //Calculate fitness public void calcFitness() &#123; fitness = 0; for (int i = 0; i &lt; 5; i++) &#123; if (genes[i] == 1) &#123; ++fitness; &#125; &#125; &#125;&#125;//Population classclass Population &#123; int popSize = 10; Individual[] individuals = new Individual[10]; int fittest = 0; //Initialize population public void initializePopulation(int size) &#123; for (int i = 0; i &lt; individuals.length; i++) &#123; individuals[i] = new Individual(); &#125; &#125; //Get the fittest individual public Individual getFittest() &#123; int maxFit = Integer.MIN_VALUE; for (int i = 0; i &lt; individuals.length; i++) &#123; if (maxFit &lt;= individuals[i].fitness) &#123; maxFit = i; &#125; &#125; fittest = individuals[maxFit].fitness; return individuals[maxFit]; &#125; //Get the second most fittest individual public Individual getSecondFittest() &#123; int maxFit1 = 0; int maxFit2 = 0; for (int i = 0; i &lt; individuals.length; i++) &#123; if (individuals[i].fitness &gt; individuals[maxFit1].fitness) &#123; maxFit2 = maxFit1; maxFit1 = i; &#125; else if (individuals[i].fitness &gt; individuals[maxFit2].fitness) &#123; maxFit2 = i; &#125; &#125; return individuals[maxFit2]; &#125; //Get index of least fittest individual public int getLeastFittestIndex() &#123; int minFit = 0; for (int i = 0; i &lt; individuals.length; i++) &#123; if (minFit &gt;= individuals[i].fitness) &#123; minFit = i; &#125; &#125; return minFit; &#125; //Calculate fitness of each individual public void calculateFitness() &#123; for (int i = 0; i &lt; individuals.length; i++) &#123; individuals[i].calcFitness(); &#125; getFittest(); &#125;&#125; 原文来自：Introduction to Genetic Algorithms — Including Example Code","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"搜索","slug":"搜索","permalink":"http://lvshen9.gitee.io/tags/搜索/"}]},{"title":"【算法】10亿int型数，统计只出现一次的数","slug":"bitmap","date":"2017-08-27T07:52:21.000Z","updated":"2017-08-27T08:16:31.401Z","comments":true,"path":"2017/08/27/bitmap/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/27/bitmap/","excerpt":"本文来自 Itimetraveler’s Blog： 【算法】10亿int型数，统计只出现一次的数 题目10亿int整型数，以及一台可用内存为1GB的机器，时间复杂度要求O(n)，统计只出现一次的数？ 分析首先分析多大的内存能够表示10亿的数呢？一个int型占4字节，10亿就是40亿字节（很明显就是4GB），也就是如果完全读入内存需要占用4GB，而题目只给1GB内存，显然不可能将所有数据读入内存。 我们先不考虑时间复杂度，仅考虑解决问题。那么接下来的思路一般有两种。 位图法：用一个bit位来标识一个int整数。 分治法：分批处理这10亿的数。","text":"本文来自 Itimetraveler’s Blog： 【算法】10亿int型数，统计只出现一次的数 题目10亿int整型数，以及一台可用内存为1GB的机器，时间复杂度要求O(n)，统计只出现一次的数？ 分析首先分析多大的内存能够表示10亿的数呢？一个int型占4字节，10亿就是40亿字节（很明显就是4GB），也就是如果完全读入内存需要占用4GB，而题目只给1GB内存，显然不可能将所有数据读入内存。 我们先不考虑时间复杂度，仅考虑解决问题。那么接下来的思路一般有两种。 位图法：用一个bit位来标识一个int整数。 分治法：分批处理这10亿的数。 一种是位图法，如果各位老司机有经验的话很快会想到int整型数是4字节（Byte），也就是32位（bit），如果能用一个bit位来标识一个int整数那么存储空间将大大减少。另一种是分治法，内存有限，我想办法分批读取处理。下面大致分析一下两种思路。 1、位图法（Bitmap）位图法是基于int型数的表示范围这个概念的，用一个bit位来标识一个int整数，若该位为1，则说明该数出现；若该位为0，则说明该数没有出现。一个int整型数占4字节（Byte），也就是32位（bit）。那么把所有int整型数字表示出来需要2^32 bit的空间，换算成字节单位也就是2^32/8 = 2^29 Byte，大约等于512MB 123// 插播一个常识2^10 Byte = 1024 Byte = 1KB2^30 Byte = (2^10)^3 Byte = 1024 * 1024 * 1024 Byte = 1GB 这下就好办了，只需要用512MB的内存就能存储所有的int的范围数。 具体方案那么接下来我们只需要申请一个int数组长度为 int tmp[N/32+1]即可存储完这些数据，其中N代表要进行查找的总数（这里也就是2^32），tmp中的每个元素在内存在占32位可以对应表示十进制数0~31,所以可得到BitMap表: tmp[0]:可表示0~31 tmp[1]:可表示32~63 tmp[2]可表示64~95 ~~ 假设这10亿int数据为：6,3,8,32,36,……，那么具体的BitMap表示为： [ img](https://itimetraveler.github.io/gallery/bitmap/37237-20160302211041080-958649492.png) (1). 如何判断int数字放在哪一个tmp数组中：将数字直接除以32取整数部分(x/32)，例如：整数8除以32取整等于0，那么8就在tmp[0]上； (2). 如何确定数字放在32个位中的哪个位：将数字mod32取模(x%32)。上例中我们如何确定8在tmp[0]中的32个位中的哪个位，这种情况直接mod上32就ok，又如整数8，在tmp[0]中的第8 mod上32等于8，那么整数8就在tmp[0]中的第八个bit位（从右边数起）。 然后我们怎么统计只出现一次的数呢？每一个数出现的情况我们可以分为三种：0次、1次、大于1次。也就是说我们需要用2个bit位才能表示每个数的出现情况。此时则三种情况分别对应的bit位表示是：00、01、11 我们顺序扫描这10亿的数，在对应的双bit位上标记该数出现的次数。最后取出所有双bit位为01的int型数就可以了。 Bitmap拓展位图（Bitmap）算法思想比较简单，但关键是如何确定十进制的数映射到二进制bit位的map图。 优点： 运算效率高，不许进行比较和移位； 占用内存少，比如N=10000000；只需占用内存为N/8=1250000Byte=1.25M 缺点：所有的数据不能重复。即不可对重复的数据进行排序和查找。 建立了Bit-Map之后，就可以方便的使用了。一般来说Bit-Map可作为数据的查找、去重、排序等操作。比如以下几个例子： 1、在3亿个整数中找出重复的整数个数，限制内存不足以容纳3亿个整数 对于这种场景可以采用2-BitMap来解决，即为每个整数分配2bit，用不同的0、1组合来标识特殊意思，如00表示此整数没有出现过，01表示出现一次，11表示出现过多次，就可以找出重复的整数了，其需要的内存空间是正常BitMap的2倍，为：3亿*2/8/1024/1024=71.5MB。 具体的过程如下：扫描着3亿个整数，组BitMap，先查看BitMap中的对应位置，如果00则变成01，是01则变成11，是11则保持不变，当将3亿个整数扫描完之后也就是说整个BitMap已经组装完毕。最后查看BitMap将对应位为11的整数输出即可。 2、对没有重复元素的整数进行排序 对于非重复的整数排序BitMap有着天然的优势，它只需要将给出的无重复整数扫描完毕，组装成为BitMap之后，那么直接遍历一遍Bit区域就可以达到排序效果了。 举个例子：对整数4、3、1、7、6进行排序： [ img](https://itimetraveler.github.io/gallery/bitmap/37237-20160302215109220-1394239868.png) 直接按Bit位输出就可以得到排序结果了。 3、已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数 8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。可以理解为从0-99 999 999的数字，每个数字对应一个Bit位，所以只需要99M个Bit==1.2MBytes，这样，就用了小小的1.2M左右的内存表示了所有的8位数的电话。 4、2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数 将bit-map扩展一下，用2bit表示一个数即可：0表示未出现；1表示出现一次；2表示出现2次及以上，即重复，在遍历这些数的时候，如果对应位置的值是0，则将其置为1；如果是1，将其置为2；如果是2，则保持不变。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map，都是一样的道理。 最后放一个使用Byte[]数组存储、读取bit位的示例代码，来自利用位映射原理对大数据排重： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class BitmapTest &#123; private static final int CAPACITY = 1000000000;//数据容量 // 定义一个byte数组缓存所有的数据 private byte[] dataBytes = new byte[1 &lt;&lt; 29]; public static void main(String[] args) &#123; BitmapTest ms = new BitmapTest(); byte[] bytes = null; Random random = new Random(); for (int i = 0; i &lt; CAPACITY; i++) &#123; int num = random.nextInt(); System.out.println(\"读取了第 \" + (i + 1) + \"\\t个数: \" + num); bytes = ms.splitBigData(num); &#125; System.out.println(\"\"); ms.output(bytes); &#125; /** * 读取数据，并将对应数数据的 到对应的bit中，并返回byte数组 * @param num 读取的数据 * @return byte数组 dataBytes */ private byte[] splitBigData(int num) &#123; long bitIndex = num + (1l &lt;&lt; 31); //获取num数据对应bit数组（虚拟）的索引 int index = (int) (bitIndex / 8); //bit数组（虚拟）在byte数组中的索引 int innerIndex = (int) (bitIndex % 8); //bitIndex 在byte[]数组索引index 中的具体位置 System.out.println(\"byte[\" + index + \"] 中的索引：\" + innerIndex); dataBytes[index] = (byte) (dataBytes[index] | (1 &lt;&lt; innerIndex)); return dataBytes; &#125; /** * 输出数组中的数据 * @param bytes byte数组 */ private void output(byte[] bytes) &#123; int count = 0; for (int i = 0; i &lt; bytes.length; i++) &#123; for (int j = 0; j &lt; 8; j++) &#123; if (!(((bytes[i]) &amp; (1 &lt;&lt; j)) == 0)) &#123; count++; int number = (int) ((((long) i * 8 + j) - (1l &lt;&lt; 31))); System.out.println(\"取出的第 \" + count + \"\\t个数: \" + number); &#125; &#125; &#125; &#125;&#125; 2、分治法分治法目前看到的解决方案有哈希分桶（Hash Buckets）和归并排序两种方案。 哈希分桶的思想是先遍历一遍，按照hash分N桶（比如1000桶），映射到不同的文件中。这样平均每个文件就10MB，然后分别处理这1000个文件，找出没有重复的即可。一个相同的数字，绝对不会夸文件，有hash做保证。因为算法具体还不甚了解，这里先不做详细介绍。 归并排序的思想可以参考这篇文章：面试题之10亿正整数问题续–关于多通道排序的问题 参考资料 程序员编程艺术：第十章、如何给10^7个数据量的磁盘文件排序 面试题之10亿正整数问题续–关于多通道排序的问题 利用位映射原理对大数据排重 十道海量数据处理面试题与十个方法大总结 海量数据处理之BitMap **","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"bitmap","slug":"bitmap","permalink":"http://lvshen9.gitee.io/tags/bitmap/"}]},{"title":"八大排序算法总结与java实现","slug":"sort","date":"2017-08-27T03:50:13.000Z","updated":"2017-08-27T07:33:00.504Z","comments":true,"path":"2017/08/27/sort/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/27/sort/","excerpt":"本文来自 Itimetraveler’s Blog： 八大排序算法总结与java实现 概述因为健忘，加上对各种排序算法理解不深刻，过段时间面对排序就蒙了。所以决定对我们常见的这几种排序算法进行统一总结，强行学习。首先罗列一下常见的十大排序算法：","text":"本文来自 Itimetraveler’s Blog： 八大排序算法总结与java实现 概述因为健忘，加上对各种排序算法理解不深刻，过段时间面对排序就蒙了。所以决定对我们常见的这几种排序算法进行统一总结，强行学习。首先罗列一下常见的十大排序算法： [ img](https://itimetraveler.github.io/gallery/sort-algorithms/big-o.png) 直接插入排序 希尔排序 简单选择排序 堆排序 冒泡排序 快速排序 归并排序 基数排序 其中我们讨论的这八大排序算法的实现可以参考我的Github：SortAlgorithms，它们都属于内部排序，也就是只考虑数据量较小仅需要使用内存的排序算法 一、直接插入排序（Insertion Sort） 插入排序的设计初衷是往有序的数组中快速插入一个新的元素。它的算法思想是：把要排序的数组分为了两个部分, 一部分是数组的全部元素(除去待插入的元素), 另一部分是待插入的元素; 先将第一部分排序完成, 然后再插入这个元素. 其中第一部分的排序也是通过再次拆分为两部分来进行的. 插入排序由于操作不尽相同, 可分为 直接插入排序 , 折半插入排序(又称二分插入排序), 链表插入排序 , 希尔排序 。我们先来看下直接插入排序。 1、基本思想直接插入排序的基本思想是：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过为止。 [ 使用插入排序为一列数字进行排序的过程](https://itimetraveler.github.io/gallery/sort-algorithms/Insertion-sort-example-300px.gif) 使用插入排序为一列数字进行排序的过程 2、算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： ①. 从第一个元素开始，该元素可以认为已经被排序②. 取出下一个元素，在已经排序的元素序列中从后向前扫描③. 如果该元素（已排序）大于新元素，将该元素移到下一位置④. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置⑤. 将新元素插入到该位置后⑥. 重复步骤②~⑤ [ 直接插入排序演示](https://itimetraveler.github.io/gallery/sort-algorithms/insert-sort.gif) 如果比较操作的代价比交换操作大的话，可以采用二分查找法来减少比较操作的数目。该算法可以认为是插入排序的一个变种，称为二分查找插入排序。 3、代码实现1234567891011121314151617181920212223/** * 插入排序 * * 1. 从第一个元素开始，该元素可以认为已经被排序 * 2. 取出下一个元素，在已经排序的元素序列中从后向前扫描 * 3. 如果该元素（已排序）大于新元素，将该元素移到下一位置 * 4. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 * 5. 将新元素插入到该位置后 * 6. 重复步骤2~5 * @param arr 待排序数组 */public static void insertionSort(int[] arr)&#123; for( int i=0; i&lt;arr.length-1; i++ ) &#123; for( int j=i+1; j&gt;0; j-- ) &#123; if( arr[j-1] &lt;= arr[j] ) break; int temp = arr[j]; //交换操作 arr[j] = arr[j-1]; arr[j-1] = temp; System.out.println(\"Sorting: \" + Arrays.toString(arr)); &#125; &#125;&#125; 直接插入排序复杂度如下： 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n²) O(n²) O(1) Tips: 由于直接插入排序每次只移动一个元素的位， 并不会改变值相同的元素之间的排序， 因此它是一种稳定排序。 二、希尔排序（Shell Sort） 第一个突破O(n^2)的排序算法；是简单插入排序的改进版；它与插入排序的不同之处在于，它会优先比较距离较远的元素。 希尔排序，也称递减增量排序算法，1959年Shell发明。是插入排序的一种高速而稳定的改进版本。 希尔排序是先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。 1、基本思想[ img](https://itimetraveler.github.io/gallery/sort-algorithms/shell-sort.jpg) 将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；每次再将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。 可以看到步长的选择是希尔排序的重要部分。只要最终步长为1任何步长序列都可以工作。一般来说最简单的步长取值是初次取数组长度的一半为增量，之后每次再减半，直到增量为1。更好的步长序列取值可以参考维基百科。 2、算法描述①. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（一般初次取数组半长，之后每次再减半，直到增量为1）②. 按增量序列个数k，对序列进行k 趟排序；③. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 3、代码实现以下是我自己的实现，可以看到实现很幼稚，但是好处是理解起来很简单。因为没有经过任何的优化，所以不建议大家直接使用。建议对比下方的维基百科官方实现代码，特别是步长取值策略部分。 123456789101112131415161718192021222324252627/** * 希尔排序 * * 1. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（一般初次取数组半长，之后每次再减半，直到增量为1） * 2. 按增量序列个数k，对序列进行k 趟排序； * 3. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void shellSort(int[] arr)&#123; int gap = arr.length / 2; for (; gap &gt; 0; gap /= 2) &#123; //不断缩小gap，直到1为止 for (int j = 0; (j+gap) &lt; arr.length; j++)&#123; //使用每个gap进行遍历 for(int k = 0; (k+gap) &lt; arr.length; k += gap)&#123; if(arr[k] &gt; arr[k+gap])&#123; int temp = arr[k+gap]; //交换操作 arr[k+gap] = arr[k]; arr[k] = temp; System.out.println(\"Gap=\" + gap + \", Sorting: \" + Arrays.toString(arr)); &#125; &#125; &#125; if(gap == 1)&#123; break; &#125; &#125;&#125; 下面是维基百科官方实现，大家注意gap步长取值部分： 1234567891011121314151617181920212223/** * 希尔排序（Wiki官方版） * * 1. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（注意此算法的gap取值） * 2. 按增量序列个数k，对序列进行k 趟排序； * 3. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void shell_sort(int[] arr) &#123; int gap = 1, i, j, len = arr.length; int temp; while (gap &lt; len / 3) gap = gap * 3 + 1; // &lt;O(n^(3/2)) by Knuth,1973&gt;: 1, 4, 13, 40, 121, ... for (; gap &gt; 0; gap /= 3) &#123; for (i = gap; i &lt; len; i++) &#123; temp = arr[i]; for (j = i - gap; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j -= gap) arr[j + gap] = arr[j]; arr[j + gap] = temp; &#125; &#125;&#125; 以下是希尔排序复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog2 n) O(nlog2 n) O(nlog2 n) O(1) 三、选择排序（Selection Sort） 从算法逻辑上看，选择排序是一种简单直观的排序算法，在简单选择排序过程中，所需移动记录的次数比较少。 1、基本思想选择排序的基本思想：比较 + 交换。 在未排序序列中找到最小（大）元素，存放到未排序序列的起始位置。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。 2、算法描述①. 从待排序序列中，找到关键字最小的元素；②. 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；③. 从余下的 N - 1 个元素中，找出关键字最小的元素，重复①、②步，直到排序结束。 3、代码实现选择排序比较简单，以下是我自己的实现，跟官方版差不多，所以完全可以参考。 12345678910111213141516171819202122232425/** * 选择排序 * * 1. 从待排序序列中，找到关键字最小的元素； * 2. 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换； * 3. 从余下的 N - 1 个元素中，找出关键字最小的元素，重复①、②步，直到排序结束。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void selectionSort(int[] arr)&#123; for(int i = 0; i &lt; arr.length-1; i++)&#123; int min = i; for(int j = i+1; j &lt; arr.length; j++)&#123; //选出之后待排序中值最小的位置 if(arr[j] &lt; arr[min])&#123; min = j; &#125; &#125; if(min != i)&#123; int temp = arr[min]; //交换操作 arr[min] = arr[i]; arr[i] = temp; System.out.println(\"Sorting: \" + Arrays.toString(arr)); &#125; &#125;&#125; 以下是选择排序复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n²) O(n²) O(1) 选择排序的简单和直观名副其实，这也造就了它”出了名的慢性子”，无论是哪种情况，哪怕原数组已排序完成，它也将花费将近n²/2次遍历来确认一遍。即便是这样，它的排序结果也还是不稳定的。 唯一值得高兴的是，它并不耗费额外的内存空间。 四、堆排序（Heap Sort） 1991年的计算机先驱奖获得者、斯坦福大学计算机科学系教授罗伯特·弗洛伊德(Robert W．Floyd) 和威廉姆斯(J．Williams) 在1964年共同发明了著名的堆排序算法(Heap Sort). 堆的定义如下：n个元素的序列 {k1,k2,···,kn} 当且仅当满足下关系时，称之为堆。 把此序列对应的二维数组看成一个完全二叉树。那么堆的含义就是：完全二叉树中任何一个非叶子节点的值均不大于（或不小于）其左，右孩子节点的值。由上述性质可知大顶堆的堆顶的关键字肯定是所有关键字中最大的，小顶堆的堆顶的关键字是所有关键字中最小的。因此我们可使用大顶堆进行升序排序, 使用小顶堆进行降序排序。 1、基本思想此处以大顶堆为例，堆排序的过程就是将待排序的序列构造成一个堆，选出堆中最大的移走，再把剩余的元素调整成堆，找出最大的再移走，重复直至有序。 2、算法描述①. 先将初始序列K[1..n]K[1..n]建成一个大顶堆, 那么此时第一个元素K1K1最大, 此堆为初始的无序区.②. 再将关键字最大的记录K1K1 (即堆顶, 第一个元素)和无序区的最后一个记录 KnKn 交换, 由此得到新的无序区K[1..n−1]K[1..n−1]和有序区K[n]K[n], 且满足K[1..n−1].keys⩽K[n].keyK[1..n−1].keys⩽K[n].key③. 交换K1K1 和 KnKn 后, 堆顶可能违反堆性质, 因此需将K[1..n−1]K[1..n−1]调整为堆. 然后重复步骤②, 直到无序区只有一个元素时停止. 动图效果如下所示： [ 堆排序过程](https://itimetraveler.github.io/gallery/sort-algorithms/heap_sort_gif.gif) 堆排序过程 [ 堆排序算法的演示。首先，将元素进行重排，以匹配堆的条件。图中排序过程之前简单的绘出了堆树的结构。](https://itimetraveler.github.io/gallery/sort-algorithms/Sorting_heapsort_anim.gif) 堆排序算法的演示。首先，将元素进行重排，以匹配堆的条件。图中排序过程之前简单的绘出了堆树的结构。 3、代码实现从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆函数，二是反复调用建堆函数以选择出剩余未排元素中最大的数来实现排序的函数。 总结起来就是定义了以下几种操作： 最大堆调整（Max_Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点 创建最大堆（Build_Max_Heap）：将堆所有数据重新排序 堆排序（HeapSort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 对于堆节点的访问： 父节点i的左子节点在位置：(2*i+1); 父节点i的右子节点在位置：(2*i+2); 子节点i的父节点在位置：floor((i-1)/2); 1234567891011121314151617181920212223242526272829303132333435363738/** * 堆排序 * * 1. 先将初始序列K[1..n]建成一个大顶堆, 那么此时第一个元素K1最大, 此堆为初始的无序区. * 2. 再将关键字最大的记录K1 (即堆顶, 第一个元素)和无序区的最后一个记录 Kn 交换, 由此得到新的无序区K[1..n−1]和有序区K[n], 且满足K[1..n−1].keys⩽K[n].key * 3. 交换K1 和 Kn 后, 堆顶可能违反堆性质, 因此需将K[1..n−1]调整为堆. 然后重复步骤②, 直到无序区只有一个元素时停止. * @param arr 待排序数组 */public static void heapSort(int[] arr)&#123; for(int i = arr.length; i &gt; 0; i--)&#123; max_heapify(arr, i); int temp = arr[0]; //堆顶元素(第一个元素)与Kn交换 arr[0] = arr[i-1]; arr[i-1] = temp; &#125;&#125;private static void max_heapify(int[] arr, int limit)&#123; if(arr.length &lt;= 0 || arr.length &lt; limit) return; int parentIdx = limit / 2; for(; parentIdx &gt;= 0; parentIdx--)&#123; if(parentIdx * 2 &gt;= limit)&#123; continue; &#125; int left = parentIdx * 2; //左子节点位置 int right = (left + 1) &gt;= limit ? left : (left + 1); //右子节点位置，如果没有右节点，默认为左节点位置 int maxChildId = arr[left] &gt;= arr[right] ? left : right; if(arr[maxChildId] &gt; arr[parentIdx])&#123; //交换父节点与左右子节点中的最大值 int temp = arr[parentIdx]; arr[parentIdx] = arr[maxChildId]; arr[maxChildId] = temp; &#125; &#125; System.out.println(\"Max_Heapify: \" + Arrays.toString(arr));&#125; 注: x&gt;&gt;1 是位运算中的右移运算, 表示右移一位, 等同于x除以2再取整, 即 x&gt;&gt;1 == Math.floor(x/2) . 以上,①. 建立堆的过程, 从length/2 一直处理到0, 时间复杂度为O(n);②. 调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为O(lgn);③. 堆排序的过程由n次第②步完成, 时间复杂度为O(nlgn). 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog2n)O(nlog2⁡n) O(nlog2n)O(nlog2⁡n) O(nlog2n)O(nlog2⁡n) O(1) Tips: 由于堆排序中初始化堆的过程比较次数较多, 因此它不太适用于小序列. 同时由于多次任意下标相互交换位置, 相同元素之间原本相对的顺序被破坏了, 因此, 它是不稳定的排序. 五、冒泡排序（Bubble Sort） [ 冒泡排序的思想](https://itimetraveler.github.io/gallery/sort-algorithms/bubble-sort02.gif) 冒泡排序的思想 我想对于它每个学过C语言的都会了解，这可能是很多人接触的第一个排序算法。 1、基本思想冒泡排序（Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 [ 冒泡排序演示](https://itimetraveler.github.io/gallery/sort-algorithms/bubble-sort.gif) 冒泡排序演示 2、算法描述冒泡排序算法的运作如下： ①. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。②. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。③. 针对所有的元素重复以上的步骤，除了最后一个。④. 持续每次对越来越少的元素重复上面的步骤①~③，直到没有任何一对数字需要比较。 3、代码实现冒泡排序需要两个嵌套的循环. 其中, 外层循环移动游标; 内层循环遍历游标及之后(或之前)的元素, 通过两两交换的方式, 每次只确保该内循环结束位置排序正确, 然后内层循环周期结束, 交由外层循环往后(或前)移动游标, 随即开始下一轮内层循环, 以此类推, 直至循环结束. 123456789101112131415161718192021/** * 冒泡排序 * * ①. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 * ②. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 * ③. 针对所有的元素重复以上的步骤，除了最后一个。 * ④. 持续每次对越来越少的元素重复上面的步骤①~③，直到没有任何一对数字需要比较。 * @param arr 待排序数组 */public static void bubbleSort(int[] arr)&#123; for (int i = arr.length; i &gt; 0; i--) &#123; //外层循环移动游标 for(int j = 0; j &lt; i &amp;&amp; (j+1) &lt; i; j++)&#123; //内层循环遍历游标及之后(或之前)的元素 if(arr[j] &gt; arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; System.out.println(\"Sorting: \" + Arrays.toString(arr)); &#125; &#125; &#125;&#125; 以下是冒泡排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n) O(n²) O(1) 冒泡排序是最容易实现的排序, 最坏的情况是每次都需要交换, 共需遍历并交换将近n²/2次, 时间复杂度为O(n²). 最佳的情况是内循环遍历一次后发现排序是对的, 因此退出循环, 时间复杂度为O(n). 平均来讲, 时间复杂度为O(n²). 由于冒泡排序中只有缓存的temp变量需要内存空间, 因此空间复杂度为常量O(1). Tips: 由于冒泡排序只在相邻元素大小不符合要求时才调换他们的位置, 它并不改变相同元素之间的相对顺序, 因此它是稳定的排序算法. 六、快速排序（Quick Sort） 快速排序（Quicksort）是对冒泡排序的一种改进，借用了分治的思想，由C. A. R. Hoare在1962年提出。 1、基本思想快速排序的基本思想：挖坑填数+分治法。 首先选一个轴值(pivot，也有叫基准的)，通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 [ 使用快速排序法对一列数字进行排序的过程](https://itimetraveler.github.io/gallery/sort-algorithms/Sorting_quicksort_anim.gif) 使用快速排序法对一列数字进行排序的过程 2、算法描述快速排序使用分治策略来把一个序列（list）分为两个子序列（sub-lists）。步骤为： ①. 从数列中挑出一个元素，称为”基准”（pivot）。②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。 [ 快速排序演示](https://itimetraveler.github.io/gallery/sort-algorithms/quick-sort09.gif) 快速排序演示 3、代码实现用伪代码描述如下： ①. i = L; j = R; 将基准数挖出形成第一个坑a[i]。②．j--，由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。③．i++，由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。④．再重复执行②，③二步，直到i==j，将基准数填入a[i]中 [ 快速排序采用“分而治之、各个击破”的观念，此为原地（In-place）分区版本。](https://itimetraveler.github.io/gallery/sort-algorithms/200px-Partition_example.svg.png) 快速排序采用“分而治之、各个击破”的观念，此为原地（In-place）分区版本。 1234567891011121314151617181920212223242526272829303132/** * 快速排序（递归） * * ①. 从数列中挑出一个元素，称为\"基准\"（pivot）。 * ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 * ③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 * @param arr 待排序数组 * @param low 左边界 * @param high 右边界 */public static void quickSort(int[] arr, int low, int high)&#123; if(arr.length &lt;= 0) return; if(low &gt;= high) return; int left = low; int right = high; int temp = arr[left]; //挖坑1：保存基准的值 while (left &lt; right)&#123; while(left &lt; right &amp;&amp; arr[right] &gt;= temp)&#123; //坑2：从后向前找到比基准小的元素，插入到基准位置坑1中 right--; &#125; arr[left] = arr[right]; while(left &lt; right &amp;&amp; arr[left] &lt;= temp)&#123; //坑3：从前往后找到比基准大的元素，放到刚才挖的坑2中 left++; &#125; arr[right] = arr[left]; &#125; arr[left] = temp; //基准值填补到坑3中，准备分治递归快排 System.out.println(\"Sorting: \" + Arrays.toString(arr)); quickSort(arr, low, left-1); quickSort(arr, left+1, high);&#125; 快速排序是通常被认为在同数量级（O(nlog2n)）的排序方法中平均性能最好的。但若初始序列按关键码有序或基本有序时，快排序反而蜕化为冒泡排序。为改进之，通常以“三者取中法”来选取基准记录，即将排序区间的两个端点与中点三个记录关键码居中的调整为支点记录。快速排序是一个不稳定的排序方法。 以下是快速排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog₂n) O(nlog₂n) O(n²) O(1)（原地分区递归版） 快速排序排序效率非常高。 虽然它运行最糟糕时将达到O(n²)的时间复杂度, 但通常平均来看, 它的时间复杂为O(nlogn), 比同样为O(nlogn)时间复杂度的归并排序还要快. 快速排序似乎更偏爱乱序的数列, 越是乱序的数列, 它相比其他排序而言, 相对效率更高. Tips: 同选择排序相似, 快速排序每次交换的元素都有可能不是相邻的, 因此它有可能打破原来值为相同的元素之间的顺序. 因此, 快速排序并不稳定. 七、归并排序（Merging Sort） [ img](https://itimetraveler.github.io/gallery/sort-algorithms/merging-sort_sample.jpg) 归并排序是建立在归并操作上的一种有效的排序算法，1945年由约翰·冯·诺伊曼首次提出。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用，且各层分治递归可以同时进行。 1、基本思想归并排序算法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 [ 这个图很有概括性，来自维基](https://itimetraveler.github.io/gallery/sort-algorithms/2016-07-15_%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.gif) 这个图很有概括性，来自维基 2、算法描述归并排序可通过两种方式实现： 自上而下的递归 自下而上的迭代 一、递归法（假设序列共有n个元素）： ①. 将序列每相邻两个数字进行归并操作，形成 floor(n/2)个序列，排序后每个序列包含两个元素；②. 将上述序列再次归并，形成 floor(n/4)个序列，每个序列包含四个元素；③. 重复步骤②，直到所有元素排序完毕。 [ img](https://itimetraveler.github.io/gallery/sort-algorithms/merging-sort.gif) 二、迭代法 ①. 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列②. 设定两个指针，最初位置分别为两个已经排序序列的起始位置③. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置④. 重复步骤③直到某一指针到达序列尾⑤. 将另一序列剩下的所有元素直接复制到合并序列尾 3、代码实现归并排序其实要做两件事： 分解：将序列每次折半拆分 合并：将划分后的序列段两两排序合并 因此，归并排序实际上就是两个操作，拆分+合并 如何合并？ L[first…mid]为第一段，L[mid+1…last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first…last]并且也有序。 首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]此时将temp[]中的元素复制给L[]，则得到的L[first…last]有序 如何分解？ 在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列分组；直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。 这里我写了递归算法如下： 12345678910111213141516171819202122232425262728293031323334353637/** * 归并排序（递归） * * ①. 将序列每相邻两个数字进行归并操作，形成 floor(n/2)个序列，排序后每个序列包含两个元素； * ②. 将上述序列再次归并，形成 floor(n/4)个序列，每个序列包含四个元素； * ③. 重复步骤②，直到所有元素排序完毕。 * @param arr 待排序数组 */public static int[] mergingSort(int[] arr)&#123; if(arr.length &lt;= 1) return arr; int num = arr.length &gt;&gt; 1; int[] leftArr = Arrays.copyOfRange(arr, 0, num); int[] rightArr = Arrays.copyOfRange(arr, num, arr.length); System.out.println(\"split two array: \" + Arrays.toString(leftArr) + \" And \" + Arrays.toString(rightArr)); return mergeTwoArray(mergingSort(leftArr), mergingSort(rightArr)); //不断拆分为最小单元，再排序合并&#125;private static int[] mergeTwoArray(int[] arr1, int[] arr2)&#123; int i = 0, j = 0, k = 0; int[] result = new int[arr1.length + arr2.length]; //申请额外的空间存储合并之后的数组 while(i &lt; arr1.length &amp;&amp; j &lt; arr2.length)&#123; //选取两个序列中的较小值放入新数组 if(arr1[i] &lt;= arr2[j])&#123; result[k++] = arr1[i++]; &#125;else&#123; result[k++] = arr2[j++]; &#125; &#125; while(i &lt; arr1.length)&#123; //序列1中多余的元素移入新数组 result[k++] = arr1[i++]; &#125; while(j &lt; arr2.length)&#123; //序列2中多余的元素移入新数组 result[k++] = arr2[j++]; &#125; System.out.println(\"Merging: \" + Arrays.toString(result)); return result;&#125; 由上, 长度为n的数组, 最终会调用mergeSort函数2n-1次。通过自上而下的递归实现的归并排序, 将存在堆栈溢出的风险。 以下是归并排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(n) 从效率上看，归并排序可算是排序算法中的”佼佼者”. 假设数组长度为n，那么拆分数组共需logn，, 又每步都是一个普通的合并子数组的过程， 时间复杂度为O(n)， 故其综合时间复杂度为O(nlogn)。另一方面， 归并排序多次递归过程中拆分的子数组需要保存在内存空间， 其空间复杂度为O(n)。 和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(n log n）的时间复杂度。代价是需要额外的内存空间。 八、基数排序（Radix Sort） 基数排序的发明可以追溯到1887年赫尔曼·何乐礼在打孔卡片制表机（Tabulation Machine）, 排序器每次只能看到一个列。它是基于元素值的每个位上的字符来排序的。 对于数字而言就是分别基于个位，十位， 百位或千位等等数字来排序。 基数排序（Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 1、基本思想它是这样实现的：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 基数排序按照优先从高位或低位来排序有两种实现方案： MSD（Most significant digital） 从最左侧高位开始进行排序。先按k1排序分组, 同一组中记录, 关键码k1相等, 再对各组按k2排序分成子组, 之后, 对后面的关键码继续这样的排序分组, 直到按最次位关键码kd对各子组排序后. 再将各组连接起来, 便得到一个有序序列。MSD方式适用于位数多的序列。 LSD （Least significant digital）从最右侧低位开始进行排序。先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。LSD方式适用于位数少的序列。 [ 基数排序LSD动图演示](https://itimetraveler.github.io/gallery/sort-algorithms/radix-sort_sample.gif) 基数排序LSD动图演示 2、算法描述我们以LSD为例，从最低位开始，具体算法描述如下： ①. 取得数组中的最大数，并取得位数；②. arr为原始数组，从最低位开始取每个位组成radix数组；③. 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 3、代码实现基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。 分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中 收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[]。对新形成的序列L[]重复执行分配和收集元素中的十位、百位…直到分配完该序列中的最高位，则排序结束 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 基数排序（LSD 从低位开始） * * 基数排序适用于： * (1)数据范围较小，建议在小于1000 * (2)每个数值都要大于等于0 * * ①. 取得数组中的最大数，并取得位数； * ②. arr为原始数组，从最低位开始取每个位组成radix数组； * ③. 对radix进行计数排序（利用计数排序适用于小范围数的特点）； * @param arr 待排序数组 */public static void radixSort(int[] arr)&#123; if(arr.length &lt;= 1) return; //取得数组中的最大数，并取得位数 int max = 0; for(int i = 0; i &lt; arr.length; i++)&#123; if(max &lt; arr[i])&#123; max = arr[i]; &#125; &#125; int maxDigit = 1; while(max / 10 &gt; 0)&#123; maxDigit++; max = max / 10; &#125; System.out.println(\"maxDigit: \" + maxDigit); //申请一个桶空间 int[][] buckets = new int[10][arr.length-1]; int base = 10; //从低位到高位，对每一位遍历，将所有元素分配到桶中 for(int i = 0; i &lt; maxDigit; i++)&#123; int[] bktLen = new int[10]; //存储各个桶中存储元素的数量 //分配：将所有元素分配到桶中 for(int j = 0; j &lt; arr.length; j++)&#123; int whichBucket = (arr[j] % base) / (base / 10); buckets[whichBucket][bktLen[whichBucket]] = arr[j]; bktLen[whichBucket]++; &#125; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 int k = 0; for(int b = 0; b &lt; buckets.length; b++)&#123; for(int p = 0; p &lt; bktLen[b]; p++)&#123; arr[k++] = buckets[b][p]; &#125; &#125; System.out.println(\"Sorting: \" + Arrays.toString(arr)); base *= 10; &#125;&#125; 以下是基数排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n * k) O(n * k) O(n * k) O(k+N) 基数排序更适合用于对时间, 字符串等这些整体权值未知的数据进行排序。 Tips: 基数排序不改变相同元素之间的相对顺序，因此它是稳定的排序算法。 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 总结 各种排序性能对比如下，有些排序未详细介绍，暂且放到这里: 排序类型 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n²) O(n) O(n²) O(1) 稳定 选择排序 O(n²) O(n²) O(n²) O(1) 不稳定 直接插入排序 O(n²) O(n) O(n²) O(1) 稳定 折半插入排序 O(n²) O(n) O(n²) O(1) 稳定 希尔排序 O(n^1.3) O(nlogn) O(n²) O(1) 不稳定 归并排序 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(n) 稳定 快速排序 O(nlog₂n) O(nlog₂n) O(n²) O(nlog₂n) 不稳定 堆排序 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(1) 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) 稳定 桶排序 O(n+k) O(n+k) O(n²) O(n+k) (不)稳定 基数排序 O(d(n+k)) O(d(n+k)) O(d(n+kd)) O(n+kd) 稳定 从时间复杂度来说： (1). 平方阶O(n²)排序：各类简单排序：直接插入、直接选择和冒泡排序； (2). 线性对数阶O(nlog₂n)排序：快速排序、堆排序和归并排序； (3). O(n1+§))排序，§是介于0和1之间的常数：希尔排序 (4). 线性阶O(n)排序：基数排序，此外还有桶、箱排序。 说明 当原表有序或基本有序时，直接插入排序和冒泡排序将大大减少比较次数和移动记录的次数，时间复杂度可降至O（n）； 而快速排序则相反，当原表基本有序时，将蜕化为冒泡排序，时间复杂度提高为O（n2）； 原表是否有序，对简单选择排序、堆排序、归并排序和基数排序的时间复杂度影响不大。 [ img](https://itimetraveler.github.io/gallery/sort-algorithms/2016-07-15_%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.png) 参考资料 数据结构可视化：visualgo，Sorting Algorithms Animations，CodePen &amp; sort it out 排序算法测试：Lab 1: Sorting - 哥德堡大学课件（University of Gothenburg） Sorting - 卡内基梅隆大学课件 数据结构常见的八大排序算法（详细整理） 必须知道的八大种排序算法【java实现】 十大经典排序算法 视觉直观感受 7 种常用的排序算法 JS中可能用得到的全部的排序算法 总结5种比较高效常用的排序算法 常见排序算法C++总结","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lvshen9.gitee.io/tags/算法/"},{"name":"Java","slug":"Java","permalink":"http://lvshen9.gitee.io/tags/Java/"},{"name":"排序","slug":"排序","permalink":"http://lvshen9.gitee.io/tags/排序/"}]},{"title":"Java 8系列之重新认识HashMap","slug":"hasmap2","date":"2017-08-27T03:15:21.000Z","updated":"2017-08-27T03:27:38.797Z","comments":true,"path":"2017/08/27/hasmap2/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/27/hasmap2/","excerpt":"本文来自美团点评技术团队： Java 8系列之重新认识HashMap 摘要HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。 简介Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示： [ img](http://img.blog.csdn.net/20170616165413193)","text":"本文来自美团点评技术团队： Java 8系列之重新认识HashMap 摘要HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。 简介Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示： [ img](http://img.blog.csdn.net/20170616165413193) 下面针对各个实现类的特点做一些说明： (1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 (2) Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 (3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 (4) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。 通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。 内部实现搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。 存储结构-字段从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。 [ img](http://img.blog.csdn.net/20170616165613975) 这里需要讲明白两个问题：数据底层具体存储的是什么？这样的存储方式有什么？优点呢？ (1) 从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 (2) HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码： 1map.put(\"美团\",\"小美\"); 系统将调用”美团”这个key的hashCode()方法得到其hashCode 值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。 如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的Hash算法和扩容机制。 在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下： 1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考http://blog.csdn.net/liuqiyao_01/article/details/14475159 ，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考http://blog.csdn.net/v_july_v/article/details/6105630 。 功能实现-方法HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。 1. 确定哈希桶数组索引位置不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二): 1234567891011方法一：static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 下面举例说明下，n为table的长度。 [ img](http://img.blog.csdn.net/20170616170559316) 2. 分析HashMap的put方法HashMap的put方法执行过程可以通过下图来理解，自己有兴趣可以去对比源码更清楚地研究学习。 [ img](http://img.blog.csdn.net/20170616170655449) ①. 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②. 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③. 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④. 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤. 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥. 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 JDK1.8HashMap的put方法源码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 1 public V put(K key, V value) &#123; 2 // 对key的hashCode()做hash 3 return putVal(hash(key), key, value, false, true); 4 &#125; 5 6 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, 7 boolean evict) &#123; 8 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; 9 // 步骤①：tab为空则创建10 if ((tab = table) == null || (n = tab.length) == 0)11 n = (tab = resize()).length;12 // 步骤②：计算index，并对null做处理 13 if ((p = tab[i = (n - 1) &amp; hash]) == null) 14 tab[i] = newNode(hash, key, value, null);15 else &#123;16 Node&lt;K,V&gt; e; K k;17 // 步骤③：节点key存在，直接覆盖value18 if (p.hash == hash &amp;&amp;19 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))20 e = p;21 // 步骤④：判断该链为红黑树22 else if (p instanceof TreeNode)23 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);24 // 步骤⑤：该链为链表25 else &#123;26 for (int binCount = 0; ; ++binCount) &#123;27 if ((e = p.next) == null) &#123;28 p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理29 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st 30 treeifyBin(tab, hash);31 break;32 &#125; // key已经存在直接覆盖value33 if (e.hash == hash &amp;&amp;34 ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) 35 break;36 p = e;37 &#125;38 &#125;39 40 if (e != null) &#123; // existing mapping for key41 V oldValue = e.value;42 if (!onlyIfAbsent || oldValue == null)43 e.value = value;44 afterNodeAccess(e);45 return oldValue;46 &#125;47 &#125;48 ++modCount;49 // 步骤⑥：超过最大容量 就扩容50 if (++size &gt; threshold)51 resize();52 afterNodeInsertion(evict);53 return null;54 &#125; 3. 扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213 1 void resize(int newCapacity) &#123; //传入新的容量 2 Entry[] oldTable = table; //引用扩容前的Entry数组 3 int oldCapacity = oldTable.length; 4 if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 5 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 6 return; 7 &#125; 8 9 Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组10 transfer(newTable); //！！将数据转移到新的Entry数组里11 table = newTable; //HashMap的table属性引用新的Entry数组12 threshold = (int)(newCapacity * loadFactor);//修改阈值13 &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617 1 void transfer(Entry[] newTable) &#123; 2 Entry[] src = table; //src引用了旧的Entry数组 3 int newCapacity = newTable.length; 4 for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 5 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 6 if (e != null) &#123; 7 src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） 8 do &#123; 9 Entry&lt;K,V&gt; next = e.next;10 int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置11 e.next = newTable[i]; //标记[1]12 newTable[i] = e; //将元素放在数组上13 e = next; //访问下一个Entry链上的元素14 &#125; while (e != null);15 &#125;16 &#125;17 &#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 [ img](http://img.blog.csdn.net/20170616171207339) 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 [ img](http://img.blog.csdn.net/20170616171255934) 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： [ img](http://img.blog.csdn.net/20170616171330516) 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： [ img](http://img.blog.csdn.net/20170616171352780) 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182 1 final Node&lt;K,V&gt;[] resize() &#123; 2 Node&lt;K,V&gt;[] oldTab = table; 3 int oldCap = (oldTab == null) ? 0 : oldTab.length; 4 int oldThr = threshold; 5 int newCap, newThr = 0; 6 if (oldCap &gt; 0) &#123; 7 // 超过最大值就不再扩充了，就只好随你碰撞去吧 8 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; 9 threshold = Integer.MAX_VALUE;10 return oldTab;11 &#125;12 // 没超过最大值，就扩充为原来的2倍13 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;14 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)15 newThr = oldThr &lt;&lt; 1; // double threshold16 &#125;17 else if (oldThr &gt; 0) // initial capacity was placed in threshold18 newCap = oldThr;19 else &#123; // zero initial threshold signifies using defaults20 newCap = DEFAULT_INITIAL_CAPACITY;21 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);22 &#125;23 // 计算新的resize上限24 if (newThr == 0) &#123;25 26 float ft = (float)newCap * loadFactor;27 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?28 (int)ft : Integer.MAX_VALUE);29 &#125;30 threshold = newThr;31 @SuppressWarnings(&#123;\"rawtypes\"，\"unchecked\"&#125;)32 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];33 table = newTab;34 if (oldTab != null) &#123;35 // 把每个bucket都移动到新的buckets中36 for (int j = 0; j &lt; oldCap; ++j) &#123;37 Node&lt;K,V&gt; e;38 if ((e = oldTab[j]) != null) &#123;39 oldTab[j] = null;40 if (e.next == null)41 newTab[e.hash &amp; (newCap - 1)] = e;42 else if (e instanceof TreeNode)43 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);44 else &#123; // 链表优化重hash的代码块45 Node&lt;K,V&gt; loHead = null, loTail = null;46 Node&lt;K,V&gt; hiHead = null, hiTail = null;47 Node&lt;K,V&gt; next;48 do &#123;49 next = e.next;50 // 原索引51 if ((e.hash &amp; oldCap) == 0) &#123;52 if (loTail == null)53 loHead = e;54 else55 loTail.next = e;56 loTail = e;57 &#125;58 // 原索引+oldCap59 else &#123;60 if (hiTail == null)61 hiHead = e;62 else63 hiTail.next = e;64 hiTail = e;65 &#125;66 &#125; while ((e = next) != null);67 // 原索引放到bucket里68 if (loTail != null) &#123;69 loTail.next = null;70 newTab[j] = loHead;71 &#125;72 // 原索引+oldCap放到bucket里73 if (hiTail != null) &#123;74 hiTail.next = null;75 newTab[j + oldCap] = hiHead;76 &#125;77 &#125;78 &#125;79 &#125;80 &#125;81 return newTab;82 &#125; 线程安全性在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)： 1234567891011121314151617181920public class HashMapInfiniteLoop &#123; private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2, 0.75f); public static void main(String[] args) &#123; map.put(5, \"C\"); new Thread(\"Thread1\") &#123; public void run() &#123; map.put(7, \"B\"); System.out.println(map); &#125;; &#125;.start(); new Thread(\"Thread2\") &#123; public void run() &#123; map.put(3, \"A); System.out.println(map); &#125;; &#125;.start(); &#125; &#125; 其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。 [ img](http://img.blog.csdn.net/20170616171711863) 注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。 线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。 [ img](http://img.blog.csdn.net/20170616171741879) [ img](http://img.blog.csdn.net/20170616171859708) e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。 [ img](http://img.blog.csdn.net/20170616171810754) 于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。 JDK1.8与JDK1.7的性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。 Hash较均匀的情况为了便于测试，我们先写一个类Key，如下： 123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125; 这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下： 123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125; 现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下： 1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125; 在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下： [ img](http://img.blog.csdn.net/20170616172058883) 通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。 Hash极不均匀的情况假设我们又一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下： 123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125; 仍然执行main方法，得出的结果如下表所示： [ img](http://img.blog.csdn.net/20170616172148396) 从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。 1测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。 小结(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。 (2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 (3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。 (4) JDK1.8引入红黑树大程度优化了HashMap的性能。 (5) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。 参考 JDK1.7&amp;JDK1.8 源码。 酷壳COOLSHELL，疫苗：JAVA HASHMAP的死循环，2013 CSDN博客频道，HashMap多线程死循环问题，2014。 红黑联盟，Java类集框架之HashMap(JDK1.8)源码剖析，2015。 CSDN博客频道， 教你初步了解红黑树，2010。 Java Code Geeks，HashMap performance improvements in Java 8，2014。 Importnew，危险！在HashMap中将可变对象用作Key，2014。 CSDN博客频道，为什么一般hashtable的桶数会取一个素数，2013。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://lvshen9.gitee.io/tags/HashMap/"},{"name":"Java","slug":"Java","permalink":"http://lvshen9.gitee.io/tags/Java/"}]},{"title":"OSI七层模型","slug":"myosi","date":"2017-08-26T14:07:09.000Z","updated":"2017-08-26T14:16:10.260Z","comments":true,"path":"2017/08/26/myosi/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/26/myosi/","excerpt":"开放系统互连参考模型 (Open System Interconnect 简称OSI）是国际标准化组织(ISO)和国际电报电话咨询委员会(CCITT)联合制定的开放系统互连参考模型，为开放式互连信息系统提供了一种功能结构的框架。它从低到高分别是：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。 下图为OSI七层模型图解:","text":"开放系统互连参考模型 (Open System Interconnect 简称OSI）是国际标准化组织(ISO)和国际电报电话咨询委员会(CCITT)联合制定的开放系统互连参考模型，为开放式互连信息系统提供了一种功能结构的框架。它从低到高分别是：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。 下图为OSI七层模型图解: OSI七层模型详解","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"http","slug":"http","permalink":"http://lvshen9.gitee.io/tags/http/"},{"name":"OSI","slug":"OSI","permalink":"http://lvshen9.gitee.io/tags/OSI/"}]},{"title":"Redis面试总结","slug":"redis2","date":"2017-08-26T11:50:16.000Z","updated":"2017-09-05T01:58:13.076Z","comments":true,"path":"2017/08/26/redis2/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/26/redis2/","excerpt":"本文转载至:http://www.cnblogs.com/jiahaoJAVA/p/6244278.html （1）什么是redis? Redis 是一个基于内存的高性能key-value数据库。 (有空再补充，有理解错误或不足欢迎指正) （2）Reids的特点Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。","text":"本文转载至:http://www.cnblogs.com/jiahaoJAVA/p/6244278.html （1）什么是redis? Redis 是一个基于内存的高性能key-value数据库。 (有空再补充，有理解错误或不足欢迎指正) （2）Reids的特点Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 （3）Redis支持的数据类型Redis通过Key-Value的单值不同类型来区分, 以下是支持的类型:Strings Lists Sets 求交集、并集Sorted Set hashes （4）为什么redis需要把所有数据放到内存中？Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 （5）Redis是单进程的redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销 （6）虚拟内存当你的key很小而value很大时,使用VM的效果会比较好.因为这样节约的内存比较大.当你的key不小时,可以考虑使用一些非常方法将很大的key变成很大的value,比如你可以考虑将key,value组合成一个新的value. vm-max-threads这个参数,可以设置访问swap文件的线程数,设置最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证. 自己测试的时候发现用虚拟内存性能也不错。如果数据量很大，可以考虑分布式或者其他数据库 （7）分布式redis支持主从的模式。原则：Master会将数据同步到slave，而slave不会将数据同步到master。Slave启动时会连接master来同步数据。 这是一个典型的分布式读写分离模型。我们可以利用master来插入数据，slave提供检索服务。这样可以有效减少单个机器的并发访问数量 （8）读写分离模型通过增加Slave DB的数量，读的性能可以线性增长。为了避免Master DB的单点故障，集群一般都会采用两台Master DB做双机热备，所以整个集群的读和写的可用性都非常高。​ 读写分离架构的缺陷在于，不管是Master还是Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，集群的扩展能力还是受限于单个节点的存储能力，而且对于Write-intensive类型的应用，读写分离架构并不适合。 （9）数据分片模型为了解决读写分离模型的缺陷，可以将数据分片模型应用进来。 可以将每个节点看成都是独立的master，然后通过业务实现数据分片。 结合上面两种模型，可以将每个master设计成由一个master和多个slave组成的模型。 （10）Redis的回收策略 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 1. 使用Redis有哪些好处？(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) (2) 支持丰富数据类型，支持string，list，set，sorted set，hash (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 2. redis相比memcached有哪些优势？(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 (2) redis的速度比memcached快很多 (3) redis可以持久化其数据 3. redis常见性能问题和解决方案(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 (2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 (3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 (4) 尽量避免在压力很大的主库上增加从库 (5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3… 这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 4. MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 5. Memcache与Redis的区别都有哪些？1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，这样能保证数据的持久性。 2)、数据支持类型 Memcache对数据类型支持相对简单。 Redis有复杂的数据类型。 3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 4）、value大小 redis最大可以达到1GB，而memcache只有1MB 6. Redis 常见的性能问题都有哪些？如何解决？1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 7, redis 最适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢? ​ 如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点： ​ 1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。​ 2 、Redis支持数据的备份，即master-slave模式的数据备份。​ 3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 （1）、会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 （2）、全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 （3）、队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 （4）、排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： 1ZRANGE user_scores 0 10 WITHSCORES Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 （5）、发布/订阅最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。 Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。 ​ ​ ​ ​","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://lvshen9.gitee.io/tags/redis/"},{"name":"数据库","slug":"数据库","permalink":"http://lvshen9.gitee.io/tags/数据库/"}]},{"title":"SQL语句优化问题(续)","slug":"sql-2","date":"2017-08-26T03:09:02.000Z","updated":"2017-08-26T07:22:14.312Z","comments":true,"path":"2017/08/26/sql-2/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/26/sql-2/","excerpt":"话不多说，接着上次的来。 （11）sql语句用大写的，因为oracle总是在解析sql语句时把小写的字母转换成大写的再执行。 （12）避免在索引列上使用NOT，NOT会产生在和在索引列上使用函数相同的影响。 当ORACLE”遇到”NOT,他就会停止使用索引转而执行全表扫描。 （13） 避免在索引列上使用计算，WHERE子句中，如果索引列是函数的一部分，优化器将不使用索引而使用全表扫描。 例如: 1234567低效：SELECT …FROM DEPT WHERE SAL * 12 &gt; 25000;高效:SELECT …FROM DEPT WHERE SAL &gt; 25000/12;","text":"话不多说，接着上次的来。 （11）sql语句用大写的，因为oracle总是在解析sql语句时把小写的字母转换成大写的再执行。 （12）避免在索引列上使用NOT，NOT会产生在和在索引列上使用函数相同的影响。 当ORACLE”遇到”NOT,他就会停止使用索引转而执行全表扫描。 （13） 避免在索引列上使用计算，WHERE子句中，如果索引列是函数的一部分，优化器将不使用索引而使用全表扫描。 例如: 1234567低效：SELECT …FROM DEPT WHERE SAL * 12 &gt; 25000;高效:SELECT …FROM DEPT WHERE SAL &gt; 25000/12; （14） 用&gt;=替代&gt; 1234567高效:SELECT *FROM EMP WHERE DEPTNO &gt;=4低效:SELECT *FROM EMP WHERE DEPTNO &gt;3 两者的区别在于，前者DBMS将直接跳到第一个DEPT等于4的记录而后者将首先定位到DEPTNO=3的记录并且向前扫描到第一个DEPT大于3的记录。 （15） 用UNION替换OR (适用于索引列) 通常情况下, 用UNION替换WHERE子句中的OR将会起到较好的效果. 对索引列使用OR将造成全表扫描. 注意, 以上规则只针对多个索引列有效. 如果有column没有被索引, 查询效率可能会因为你没有选择OR而降低. 在下面的例子中,LOC_ID 和REGION上都建有索引. 1234567891011121314151617181920212223高效:SELECTLOC_ID , LOC_DESC , REGIONFROMLOCATIONWHERELOC_ID = 10UNIONSELECTLOC_ID , LOC_DESC , REGIONFROMLOCATIONWHEREREGION = “MELBOURNE”低效:SELECTLOC_ID , LOC_DESC , REGIONFROMLOCATIONWHERE LOC_ID= 10 OR REGION = “MELBOURNE” 如果你坚持要用OR，那就需要返回记录最少的索引列写在最前面。 （16） 用IN来替换OR 这是一条简单易记的规则，但是实际的执行效果还须检验，在ORACLE8i下，两者的执行路径似乎是相同的。 1234567低效:SELECT….FROM LOCATION WHERE LOC_ID = 10 OR LOC_ID = 20 OR LOC_ID = 30高效SELECT…FROM LOCATION WHERE LOC_IN IN (10,20,30); （17） 总是使用索引的第一个列 如果索引是建立在多个列上，只有在它的第一个列(leading column)被where子句引用时，优化器才会选择使用该索引。这也是一条简单而重要的规则，当仅引用索引的第二个列时，优化器使用了全表扫描而忽略了索引。 （18） 用WHERE替代ORDER BY ORDER BY 子句只在两种严格的条件下使用索引。 ORDER BY中所有的列必须包含在相同的索引中并保持在索引中的排列顺序。 ORDER BY中所有的列必须定义为非空。 WHERE子句使用的索引和ORDER BY子句中所使用的索引不能并列。 例如: 1234567表DEPT包含以下列:DEPT_CODE PK NOT NULLDEPT_DESC NOT NULLDEPT_TYPE NULL 1234567低效: (索引不被使用)SELECTDEPT_CODE FROM DEPT ORDER BY DEPT_TYPE高效: (使用索引)SELECTDEPT_CODE FROM DEPT WHERE DEPT_TYPE &gt; 0 （18） 避免改变索引列的类型 当比较不同数据类型的数据时, ORACLE自动对列进行简单的类型转换。 假设 EMPNO是一个数值类型的索引列。 1SELECT… FROM EMP WHERE EMPNO = ‘123′ 实际上,经过ORACLE类型转换, 语句转化为: 1SELECT… FROM EMP WHERE EMPNO = TO_NUMBER(‘123′) 幸运的是,类型转换没有发生在索引列上,索引的用途没有被改变. 现在,假设EMP_TYPE是一个字符类型的索引列. 1SELECT… FROM EMP WHERE EMP_TYPE = 123 这个语句被ORACLE转换为: 1SELECT… FROM EMP WHERE TO_NUMBER(EMP_TYPE)=123 因为内部发生的类型转换，这个索引将不会被用到！为了避免ORACLE对你的SQL进行隐式的类型转换， 最好把类型转换用显式表现出来。注意当字符和数值比较时， ORACLE会优先转换数值类型到字符类型。 （19） 需要当心的WHERE子句: 某些SELECT 语句中的WHERE子句不使用索引。 例如，(a)‘!=’ 将不使用索引。记住， 索引只能告诉你什么存在于表中，而不能告诉你什么不存在于表中。(b) ‘||’是字符连接函数， 就象其他函数那样， 停用了索引。(c) ‘+’是数学函数。 就象其他数学函数那样，停用了索引。 (4)相同的索引列不能互相比较，这将会启用全表扫描。 （20） 避免使用耗费资源的操作 带有DISTINCT,UNION,MINUS,INTERSECT,ORDERBY的SQL语句会启动SQL引擎 执行耗费资源的排序(SORT)功能。 DISTINCT需要一次排序操作， 而其他的至少需要执行两次排序。 通常， 带有UNION, MINUS, INTERSECT的SQL语句都可以用其他方式重写。 如果你的数据库的SORT_AREA_SIZE调配得好， 使用UNION , MINUS, INTERSECT也是可以考虑的, 毕竟它们的可读性很强。 （21） 优化GROUP BY 提高GROUP BY 语句的效率，可以通过将不需要的记录在GROUP BY 之前过滤掉。下面两个查询返回相同结果但第二个明显就快了许多。 1234567891011低效:SELECT JOB, AVG(SAL)FROM EMPGROUP byJOBHAVING JOB= ‘PRESIDENT’OR JOB =‘MANAGER’ 1234567891011高效:SELECT JOB, AVG(SAL)FROM EMPWHERE JOB =‘PRESIDENT’OR JOB =‘MANAGER’GROUP by JOB","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://lvshen9.gitee.io/tags/sql/"},{"name":"Oracle","slug":"Oracle","permalink":"http://lvshen9.gitee.io/tags/Oracle/"}]},{"title":"你的项目为甚么要使用Redis","slug":"redis","date":"2017-08-25T08:34:14.000Z","updated":"2017-08-27T02:52:14.574Z","comments":true,"path":"2017/08/25/redis/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/25/redis/","excerpt":"本文摘自《Redis实战》 链接：http://www.epubit.com.cn/article/200 Redis简介Redis是一个远程内存数据库，它不仅性能强劲，而且还具有复制特性以及为解决问题而生的独一无二的数据模型。Redis提供了5种不同类型的数据结构，各式各样的问题都可以很自然地映射到这些数据结构上：Redis的数据结构致力于帮助用户解决问题，而不会像其他数据库那样，要求用户扭曲问题来适应数据库。除此之外，通过复制、持久化（persistence）和客户端分片（client-side sharding）等特性，用户可以很方便地将Redis扩展成一个能够包含数百GB数据、每秒处理上百万次请求的系统。","text":"本文摘自《Redis实战》 链接：http://www.epubit.com.cn/article/200 Redis简介Redis是一个远程内存数据库，它不仅性能强劲，而且还具有复制特性以及为解决问题而生的独一无二的数据模型。Redis提供了5种不同类型的数据结构，各式各样的问题都可以很自然地映射到这些数据结构上：Redis的数据结构致力于帮助用户解决问题，而不会像其他数据库那样，要求用户扭曲问题来适应数据库。除此之外，通过复制、持久化（persistence）和客户端分片（client-side sharding）等特性，用户可以很方便地将Redis扩展成一个能够包含数百GB数据、每秒处理上百万次请求的系统。 举个栗子: 公司需要对一个保存了6万个客户联系方式的关系数据库进行搜索，搜索可以根据名字、邮件地址、所在地和电话号码来进行，每次搜索需要花费10～15秒的时间。这样的搜索速度满足不了业务需求。公司采用redis重写了一个搜索引擎，经过长时间的测试，这个新的搜索系统不仅可以根据名字、邮件地址、所在地和电话号码等信息来过滤和排序客户联系方式，并且每次操作都可以在50毫秒之内完成，这比原来的搜索系统足足快了 200 倍。 Redis是一个速度非常快的非关系数据库（non-relational database），它可以存储键（key）与5种不同类型的值（value）之间的映射（mapping），可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展写性能。 为什么使用Redis内存数据库除了redis还有memcached，对于mencached，用户只能用APPEND命令将数据添加到已有字符串的末尾。但怎么删除元素呢？memcached采用的办法是通过黑名单（blacklist）来隐藏列表里面的元素，从而避免对元素执行读取、更新、写入（包括在一次数据库查询之后执行的memcached写入）等操作。相反地，Redis的LIST和SET允许用户直接添加或者删除元素。 因此，使用Redis而不是memcached来解决问题，不仅可以让代码变得更简短、更易懂、更易维护，而且还可以使代码的运行速度更快（因为用户不需要通过读取数据库来更新数据）。除此之外，在其他许多情况下，Redis的效率和易用性也比关系数据库要好得多。 在关系型数据库中，对表里面的数据更新是一个速度相当慢的操作，因为这种更新除了会引起一次随机读（random read）之外，还可能会引起一次随机写（random write）。而在Redis里面，用户可以直接使用原子的（atomic）INCR命令及其变种来计算聚合数据，并且因为Redis将数据存储在内存里面2，而且发送给Redis的命令请求并不需要经过典型的查询分析器（parser）或者查询优化器（optimizer）进行处理，所以对Redis存储的数据执行随机写的速度总是非常迅速的。 使用 Redis 而不是关系数据库或者其他硬盘存储数据库，可以避免写入不必要的临时数据，也免去了对临时数据进行扫描或者删除的麻烦，并最终改善程序的性能。 Redis与mencached高性能键值缓存服务器memcached也经常被拿来与Redis进行比较：这两者都可用于存储键值映射，彼此的性能也相差无几，但是Redis能够自动以两种不同的方式将数据写入硬盘，并且Redis除了能存储普通的字符串键之外，还可以存储其他4种数据结构，而memcached只能存储普通的字符串键。这些不同之处使得Redis可以用于解决更为广泛的问题，并且既可以用作主数据库（primary database）使用，又可以作为其他存储系统的辅助数据库（auxiliary database）使用。 什么时候不考虑redis一般来说，许多用户只会在Redis的性能或者功能是必要的情况下，才会将数据存储到Redis里面：如果程序对性能的要求不高，又或者因为费用原因而没办法将大量数据存储到内存里面，那么用户可能会选择使用关系数据库，或者其他非关系数据库。在实际中，读者应该根据自己的需求来决定是否使用Redis，并考虑是将Redis用作主存储还是辅助存储，以及如何通过复制、持久化和事务等手段保证数据的完整性。 主流数据库对比 名称 类型 数据存储选项 查询类型 附加功能 Redis 使用内存存储（in-memory）的非关系数据库 字符串、列表、集合、散列表、有序集合 每种数据类型都有自己的专属命令，另外还有批量操作（bulk operation）和不完全（partial）的事务支持 发布与订阅，主从复制（master/slave replication），持久化，脚本（存储过程，stored procedure） memcached 使用内存存储的键值缓存 键值之间的映射 创建命令、读取命令、更新命令、删除命令以及其他几个命令 为提升性能而设的多线程服务器 MySQL 关系数据库 每个数据库可以包含多个表，每个表可以包含多个行；可以处理多个表的视图（view）；支持空间（spatial）和第三方扩展 SELECT、INSERT、UPDATE、DELETE、函数、存储过程 支持ACID性质（需要使用InnoDB），主从复制和主主复制 （master/master replication） PostgreSQL 关系数据库 每个数据库可以包含多个表，每个表可以包含多个行；可以处理多个表的视图；支持空间和第三方扩展；支持可定制类型 SELECT、INSERT、UPDATE、DELETE、内置函数、自定义的存储过程 支持ACID性质，主从复制，由第三方支持的多主复制（multi-master replication） MongoDB 使用硬盘存储（on-disk）的非关系文档存储 每个数据库可以包含多个表，每个表可以包含多个无schema（schema-less）的BSON文档 创建命令、读取命令、更新命令、删除命令、条件查询命令等 支持map-reduce操作，主从复制，分片，空间索引（spatial index） Redis持久化特性在使用类似Redis这样的内存数据库时，一个首先要考虑的问题就是“当服务器被关闭时，服务器存储的数据将何去何从呢？”Redis拥有两种不同形式的持久化方法，它们都可以用小而紧凑的格式将存储在内存中的数据写入硬盘：第一种持久化方法为时间点转储（point-in-time dump），转储操作既可以在“指定时间段内有指定数量的写操作执行”这一条件被满足时执行，又可以通过调用两条转储到硬盘（dump-to-disk）命令中的任何一条来执行；第二种持久化方法将所有修改了数据库的命令都写入一个只追加（append-only）文件里面，用户可以根据数据的重要程度，将只追加写入设置为从不同步（sync）、每秒同步一次或者每写入一个命令就同步一次。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://lvshen9.gitee.io/tags/redis/"},{"name":"数据库","slug":"数据库","permalink":"http://lvshen9.gitee.io/tags/数据库/"}]},{"title":"SpringMVC的执行流程","slug":"springmvc","date":"2017-08-24T06:46:32.000Z","updated":"2017-09-04T03:18:45.131Z","comments":true,"path":"2017/08/24/springmvc/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/24/springmvc/","excerpt":"一、图解SpringMVC下面为SpringMVC的执行流程: springmvc执行流程","text":"一、图解SpringMVC下面为SpringMVC的执行流程: springmvc执行流程 详细图： 二、SpringMVC工作流程描述1.用户向服务器发送请求时，请求被Spring 前端控制器DispatcherServlet获取，如详细图第一步 2.DispatcherServlet对请求URL进行解析（比如我们发送一个url如下的请求 http://localhost:8080/SpringMVC/hello.action），就会得到请求资源标示符（URI，相当于就是上面的hello.action ）。然后根据URI，调用处理器映射器（HandlerMapping）获得该Handler配置的所有相关对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回。 3.DispatcherServlet获取上面返回的Handler，并选择一个适合的HandlerAdapter。（附注：如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler(…)方法） 4.选择好合适的HandlerAdapter后就会开始执行Handler。在填充Handler的入参过程中，根据配置，Spring将帮你做一些额外的工作（我们不需要管）： EG: ​ HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息 ​ 数据转换：对请求消息进行数据转换。如String转换成Integer、Double等 ​ 数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等 ​ 数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中 5.Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象(包含视图名或视图名和模型) 6.根据返回的ModelAndView对象，选择一个合适的ViewResolver返会给DispatcherServlet ； 7.ViewResolver结合，Model和View来渲染视图 8.最后将视图渲染结果返回给客户端 三、组件名词解释1.DispatcherServlet:前端控制器 等同于以前的Controller， 是整个流程的中心， 负责调用其他组件 2.HandlerMapping： 处理器映射器 负责根据请求找到Handler（处理器），springMVC中可以根据不同的映射器实现不同映射，比如 xml配置方式，注解方式，接口方式等 3.Handler：后端控制器 在前端控制器的控制下对具体的用户请求进行处理，所以一般情况下都需要开发者进行根据需求进行开发。 4.HandlerAdapter：处理器适配器 处理Handler，可以对多种类型的处理器进行执行，这是对适配器模式的应用体现。 5.ViewResolver : 视图解析器 负责将处理结果生成view视图、开发者可以根据需要开发**view** 入门程序（详细步骤）： 在理解了springMVC的工作流程后，下面我们根据流程步骤，来实现我们的入门程序，步骤如下： 1.导入我们的spring架包（一般去官网下载即可 4.2版本用的比较多） 2.在web.xml配置前端控制器 123456789&lt;servlet&gt;&lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;!-- 让servlet随服务启动 --&gt;&lt;servlet-mapping&gt;&lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;&lt;url-pattern&gt;*.action&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 这里说一下 我们的 四、拦截方式 拦截固定后缀名的URL ： 如 .action, .do 拦截所有：设置为/，但是该方法会导致静态文件（css,js.jpg）被拦截下来不能正常显示，所以该方式需要特殊处理 注意：不能设置拦截所有为/ 该方式是错误的，因为请求action时，当action跳转到jsp时会再次被拦截，*出现异常：根据jsp路径找不到映射地址 3.设置springmvc的配置文件 123456&lt;servlet&gt;&lt;init-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/springmvc.xml&lt;/param-value&gt;&lt;/init-param&gt;&lt;/servlet&gt; 4.开发处理器 1234567891011public class Hello implements Controller&#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; List list = new ArrayList&lt;&gt;(); list.add(\"one\"); list.add(\"two\"); ModelAndView mv = new ModelAndView(); mv.addObject(\"list\",list); return mv; &#125;&#125; 5．在springmvc.xml中配置 12345678910&lt;!-- 配置适配器 --&gt;&lt;bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\"&gt;&lt;/bean&gt;&lt;!-- 处理器映射器 --&gt;&lt;!-- 根据bean的 name 查找Handler , 将action的URL 配置在bean的name中--&gt;&lt;bean class=\"org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping\"&gt;&lt;/bean&gt;&lt;!-- 配置处理器 --&gt;&lt;bean name=\"/hello.action\" class=\"com.mt.controller.Hello\"&gt;&lt;/bean&gt;&lt;!-- 配置视图解析器 --&gt;&lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt;&lt;/bean&gt; 6.视图开发 ，jsp文件 12345678910111213&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;asdfadfadfa$&#123;list &#125;&lt;/body&gt;&lt;/html&gt; 测试结果： 开启服务器后， 发送 http://localhost:8080/SpringMVC/hello.action的请求 页面显示： img 对应理解springMVC 的流程即可。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lvshen9.gitee.io/tags/SpringMVC/"},{"name":"拦截器","slug":"拦截器","permalink":"http://lvshen9.gitee.io/tags/拦截器/"}]},{"title":"SQL语句优化问题","slug":"sql","date":"2017-08-24T00:23:35.000Z","updated":"2017-08-24T06:24:20.105Z","comments":true,"path":"2017/08/24/sql/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/24/sql/","excerpt":"​ 系统优化中一个很重要的方面就是SQL语句的优 化。对于海量数据，劣质SQL语句和优质SQL语句之间的速度差别可以达到上百倍，可见对于一个系统不是简单地能实现其功能就可，而是要写出高质量的 SQL语句，提高系统的可用性。 ​ 在多数情况下，Oracle使用索引来更快地遍历表，优化器主要根据定义的索引来提高性能。但是，如果在SQL语句的where子句中写的 SQL代码不合理，就会造成优化器删去索引而使用全表扫描，一般就这种SQL语句就是所谓的劣质SQL语句。在编写SQL语句时我们应清楚优化器根据何种 原则来删除索引，这有助于写出高性能的SQL语句。 一、造成索引失效的情况1.IS NULL 与 IS NOT NULL","text":"​ 系统优化中一个很重要的方面就是SQL语句的优 化。对于海量数据，劣质SQL语句和优质SQL语句之间的速度差别可以达到上百倍，可见对于一个系统不是简单地能实现其功能就可，而是要写出高质量的 SQL语句，提高系统的可用性。 ​ 在多数情况下，Oracle使用索引来更快地遍历表，优化器主要根据定义的索引来提高性能。但是，如果在SQL语句的where子句中写的 SQL代码不合理，就会造成优化器删去索引而使用全表扫描，一般就这种SQL语句就是所谓的劣质SQL语句。在编写SQL语句时我们应清楚优化器根据何种 原则来删除索引，这有助于写出高性能的SQL语句。 一、造成索引失效的情况1.IS NULL 与 IS NOT NULL ​ 不能用null作索引，任何包含null值的列都将不会被包含在索引中。即使索引有多列这样的情况下，只要这些列中有一列含有null，该列就会从索引中排除。也就是说如果某列存在空值，即使对该列建索引也不会提高性能。 ​ 任何在where子句中使用is null或is not null的语句优化器是不允许使用索引的。 2.联接列​ 对于有联接的列，即使最后的联接值为一个静态值，优化器是不会使用索引的。我们一起来看一个例子，假定有一个职工表(employee)，对于 一个职工的姓和名分成两列存放(FIRST_NAME和LAST_NAME)，现在要查询一个叫比尔.克林顿(Bill Cliton)的职工。 ​ 下面是一个采用联接查询的SQL语句: 1select * from employss where first_name || last_name = ’Beill Cliton'; ​ 上面这条语句完全可以查询出是否有Bill Cliton这个员工，但是这里需要注意，系统优化器对基于last_name创建的索引没有使用。 ​ 当采用下面这种SQL语句的编写，Oracle系统就可以采用基于last_name创建的索引。 1where first_name =’Beill’ and last_name = ’Cliton'; 3.带通配符(%)的like语句​ 同样以上面的例子来看这种情况。目前的需求是这样的，要求在职工表中查询名字中包含cliton的人。可以采用如下的查询SQL语句: 1select * from employee where last_name like ‘%cliton%'; ​ 这里由于通配符(%)在搜寻词首出现，所以Oracle系统不使用last_name的索引。在很多情况下可能无法避免这种情况，但是一定要心中有底，通 配符如此使用会降低查询速度。然而当通配符出现在字符串其他位置时，优化器就能利用索引。在下面的查询中索引得到了使用: 1select * from employee where last_name like ‘c%'; 4.Order by语句​ 仔细检查order by语句以找出非索引项或者表达式，它们会降低性能。解决这个问题的办法就是重写orderby语句以使用索引，也可以为所使用的列建立另外一个索引，同时应绝对避免在order by子句中使用表达式。 5.NOT列子: 1… where not (status =’VALID’) ​ 如果要使用NOT，则应在取反的短语前面加上括号，并在短语前面加上NOT运算符。NOT运算符包含在另外一个逻辑运算符中，这就是不等于(&lt;&gt;)运算符。换句话说，即使不在查询where子句中显式地加入NOT词，NOT仍在运算符中，见下： 1… where status &lt;&gt;’INVALID'; 对这个查询，可以改写为不使用NOT，例如: 1select * from employee where salary&lt;3000 or salary&gt;3000; ​ 虽然这两种查询的结果一样，但是第二种查询方案会比第一种查询方案更快些。第二种查询允许Oracle对salary列使用索引，而第一种查询则不能使用索引。 二、SQL语句优化总结笔记（1） 选择最有效率的表名顺序(只在基于规则的优化器中有效)： ​ ORACLE 的解析器按照从右到左的顺序处理FROM子句中的表名，FROM子句中写在最后的表(基础表 driving table)将被最先处理，在FROM子句中包含多个表的情况下，你必须选择记录条数最少的表作为基础表。如果有3个以上的表连接查询, 那就需要选择交叉表(intersection table)作为基础表, 交叉表是指那个被其他表所引用的表。 （2）WHERE子句中的连接顺序．： ​ ORACLE采用自下而上的顺序解析WHERE子句，根据这个原理,表之间的连接必须写在其他WHERE条件之前， 那些可以过滤掉最大数量记录的条件必须写在WHERE子句的末尾。 （3）SELECT子句中避免使用 ‘ * ‘： ​ ORACLE在解析的过程中，会将’*’ 依次转换成所有的列名，这个工作是通过查询数据字典完成的，这意味着将耗费更多的时间。 （4） 删除重复记录： 最高效的删除重复记录方法 ( 因为使用了ROWID)例子： 123DELETE FROM EMP E WHERE E.ROWID &gt; (SELECT MIN(X.ROWID)FROM EMP X WHERE X.EMP_NO = E.EMP_NO); （5）用TRUNCATE替代DELETE： ​ 当删除表中的记录时，在通常情况下， 回滚段(rollback segments ) 用来存放可以被恢复的信息。 如果你没有COMMIT事务，ORACLE会将数据恢复到删除之前的状态(准确地说是恢复到执行删除命令之前的状况) 而当运用TRUNCATE时， 回滚段不再存放任何可被恢复的信息，当命令运行后,数据不能被恢复。因此很少的资源被调用，执行时间也会很短。(译者按:TRUNCATE只在删除全表适用，TRUNCATE是DDL不是DML)。 （6） 用Where子句替换HAVING子句： ​ 避免使用HAVING子句, HAVING 只会在检索出所有记录之后才对结果集进行过滤. 这个处理需要排序,总计等操作. 如果能通过WHERE子句限制记录的数目,那就能减少这方面的开销. (非oracle中)on、where、having这三个都可以加条件的子句中，on是最先执行，where次之，having最后，因为on是先把不 符合条件的记录过滤后才进行统计，它就可以减少中间运算要处理的数据，按理说应该速度是最快的，where也应该比having快点的，因为它过滤数据后 才进行sum，在两个表联接时才用on的，所以在一个表的时候，就剩下where跟having比较了。在这单表查询统计的情况下，如果要过滤的条件没有涉及到要计算字段，那它们的结果是一样的，只是where可以使用rushmore技术，而having就不能，在速度上后者要慢如果要涉及到计算的字 段，就表示在没计算之前，这个字段的值是不确定的，根据上篇写的工作流程，where的作用时间是在计算之前就完成的，而having就是在计算后才起作用的，所以在这种情况下，两者的结果会不同。在多表联接查询时，on比where更早起作用。系统首先根据各个表之间的联接条件，把多个表合成一个临时表后，再由where进行过滤，然后再计算，计算完后再由having进行过滤。由此可见，要想过滤条件起到正确的作用，首先要明白这个条件应该在什么时候起作用，然后再决定放在那里。 （7） 使用表的别名(Alias)： 当在SQL语句中连接多个表时， 请使用表的别名并把别名前缀于每个Column上.这样一来，就可以减少解析的时间并减少那些由Column歧义引起的语法错误。 （8） 用EXISTS替代IN、用NOT EXISTS替代NOTIN： ​ 在许多基于基础表的查询中,为了满足一个条件,往往需要对另一个表进行联接.在这种情况下, 使用EXISTS(或NOT EXISTS)通常将提高查询的效率. 在子查询中,NOT IN子句将执行一个内部的排序和合并. 无论在哪种情况下,NOT IN都是最低效的 (因为它对子查询中的表执行了一个全表遍历). 为了避免使用NOT IN ,我们可以把它改写成外连接(Outer Joins)或NOT EXISTS. 例子： 1（高效）SELECT* FROM EMP (基础表) WHERE EMPNO &gt;0 AND EXISTS (SELECT ‘X’ FROM DEPT WHERE DEPT.DEPTNO= EMP.DEPTNO AND LOC = ‘MELB’) 1(低效)SELECT * FROM EMP (基础表) WHERE EMPNO &gt; 0 AND DEPTNO IN(SELECT DEPTNO FROM DEPT WHERE LOC = ‘MELB’) （9） 用索引提高效率： 索引是表的一个概念部分，用来提高检索数据的效率，ORACLE使用了一个复杂的自平衡B-tree结构。 通常,通过索引查询数据比全表扫描要快。当ORACLE找出执行查询和Update语句的最佳路径时， ORACLE优化器将使用索引。 同样在联结多个表时使用索引也可以提高效率。 另一个使用索引的好处是,它提供了主键(primarykey)的唯一性验证。那些LONG或LONG RAW数据类型， 你可以索引几乎所有的列。 通常, 在大型表中使用索引特别有效。当然，你也会发现，在扫描小表时，使用索引同样能提高效率。 虽然使用索引能得到查询效率的提高，但是我们也必须注意到它的代价。 索引需要空间来存储,也需要定期维护，每当有记录在表中增减或索引列被修改时， 索引本身也会被修改。这意味着每条记录的INSERT , DELETE , UPDATE将为此多付出4 , 5 次的磁盘I/O 。 因为索引需要额外的存储空间和处理,那些不必要的索引反而会使查询反应时间变慢。定期的重构索引是有必要的： 1ALTER INDEX &lt;INDEXNAME&gt; REBUILD &lt;TABLESPACENAME&gt; （10） 用EXISTS替换DISTINCT： ​ 当提交一个包含一对多表信息(比如部门表和雇员表)的查询时,避免在SELECT子句中使用DISTINCT。 一般可以考虑用EXIST替换，EXISTS 使查询更为迅速,因为RDBMS核心模块将在子查询的条件一旦满足后，立刻返回结果。 例子： 12345 (低效):SELECT DISTINCT DEPT_NO,DEPT_NAME FROM DEPT D , EMP EWHERE D.DEPT_NO = E.DEPT_NO; 12345(高效):SELECT DEPT_NO,DEPT_NAME FROM DEPT D WHERE EXISTS ( SELECT ‘X’FROM EMP E WHERE E.DEPT_NO = D.DEPT_NO); ​ 关于sql的优化先写到这里，sql的优化可以说是深不见底，根具不同的环境，所做的优化处理也不同，本人能力有限，暂时想到这么多。如果后续又想到的会继续添加。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://lvshen9.gitee.io/tags/sql/"},{"name":"Oracle","slug":"Oracle","permalink":"http://lvshen9.gitee.io/tags/Oracle/"}]},{"title":"HashMap的底层实现","slug":"hashmap","date":"2017-08-22T09:02:00.000Z","updated":"2017-08-22T09:24:26.164Z","comments":true,"path":"2017/08/22/hashmap/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/22/hashmap/","excerpt":"一、什么是HashMap?​ 在讨论HashMap的底层之前，我们必须明白什么是HashMap，HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 二、HashMap的数据结构​ 在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 如图所示:","text":"一、什么是HashMap?​ 在讨论HashMap的底层之前，我们必须明白什么是HashMap，HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 二、HashMap的数据结构​ 在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 如图所示: img 从上图中可以看出，HashMap底层就是一个数组结构，数组中的每一项又是一个链表。当新建一个HashMap的时候，就会初始化一个数组。 分析相关源码: 1234567891011121. /** 2. * The table, resized as necessary. Length MUST Always be a power of two. 3. */ 4. transient Entry[] table; 5. 6. static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; 7. final K key; 8. V value; 9. Entry&lt;K,V&gt; next; 10. final int hash; 11. …… 12. &#125; ​ 可以看出，Entry就是数组中的元素，每个 Map.Entry 其实就是一个key-value对，它持有一个指向下一个元素的引用，这就构成了链表。 ​ 三、HashMap的存取实现 1) 存储： 123456789101112131415161718192021222324251. public V put(K key, V value) &#123; 2. // HashMap允许存放null键和null值。 3. // 当key为null时，调用putForNullKey方法，将value放置在数组第一个位置。 4. if (key == null) 5. return putForNullKey(value); 6. // 根据key的keyCode重新计算hash值。 7. int hash = hash(key.hashCode()); 8. // 搜索指定hash值在对应table中的索引。 9. int i = indexFor(hash, table.length); 10. // 如果 i 索引处的 Entry 不为 null，通过循环不断遍历 e 元素的下一个元素。 11. for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; 12. Object k; 13. if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; 14. V oldValue = e.value; 15. e.value = value; 16. e.recordAccess(this); 17. return oldValue; 18. &#125; 19. &#125; 20. // 如果i索引处的Entry为null，表明此处还没有Entry。 21. modCount++; 22. // 将key、value添加到i索引处。 23. addEntry(hash, key, value, i); 24. return null; 25. &#125; ​ ​ 从上面的源代码中可以看出：当我们往HashMap中put元素的时候，先根据key的hashCode重新计算hash值，根据hash值得到这个元素在数组中的位置（即下标），如果数组该位置上已经存放有其他元素了，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。如果数组该位置上没有元素，就直接将该元素放到此数组中的该位置上。 ​ addEntry(hash, key, value, i)方法根据计算出的hash值，将key-value对放在数组table的i索引处。addEntry 是HashMap 提供的一个包访问权限的方法，代码如下： 123456789101. void addEntry(int hash, K key, V value, int bucketIndex) &#123; 2. // 获取指定 bucketIndex 索引处的 Entry 3. Entry&lt;K,V&gt; e = table[bucketIndex]; 4. // 将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry 5. table[bucketIndex] = new Entry&lt;K,V&gt;(hash, key, value, e); 6. // 如果 Map 中的 key-value 对的数量超过了极限 7. if (size++ &gt;= threshold) 8. // 把 table 对象的长度扩充到原来的2倍。 9. resize(2 * table.length); 10. &#125; ​ ​ 当系统决定存储HashMap中的key-value对时，完全没有考虑Entry中的value，仅仅只是根据key来计算并决定每个Entry的存储位置。我们完全可以把 Map 集合中的 value 当成 key 的附属，当系统决定了 key 的存储位置之后，value 随之保存在那里即可。 ​ hash(int h)方法根据key的hashCode重新计算一次散列。此算法加入了高位计算，防止低位不变，高位变化时，造成的hash冲突。 2) 读取： 123456789101112131. public V get(Object key) &#123; 2. if (key == null) 3. return getForNullKey(); 4. int hash = hash(key.hashCode()); 5. for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; 6. e != null; 7. e = e.next) &#123; 8. Object k; 9. if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) 10. return e.value; 11. &#125; 12. return null; 13. &#125; ​ ​ 有了上面存储时的hash算法作为基础，理解起来这段代码就很容易了。从上面的源代码中可以看出：从HashMap中get元素时，首先计算key的hashCode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。 ​ 归纳起来简单地说，HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 四、HashMap的性能参数：HashMap 包含如下几个构造器： HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。 HashMap(int initialCapacity)：构建一个初始容量为 initialCapacity，负载因子为 0.75 的 HashMap。 HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。 HashMap的基础构造器HashMap(int initialCapacity, float loadFactor)带有两个参数，它们是初始容量initialCapacity和加载因子loadFactor。 initialCapacity：HashMap的最大容量，即为底层数组的长度。 loadFactor：负载因子loadFactor定义为：散列表的实际元素数目(n)/ 散列表的容量(m)。 ​ 负载因子衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://lvshen9.gitee.io/tags/HashMap/"},{"name":"数组","slug":"数组","permalink":"http://lvshen9.gitee.io/tags/数组/"}]},{"title":"搜索引擎选择:Elasticsearch与Solr","slug":"my-first-blog","date":"2017-08-22T02:46:44.000Z","updated":"2017-08-22T02:57:58.821Z","comments":true,"path":"2017/08/22/my-first-blog/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/22/my-first-blog/","excerpt":"Elasticsearch简介Elasticsearch是一个实时的分布式搜索和分析引擎。它可以帮助你用前所未有的速度去处理大规模数据。 它可以用于全文搜索，结构化搜索以及分析，当然你也可以将这三者进行组合。 Elasticsearch是一个建立在全文搜索引擎 Apache Lucene™ 基础上的搜索引擎，可以说Lucene是当今最先进，最高效的全功能开源搜索引擎框架。","text":"Elasticsearch简介Elasticsearch是一个实时的分布式搜索和分析引擎。它可以帮助你用前所未有的速度去处理大规模数据。 它可以用于全文搜索，结构化搜索以及分析，当然你也可以将这三者进行组合。 Elasticsearch是一个建立在全文搜索引擎 Apache Lucene™ 基础上的搜索引擎，可以说Lucene是当今最先进，最高效的全功能开源搜索引擎框架。 但是Lucene只是一个框架，要充分利用它的功能，需要使用Java，并且在程序中集成Lucene。需要很多的学习了解，才能明白它是如何运行的，Lucene确实非常复杂。 Elasticsearch使用Lucene作为内部引擎，但是在使用它做全文搜索时，只需要使用统一开发好的API即可，而不需要了解其背后复杂的Lucene的运行原理。 当然Elasticsearch并不仅仅是Lucene这么简单，它不但包括了全文搜索功能，还可以进行以下工作: 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。 实时分析的分布式搜索引擎。 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。 这么多的功能被集成到一台服务器上，你可以轻松地通过客户端或者任何你喜欢的程序语言与ES的RESTful API进行交流。 Elasticsearch的上手是非常简单的。它附带了很多非常合理的默认值，这让初学者很好地避免一上手就要面对复杂的理论， 它安装好了就可以使用了，用很小的学习成本就可以变得很有生产力。 随着越学越深入，还可以利用Elasticsearch更多高级的功能，整个引擎可以很灵活地进行配置。可以根据自身需求来定制属于自己的Elasticsearch。 使用案例： 维基百科使用Elasticsearch来进行全文搜做并高亮显示关键词，以及提供search-as-you-type、did-you-mean等搜索建议功能。 英国卫报使用Elasticsearch来处理访客日志，以便能将公众对不同文章的反应实时地反馈给各位编辑。 StackOverflow将全文搜索与地理位置和相关信息进行结合，以提供more-like-this相关问题的展现。 GitHub使用Elasticsearch来检索超过1300亿行代码。 每天，Goldman Sachs使用它来处理5TB数据的索引，还有很多投行使用它来分析股票市场的变动。 但是Elasticsearch并不只是面向大型企业的，它还帮助了很多类似DataDog以及Klout的创业公司进行了功能的扩展。 Elasticsearch的优缺点优点 Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。 Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。 处理多租户（multitenancy）不需要特殊配置，而Solr则需要更多的高级设置。 Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。 各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。 缺点 只有一名开发者（当前Elasticsearch GitHub组织已经不只如此，已经有了相当活跃的维护者） 还不够自动（不适合当前新的Index Warmup API） Solr简介Solr（读作“solar”）是Apache Lucene项目的开源企业搜索平台。其主要功能包括全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及富文本（如Word、PDF）的处理。Solr是高度可扩展的，并提供了分布式搜索和索引复制。Solr是最流行的企业级搜索引擎，Solr4 还增加了NoSQL支持。 Solr是用Java编写、运行在Servlet容器（如 Apache Tomcat 或Jetty）的一个独立的全文搜索服务器。 Solr采用了 Lucene Java 搜索库为核心的全文索引和搜索，并具有类似REST的HTTP/XML和JSON的API。Solr强大的外部配置功能使得无需进行Java编码，便可对其进行调整以适应多种类型的应用程序。Solr有一个插件架构，以支持更多的高级定制。 因为2010年 Apache Lucene 和 Apache Solr 项目合并，两个项目是由同一个Apache软件基金会开发团队制作实现的。提到技术或产品时，Lucene/Solr或Solr/Lucene是一样的。 Solr的优缺点优点 Solr有一个更大、更成熟的用户、开发和贡献者社区。 支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。 Solr比较成熟、稳定。 不考虑建索引的同时进行搜索，速度更快。 缺点 建立索引时，搜索效率下降，实时索引搜索效率不高。 Elasticsearch与Solr的比较*当单纯的对已有数据进行搜索时，Solr更快。 Search Fesh Index While Idle 当实时建立索引时, Solr会产生io阻塞，查询性能较差, Elasticsearch具有明显的优势。 search_fresh_index_while_indexing 随着数据量的增加，Solr的搜索效率会变得更低，而Elasticsearch却没有明显的变化。 search_fresh_index_while_indexing 综上所述，Solr的架构不适合实时搜索的应用。 实际生产环境测试*下图为将搜索引擎从Solr转到Elasticsearch以后的平均查询速度有了50倍的提升。 average_execution_time Elasticsearch 与 Solr 的比较总结 二者安装都很简单； Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能; Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式； Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供； Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。 Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。 其他基于Lucene的开源搜索引擎解决方案 直接使用 Lucene 说明：Lucene 是一个 JAVA 搜索类库，它本身并不是一个完整的解决方案，需要额外的开发工作。 优点：成熟的解决方案，有很多的成功案例。apache 顶级项目，正在持续快速的进步。庞大而活跃的开发社区，大量的开发人员。它只是一个类库，有足够的定制和优化空间：经过简单定制，就可以满足绝大部分常见的需求；经过优化，可以支持 10亿+ 量级的搜索。 缺点：需要额外的开发工作。所有的扩展，分布式，可靠性等都需要自己实现；非实时，从建索引到可以搜索中间有一个时间延迟，而当前的“近实时”(Lucene Near Real Time search)搜索方案的可扩展性有待进一步完善 Katta 说明：基于 Lucene 的，支持分布式，可扩展，具有容错功能，准实时的搜索方案。 优点：开箱即用，可以与 Hadoop 配合实现分布式。具备扩展和容错机制。 缺点：只是搜索方案，建索引部分还是需要自己实现。在搜索功能上，只实现了最基本的需求。成功案例较少，项目的成熟度稍微差一些。因为需要支持分布式，对于一些复杂的查询需求，定制的难度会比较大。 Hadoop contrib/index 说明：Map/Reduce 模式的，分布式建索引方案，可以跟 Katta 配合使用。 优点：分布式建索引，具备可扩展性。 缺点：只是建索引方案，不包括搜索实现。工作在批处理模式，对实时搜索的支持不佳。 LinkedIn 的开源方案 说明：基于 Lucene 的一系列解决方案，包括 准实时搜索 zoie ，facet 搜索实现 bobo ，机器学习算法 decomposer ，摘要存储库 krati ，数据库模式包装 sensei 等等 优点：经过验证的解决方案，支持分布式，可扩展，丰富的功能实现 缺点：与 linkedin 公司的联系太紧密，可定制性比较差 Lucandra 说明：基于 Lucene，索引存在 cassandra 数据库中 优点：参考 cassandra 的优点 缺点：参考 cassandra 的缺点。另外，这只是一个 demo，没有经过大量验证 HBasene 说明：基于 Lucene，索引存在 Hbase 数据库中 优点：参考 hbase 的优点 缺点：参考 HBase 的缺点。另外，在实现中，lucene terms 是存成行，但每个 term 对应的 posting lists 是以列的方式存储的。随着单个 term 的 posting lists 的增大，查询时的速度受到的影响会非常大","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://lvshen9.gitee.io/tags/Elasticsearch/"},{"name":"搜索","slug":"搜索","permalink":"http://lvshen9.gitee.io/tags/搜索/"}]},{"title":"如何使用Hexo","slug":"hello-world","date":"2017-08-22T01:27:57.174Z","updated":"2017-08-22T02:57:04.781Z","comments":true,"path":"2017/08/22/hello-world/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/22/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"技术","slug":"技术","permalink":"http://lvshen9.gitee.io/categories/技术/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://lvshen9.gitee.io/tags/hexo/"}]},{"title":"Stephen Hawking launches Centre for the Future of Intelligence","slug":"Test","date":"2017-08-12T02:40:32.000Z","updated":"2017-08-28T02:46:47.919Z","comments":true,"path":"2017/08/12/Test/","link":"","permalink":"http://lvshen9.gitee.io/2017/08/12/Test/","excerpt":"这是一篇用于测试的文章 Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. Stephen Hawkingwww.cam.ac.uk Artificial intelligence has the power to eradicate poverty and disease or hasten the end of human civilisation as we know it – according to a speech delivered by Professor Stephen Hawking this evening. Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. “Success in creating AI could be the biggest event in the history of our civilisation,” said Professor Hawking. “But it could also be the last – unless we learn how to avoid the risks. Alongside the benefits, AI will also bring dangers like powerful autonomous weapons or new ways for the few to oppress the many. “We cannot predict what we might achieve when our own minds are amplified by AI. Perhaps with the tools of this new technological revolution, we will be able to undo some of the damage done to the natural world by the last one – industrialisation.” The Centre for the Future of Intelligence will initially focus on seven distinct projects in the first three-year phase of its work, reaching out to brilliant researchers and connecting them and their ideas to the challenges of making the best of AI. Among the initial research topics are: ‘Science, value and the future of intelligence’; ‘Policy and responsible innovation’; ‘Autonomous weapons – prospects for regulation’ and ‘Trust and transparency’.","text":"这是一篇用于测试的文章 Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. Stephen Hawkingwww.cam.ac.uk Artificial intelligence has the power to eradicate poverty and disease or hasten the end of human civilisation as we know it – according to a speech delivered by Professor Stephen Hawking this evening. Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. “Success in creating AI could be the biggest event in the history of our civilisation,” said Professor Hawking. “But it could also be the last – unless we learn how to avoid the risks. Alongside the benefits, AI will also bring dangers like powerful autonomous weapons or new ways for the few to oppress the many. “We cannot predict what we might achieve when our own minds are amplified by AI. Perhaps with the tools of this new technological revolution, we will be able to undo some of the damage done to the natural world by the last one – industrialisation.” The Centre for the Future of Intelligence will initially focus on seven distinct projects in the first three-year phase of its work, reaching out to brilliant researchers and connecting them and their ideas to the challenges of making the best of AI. Among the initial research topics are: ‘Science, value and the future of intelligence’; ‘Policy and responsible innovation’; ‘Autonomous weapons – prospects for regulation’ and ‘Trust and transparency’. The Academic Director of the Centre, and Bertrand Russell Professor of Philosophy at Cambridge, Huw Price, said: “The creation of machine intelligence is likely to be a once-in-a-planet’s-lifetime event. It is a future we humans face together. Our aim is to build a broad community with the expertise and sense of common purpose to make this future the best it can be.” Many researchers now take seriously the possibility that intelligence equal to our own will be created in computers within this century. Freed of biological constraints, such as limited memory and slow biochemical processing speeds, machines may eventually become more intelligent than we are – with profound implications for us all. AI pioneer Professor Maggie Boden (University of Sussex) sits on the Centre’s advisory board and spoke at this evening’s launch. She said: “AI is hugely exciting. Its practical applications can help us to tackle important social problems, as well as easing many tasks in everyday life. And it has advanced the sciences of mind and life in fundamental ways. But it has limitations, which present grave dangers given uncritical use. CFI aims to pre-empt these dangers, by guiding AI development in human-friendly ways.” “Recent landmarks such as self-driving cars or a computer game winning at the game of Go, are signs of what’s to come,” added Professor Hawking. “The rise of powerful AI will either be the best or the worst thing ever to happen to humanity. We do not yet know which. The research done by this centre is crucial to the future of our civilisation and of our species.” Transcript of Professor Hawking’s speech at the launch of the Leverhulme Centre for the Future of Intelligence, October 19, 2016 “It is a great pleasure to be here today to open this new Centre. We spend a great deal of time studying history, which, let’s face it, is mostly the history of stupidity. So it is a welcome change that people are studying instead the future of intelligence. Intelligence is central to what it means to be human. Everything that our civilisation has achieved, is a product of human intelligence, from learning to master fire, to learning to grow food, to understanding the cosmos. I believe there is no deep difference between what can be achieved by a biological brain and what can be achieved by a computer. It therefore follows that computers can, in theory, emulate human intelligence — and exceed it. Artificial intelligence research is now progressing rapidly. Recent landmarks such as self-driving cars, or a computer winning at the game of Go, are signs of what is to come. Enormous levels of investment are pouring into this technology. The achievements we have seen so far will surely pale against what the coming decades will bring. The potential benefits of creating intelligence are huge. We cannot predict what we might achieve, when our own minds are amplified by AI. Perhaps with the tools of this new technological revolution, we will be able to undo some of the damage done to the natural world by the last one — industrialisation. And surely we will aim to finally eradicate disease and poverty. Every aspect of our lives will be transformed. In short, success in creating AI, could be the biggest event in the history of our civilisation. But it could also be the last, unless we learn how to avoid the risks. Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. It will bring great disruption to our economy. And in the future, AI could develop a will of its own — a will that is in conflict with ours. In short, the rise of powerful AI will be either the best, or the worst thing, ever to happen to humanity. We do not yet know which. That is why in 2014, I and a few others called for more research to be done in this area. I am very glad that someone was listening to me! The research done by this centre is crucial to the future of our civilisation and of our species. I wish you the best of luck!” 以下为霍金演讲全文的中文版：今天，非常荣幸来来这里参加新中心的开启仪式。 我们花了大把的时间研究历史，让我们来直面这部历史，这近乎是部愚昧的历史。所以，人们现在转而研究未来的智慧了，这种转变将备受欢迎。 对人类而言，智慧是存在的核心所在。一切文明，皆是智慧的产物。从学会用火，到学会耕种，到理解宇宙。 我相信，生物的大脑所获得的智慧，与计算机所能获得的智慧，并无本质区别。因此，理论上，计算机可以模拟人类智慧，并超越它。 现在人工智能的研究日新月异。最新的标志性成果，比如自动驾驶汽车、阿尔法狗战胜围棋世界高手，预示着即将到来新的时代。大小额投资纷纷倾注于这个领域。我们迄今为止所见到的成就，在新时代面前，即将黯然失色。 人工智能的带来的益处是巨大的。我们无法预测，当人类心智被人工智能扩展时，我们会取得哪些成就。也许，有了这个技术革命的新工具，我们能够有能力弥补一些由工业化对自然界造成的破坏。当然，我们希望能够最终消灭疾病和贫穷。我们生活的方方面面都会被变化。简而言之，人工智能的成功创造，可以说是人类文明史上最大的事件。 但是，它也可能是人类文明史的终结，除非我们学会如何避免它所带来的危害。人工智能在带来益处的同时，也带来危险，比如强大的自动武器，或少数人欺压多数人的新方法。它也可能给我们的经济带来巨大的破坏。将来，人工智能可能会发展出来它自己的意志——一个与人类相冲突的意志。 总之，人工智能的强力崛起，在人类历史上，可能是最好的，也可能是最糟糕的。而我们尚且不知道会是哪一个。这是为什么在2014年，我和其它几个人呼吁在这个领域进行更多研究。令我欣慰的是，有人听到了我的呼声！","categories":[{"name":"AI","slug":"AI","permalink":"http://lvshen9.gitee.io/categories/AI/"}],"tags":[{"name":"Test","slug":"Test","permalink":"http://lvshen9.gitee.io/tags/Test/"}]}]}